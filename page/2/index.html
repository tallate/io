<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/page/2/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/page/2/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f89cb603.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f89cb603.html" itemprop="url">红黑树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-21T19:48:41+08:00">
                2020-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>二叉树、平衡树、AVL 树和红黑树</h1>
<p>二叉树是一类特殊的树形结构，其他类似的还有三叉树、B 树、B+树等，二叉树的特征是 1 对 2，即每个节点都有 2 个子节点（这里认为空节点也算子节点）。</p>
<blockquote>
<p>这么定义主要是为了避免将二叉树的实现局限于指针，实际上我们也可以使用数组来实现二叉树，也就是二叉堆。</p>
</blockquote>
<p>二叉树所有操作的时间复杂度为<code>O(logN)</code>，但是它存在的主要问题是不稳定，比如数据是从小到大依次插入的情况下，最终结果是得到一条斜线，这时二叉树会退化为链表。<br>
平衡树的特点是在每次写入操作后会进行一次重平衡，让树的高度保持在<code>O(logN)</code>。<br>
AVL 树是平衡树的一种，它严格保证树的高度为<code>O(logN)</code>，每次都会根据高度重平衡，其缺点是过于严格，会导致旋转操作占用比较多的时间。<br>
红黑树作为 AVL 树的一种替代，通过红黑规则控制树的旋转，能以较少次旋转作为代价得到较为平衡的树。</p>
<blockquote>
<p>AVL 树严格保证树的高度在<code>[logN, logN + 1]</code>，红黑树理论上极端情况可以出现高度达到 2*logN，但是现实中很难遇到。</p>
</blockquote>
<h1>红黑树的起源 - 23树</h1>
<p><img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/23%E6%A0%91%E7%9A%84%E5%88%86%E8%A3%82.png" alt="23树的分裂" title="23树的分裂"><br>
23树并不是指3叉树，23树是一种平衡树，不过它维持平衡的方式并不是旋转，而是分裂，如上图所示：</p>
<ul>
<li>一个节点有至多3个元素，当达到3个元素后会发生分裂；</li>
<li>分裂后中间元素上移，与父节点合并。</li>
</ul>
<p>23树可以证明高度在<code>log3(N)=(lgN)/(lg3)</code>（如果都是3-nodes即2元素节点）到<code>lgN</code>（如果都是2-nodes即1元素节点），从而保证查询时顶多查<code>lgN</code>个节点。<br>
23树的缺点是实现的<strong>额外开销过大</strong>，比如要变更节点类型、比较是否相等时要比较节点中的所有元素值等，有时候23树的性能甚至不如普通的BST，因此<code>Sedgewick</code>之后便提出了红黑树。</p>
<h1>红黑树的定义</h1>
<p>红黑树是从23树演化而来的，它将原来2-3树中的3-nodes表示为使用红线连接的两个节点，因为每个节点只有一条线连上它，因此为了简单起见把颜色字段保存到节点里。<br>
<img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/23%E6%A0%91%E5%92%8C%E7%BA%A2%E9%BB%91%E6%A0%91.png" alt="23树和红黑树" title="23树和红黑树"><br>
红黑树的定义：</p>
<ol>
<li>Red links lean left. - 红色节点必须在左边</li>
<li>No node has two red links connected to it. - 3个红色节点不能连一起</li>
<li>The tree has perfect black balance: every path from the root to a null link has the same number of black links. - 红黑树是完美黑平衡的，从root沿任意路径到达叶节点的黑节点数量都是一样的。</li>
</ol>
<p>以上3个定义其实和2-3树的定义是一一对应的：</p>
<ol>
<li>和左红节点连一块可以看作2-3树中的一个3-node；</li>
<li>2-3树中一个节点中塞满3个元素后就会分裂；</li>
<li>把红黑树中节点和其左红子节点合并后，最终的树其实和2-3树等价。</li>
</ol>
<p>红黑树的<strong>红黑规则</strong>：</p>
<ol>
<li>任何一个节点都有颜色，黑色或者红色；</li>
<li>根节点是黑色的；</li>
<li>空节点（有些实现中叶节点是哨兵节点nil）被认为是黑色的。</li>
<li>父子节点之间不能出现两个连续的红节点（如果父节点是红色，则它的两个儿子都是黑色）；</li>
<li>任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等；</li>
</ol>
<h1>红黑树操作 - 查询</h1>
<p>红黑树的查询就是普通的二叉树查询。</p>
<h1>红黑树操作 - 旋转</h1>
<p>左旋操作将右子节点旋转到父节点位置，并改变二者的颜色。<br>
<img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%B7%A6%E6%97%8B.png" alt="红黑树左旋" title="红黑树左旋"><br>
右旋同理：<br>
<img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%8F%B3%E6%97%8B.png" alt="红黑树右旋" title="红黑树右旋"></p>
<h1>红黑树操作 - 插入</h1>
<p>红黑树的插入操作和 BST 差不多，只不过插入后可能会破坏上面红黑树的定义，因此需要做一些旋转和颜色修改操作来恢复。<br>
很多地方描述红黑树的方式并不一致，这里还是以《算法》中的实现为主。<br>
<img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E8%8A%82%E7%82%B9%E5%88%B0%E4%B8%80%E4%B8%AA3-node%E7%9A%843%E7%A7%8D%E6%83%85%E5%86%B5.png" alt="插入节点到一个3-node的3种情况" title="插入节点到一个3-node的3种情况"></p>
<ul>
<li>可以看到上面3种情况最终都转换成了一个三角形的形状，然后进行了颜色的翻转，实际上相当于2-3树中一个3元素节点分裂成了3个。</li>
</ul>
<p>下图是一个插入节点到红黑树中的例子，其中被红线连接的子节点是红色的节点：<br>
<img src="http://47.88.24.11/imgs/%E7%AE%97%E6%B3%95/%E7%BA%A2%E9%BB%91%E6%A0%91%E8%8A%82%E7%82%B9%E6%8F%92%E5%85%A5%E8%BD%A8%E8%BF%B9.png" alt="红黑树节点插入轨迹" title="红黑树节点插入轨迹"></p>
<h1>红黑树操作 - 删除</h1>
<h1>参考</h1>
<ol>
<li>《Algorithms》 - Robert_Sedgewick<br>
红黑树原来是从23树演化而来，之前以为是凭空编出来的。</li>
<li><a href="https://algs4.cs.princeton.edu/33balanced/RedBlackBST.java.html" target="_blank" rel="noopener">《Algorithms》中的红黑树实现</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b5a259aa.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b5a259aa.html" itemprop="url">QMQ 总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-16T20:52:48+08:00">
                2020-08-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1>总体架构</h1>
<p><img src="http://47.88.24.11/imgs/QMQ/QMQ-%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%91%E9%80%81%E5%92%8C%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B.png" alt="QMQ-消息的发送和消费流程" title="QMQ-消息的发送和消费流程"></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/b5a259aa.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/3648b215.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/3648b215.html" itemprop="url">RocketMQ 的应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-12T12:21:48+08:00">
                2020-08-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.6k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>为什么使用RocketMQ</h1>
<h2 id="使用mq的优点"><a class="header-anchor" href="#使用mq的优点">¶</a>使用MQ的优点</h2>
<ol>
<li>解耦<br>
直连的情况下，每接入一个系统就需要直接改代码调新系统接口；<br>
使用 RocketMQ 的情况下，新系统可以自己监听消息。</li>
<li>异步<br>
非必要的业务逻辑异步处理，加快响应速度。</li>
<li>削峰<br>
直连的情况下，所有请求会直接全部打到下游服务，引入消息队列后，消息队列可以暂存消息，让下游服务慢慢消费；</li>
</ol>
<h2 id="使用-mq-的缺点"><a class="header-anchor" href="#使用-mq-的缺点">¶</a>使用 MQ 的缺点</h2>
<p>系统可用性降低：消息队列挂掉将影响系统可用性。<br>
系统复杂性增加：加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，系统复杂性增大。</p>
<h1>使用 RocketMQ</h1>
<h2 id="搭建-name-server-和-broker-server"><a class="header-anchor" href="#搭建-name-server-和-broker-server">¶</a>搭建 Name Server 和 Broker Server</h2>
<p><img src="http://rocketmq.apache.org/docs/quick-start/" alt=""><br>
为了方便，需要设置 Broker 服务器的一些属性，在 broker.conf 中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 允许使用SQL语法过滤消息</span><br><span class="line">enablePropertyFilter=true</span><br><span class="line"># 自动创建Topic，否则使用新Topic时还需要在控制台创建</span><br><span class="line">autoCreateTopicEnable=true</span><br></pre></td></tr></table></figure>
<p>对 Broker 服务器的启动可以使用下面的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start mqbroker.cmd -n 127.0.0.1:9876 -c ../conf/broker.conf &amp;</span><br></pre></td></tr></table></figure>
<h2 id="消息的生成和消费"><a class="header-anchor" href="#消息的生成和消费">¶</a>消息的生成和消费</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<p>消息生产：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">public class ProducerTest &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 同步消息</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void sendSyncMsg() throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            // 创建消息，并指定Topic，Tag和消息体</span><br><span class="line">            Message msg = new Message(&quot;TopicTest&quot;,</span><br><span class="line">                    &quot;TagA&quot;,</span><br><span class="line">                    (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)</span><br><span class="line">            );</span><br><span class="line">            // 发送消息到一个Broker</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            // 通过sendResult返回消息是否成功送达</span><br><span class="line">            System.out.printf(&quot;%s%n&quot;, sendResult);</span><br><span class="line">        &#125;</span><br><span class="line">        // 如果不再发送消息，关闭Producer实例。</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 异步消息</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void sendAsyncMsg() throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        producer.setRetryTimesWhenSendAsyncFailed(0);</span><br><span class="line">        int messageCount = 100;</span><br><span class="line">        // 根据消息数量实例化倒计时计算器</span><br><span class="line">        final CountDownLatch2 countDownLatch = new CountDownLatch2(messageCount);</span><br><span class="line">        for (int i = 0; i &lt; messageCount; i++) &#123;</span><br><span class="line">            final int index = i;</span><br><span class="line">            // 创建消息，并指定Topic，Tag和消息体</span><br><span class="line">            Message msg = new Message(&quot;TopicTest&quot;,</span><br><span class="line">                    &quot;TagA&quot;,</span><br><span class="line">                    &quot;OrderID188&quot;,</span><br><span class="line">                    &quot;Hello world&quot;.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">            // SendCallback接收异步返回结果的回调</span><br><span class="line">            producer.send(msg, new SendCallback() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onSuccess(SendResult sendResult) &#123;</span><br><span class="line">                    System.out.printf(&quot;%-10d OK %s %n&quot;, index,</span><br><span class="line">                            sendResult.getMsgId());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onException(Throwable e) &#123;</span><br><span class="line">                    System.out.printf(&quot;%-10d Exception %s %n&quot;, index, e);</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        // 等待5s</span><br><span class="line">        countDownLatch.await(5, TimeUnit.SECONDS);</span><br><span class="line">        // 如果不再发送消息，关闭Producer实例。</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 单向消息</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void testSendOnewayMsg() throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            // 创建消息，并指定Topic，Tag和消息体</span><br><span class="line">            Message msg = new Message(&quot;TopicTest&quot;,</span><br><span class="line">                    &quot;TagA&quot;,</span><br><span class="line">                    (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET)</span><br><span class="line">            );</span><br><span class="line">            // 发送单向消息，没有任何返回结果</span><br><span class="line">            producer.sendOneway(msg);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        // 如果不再发送消息，关闭Producer实例。</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息消费：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class ConsumerTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        // 实例化消费者</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line"></span><br><span class="line">        // 设置NameServer的地址</span><br><span class="line">        consumer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line"></span><br><span class="line">        // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息</span><br><span class="line">        consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);</span><br><span class="line">        // 注册回调实现类来处理从broker拉取回来的消息</span><br><span class="line">        consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&gt; &#123;</span><br><span class="line">            System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs);</span><br><span class="line">            // 标记该消息已经被成功消费</span><br><span class="line">            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;);</span><br><span class="line">        // 启动消费者实例</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(&quot;Consumer Started.%n&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="顺序消息"><a class="header-anchor" href="#顺序消息">¶</a>顺序消息</h2>
<p>发送：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">public class OrderedProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line"></span><br><span class="line">        producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line"></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagC&quot;, &quot;TagD&quot;&#125;;</span><br><span class="line"></span><br><span class="line">        // 订单列表</span><br><span class="line">        List&lt;OrderStep&gt; orderList = new OrderedProducer().buildOrders();</span><br><span class="line"></span><br><span class="line">        Date date = new Date();</span><br><span class="line">        SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class="line">        String dateStr = sdf.format(date);</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            // 加个时间前缀</span><br><span class="line">            String body = dateStr + &quot; Hello RocketMQ &quot; + orderList.get(i);</span><br><span class="line">            Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, body.getBytes());</span><br><span class="line"></span><br><span class="line">            SendResult sendResult = producer.send(msg, (mqs, msg1, arg) -&gt; &#123;</span><br><span class="line">                Long id = (Long) arg;  //根据订单id选择发送queue</span><br><span class="line">                long index = id % mqs.size();</span><br><span class="line">                return mqs.get((int) index);</span><br><span class="line">            &#125;, orderList.get(i).getOrderId());//订单id</span><br><span class="line"></span><br><span class="line">            System.out.println(String.format(&quot;SendResult status:%s, queueId:%d, body:%s&quot;,</span><br><span class="line">                    sendResult.getSendStatus(),</span><br><span class="line">                    sendResult.getMessageQueue().getQueueId(),</span><br><span class="line">                    body));</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 订单的步骤</span><br><span class="line">     */</span><br><span class="line">    private static class OrderStep &#123;</span><br><span class="line"></span><br><span class="line">        private long orderId;</span><br><span class="line">        private String desc;</span><br><span class="line"></span><br><span class="line">        public long getOrderId() &#123;</span><br><span class="line">            return orderId;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setOrderId(long orderId) &#123;</span><br><span class="line">            this.orderId = orderId;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public String getDesc() &#123;</span><br><span class="line">            return desc;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setDesc(String desc) &#123;</span><br><span class="line">            this.desc = desc;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public String toString() &#123;</span><br><span class="line">            return &quot;OrderStep&#123;&quot; +</span><br><span class="line">                    &quot;orderId=&quot; + orderId +</span><br><span class="line">                    &quot;, desc=&apos;&quot; + desc + &apos;\&apos;&apos; +</span><br><span class="line">                    &apos;&#125;&apos;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 生成模拟订单数据</span><br><span class="line">     */</span><br><span class="line">    private List&lt;OrderStep&gt; buildOrders() &#123;</span><br><span class="line">        List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;();</span><br><span class="line"></span><br><span class="line">        OrderStep orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111039L);</span><br><span class="line">        orderDemo.setDesc(&quot;创建&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111065L);</span><br><span class="line">        orderDemo.setDesc(&quot;创建&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111039L);</span><br><span class="line">        orderDemo.setDesc(&quot;付款&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103117235L);</span><br><span class="line">        orderDemo.setDesc(&quot;创建&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111065L);</span><br><span class="line">        orderDemo.setDesc(&quot;付款&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103117235L);</span><br><span class="line">        orderDemo.setDesc(&quot;付款&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111065L);</span><br><span class="line">        orderDemo.setDesc(&quot;完成&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111039L);</span><br><span class="line">        orderDemo.setDesc(&quot;推送&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103117235L);</span><br><span class="line">        orderDemo.setDesc(&quot;完成&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        orderDemo = new OrderStep();</span><br><span class="line">        orderDemo.setOrderId(15103111039L);</span><br><span class="line">        orderDemo.setDesc(&quot;完成&quot;);</span><br><span class="line">        orderList.add(orderDemo);</span><br><span class="line"></span><br><span class="line">        return orderList;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接收：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）</span><br><span class="line"> */</span><br><span class="line">public class OrderedConsumer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_3&quot;);</span><br><span class="line">        consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        /**</span><br><span class="line">         * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt;</span><br><span class="line">         * 如果非第一次启动，那么按照上次消费的位置继续消费</span><br><span class="line">         */</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line"></span><br><span class="line">        consumer.subscribe(&quot;TopicTest&quot;, &quot;TagA || TagC || TagD&quot;);</span><br><span class="line"></span><br><span class="line">        consumer.registerMessageListener(new MessageListenerOrderly() &#123;</span><br><span class="line"></span><br><span class="line">            Random random = new Random();</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123;</span><br><span class="line">                context.setAutoCommit(true);</span><br><span class="line">                for (MessageExt msg : msgs) &#123;</span><br><span class="line">                    // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序</span><br><span class="line">                    System.out.println(&quot;consumeThread=&quot; + Thread.currentThread().getName() + &quot; queueId=&quot; + msg.getQueueId() + &quot;, topic:&quot; + msg.getTopic() + &quot; content:&quot; + new String(msg.getBody()));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                try &#123;</span><br><span class="line">                    //模拟业务逻辑处理中...</span><br><span class="line">//                    TimeUnit.SECONDS.sleep(1);</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                return ConsumeOrderlyStatus.SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;Consumer Started.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="延时消息"><a class="header-anchor" href="#延时消息">¶</a>延时消息</h2>
<p>延时消息可以用于一些需要延迟处理业务的场景，比如下单后超过一定时间没支付就自动取消。<br>
发送：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class ScheduledProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        int totalMessagesToSend = 100;</span><br><span class="line">        for (int i = 0; i &lt; totalMessagesToSend; i++) &#123;</span><br><span class="line">            Message message = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());</span><br><span class="line">            // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)</span><br><span class="line">            message.setDelayTimeLevel(3);</span><br><span class="line">            producer.send(message);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接收：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class ScheduledConsumer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;ExampleConsumer&quot;);</span><br><span class="line">        consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);</span><br><span class="line">        consumer.registerMessageListener((MessageListenerConcurrently) (messages, context) -&gt; &#123;</span><br><span class="line">            for (MessageExt message : messages) &#123;</span><br><span class="line">                // Print approximate delay time period</span><br><span class="line">                System.out.println(&quot;Receive message[msgId=&quot; + message.getMsgId() + &quot;] &quot; + (System.currentTimeMillis() - message.getStoreTimestamp()) + &quot;ms later&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="批量消息"><a class="header-anchor" href="#批量消息">¶</a>批量消息</h2>
<p>批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的 topic，相同的 waitStoreMsgOK，而且不能是延时消息，此外，这一批消息的总大小不应超过 4MB。<br>
发送：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public class BatchProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        String topic = &quot;TopicTest&quot;;</span><br><span class="line">        List&lt;Message&gt; messages = new ArrayList&lt;&gt;();</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));</span><br><span class="line">        try &#123;</span><br><span class="line">            producer.send(messages);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接收逻辑并无不同：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class BatchConsumer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;ExampleConsumer&quot;);</span><br><span class="line">        consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);</span><br><span class="line">        consumer.registerMessageListener((MessageListenerConcurrently) (messages, context) -&gt; &#123;</span><br><span class="line">            for (MessageExt message : messages) &#123;</span><br><span class="line">                // Print approximate delay time period</span><br><span class="line">                System.out.println(&quot;Receive message[msgId=&quot; + message.getMsgId() + &quot;] &quot; + (System.currentTimeMillis() - message.getStoreTimestamp()) + &quot;ms later&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意我们上边提到的 4MB 的大小限制，如果消息列表中的消息变多了，很有可能会超过这个大小，这时最好对消息列表进行分割再发送：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class BatchProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        String topic = &quot;TopicTest&quot;;</span><br><span class="line">        List&lt;Message&gt; messages = new ArrayList&lt;&gt;();</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID001&quot;, &quot;Hello world 0&quot;.getBytes()));</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID002&quot;, &quot;Hello world 1&quot;.getBytes()));</span><br><span class="line">        messages.add(new Message(topic, &quot;TagA&quot;, &quot;OrderID003&quot;, &quot;Hello world 2&quot;.getBytes()));</span><br><span class="line">        try &#123;</span><br><span class="line">            splitSend(producer, messages);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static void splitSend(MQProducer producer, List&lt;Message&gt; messages) &#123;</span><br><span class="line">        //把大的消息分裂成若干个小的消息</span><br><span class="line">        ListSplitter splitter = new ListSplitter(messages);</span><br><span class="line">        while (splitter.hasNext()) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                List&lt;Message&gt; listItem = splitter.next();</span><br><span class="line">                producer.send(listItem);</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                //处理error</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">public class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private final int SIZE_LIMIT = 1024 * 1024 * 4;</span><br><span class="line">    private final List&lt;Message&gt; messages;</span><br><span class="line">    private int currIndex;</span><br><span class="line"></span><br><span class="line">    public ListSplitter(List&lt;Message&gt; messages) &#123;</span><br><span class="line">        this.messages = messages;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean hasNext() &#123;</span><br><span class="line">        return currIndex &lt; messages.size();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public List&lt;Message&gt; next() &#123;</span><br><span class="line">        int startIndex = getStartIndex();</span><br><span class="line">        int nextIndex = startIndex;</span><br><span class="line">        int totalSize = 0;</span><br><span class="line">        for (; nextIndex &lt; messages.size(); nextIndex++) &#123;</span><br><span class="line">            Message message = messages.get(nextIndex);</span><br><span class="line">            int tmpSize = calcMessageSize(message);</span><br><span class="line">            if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                totalSize += tmpSize;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;Message&gt; subList = messages.subList(startIndex, nextIndex);</span><br><span class="line">        currIndex = nextIndex;</span><br><span class="line">        return subList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private int getStartIndex() &#123;</span><br><span class="line">        Message currMessage = messages.get(currIndex);</span><br><span class="line">        int tmpSize = calcMessageSize(currMessage);</span><br><span class="line">        while (tmpSize &gt; SIZE_LIMIT) &#123;</span><br><span class="line">            currIndex += 1;</span><br><span class="line">            Message message = messages.get(currIndex);</span><br><span class="line">            tmpSize = calcMessageSize(message);</span><br><span class="line">        &#125;</span><br><span class="line">        return currIndex;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private int calcMessageSize(Message message) &#123;</span><br><span class="line">        int tmpSize = message.getTopic().length() + message.getBody().length;</span><br><span class="line">        Map&lt;String, String&gt; properties = message.getProperties();</span><br><span class="line">        for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123;</span><br><span class="line">            tmpSize += entry.getKey().length() + entry.getValue().length();</span><br><span class="line">        &#125;</span><br><span class="line">        tmpSize = tmpSize + 20; // 增加⽇日志的开销20字节</span><br><span class="line">        return tmpSize;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="消息订阅"><a class="header-anchor" href="#消息订阅">¶</a>消息订阅</h2>
<p>RocketMQ 支持用 SQL 语法的语句来“<strong>模糊</strong>”订阅消息，只有使用 push 模式的消费者才能用使用 SQL92 标准的 sql 语句，接口如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void subscribe(finalString topic, final MessageSelector messageSelector)</span><br></pre></td></tr></table></figure>
<ul>
<li>数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=；</li>
<li>字符比较，比如：=，&lt;&gt;，IN；</li>
<li>IS NULL 或者 IS NOT NULL；</li>
<li>逻辑符号 AND，OR，NOT；</li>
</ul>
<p>常量支持类型为：</p>
<ul>
<li>数值，比如：123，3.1415；</li>
<li>字符，比如：‘abc’，必须用单引号包裹起来；</li>
<li>NULL，特殊的常量</li>
<li>布尔值，TRUE 或 FALSE</li>
</ul>
<p>消息发送：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class TagProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, RemotingException, InterruptedException, MQBrokerException &#123;</span><br><span class="line">        DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        producer.start();</span><br><span class="line">        Message msg = new Message(&quot;TopicTest&quot;,</span><br><span class="line">                &quot;TagA&quot;,</span><br><span class="line">                (&quot;Hello RocketMQ&quot;).getBytes(RemotingHelper.DEFAULT_CHARSET)</span><br><span class="line">        );</span><br><span class="line">        // 设置一些属性</span><br><span class="line">        msg.putUserProperty(&quot;a&quot;, &quot;2&quot;);</span><br><span class="line">        SendResult sendResult = producer.send(msg);</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息消费：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class TagConsumer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;);</span><br><span class="line">        consumer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        // 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3</span><br><span class="line">        consumer.subscribe(&quot;TopicTest&quot;, MessageSelector.bySql(&quot;a between 0 and 3&quot;));</span><br><span class="line">        consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&gt; &#123;</span><br><span class="line">            System.out.println(new String(msgs.get(0).getBody()));</span><br><span class="line">            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="事务消息"><a class="header-anchor" href="#事务消息">¶</a>事务消息</h2>
<p>事务消息有3种状态：</p>
<ul>
<li>TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。</li>
<li>TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。</li>
<li>TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。</li>
</ul>
<p>发送事务消息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class TransactionProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException, InterruptedException &#123;</span><br><span class="line">        TransactionListener transactionListener = new TransactionListenerImpl();</span><br><span class="line">        TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        producer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2000), r -&gt; &#123;</span><br><span class="line">            Thread thread = new Thread(r);</span><br><span class="line">            thread.setName(&quot;client-transaction-msg-check-thread&quot;);</span><br><span class="line">            return thread;</span><br><span class="line">        &#125;);</span><br><span class="line">        producer.setExecutorService(executorService);</span><br><span class="line">        // 事务监听</span><br><span class="line">        producer.setTransactionListener(transactionListener);</span><br><span class="line">        producer.start();</span><br><span class="line">        String[] tags = new String[]&#123;&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;&#125;;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                Message msg =</span><br><span class="line">                        new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i,</span><br><span class="line">                                (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">                SendResult sendResult = producer.sendMessageInTransaction(msg, null);</span><br><span class="line">                System.out.printf(&quot;%s%n&quot;, sendResult);</span><br><span class="line">                Thread.sleep(10);</span><br><span class="line">            &#125; catch (MQClientException | UnsupportedEncodingException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        for (int i = 0; i &lt; 100000; i++) &#123;</span><br><span class="line">            Thread.sleep(1000);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现事务监听接口，在发送半消息成功后会触发<code>executeLocalTransaction</code>方法来执行本地事务，<code>checkLocalTransaction</code>用于检查本地事务状态，并回应消息队列的检查请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class TransactionListenerImpl implements TransactionListener &#123;</span><br><span class="line">  private AtomicInteger transactionIndex = new AtomicInteger(0);</span><br><span class="line">  private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;();</span><br><span class="line">  @Override</span><br><span class="line">  public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123;</span><br><span class="line">      int value = transactionIndex.getAndIncrement();</span><br><span class="line">      int status = value % 3;</span><br><span class="line">      localTrans.put(msg.getTransactionId(), status);</span><br><span class="line">      return LocalTransactionState.UNKNOW;</span><br><span class="line">  &#125;</span><br><span class="line">  @Override</span><br><span class="line">  public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123;</span><br><span class="line">      Integer status = localTrans.get(msg.getTransactionId());</span><br><span class="line">      if (null != status) &#123;</span><br><span class="line">          switch (status) &#123;</span><br><span class="line">              case 0:</span><br><span class="line">                  return LocalTransactionState.UNKNOW;</span><br><span class="line">              case 1:</span><br><span class="line">                  return LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">              case 2:</span><br><span class="line">                  return LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      return LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>事务消息使用上的限制：</p>
<ul>
<li>事务消息不支持延时消息和批量消息。</li>
<li>为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax 参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionalMessageCheckListener 类来修改这个行为。</li>
<li>事务消息将在 Broker 配置文件中的参数 transactionTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionTimeout 参数。</li>
<li>事务性消息可能不止一次被检查或消费。</li>
<li>提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。</li>
<li>事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ 服务器能通过它们的生产者 ID 查询到消费者。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e095c2f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/e095c2f.html" itemprop="url">RocketMQ 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-12T12:21:48+08:00">
                2020-08-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  11.7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  43 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>架构</h1>
<h2 id="概念"><a class="header-anchor" href="#概念">¶</a>概念</h2>
<ul>
<li>groupName：一个 group 可能包含多个主机，生产和消费都是针对 group 来的</li>
</ul>
<h2 id="选型"><a class="header-anchor" href="#选型">¶</a>选型</h2>
<ol>
<li>顺序消息</li>
</ol>
<table>
<thead>
<tr>
<th>消息队列</th>
<th>Kafka</th>
<th>RocketMQ</th>
</tr>
</thead>
<tbody>
<tr>
<td>适用场景</td>
<td>大量消息快速消费如流式计算</td>
<td>高性能、稳定、高可靠</td>
</tr>
<tr>
<td>热度</td>
<td>与周边生态系统的兼容性最好</td>
<td>有活跃中文社区</td>
</tr>
<tr>
<td>消息可靠传递</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>延迟</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
<tr>
<td>性能</td>
<td>每秒几十万</td>
<td>每秒几十万</td>
</tr>
<tr>
<td>消息丢失</td>
<td>参数优化配置后0丢失</td>
<td>参数优化配置后0丢失</td>
</tr>
<tr>
<td>消费模式</td>
<td>Pull</td>
<td>Pull + Push</td>
</tr>
<tr>
<td>可用性</td>
<td>非常高（分布式）</td>
<td>非常高（主从）</td>
</tr>
<tr>
<td>topic数量对吞吐量的影响</td>
<td>topic达到几十，几百个时，吞吐量会大幅度下降</td>
<td>topic达到几百，几千个时，吞吐量会有较小幅度的下降</td>
</tr>
</tbody>
</table>
<p>缺点：</p>
<ul>
<li>Kafka：同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。</li>
<li>RocketMQ：没有太明显的缺点</li>
</ul>
<h2 id="部署结构"><a class="header-anchor" href="#部署结构">¶</a>部署结构</h2>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="RocketMQ-架构图" title="RocketMQ-架构图"><br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E9%83%A8%E7%BD%B2%E5%9B%BE.png" alt="RocketMQ-部署图" title="RocketMQ-部署图"></p>
<ul>
<li>启动 NameServer，NameServer 起来后监听端口，等待 Broker、Producer、Consumer 连上来，相当于一个路由控制中心。</li>
<li>Broker 启动，跟所有的 NameServer 保持长连接，定时发送心跳包。心跳包中包含当前 Broker 信息(IP+端口等)以及存储所有 Topic 信息。注册成功后，NameServer 集群中就有 Topic 跟 Broker 的映射关系。</li>
<li>收发消息前，先创建 Topic，创建 Topic 时需要指定该 Topic 要存储在哪些 Broker 上，也可以在发送消息时自动创建 Topic。</li>
<li>Producer 发送消息，启动时先跟 NameServer 集群中的其中一台建立长连接，并从 NameServer 中获取当前发送的 Topic 存在哪些 Broker 上，轮询从队列列表中选择一个队列，然后与队列所在的 Broker 建立长连接从而向 Broker 发消息。</li>
<li>Consumer 跟 Producer 类似，跟其中一台 NameServer 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。</li>
</ul>
<p>下图来自<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/architecture.md" target="_blank" rel="noopener">GitHub</a><br>
<img src="http://47.88.24.11/imgs/RocketMQ/rocketmq_architecture.png" alt="rocketmq_architecture" title="rocketmq_architecture"></p>
<h1>消息的存储和查询</h1>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8.png" alt="RocketMQ-消息存储" title="RocketMQ-消息存储"><br>
如上图所示，消息的存储分为如下 3 个部分：</p>
<ol>
<li>CommitLog：日志，存储消息主体；</li>
<li>ConsumerQueue：在 CommitLog 中根据 Topic 和 Tag 检索消息是非常低效的，因此引入了 ConsumerQueue 作为消费消息的<strong>索引</strong>，它保存的其实是 CommitLog 中存储的消息的指针。</li>
<li>IndexFile：<strong>hash 索引</strong>，提供一种通过 key 或时间区间来查询消息的方法。</li>
</ol>
<h2 id="页缓存与内存映射"><a class="header-anchor" href="#页缓存与内存映射">¶</a>页缓存与内存映射</h2>
<ol>
<li>ConsumerQueue 存储的数据少、且是顺序读取（按顺序被消费），因此在<code>page cache</code>机制的预读取作用下，ConsumerQueue 文件的读取性能几乎接近于读内存。</li>
<li>RocketMQ 主要通过 MappedByteBuffer 对文件进行读写操作，其主要利用 NIO 中的 FileChannel 模型将磁盘上的物理文件直接映射到用户态的内存地址中，避免了传统 IO 方式需要将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间拷贝带来的开销。</li>
</ol>
<h2 id="消息刷盘"><a class="header-anchor" href="#消息刷盘">¶</a>消息刷盘</h2>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E5%88%B7%E7%9B%98.png" alt="RocketMQ-刷盘" title="RocketMQ-刷盘"><br>
刷盘有两种策略：</p>
<ol>
<li>同步刷盘，只有在消息真正持久化到磁盘中后 Broker 才会返回给 Producer 一个 ACK 响应。<br>
同步刷盘可以保证消息的可靠性，但是对性能会有比较大的影响。</li>
<li>异步刷盘，利用 OS 的 PageCache，只要消息写入 PageCache 即可将 ACK 返回给 Producer。<br>
消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了 MQ 的性能和吞吐量。</li>
</ol>
<p>刷盘策略见配置文件<code>broker.conf</code>，默认为异步刷盘：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flushDiskType = ASYNC_FLUSH</span><br></pre></td></tr></table></figure>
<h3 id="commitlog的刷盘"><a class="header-anchor" href="#commitlog的刷盘">¶</a>CommitLog的刷盘</h3>
<p>异步刷盘的实现代码见：<code>org.apache.rocketmq.store.CommitLog.FlushRealTimeService</code><br>
可以看到，默认情况下是每<code>500ms</code>刷新一次，刷盘时先找到要刷盘的<code>MappedFile</code>，刷盘利用了NIO的<code>MappedByteBuffer</code>。<br>
一般情况下每次刷4页，并且每10S将未同步的页面全量同步一次。</p>
<h3 id="consumequeue的刷盘"><a class="header-anchor" href="#consumequeue的刷盘">¶</a>ConsumeQueue的刷盘</h3>
<p>实现代码见<code>FlushConsumeQueueService</code><br>
每秒执行一次，一般每次刷2页，Broker将退出时将所有缓存页全量刷一次。</p>
<h2 id="topic-和-consumerqueue"><a class="header-anchor" href="#topic-和-consumerqueue">¶</a>Topic 和 ConsumerQueue</h2>
<p>在消息队列中主题和队列一般是包含的关系，刚开始消息队列只是一个单纯的队列，后来为了应对多消费者重复消费的需求，出现了发布订阅、Topic的概念，一个Topic中的消息是可以被订阅者重复消费的。<br>
在RocketMQ中Topic和队列之间的关系如下图所示：<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-Topic%E5%92%8CConsumerQueue.png" alt="RocketMQ-Topic和ConsumerQueue" title="RocketMQ-Topic和ConsumerQueue"><br>
如上图所示，RocketMQ 消息存储中有三个容易混淆的概念：</p>
<ul>
<li>Broker：消息代理服务器；</li>
<li>Topic：消息主题，一个 Topic 分片是 Topic 在一个 Broker 上的子集，是 Queue 的逻辑集合；<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-Queue%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85.png" alt="RocketMQ-Queue和消费者" title="RocketMQ-Queue和消费者"></li>
<li>Queue：队列，负载均衡过程中资源分配的基本单元，<strong>每个 Queue 只有一个消费者，但一个消费者可以消费多个 Queue</strong>，可以避免消费过程中多线程的竞争，提高多 Consumer 的并发消费效率。</li>
</ul>
<p>在RocketMQ中，订阅者的概念是通过<strong>消费组（Consumer Group）<strong>来体现的，多个消费组都能消费主题中的一份完整消息，不同消费组之间消费进度彼此互不影响。<br>
但是要注意，一个消费组内可能会有多个消费者，这些消费者不能重复消费一条消息，主要一个消息被其中一个消费者消费了，那同组的其他消费者就不会再收到这条消息。<br>
那么如何实现多个消费组能重复消费一条消息的功能呢？<br>
在RocketMQ中，Broker会为每个消费组在每个队列上维护一个</strong>消费位置（Consumer Offset）</strong>，这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。</p>
<h2 id="按-message-id-查询消息"><a class="header-anchor" href="#按-message-id-查询消息">¶</a>按 Message ID 查询消息</h2>
<p>MessageID 包含：</p>
<ul>
<li>消息存储的主机地址（IP 和端口号）；</li>
<li>消息存储的 Commit Log 的 offset；</li>
</ul>
<p>按 Message ID 查询的过程是：</p>
<ol>
<li>Client 端从 MessageID 中解析出 Broker 地址和 CommitLog 的 offset 地址后封装为一个 RPC 请求，通过 Remoting 通信层发送；</li>
<li>Broker 端走的是 QueryMessageProcessor，读取消息的过程用其中的 commitLog offset 和 size 去 commitLog 中找到真正的记录并解析成一个完整的消息返回。</li>
</ol>
<h2 id="按-message-key-查询消息"><a class="header-anchor" href="#按-message-key-查询消息">¶</a>按 Message Key 查询消息</h2>
<p>主要是基于 RocketMQ 的 IndexFile 索引文件来实现的，IndexFile 的结构类似 JDK 中 HashMap 的实现：<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-IndexFile%E7%BB%93%E6%9E%84.png" alt="RocketMQ-IndexFile结构" title="RocketMQ-IndexFile结构"></p>
<h2 id="按-tag-过滤消息"><a class="header-anchor" href="#按-tag-过滤消息">¶</a>按 Tag 过滤消息</h2>
<p>一般来说，Topic 可以用于区分业务类型，Tag 可以细分比如数据的类型、状态等。<br>
在 RocketMQ 中，Topic 对应的是一些 ConsumerQueue 文件，而 Tag 是消息的属性，用于过滤消息，RocketMQ 有别于其他 MQ 中间件，Tag 是在 Consumer 端执行过滤的，这和其存储结构有关，Tag 存储在两个地方：</p>
<ol>
<li>ConsumerQueue 存储 Tag 的 hash 值；</li>
<li>CommitLog 存储 Tag 的原值。</li>
</ol>
<p>过滤时：</p>
<ol>
<li>服务端接收 Pull 消息的请求后，先根据消息 Tag hash 值去过滤 ConsumerQueue 中的数据，得到消息偏移量等信息后到 CommitLog 中查出消息数据；</li>
<li>Consumer 端接收到消息后，还需要对消息的原始 Tag 字符串进行比对，如果不同，则丢弃该消息，不进行消息消费。</li>
</ol>
<h2 id="offset-的存储"><a class="header-anchor" href="#offset-的存储">¶</a>offset 的存储</h2>
<p>消息消费完成后，需要将消费进度存储起来，即前面提到的offset。<br>
广播模式下，同消费组的消费者相互独立，消费进度要单独存储；集群模式下，同一条消息只会被同一个消费组消费一次，消费进度会参与到负载均衡中，故消费进度是需要共享的。</p>
<h3 id="consumer更新offset到broker"><a class="header-anchor" href="#consumer更新offset到broker">¶</a>Consumer更新offset到Broker</h3>
<ol>
<li>定时任务<br>
每隔一段时间将各个队列的消费进度存储到对应的broker上，该时间由<code>DefaultMQPushConsumer</code>的<code>persistConsumerOffsetInterval</code>属性控制，默认为5秒。<br>
<code>MQClientInstance#startScheduledTask</code> -&gt; <code>MQClientInstance#persistAllConsumerOffset</code><br>
启动一个定时任务提交offset。<br>
<code>RemoteBrokerOffsetStore#updateConsumeOffsetToBroker</code><br>
将offset发送到Broker。</li>
</ol>
<h3 id="consumer从broker拉取offset"><a class="header-anchor" href="#consumer从broker拉取offset">¶</a>Consumer从Broker拉取offset</h3>
<p><code>DefaultMQPushConsumerImpl#pullMessage</code><br>
拉消息后触发offset的更新。<br>
<code>RemoteBrokerOffsetStore#readOffset</code><br>
将offset保存到缓存<code>offsetTable</code>中。</p>
<h2 id="消息堆积-积压"><a class="header-anchor" href="#消息堆积-积压">¶</a>消息堆积（积压）</h2>
<p>在RocketMQ中，每条消息会记录一个它所在的偏移量offset，我们可以比较当前消息的offset和队列的总偏移量maxOffset来确定是否发生了消息堆积。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class PileUpConsumerTest &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws MQClientException &#123;</span><br><span class="line">        // 实例化消费者</span><br><span class="line">        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name&quot;);</span><br><span class="line">        consumer.setNamesrvAddr(&quot;localhost:9876&quot;);</span><br><span class="line">        consumer.subscribe(&quot;PileUpTopicTest&quot;, &quot;*&quot;);</span><br><span class="line">        // 注册回调实现类来处理从broker拉取回来的消息</span><br><span class="line">        consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&gt; &#123;</span><br><span class="line">            for (MessageExt msg : msgs) &#123;</span><br><span class="line">                long offset = msg.getQueueOffset();</span><br><span class="line">                String maxOffset = msg.getProperty(MessageConst.PROPERTY_MAX_OFFSET);</span><br><span class="line">                long diff = Long.parseLong(maxOffset) - offset;</span><br><span class="line">                if(diff &gt; 10) &#123;</span><br><span class="line">                    // 处理消息堆积情况</span><br><span class="line">                    System.out.println(&quot;消息堆积 maxOffset:&quot; + maxOffset + &quot; currOffset:&quot; + offset + &quot; 消息堆积个数:&quot; + diff);</span><br><span class="line">                    return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(&quot;正常消费 maxOffset:&quot; + maxOffset + &quot; currOffset:&quot; + offset + &quot; 消息堆积个数:&quot; + diff);</span><br><span class="line">            &#125;</span><br><span class="line">            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;);</span><br><span class="line">        // 启动消费者实例</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(&quot;Consumer Started.%n&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>或者可以通过RocketMQ的Console界面来检查堆积情况：<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-Console%E6%9F%A5%E7%9C%8B%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF1.png" alt="RocketMQ-Console查看消息堆积1" title="RocketMQ-Console查看消息堆积1"><br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-Console%E6%9F%A5%E7%9C%8B%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF2.png" alt="RocketMQ-Console查看消息堆积2" title="RocketMQ-Console查看消息堆积2"></p>
<p>发生消息堆积的主要原因是消息生产速度远远大于消息消费速度：</p>
<ul>
<li>如果堆积不严重，可以放着让消费者继续慢慢消费完；</li>
<li>如果堆积严重且消息生产速度一直处于远远高于消费速度的程度，可以加机器来提升并发消费能力，但是单纯地加机器不能改善这种堆积情况，因为<strong>每个队列实际上只能被一个Consumer消费</strong>；<br>
可以先将堆积的消息发给另一个Topic，该Topic有更多Consumer。<br>
或者，可以选择丢弃不重要的消息，即仅仅记录日志，而不真正消费，从而在不影响消息完整性的前提下，达到处理消息堆积问题的目的。<br>
解决消息堆积问题的根本还是优化系统本身，比如是赶上大促或抢购这种场景，就很容易引起消息堆积，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。</li>
</ul>
<h2 id="rocketmq怎么保证高效读消息"><a class="header-anchor" href="#rocketmq怎么保证高效读消息">¶</a>RocketMQ怎么保证高效读消息</h2>
<ul>
<li>发送消息时，生产者端的消息确实是<strong>顺序写入</strong>CommitLog；</li>
<li>订阅消息时，消费者端也是<strong>顺序读取</strong>ConsumeQueue，然而<strong>根据其中的起始物理位置偏移量offset读取消息真实内容却是随机读取CommitLog</strong>。</li>
<li>RocketMQ通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型直接将磁盘上的物理文件直接映射到用户态的内存地址中，这样程序就好像可以直接从内存中完成对文件读/写操作一样。只有当缺页中断发生时，直接将文件从磁盘拷贝至用户态的进程空间内，只进行了一次数据拷贝。对于容量较大的文件来说（文件大小一般需要限制在1.5~2G以下），采用Mmap的方式其读/写的效率和性能都非常高。</li>
</ul>
<p>优点：</p>
<ol>
<li>对ConsumeQueue的读取是顺序读取，在<strong>pageCache</strong>机制的预读取作用下，ConsumeQueue的读性能会比较高近乎内存，即使在有消息堆积情况下也不会影响性能。</li>
<li>ConsumeQueue消息逻辑队列较为轻量级；</li>
<li>对磁盘的访问串行化，避免磁盘竟争，不会因为队列增加导致IOWAIT增高；</li>
</ol>
<p>缺点：</p>
<ol>
<li>对于CommitLog来说写入消息虽然是顺序写，但是读却变成了完全的随机读；</li>
<li>Consumer端订阅消费一条消息，需要先读ConsumeQueue，再读CommitLog，一定程度上增加了开销；</li>
</ol>
<h1>通信机制</h1>
<h2 id="启动"><a class="header-anchor" href="#启动">¶</a>启动</h2>
<p>RocketMQ 的消息队列集群结构主要包含 NameServer、Broker（Master/Slave）、Producer、Consumer 4 个部分，基本通信流程如下：</p>
<ol>
<li>Broker 启动后需要完成一次将自己注册至 NameServer 的操作；随后每隔 30s 时间定时向 NameServer 上报 Topic 路由信息。<br>
Broker 启动入口：<code>org.apache.rocketmq.broker.BrokerController#start</code><br>
注册到每个 NameServer：<code>org.apache.rocketmq.broker.out.BrokerOuterAPI#registerBrokerAll</code></li>
<li>消息生产者 Producer 作为客户端发送消息时候，需要根据消息的 Topic 从本地缓存的 TopicPublishInfoTable 获取路由信息。如果没有则更新路由信息会从 NameServer 上重新拉取，同时 Producer 会默认每隔 30s 向 NameServer 拉取一次路由信息。</li>
<li>消息生产者 Producer 根据<code>2</code>中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker 作为消息的接收者接收消息并落盘存储。</li>
<li>消息消费者 Consumer 根据<code>2</code>中获取的路由信息，并再完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。</li>
</ol>
<h2 id="服务发现"><a class="header-anchor" href="#服务发现">¶</a>服务发现</h2>
<h3 id="broker"><a class="header-anchor" href="#broker">¶</a>Broker</h3>
<p>Broker端启动时会向NameServer注册，并开启一个定时任务，用于每隔十秒向所有NameServer发送心跳请求，将Topic信息注册到NameServer。</p>
<h3 id="nameserver"><a class="header-anchor" href="#nameserver">¶</a>NameServer</h3>
<p>除了Broker可以向NameServer注册服务信息，NameServer也会启动一个定时任务来定时清理不活动的Broker，默认情况下是清除两分钟没有向NameServer发送心跳更新的Broker。<br>
NameServer的结构比较简单，主要类只有6个：</p>
<ul>
<li><code>NamesrvStartup</code>：程序入口。</li>
<li><code>NamesrvController</code>：NameServer 的总控制器，负责所有服务的生命周期管理。</li>
<li><code>RouteInfoManager</code>：NameServer 最核心的实现类，负责保存和管理<strong>集群路由信息</strong>。<br>
<code>topicQueueTable</code> 保存的是主题和队列信息，其中每个队列信息对应的类 QueueData 中，还保存了 brokerName。需要注意的是，这个 brokerName 并不真正是某个 Broker 的物理地址，它对应的一组 Broker 节点，包括一个主节点和若干个从节点。<br>
<code>brokerAddrTable</code> 中保存了集群中每个 brokerName 对应 Broker 信息，每个 Broker 信息用一个 BrokerData 对象表示</li>
<li><code>BrokerHousekeepingService</code>：监控 Broker 连接状态的代理类。</li>
<li><code>DefaultRequestProcessor</code>：负责处理客户端和 Broker 发送过来的 RPC 请求的处理器。<br>
先用读写锁保证并发安全，然后比较所有路由信息Map并更新。</li>
<li><code>ClusterTestRequestProcessor</code>：用于测试的请求处理器。</li>
</ul>
<h2 id="一个消息的发送轨迹"><a class="header-anchor" href="#一个消息的发送轨迹">¶</a>一个消息的发送轨迹</h2>
<h3 id="producer-端发送"><a class="header-anchor" href="#producer-端发送">¶</a>Producer 端发送</h3>
<p>Producer端的发送分为<strong>同步</strong>、<strong>异步</strong>、<strong>单向</strong>三种，下面以同步发送为例，异步发送只是把发送任务放到了一个线程池中执行，单向和同步的区别只是单向发出去后不会再管发没发成功（）。</p>
<ol>
<li>Producer 端调发送接口<br>
<code>org.apache.rocketmq.client.producer.DefaultMQProducer#send(Message)</code><br>
发送前需要设置 NameServer 的地址信息，这样发消息前才能根据 NameServer 中的服务注册表信息来进行消息的路由。</li>
<li>找 Topic 的路由信息<br>
<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#tryToFindTopicPublishInfo()</code><br>
Client 需要根据 Topic 来决定应该将消息发往哪台 Broker，这部分路由信息是保存在 NameServer 上的。<br>
<code>org.apache.rocketmq.client.impl.factory.MQClientInstance#updateTopicRouteInfoFromNameServer(topic)</code><br>
第一次获取某个 Topic 的路由信息、或路由信息发生变化时，需要刷新一次本地路由表信息，并更新发布和订阅信息。<br>
<code>org.apache.rocketmq.remoting.netty.NettyRemotingClient#getAndCreateNameserverChannel</code><br>
随机选一个 NameServer 获取 Topic 路由信息。</li>
<li>选一个 ConsumerQueue 发送<br>
<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#selectOneMessageQueue</code><br>
一个 Topic 包含多个 ConsumerQueue，客户端的负载均衡机制会<strong>从中选择一个发送</strong>。</li>
<li>发送<br>
<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#sendKernelImpl</code><br>
获取 Broker 的地址，调 Netty 接口发送。</li>
</ol>
<h3 id="server-端存储"><a class="header-anchor" href="#server-端存储">¶</a>Server 端存储</h3>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BB%A3%E7%A0%81%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.jpg" alt="RocketMQ服务端代码层次结构" title="RocketMQ服务端代码层次结构"></p>
<ol>
<li>启动Server<br>
<code>org.apache.rocketmq.broker.BrokerStartup#main</code></li>
<li>注册Processor<br>
<code>org.apache.rocketmq.broker.BrokerController#registerProcessor</code></li>
<li>启动 Netty 监听器<br>
<code>org.apache.rocketmq.remoting.netty.NettyRemotingServer#start</code><br>
Netty 中的线程模型总而言之：
<ul>
<li>一个线程负责监听 TCP 请求（<code>eventLoopGroupBoss</code>），建立好连接后丢给<strong>Reactor 线程池</strong>（<code>eventLoopGroupSelector</code>）；</li>
<li>Reactor 负责将 socket 注册到 selector，当监听到网络数据后，再丢给<strong>Worker 线程池</strong>（<code>defaultEventExecutorGroup</code>）；</li>
<li>Worker 线程在真正执行业务逻辑之前需要进行 SSL 验证、编解码、空闲检查、网络连接管理，然后根据 RomotingCommand 的业务请求码 code 去 processorTable 这个本地缓存变量中找到对应的 processor，然后封装成 task 任务后，提交给对应的<strong>业务 processor 处理线程池</strong>来执行（<code>sendMessageExecutor</code>）。<br>
<code>org.apache.rocketmq.remoting.netty.NettyRemotingServer.NettyServerHandler#channelRead0</code><br>
之后，利用 Netty 的 Handler 链处理请求，实际处理命令的 Handler 为<code>NettyServerHandler</code>。</li>
</ul>
</li>
<li>处理请求<br>
<code>org.apache.rocketmq.remoting.netty.NettyRemotingAbstract#processRequestCommand</code><br>
每个请求对应一个<code>NettyRequestProcessor</code>和一个线程池。</li>
<li>开始实际发送逻辑<br>
<code>org.apache.rocketmq.broker.processor.SendMessageProcessor#asyncSendMessage</code><br>
获取MessageStore，MessageStore负责消息的存储。</li>
<li>处理存储请求<br>
<code>org.apache.rocketmq.store.DefaultMessageStore#asyncPutMessage</code><br>
存储消息是最常见的请求，当然RocketMQ还支持很多其他命令。<br>
<code>org.apache.rocketmq.store.CommitLog#asyncPutMessage</code><br>
RocketMQ并不会立刻将消息写入到磁盘（<strong>CommitLog文件</strong>），而是使用<code>MappedFile</code>先写入<strong>PageCache</strong>，然后异步同步。<br>
<code>org.apache.rocketmq.store.DefaultMessageStore.ReputMessageService#doReput</code> -&gt; <code>org.apache.rocketmq.store.DefaultMessageStore#doDispatch</code><br>
存储的消息也并不会立刻被写入到<strong>索引文件（IndexFile）<strong>和</strong>队列文件（ConsumeQueue）</strong>，而是由一个线程异步同步。</li>
</ol>
<h3 id="consumer-端拉取"><a class="header-anchor" href="#consumer-端拉取">¶</a>Consumer 端拉取</h3>
<ol>
<li>
<p>启动客户端<br>
<code>org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl#start</code><br>
可以看到，启动了很多实例，重点需要关注的是最后启动的<code>MQClientInstance</code>实例。</p>
</li>
<li>
<p>客户端实例的初始化<br>
<code>org.apache.rocketmq.client.impl.factory.MQClientInstance#startScheduledTask</code><br>
使用定时任务执行从 NameServer 拉取路由信息（包括 Topic 下的 Queue 和 Consumer 列表）、向 Broker 发送心跳等任务。<br>
<code>org.apache.rocketmq.client.impl.consumer.PullMessageService#start</code><br>
启动一个线程轮询拉消息。<br>
<code>org.apache.rocketmq.client.impl.consumer.RebalanceService#start</code><br>
重新负载均衡。</p>
</li>
<li>
<p>接收消息<br>
Consumer端<strong>Pull消息是单线程的</strong></p>
</li>
<li>
<p>提交处理<br>
<code>org.apache.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService#submitConsumeRequest</code><br>
虽然Pull消息是单线程的，但是<strong>消费消息是多线程的</strong>。</p>
</li>
</ol>
<h2 id="负载均衡"><a class="header-anchor" href="#负载均衡">¶</a>负载均衡</h2>
<h3 id="producer-端负载均衡"><a class="header-anchor" href="#producer-端负载均衡">¶</a>Producer 端负载均衡</h3>
<p><code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#selectOneMessageQueue</code><br>
Producer 端发送消息前会先从 NameServer 拿到 Topic 的路由信息，即 Topic 有几个 Queue、及这些 Queue 位于哪个 Broker。之后，客户端会根据负载均衡和容错策略从中选择一个发送。</p>
<h3 id="consumer-端负载均衡"><a class="header-anchor" href="#consumer-端负载均衡">¶</a>Consumer 端负载均衡</h3>
<p>RocketMQ 中 Consumer 端有两种消费模式（Push/Pull），它们本质上都是基于拉模式来获取消息的，Push 模式只是对 Pull 模式的一种封装：</p>
<ol>
<li>Pull：向服务器直连发请求拉取消息。</li>
<li>Push：每次拉取后立刻向服务器再次尝试拉取消息，如果没拉取到则延迟一段时间再继续拉取。</li>
</ol>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png" alt="RocketMQ-负载均衡" title="RocketMQ-负载均衡"><br>
Consumer 端的负载均衡体现在 RocketMQ 对 Queue 的分配：</p>
<ol>
<li>Consumer 端心跳<br>
Consumer 启动后会通过定时任务不断向集群中所有 Broker 实例发送心跳包，Broker 会将 Consumer 注册到缓存中；<br>
另还有个定时任务从 NameServer 拉取 Topic 下的 Queue 和 Consumer 列表，便于之后的负载均衡。</li>
<li>Consumer 端负载均衡<br>
<code>RebalanceImpl#rebalanceByTopic</code><br>
获取该 Topic 下的消息队列和消费者集合，按消息队列分配策略算法（<code>AllocateMessageQueueStrategy</code>）将每个消息队列分配给消费者，默认为平均分配。<br>
这里的平均分配算法，类似于分页的算法，将所有 MessageQueue 排好序类似于记录，将所有消费端 Consumer 排好序类似页数，并求出每一页需要包含的平均 size 和每个页面记录的范围 range，最后遍历整个 range 而计算出当前 Consumer 端应该分配到的记录（这里即为：MessageQueue）。<br>
其中的源码如下所示：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public static List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll,</span><br><span class="line">        List&lt;String&gt; cidAll) &#123;</span><br><span class="line">    if (currentCID == null || currentCID.length() &lt; 1) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;currentCID is empty&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    if (mqAll == null || mqAll.isEmpty()) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;mqAll is null or mqAll empty&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    if (cidAll == null || cidAll.isEmpty()) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;cidAll is null or cidAll empty&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;();</span><br><span class="line">    if (!cidAll.contains(currentCID)) &#123;</span><br><span class="line">        log.info(&quot;[BUG] ConsumerGroup: &#123;&#125; The consumerId: &#123;&#125; not in cidAll: &#123;&#125;&quot;,</span><br><span class="line">                consumerGroup,</span><br><span class="line">                currentCID,</span><br><span class="line">                cidAll);</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 当前Consumer在第几页</span><br><span class="line">    int index = cidAll.indexOf(currentCID);</span><br><span class="line">    // 如果是最后一页，取余数</span><br><span class="line">    int mod = mqAll.size() % cidAll.size();</span><br><span class="line">    // 每页数量</span><br><span class="line">    int averageSize = mqAll.size() &lt;= cidAll.size() ?</span><br><span class="line">            1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1</span><br><span class="line">            : mqAll.size() / cidAll.size());</span><br><span class="line">    // 当前Consumer负责的第一个Queue所处的下标</span><br><span class="line">    int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod;</span><br><span class="line">    // 当前Consumer需要负责几个Queue</span><br><span class="line">    int range = Math.min(averageSize, mqAll.size() - startIndex);</span><br><span class="line">    for (int i = 0; i &lt; range; i++) &#123;</span><br><span class="line">        result.add(mqAll.get((startIndex + i) % mqAll.size()));</span><br><span class="line">    &#125;</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="重试和幂等"><a class="header-anchor" href="#重试和幂等">¶</a>重试和幂等</h2>
<h3 id="producer端重试"><a class="header-anchor" href="#producer端重试">¶</a>Producer端重试</h3>
<p>下面的代码同步发送消息，如果5秒内没有发送成功，则重试5次</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DefaultMQProducer producer = new DefaultMQProducer(&quot;DefaultProducer&quot;);</span><br><span class="line">producer.setRetryTimesWhenSendFailed(5);</span><br><span class="line">producer.send(msg,5000L);</span><br></pre></td></tr></table></figure>
<p>Producer 的 send 方法本身支持<strong>内部重试</strong>：<br>
同步发送代码：<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#send(Message)</code>，注意传超时参数时取的<code>defaultMQProducer.getSendMsgTimeout()</code>。<br>
异步发送：<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#send(Message, SendCallback)</code><br>
实际发送消息的代码位置（注意对sendResult的处理）：<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#sendDefaultImpl</code><br>
从源码中可以得到以下结论：</p>
<ul>
<li>至多重试 2 次。<br>
同步发送为 2 次，异步发送为 0 次，也就是说，异步发送是不会重试的。</li>
<li>如果发送失败，则轮转到下一个 Broker。这个方法的总耗时时间不超过 sendMsgTimeout 设置的值，默认 10s。</li>
<li>如果本身向 broker 发送消息产生超时异常，就不会再重试。</li>
</ul>
<p>除了Producer客户端的自动重试外，应用程序在接收到SendResult后也可以自己尝试去重试。</p>
<h3 id="consumer重试"><a class="header-anchor" href="#consumer重试">¶</a>Consumer重试</h3>
<p>消费者消费消息后需要给Broker返回消费状态，比如并发消费者<code>MessageListenerConcurrently</code>会返回<code>ConsumeConcurrentlyStatus</code>：</p>
<ul>
<li>如果消费成功，返回<code>CONSUME_SUCCESS</code>；</li>
<li>如果消费出错，返回<code>RECONSUME_LATER</code>，一段时间后重试。</li>
</ul>
<p>状态的返回是由用户线程控制的，但还有第三种可能，就是超时了，因此Consumer端的重试包含以下两种情况：</p>
<ol>
<li>异常重试：Consumer端主动返回<code>RECONSUME_LATER</code>状态，Broker会在一段时间后重试；</li>
<li>超时重试：Consumer端处理时间过长，或者由于某些原因线程挂起，导致迟迟没有返回消费状态，Broker就会认为Consumer消费超时，此时会发起超时重试。</li>
</ol>
<p>如果Consumer端因为各种类型异常导致本次消费失败（如上所述的两种情况），为防止该消息丢失而需要将其重新回发给Broker端保存，保存这种因为异常无法正常消费而回发给MQ的消息队列称之为<strong>重试队列</strong>。RocketMQ会为每个消费组都设置一个Topic名称为**“%RETRY%+consumerGroup”的重试队列**（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的）。</p>
<blockquote>
<p>不能保证消息消费失败加入重试队列后还能被同一消费者消费，可能会破坏消息的顺序性。</p>
</blockquote>
<p>由于有些原因导致Consumer端长时间的无法正常消费从Broker端Pull过来的业务消息，为了确保消息不会被无故的丢弃，那么超过配置的“最大重试消费次数”后就会移入到这个<strong>死信队列</strong>中，RocketMQ会为每个消费组都设置一个Topic命名为“%DLQ%+consumerGroup”的死信队列。一般在实际应用中，移入至死信队列的消息，需要人工干预处理；</p>
<p>另外还有两种需要注意的情况：</p>
<ul>
<li>只有消息模式为<code>MessageModel.CLUSTERING</code>集群模式时，Broker才会自动进行重试，而广播消息是不会重试的。</li>
<li>事务消息中的半事务消息通过 Broker 的回查机制重试，具体流程见下面的<strong>事务消息</strong>。</li>
</ul>
<h3 id="消息幂等"><a class="header-anchor" href="#消息幂等">¶</a>消息幂等</h3>
<p>RocketMQ提供<strong>At least once</strong>的消息服务质量标准，表示一条消息至少被送达一次，也就是说，不允许丢消息，但允许有少量重复消息出现。</p>
<blockquote>
<p>另外两种服务质量标准是<strong>At most once</strong>和<strong>Exactly once</strong>。</p>
</blockquote>
<p>比如Producer发出了10个消息，如果Consumer接收中间两条消息时出错了，返回<code>RECONSUME_LATER</code>，则该两条消息会被加入到<code>RETRY</code>队列中重新消费。</p>
<p>解决消息重复消费问题的主要方法是<strong>幂等</strong>，一个幂等操作的特点是，<strong>其任意多次执行仅会产生一次影响</strong>，因此从对系统的影响结果来说：<strong>At least once + 幂等消费 = Exactly once</strong>。<br>
实现幂等的方式有很多种，不过这些方案与消息队列本身已经没有多大关系了，因此这里仅仅简单描述一下这些实现方式：</p>
<ol>
<li>利用数据库的唯一约束实现幂等<br>
为一个操作设置一个唯一键，比如一个账单每个用户只允许变更一次，则可以给转账流水表中的账单ID和账户ID创建一个唯一约束。</li>
<li>加上前置条件<br>
限制数据更新前的状态，比如只有在余额为500的时候才允许更新。<br>
也可以单独加上一个唯一ID，每次发消息时生成一个全局唯一ID，消费时检查这个唯一ID是否有被消费过。</li>
</ol>
<h2 id="消息优先级"><a class="header-anchor" href="#消息优先级">¶</a>消息优先级</h2>
<p>消息优先级机制可以让消息队列中优先级较高的消息先投递，比如订单创建消息就可以优先于日常推送消息。<br>
RocketMQ 没有直接实现消息的优先级，主要是处于性能考虑，因为 RocketMQ 所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大。但也可以用一种变通的方式实现消息的优先级，比如创建 3 个代表不同优先级的队列。</p>
<h2 id="消息有序性"><a class="header-anchor" href="#消息有序性">¶</a>消息有序性</h2>
<p>一些场景需要保证操作的顺序性，比如A系统要将订单同步给B系统，但是要按照订单所发生事件顺序来同步，比如后台先修改订单价格再用户支付，那么就要先发修改价格的状态再发送支付成功的状态。<br>
RocketMQ 可以严格的保证消息有序。</p>
<h3 id="有序消息的实现方式"><a class="header-anchor" href="#有序消息的实现方式">¶</a>有序消息的实现方式</h3>
<p>要保证MQ消息消费的有序性，需要保证以下3个阶段的有序性：<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ%E4%BF%9D%E6%8C%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7.png" alt="RocketMQ保持消息的有序性" title="RocketMQ保持消息的有序性"></p>
<ol>
<li>消息被发送时保持有序；</li>
<li>消息被存储时保持和发送时的顺序一致；</li>
<li>消息被消费时保持和存储时的顺序一致。</li>
</ol>
<p>在RocketMQ中，有两种实现方式：</p>
<ol>
<li>全局有序<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E5%85%A8%E5%B1%80%E6%9C%89%E5%BA%8F.png" alt="RocketMQ-全局有序" title="RocketMQ-全局有序"><br>
一个Topic内所有的消息都发送到同一个Queue。<br>
适用于性能要求不高，所有的消息严格按照FIFO原则进行消息发布和消费的场景。</li>
<li>分区有序<br>
<img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E5%88%86%E5%8C%BA%E6%9C%89%E5%BA%8F.png" alt="RocketMQ-分区有序" title="RocketMQ-分区有序"><br>
RocketMQ根据用户自定义的<strong>Sharding Key</strong>将消息散列到不同的Queue，每个Queue内的消费是严格有序的。<br>
适用于性能要求较高的场景。</li>
</ol>
<h3 id="rocketmq中有序消息的实现原理"><a class="header-anchor" href="#rocketmq中有序消息的实现原理">¶</a>RocketMQ中有序消息的实现原理</h3>
<p>发送端需要指定消息的ShardingKey：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.rocketmq.client.producer.DefaultMQProducer#send(Message, MessageQueueSelector, Object)</span><br></pre></td></tr></table></figure>
<p>如上述消息发送API所示，第二个参数<code>MessageQueueSelector</code>可以用于发送消息时指定某个Queue，在API层面没有区分全局有序和分区有序，如果要实现全局有序就把所有消息都Sharding到一个Queue上即可。</p>
<p>消费方拉取时需要区分Pull和Push两种模式：</p>
<ol>
<li>Pull<br>
Pull模式就是每次从一个Queue中拉取。</li>
<li>Push<br>
Push模式使用一个线程轮询Broker拉取消息，然后调用客户端提供的回调函数进行消费，在客户端中需要保证调用<code>MessageListener</code>时消息的顺序性。<br>
<code>ConsumeMessageOrderlyService</code><br>
实现上，就是在消费前先对队列加锁，避免Consumer并发消费一个队列（一个队列只能被一个Consumer消费，因此这个锁主要是保证Consumer不会并发消费一个消息，是单机锁而不是分布式锁）。</li>
</ol>
<h3 id="有序性与可用性间存在的矛盾"><a class="header-anchor" href="#有序性与可用性间存在的矛盾">¶</a>有序性与可用性间存在的矛盾</h3>
<p>为了保证服务的高可用性，RocketMQ支持把一个主题分布到多对主从节点上去，每对主从节点中承担主题中的一部分队列，如果某个主节点宕机了，会自动切换到其他主节点上继续发消息，这样既解决了可用性的问题，还可以通过水平扩容来提升 Topic 总体的性能。<br>
但是严格的顺序性要求指定队列来发送消息，一个队列一定是落在一个特定的主节点上的，如果该主节点宕机了，那么顺序性也就不存在了。<br>
在RocketMQ中引入了<strong>Dledger</strong>的复制方式，这种方式对上述问题的解决方案是：消息必须被复制到半数以上节点才能返回成功，且主节点宕机后支持通过选举来动态切换主节点，Dledger在选举时，总会把数据和主节点一致的从节点选为新的主节点，这样就保证了数据的一致性，既不会丢消息，还可以保证严格顺序。</p>
<h2 id="延时消息"><a class="header-anchor" href="#延时消息">¶</a>延时消息</h2>
<p>RocketMQ里延时消息功能并不能指定时间，而是只能指定延时级别：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Message message = new Message(&quot;TopicTest&quot;, &quot;TagA&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());</span><br><span class="line">// 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)</span><br><span class="line">message.setDelayTimeLevel(3);</span><br><span class="line">producer.send(message);</span><br></pre></td></tr></table></figure>
<ol>
<li>延时消息和普通消息一样会先被写入<code>commitLog</code>，但不会立刻写入<code>consumerQueue</code>中，而是存放到<code>SCHEDULE_TOPIC_XXX</code>的topic下面，并且以延时粒度作为queueId区分；</li>
<li>之后Broker端会有定时任务扫描<code>SCHEDULE_TOPIC_XXX</code>下的每个Queue，到时候后写入到consumerQueue中。</li>
</ol>
<h2 id="消息可靠性"><a class="header-anchor" href="#消息可靠性">¶</a>消息可靠性</h2>
<p>只要不是存储硬件发生不可逆的损坏，RocketMQ 都可以保证消息不丢或少丢，比如 Broker 挂掉、操作系统挂掉等；<br>
如果硬件发生不可逆的损坏，则该节点的消息就无法恢复了，需要通过异步复制来恢复。</p>
<h3 id="如何检测消息丢失？"><a class="header-anchor" href="#如何检测消息丢失？">¶</a>如何检测消息丢失？</h3>
<ol>
<li>利用分布式链路追踪系统</li>
<li>利用消息队列的有序性来验证是否有消息丢失</li>
</ol>
<h3 id="rocketmq-如何保证消息不丢？"><a class="header-anchor" href="#rocketmq-如何保证消息不丢？">¶</a>RocketMQ 如何保证消息不丢？</h3>
<p>保证消息不丢失的原理是复制，传统的复制方式有异步复制和同步双写复制两种：</p>
<ol>
<li><strong>异步复制</strong><br>
消息先发送到主节点上，就返回&quot;写入成功&quot;，然后消息再异步复制到从节点上。</li>
<li><strong>同步双写复制</strong><br>
消息同步双写到主从节点上，主从都写成功，才返回&quot;写入成功&quot;。</li>
</ol>
<blockquote>
<p>这两种方式本质区别是：写入多少个副本再返回，异步复制需要的副本数是1，而同步双写需要的副本数为2。</p>
</blockquote>
<p>RocketMQ的复制模式是<strong>基于Deldger的新复制模式</strong>。<br>
在 RocketMQ 中，Broker 的主从关系是通过配置固定的，不支持动态切换。如果主节点宕机，生产者就不能再生产消息了，消费者可以自动切换到从节点继续进行消费。这时候，即使有一些消息没有来得及复制到从节点上，这些消息依然躺在主节点的磁盘上，除非是主节点的磁盘坏了，否则等主节点重新恢复服务的时候，这些消息依然可以继续复制到从节点上，也可以继续消费，不会丢消息，消息的顺序也是没有问题的。</p>
<h3 id="deldger的复制模式"><a class="header-anchor" href="#deldger的复制模式">¶</a>Deldger的复制模式</h3>
<ul>
<li>RocketMQ-on-DLedger Group 是指一组相同名称的 Broker，至少需要 3 个节点，通过 <strong>Raft</strong> 自动选举出一个 Leader，其余节点 作为 Follower，并在 Leader 和 Follower 之间复制数据以保证高可用。</li>
<li>RocketMQ-on-DLedger Group 能自动容灾切换，并保证数据一致。</li>
<li>RocketMQ-on-DLedger Group 是可以水平扩展的，也即可以部署任意多个 RocketMQ-on-DLedger Group 同时对外提供服务。</li>
</ul>
<p>一主二从的三副本集群的复制过程：</p>
<ol>
<li>Dledger 在写入消息的时候，要求<strong>至少消息复制到半数以上的节点之后，才给客户端返回写入成功</strong>，并且它是支持通过选举来动态切换主节点的。</li>
</ol>
<blockquote>
<p>至少半数这个要求有点像MySQL里的semi-sync和Redis里的复制策略，说明这种方案确实非常有效，只要是涉及集群复制的场景都可以考虑采用。</p>
</blockquote>
<ol>
<li>拿 3 个节点举例说明一下。<br>
当主节点宕机的时候，2 个从节点会通过投票选出一个新的主节点来继续提供服务，相比主从的复制模式，解决了可用性的问题。<br>
由于消息要至少复制到 2 个节点上才会返回写入成功，即使主节点宕机了，也至少有一个节点上的消息是和<br>
主节点一样的。</li>
<li>Dledger 在选举时，总会把数据和主节点一样的从节点选为新的主节点，<br>
这样就保证了数据的一致性，既不会丢消息，还可以保证严格顺序。</li>
</ol>
<p>Dledger的不足：</p>
<ul>
<li>选举过程中不能提供服务。<br>
最少需要 3 个节点才能保证数据一致性，3 节点时，只能保证 1 个节点宕机时可<br>
用，如果 2 个节点同时宕机，即使还有 1 个节点存活也无法提供服务，资源的利用率比较<br>
低。另外，由于至少要复制到半数以上的节点才返回写入成功，性能上也不如主从异步复制<br>
的方式快。</li>
</ul>
<h3 id="rocketmq如何保证高可用"><a class="header-anchor" href="#rocketmq如何保证高可用">¶</a>RocketMQ如何保证高可用</h3>
<ul>
<li>通过多主多从架构保证高可用<br>
RocketMQ 支持<strong>把一个主题分布到多对主从节点上去，每对主从节点中承担主题中的一部分队列</strong>，如果某个主节点宕机了，会自动切换到其他主节点上继续发消息，这样既解决了可用性的问题，还可以通过水平扩容来提升 Topic 总体的性能。</li>
<li>高可用与严格顺序不能并存<br>
在需要保证消息严格顺序的场景下，由于在主题层面无法保证严格顺序，所以必须指定队列来发送消息（指分区有序或全局有序），对于任何一个队列，它一定是落在一组特定的主从节点上，如果这个主节点宕机，其他的主节点是无法替代这个主节点的，否则就无法保证严格顺序。在这种复制模式下，严格顺序和高可用只能选择一个。</li>
</ul>
<h2 id="消息实时性"><a class="header-anchor" href="#消息实时性">¶</a>消息实时性</h2>
<p>RocketMQ 支持 pull 和 push 两种消息消费模式，但 push 是使用长轮询 Pull 的方式实现的，可保证消息非常实时，消息实时性不低于 Push。<br>
长轮询 pull 的原理是：发起 pull 请求失败后（比如 Broker 端暂时没有可以消费的消息），先 hold 住线程并挂起该请求。</p>
<h2 id="事务消息"><a class="header-anchor" href="#事务消息">¶</a>事务消息</h2>
<ul>
<li><strong>半事务消息</strong>：发事务消息时，发送方会先发送一条半事务消息给 Broker，此时 Broker 暂未收到 Producer 对该消息的二次确认，此时该消息被标记成<strong>暂不能投递</strong>状态，处于该种状态下的消息即半事务消息；</li>
<li><strong>消息回查</strong>：由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，Broker 通过扫描发现某条消息长期处于<strong>半事务消息</strong>时，需要主动向 Producer 询问该消息的最终状态（Commit 或是 Rollback），该询问过程即消息回查。</li>
</ul>
<p><img src="http://47.88.24.11/imgs/RocketMQ/RocketMQ-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF.png" alt="RocketMQ-事务消息" title="RocketMQ-事务消息"><br>
事务消息的处理流程如上图所示：<br>
图片来自<a href="https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7" target="_blank" rel="noopener">事务消息</a></p>
<ol>
<li>Producer 发半事务消息给 Broker；</li>
<li>Broker 将半事务消息持久化后，向 Producer 返回 ACK 确认消息已发送成功，此时消息为半事务消息；</li>
<li>Producer 端开始执行本地事务逻辑；</li>
<li>Producer 端根据本地事务执行结果向服务端提交<strong>二次确认（Commit 或是 Rollback）</strong>，Broker 收到 Commit 状态则将半事务消息标记为<strong>可投递</strong>，Consumer 最终将收到该消息；Broker 收到 Rollback 状态则删除半事务消息，Consumer 将不会接受该消息。</li>
</ol>
<p>接下来我们看看各步骤如果出错会怎么样：</p>
<ol>
<li><code>2</code>消息丢失或<code>3</code>执行失败：发送方终止本次事务，提交 Rollback 消息给服务端；</li>
<li><code>4</code>的 Commit 消息提交失败：见<code>5</code>，即服务端会回查事务状态；</li>
</ol>
<p>事务消息回查步骤如下：</p>
<ol>
<li>在断网或者是应用重启的特殊情况下，上述步骤 4 提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。</li>
<li>发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li>
<li>发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤 4 对半事务消息进行操作。</li>
</ol>
<h3 id="事务消息源码"><a class="header-anchor" href="#事务消息源码">¶</a>事务消息源码</h3>
<p>Producer发送</p>
<ol>
<li>发送<br>
<code>org.apache.rocketmq.client.producer.TransactionMQProducer#sendMessageInTransaction</code><br>
先添加<strong>半消息</strong>的标识，然后和普通消息一样发送，如果发送成功则执行本地事务。</li>
<li>执行本地事务<br>
<code>org.apache.rocketmq.client.producer.TransactionListener#executeLocalTransaction</code><br>
使用了发送前传入的回调。<br>
返回值表示本地事务（<code>LocalTransactionState</code>）的执行情况：
<ul>
<li>COMMIT_MESSAGE：endTransaction时发送<code>TRANSACTION_COMMIT_TYPE</code>类型的消息到Broker，此时事务被提交，Consumer端可以消费该条消息；</li>
<li>ROLLBACK_MESSAGE：endTransaction时通知Broker <code>TRANSACTION_ROLLBACK_TYPE</code>，事务被回滚，Consumer端不可消费该消息；</li>
<li>UNKNOW：endTransaction时通知Broker <code>TRANSACTION_NOT_TYPE</code>，本地事务未执行完毕，Broker需要稍后反查本地事务状态。</li>
</ul>
</li>
<li>根据本地事务执行结果，开始执行提交或回滚<br>
<code>org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#endTransaction</code><br>
正如我们之前讨论的那样，这个消息发失败也没有关系，Broker之后会有反查。</li>
</ol>
<p>Broker接收</p>
<ol>
<li>处理发消息请求<br>
<code>org.apache.rocketmq.broker.processor.SendMessageProcessor#sendMessage</code></li>
<li>处理事务消息<br>
<code>org.apache.rocketmq.broker.transaction.queue.TransactionalMessageServiceImpl#prepareMessage</code> -&gt; <code>org.apache.rocketmq.broker.transaction.queue.TransactionalMessageBridge#putHalfMessage</code><br>
可以看到RocketMQ并没有将半消息保存到客户端指定的那个队列中，而是记录了原始的主题队列后，把这个半消息保存在了一个特殊的内部主题 <code>RMQ_SYS_TRANS_HALF_TOPIC</code> 中，使用的队列号固定为 <code>0</code>。<br>
这个主题和队列对消费者是不可见的，所以里面的消息永远不会被消费。这样，就保证了<strong>在事务提交成功之前，这个半消息对消费者来说是消费不到的。</strong></li>
</ol>
<p>Broker反查</p>
<ol>
<li>启动反查定时任务<br>
<code>TransactionalMessageCheckService</code></li>
<li>反查<br>
<code>org.apache.rocketmq.broker.transaction.AbstractTransactionalMessageCheckListener#resolveHalfMsg</code><br>
定时从半消息队列中读出所有待反查的半消息，针对每个需要反查的半消息，Broker 会给对应的 Producer 发一个要求执行事务状态反查的 RPC 请求，根据 RPC 返回响应中的反查结果，来决定这个半消息是需要提交还是回滚，或者后续继续来反查。</li>
<li>结束事务<br>
<code>org.apache.rocketmq.broker.processor.EndTransactionProcessor#processRequest</code><br>
最后，提交或者回滚事务实现的逻辑是差不多的，首先把半消息标记为已处理，如果是提交事务，那就把半消息从半消息队列中复制到这个消息真正的主题和队列中去，如果要回滚事务，这一步什么都不需要做，最后结束这个事务。</li>
</ol>
<h1>QA</h1>
<h2 id="消息队列可以做什么？"><a class="header-anchor" href="#消息队列可以做什么？">¶</a>消息队列可以做什么？</h2>
<p>异步处理耗时任务<br>
解耦上下游系统<br>
削峰填谷</p>
<h2 id="哪些消息队列可以做到在消息生产-消费过程中不重-不丢-exactly-once-？"><a class="header-anchor" href="#哪些消息队列可以做到在消息生产-消费过程中不重-不丢-exactly-once-？">¶</a>哪些消息队列可以做到在消息生产、消费过程中不重、不丢（Exactly once）？</h2>
<p>Kafka、RocketMQ、RabbitMQ都没有实现这个需求，因为要实现Exactly once，除了重发外还需要做幂等，实现比较复杂，而且对性能影响比较大。</p>
<h2 id="rocketmq发送-存储-接收的流程？"><a class="header-anchor" href="#rocketmq发送-存储-接收的流程？">¶</a>RocketMQ发送、存储、接收的流程？</h2>
<h2 id="当发现消费者不消费时-如何诊断问题？"><a class="header-anchor" href="#当发现消费者不消费时-如何诊断问题？">¶</a>当发现消费者不消费时，如何诊断问题？</h2>
<ol>
<li>检查连接状态，看消费者是否正常连接Broker；</li>
<li>看消费者是否有分配到ConsumeQueue，因为一个ConsumeQueue只能被一个消费者消费，所以消费者数量超过ConsumeQueue时，就会出现部分消费者没有ConsumeQueue可消费的情况；</li>
<li>生产者是否有正常消费，从控制台就可以看；</li>
<li>如果检查完以上步骤后仍然没有发现问题，则需要查看消费者的客户端日志再进一步分析。</li>
</ol>
<h2 id="怎么实现消息发送的严格顺序性？"><a class="header-anchor" href="#怎么实现消息发送的严格顺序性？">¶</a>怎么实现消息发送的严格顺序性？</h2>
<p>RMQ中的<strong>分区算法</strong>指的就是把消息发到固定的某些队列上，因为同一队列只能被一个消费者消费，因此可以保证这个队列中消息的顺序性。<br>
可选的分区算法如：</p>
<ol>
<li>在表中存储key和分区的对应关系，通过查表确定分区号；</li>
<li>取模</li>
</ol>
<h2 id="rocketmq能否做到单队列的并行消费？"><a class="header-anchor" href="#rocketmq能否做到单队列的并行消费？">¶</a>RocketMQ能否做到单队列的并行消费？</h2>
<p>RocketMQ 在消费的时候，为了保证消息的不丢失和严格顺序，每个队列只能串行消费（一个消费者可以消费多个队列），无法做到并发，否则会出现消费空洞的问题。那如果放宽一下限制，不要求严格顺序，能否做到单个队列的并行消费呢？</p>
<h2 id="怎么实现负载均衡？"><a class="header-anchor" href="#怎么实现负载均衡？">¶</a>怎么实现负载均衡？</h2>
<h2 id="rocketmq如何保证消息不丢？"><a class="header-anchor" href="#rocketmq如何保证消息不丢？">¶</a>RocketMQ如何保证消息不丢？</h2>
<h2 id="消费失败怎么重发的？"><a class="header-anchor" href="#消费失败怎么重发的？">¶</a>消费失败怎么重发的？</h2>
<h2 id="怎么判断消息堆积了？"><a class="header-anchor" href="#怎么判断消息堆积了？">¶</a>怎么判断消息堆积了？</h2>
<h2 id="刷盘的原理？"><a class="header-anchor" href="#刷盘的原理？">¶</a>刷盘的原理？</h2>
<ol>
<li>CommitLog</li>
<li>ConsumeLog</li>
</ol>
<h2 id="怎么实现消息复制-broker主从之间-？"><a class="header-anchor" href="#怎么实现消息复制-broker主从之间-？">¶</a>怎么实现消息复制（Broker主从之间）？</h2>
<h2 id="rocketmq-如何保证消息的高可用？"><a class="header-anchor" href="#rocketmq-如何保证消息的高可用？">¶</a>RocketMQ 如何保证消息的高可用？</h2>
<ol>
<li>NameServer 集群<br>
NameServer都是无状态的，即使挂掉其中几台，其他的仍可提供服务。</li>
<li>Broker多主多从<br>
Broker支持多主多从集群，即使其中某台Master挂掉了，其他Master照样可以提供服务，而且挂掉的Master，其从节点照样可以通过选举得到一个新的Master。</li>
</ol>
<h2 id="broker集群的master宕机-slave是怎么提供服务的？master是怎么切换回来的？"><a class="header-anchor" href="#broker集群的master宕机-slave是怎么提供服务的？master是怎么切换回来的？">¶</a>broker集群的master宕机，slave是怎么提供服务的？master是怎么切换回来的？</h2>
<h2 id="为什么-rocketmq-使用-nameserver-而不是-zookeeper-作为服务注册表"><a class="header-anchor" href="#为什么-rocketmq-使用-nameserver-而不是-zookeeper-作为服务注册表">¶</a>为什么 RocketMQ 使用 NameServer 而不是 ZooKeeper 作为服务注册表</h2>
<p>NameServer 具有高可用性，就算其中某台挂掉，其他服务器仍然能提供服务注册和查询功能。<br>
ZooKeeper 的设计目标是高一致性，其中某台服务器挂掉，整个 ZooKeeper 集群就无法提供服务了。</p>
<h2 id="nameserver是怎么感知broker的变化的？"><a class="header-anchor" href="#nameserver是怎么感知broker的变化的？">¶</a>NameServer是怎么感知Broker的变化的？</h2>
<h2 id="rocketmq的事务消息是否完整实现了事务的acid特性？"><a class="header-anchor" href="#rocketmq的事务消息是否完整实现了事务的acid特性？">¶</a>RocketMQ的事务消息是否完整实现了事务的ACID特性？</h2>
<h2 id="rocketmq使用某个消息序号messageid消费某个队列的消息-时间复杂度是多少？-假设消息文件commitlog数量为m-每个消息文件中消息条数是k-索引文件consumerqueue的数量是n-队列中共有j条消息"><a class="header-anchor" href="#rocketmq使用某个消息序号messageid消费某个队列的消息-时间复杂度是多少？-假设消息文件commitlog数量为m-每个消息文件中消息条数是k-索引文件consumerqueue的数量是n-队列中共有j条消息">¶</a>RocketMQ使用某个消息序号messageID消费某个队列的消息，时间复杂度是多少？（假设消息文件commitLog数量为m，每个消息文件中消息条数是k，索引文件consumerQueue的数量是n，队列中共有j条消息）</h2>
<p>复杂度是O(1)，因为消息序号中包含了消息在commitLog中的偏移量，因此可以直接通过偏移量来拿到消息。</p>
<h1>参考</h1>
<h2 id="环境"><a class="header-anchor" href="#环境">¶</a>环境</h2>
<ol>
<li><a href="https://www.cnblogs.com/miaoying/p/10319840.html" target="_blank" rel="noopener">rocketmq 控制台搭建（rocketmq-console）</a></li>
<li><a href="http://rocketmq.apache.org/docs/quick-start/" target="_blank" rel="noopener">Quick Start</a></li>
<li><a href="http://www.iocoder.cn/RocketMQ/build-debugging-environment/" target="_blank" rel="noopener">RocketMQ 源码解析 —— 调试环境搭建</a></li>
</ol>
<h2 id="原理"><a class="header-anchor" href="#原理">¶</a>原理</h2>
<ol>
<li><a href="https://github.com/apache/rocketmq/blob/master/docs/cn/features.md" target="_blank" rel="noopener">特性(features)</a></li>
<li><a href="https://github.com/apache/rocketmq/blob/master/docs/cn/design.md" target="_blank" rel="noopener">设计(design)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/91528718" target="_blank" rel="noopener">RocketMQ 实战(三) - 消息的有序性</a></li>
<li><a href="https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7" target="_blank" rel="noopener">事务消息</a></li>
<li><a href="http://www.iocoder.cn/categories/RocketMQ/" target="_blank" rel="noopener">RocketMQ 源码分析</a></li>
</ol>
<p>name-server 和 zookeeper 的取舍，主机配置拉的还是推的（拉）<br>
消费模式：根据 offset 消费 FROM_LAST_OFFSET、根据时间戳消费<br>
push 只能一个一个消费，poll 可以多线程并发消费（？）<br>
msgId 根据 queueNum 取模放到 broker 队列</p>
<p>如何保证消息一定能被消费：<br>
能发上去（默认 push 重试 3 次）<br>
能消费到（push 默认超时重试无限次、默认异常重试 16 次，过期或重试不成功则进入死信队列、默认凌晨 3 点清死信队列，业务逻辑需要保证幂等幂等 key 使用业务 oid 或 uniqId，注意 msgId 不是消息标识 Producer 端每次重试都会重新生成一个，消息必须要有唯一标识且保证处理成功与去重表的日志同时出现）<br>
挂掉不会丢（broker 两主两从，topic 需要给两台 master 都建上，producer 和 consumer 都访问 master，slave 作为 fallback 只在 master 挂掉时才访问，新版通过 nameserver 协调可以 slave 升主，slave 对 master30 秒探活，如果刷盘后挂掉消息不会丢，重启后可以同步到 slave）<br>
事务：2PC、3PC、TCC、消息列表驱动（本地事件列表驱动存 MySQL 由一个 Task 重试、外部事件列表驱动只有 ACK 才成功）<br>
无法保证百分之百的成功消费，因为 bug 总是可能出现的，这时必须要做对账（资金中的概念）<br>
负载均衡：Producer 负载均衡是回执负载均衡，如果 producer1 接收 ask 失败可以由 producer2 接收，Consumer 是消费负载均衡，一个失败换另一个消费<br>
广播：组内所有 Consumer 都会消费一次<br>
总而言之：重试机制、复制（两主都能接收到）、主从、幂等</p>
<p>instanceName 每个集群不一致，同一集群 groupName 不能重，两个 topic 的 groupName 不能一样<br>
本地最大缓存<br>
Consumer 序列化异常直接返回 SUCCESS，就不要重试了，<br>
两种模式本质都是拉：push 是构建长连接，一次拉完，一个一个给 broker 回执 ask，多个 Consumer 平分（必须是 4 的倍数，不够再给余数，比如 9 个消息三个 Consumer 分别拉到 4、4、1），poll 模式批量，按设定拉取</p>
<p>MySQL 页缓存：B+数，一个节点 4 个 key，每个 4k，4 个合一块 16k，符合 Linux 的 pageCache 大小，会一次性加载到 Linux 的 Buffer 里<br>
零拷贝：减少从内核进程拷贝数据到用户进程空间的耗时</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/1e6a7cbc.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/1e6a7cbc.html" itemprop="url">海量数据处理方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-07T22:01:47+08:00">
                2020-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  731 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1>海量数据处理方法</h1>
<p>当数据量特别大时，首先排除直接加载到内存中的算法，最核心的思路往往是<strong>分治</strong>，比如排序时先将大文件分割成多个足以加载到内存中的小文件，然后利用内存排序算法分别排序得到有序的一些小文件，最后通过归并排序得到最终的结果。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/1e6a7cbc.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/679dc1ee.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/679dc1ee.html" itemprop="url">MySQL 中的 CacheBuffer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-21T11:14:01+08:00">
                2020-07-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  16 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>Buffer Pool</h1>
<h2 id="buffer-pool-配置"><a class="header-anchor" href="#buffer-pool-配置">¶</a>Buffer Pool 配置</h2>
<ul>
<li><code>innodb_buffer_pool_size</code>：Buffer Pool 占用的总内存空间大小，单位是字节。</li>
<li><code>innodb_buffer_pool_instances</code>：访问 Buffer Pool 中的各种链表的时候都是需要加锁的，如果 Buffer Pool 特别大，且并发访问频率较高的情况下，会发生大量竞争，因此可以分配多个独立的小的 Buffer Pool。<br>
每个实例占用的内存空间为：<code>innodb_buffer_pool_size/innodb_buffer_pool_instances</code>。<br>
注意当<code>innodb_buffer_pool_size</code>的值小于 1G 的时候设置多个实例是无效的，InnoDB 会默认把 <code>innodb_buffer_pool_instances</code> 的值修改为 1。</li>
<li><code>innodb_buffer_pool_chunk_size</code>：出于对运行时可以方便调整 Buffer Pool 大小的考虑，每个 Buffer Pool 实例都是由若干 chunk 组成的。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2a5de8f2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
</ul>
<p>注意：</p>
<ul>
<li><code>innodb_buffer_pool_size</code>必须是<code>innodb_buffer_pool_chunk_size</code> × <code>innodb_buffer_pool_instances</code>的倍数</li>
<li>如果在服务器启动时，innodb_buffer_pool_chunk_size × innodb_buffer_pool_instances 的值已经大于 innodb_buffer_pool_size 的值，那么 innodb_buffer_pool_chunk_size 的值会被服务器自动设置为 innodb_buffer_pool_size/innodb_buffer_pool_instances 的值。</li>
</ul>
<h2 id="查看-buffer-pool-状态"><a class="header-anchor" href="#查看-buffer-pool-状态">¶</a>查看 Buffer Pool 状态</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINE INNODB STATUS</span><br></pre></td></tr></table></figure>
<ul>
<li>Total memory allocated：代表 Buffer Pool 向操作系统申请的连续内存空间大小，包括全部控制块、缓存页、以及碎片的大小。</li>
<li>Dictionary memory allocated：为数据字典信息分配的内存空间大小，注意这个内存空间和 Buffer Pool 没啥关系，不包括在 Total memory allocated 中。</li>
<li>Buffer pool size：代表该 Buffer Pool 可以容纳多少缓存页，注意，单位是页！</li>
<li>Free buffers：代表当前 Buffer Pool 还有多少空闲缓存页，也就是 free 链表中还有多少个节点。</li>
<li>Database pages：代表 LRU 链表中的页的数量，包含 young 和 old 两个区域的节点数量。</li>
<li>Old database pages：代表 LRU 链表 old 区域的节点数量。</li>
<li>Modified db pages：代表脏页数量，也就是 flush 链表中节点的数量。</li>
<li>Pending reads：正在等待从磁盘上加载到 Buffer Pool 中的页面数量。</li>
<li>当准备从磁盘中加载某个页面时，会先为这个页面在 Buffer Pool 中分配一个缓存页以及它对应的控制块，然后把这个控制块添加到 LRU 的 old 区域的头部，但是这个时候真正的磁盘页并没有被加载进来，Pending reads 的值会跟着加 1。</li>
<li>Pending writes LRU：即将从 LRU 链表中刷新到磁盘中的页面数量。</li>
<li>Pending writes flush list：即将从 flush 链表中刷新到磁盘中的页面数量。</li>
<li>Pending writes single page：即将以单个页面的形式刷新到磁盘中的页面数量。</li>
<li>Pages made young：代表 LRU 链表中曾经从 old 区域移动到 young 区域头部的节点数量。</li>
<li>这里需要注意，一个节点每次只有从 old 区域移动到 young 区域头部时才会将 Pages made young 的值加 1，也就是说如果该节点本来就在 young 区域，由于它符合在 young 区域 1/4 后边的要求，下一次访问这个页面时也会将它移动到 young 区域头部，但这个过程并不会导致 Pages made young 的值加 1。</li>
<li>Page made not young：在将 innodb_old_blocks_time 设置的值大于 0 时，首次访问或者后续访问某个处在 old 区域的节点时由于不符合时间间隔的限制而不能将其移动到 young 区域头部时，Page made not young 的值会加 1。</li>
<li>这里需要注意，对于处在 young 区域的节点，如果由于它在 young 区域的 1/4 处而导致它没有被移动到 young 区域头部，这样的访问并不会将 Page made not young 的值加 1。</li>
<li>youngs/s：代表每秒从 old 区域被移动到 young 区域头部的节点数量。</li>
<li>non-youngs/s：代表每秒由于不满足时间限制而不能从 old 区域移动到 young 区域头部的节点数量。</li>
<li>Pages read、created、written：代表读取，创建，写入了多少页。后边跟着读取、创建、写入的速率。</li>
<li>Buffer pool hit rate：表示在过去某段时间，平均访问 1000 次页面，有多少次该页面已经被缓存到 Buffer Pool 了。</li>
<li>young-making rate：表示在过去某段时间，平均访问 1000 次页面，有多少次访问使页面移动到 young 区域的头部了。</li>
<li>需要大家注意的一点是，这里统计的将页面移动到 young 区域的头部次数不仅仅包含从 old 区域移动到 young 区域头部的次数，还包括从 young 区域移动到 young 区域头部的次数（访问某个 young 区域的节点，只要该节点在 young 区域的 1/4 处往后，就会把它移动到 young 区域的头部）。</li>
<li>not (young-making rate)：表示在过去某段时间，平均访问 1000 次页面，有多少次访问没有使页面移动到 young 区域的头部。</li>
<li>需要大家注意的一点是，这里统计的没有将页面移动到 young 区域的头部次数不仅仅包含因为设置了 innodb_old_blocks_time 系统变量而导致访问了 old 区域中的节点但没把它们移动到 young 区域的次数，还包含因为该节点在 young 区域的前 1/4 处而没有被移动到 young 区域头部的次数。</li>
<li>LRU len：代表 LRU 链表中节点的数量。</li>
<li>unzip_LRU：代表 unzip_LRU 链表中节点的数量（由于我们没有具体唠叨过这个链表，现在可以忽略它的值）。</li>
<li>I/O sum：最近 50s 读取磁盘页的总数。</li>
<li>I/O cur：现在正在读取的磁盘页数量。</li>
<li>I/O unzip sum：最近 50s 解压的页面数量。</li>
<li>I/O unzip cur：正在解压的页面数量。</li>
</ul>
<h2 id="buffer-pool-的组成"><a class="header-anchor" href="#buffer-pool-的组成">¶</a>Buffer Pool 的组成</h2>
<h2 id="buffer-pool-的作用原理"><a class="header-anchor" href="#buffer-pool-的作用原理">¶</a>Buffer Pool 的作用原理</h2>
<h3 id="加载磁盘页面到-buffer-pool"><a class="header-anchor" href="#加载磁盘页面到-buffer-pool">¶</a>加载磁盘页面到 Buffer Pool</h3>
<p>当我们需要访问某页中的数据时，需要将该页加载到 Buffer Pool 内。<br>
InnoDB 中还存在两种特殊情况：</p>
<ul>
<li>预读<br>
预先将以后可能用到的页面加载到 Buffer Pool，根据加载方式还细分为线性预读和随机预读：<br>
线性预读：如果顺序访问了某个区（extent）的页面超过<code>innodb_read_ahead_threshold</code>这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，注意异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。<br>
随机预读：如果 Buffer Pool 中已经缓存了某个区的 13 个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool 的请求。<br>
如果预读的页面很常用，则可以极大地提高语句的执行效率，而如果并不常用的话，反而会将 LRU 链表尾部的缓存页被迅速淘汰掉，导致缓存命中率降低。</li>
<li>全表扫描<br>
全表扫描会导致大量页统统被加载到 Buffer Pool 内，这些页一般被使用到的频率也不高（全表扫描的执行频率不会太高），导致大大降低缓存命中率。</li>
</ul>
<h3 id="刷新脏页到磁盘"><a class="header-anchor" href="#刷新脏页到磁盘">¶</a>刷新脏页到磁盘</h3>
<p>后台有专门的线程每隔一段时间负责把脏页刷新到磁盘，这样可以不影响用户线程处理正常的请求。</p>
<ul>
<li>从<strong>LRU 链表</strong>的冷数据中刷新一部分页面到磁盘。<br>
后台线程会定时从 LRU 链表尾部开始扫描一些页面，扫描的页面数量可以通过系统变量<code>innodb_lru_scan_depth</code>来指定，如果从里边儿发现脏页，会把它们刷新到磁盘。这种刷新页面的方式被称之为<code>BUF_FLUSH_LRU</code>。</li>
<li>从<strong>flush 链表</strong>中刷新一部分页面到磁盘。<br>
后台线程也会定时从 flush 链表中刷新一部分页面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新页面的方式被称之为<code>BUF_FLUSH_LIST</code>。</li>
<li>同步刷新<br>
有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到 Buffer Pool 时没有可用的缓存页，这时就会尝试看看 LRU 链表尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将 LRU 链表尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为<code>BUF_FLUSH_SINGLE_PAGE</code>。</li>
</ul>
<h2 id="buffer-pool-内部组成"><a class="header-anchor" href="#buffer-pool-内部组成">¶</a>Buffer Pool 内部组成</h2>
<p>Buffer Pool 的基础组成部分是<strong>缓存页</strong>，大小和磁盘上的默认页大小一致都是 16KB，每一个缓存页都对应一个<strong>控制块</strong>。<br>
这些控制信息包括该页所属的表空间编号、页号、缓存页在 Buffer Pool 中的地址、链表节点信息、一些锁信息以及 LSN 信息，当然还有一些别的控制信息。<br>
每个页对应的控制信息占用的空间大小都是相同的，这块空间被称为<strong>控制块</strong>，控制块与缓存页之间是一一对应的关系，控制块被放到 Buffer Pool 的前面，而缓存页则被放到后面：<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2b9d6dd1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
中间碎片空间的产生是由于 Buffer Pool 中剩余的空间已经不够容纳一对控制块和缓存页的大小了。</p>
<h2 id="free-链表管理"><a class="header-anchor" href="#free-链表管理">¶</a>free 链表管理</h2>
<p>Buffer Pool 初始化时会被划分成若干对控制块和缓存页，随着程序的运行，会不断的有磁盘页被加载到 Buffer Pool 中、或从 Buffer Pool 中被释放，为了知道哪些页是空闲的、哪些页已经被占用了，MySQL 会将所有空闲的缓存页对应的控制块作为一个节点放到一个链表中，称为<strong>free 链表</strong>。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e300173c1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
注意 free 链表的结构中还有一个<strong>基节点</strong>，它是 Buffer Pool 外的一块空间，包含头节点（start）、尾节点（end）属性，主要用于定位这个 free 链表。</p>
<h2 id="缓存页的哈希表"><a class="header-anchor" href="#缓存页的哈希表">¶</a>缓存页的哈希表</h2>
<p>当我们需要访问某页中的数据时，需要将该页加载到 Buffer Pool 内，那么我们怎么知道该页是不是已经在 Buffer Pool 中了呢？其实是用一个<strong>哈希表</strong>来定位的，该哈希表的 key 为<code>表空间号 + 页号</code>、value 为缓存页。</p>
<h2 id="flush-链表管理"><a class="header-anchor" href="#flush-链表管理">¶</a>flush 链表管理</h2>
<p>当 Buffer Pool 中某个缓存页的内容被修改，则它和磁盘上的对应页就不一致了，这样的缓存页就被称为<code>脏页</code>，脏页并不会立刻被同步到磁盘上，而是会被加入到一个链表中，称为<code>flush链表</code>。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2ec4572a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<h2 id="lru-链表管理"><a class="header-anchor" href="#lru-链表管理">¶</a>LRU 链表管理</h2>
<p>当 Buffer Pool 中不再有空闲的缓存页时，我们需要淘汰掉部分最近很少使用的缓存页，所以 InnoDB 会使用一个<strong>LRU 链表</strong>来组织缓存页，并按<strong>最近最少使用</strong>原则来淘汰旧的缓存页：</p>
<ul>
<li>如果该页不在 Buffer Pool 中，在把该页从磁盘加载到 Buffer Pool 中的缓存页时，就把该缓存页对应的控制块作为节点塞到链表的头部。</li>
<li>如果该页已经缓存在 Buffer Pool 中，则直接把该页对应的控制块移动到 LRU 链表的头部。<br>
只要我们使用到某个缓存页，就把该缓存页调整到 LRU 链表的头部，这样 LRU 链表尾部就是最近最少使用的缓存页，每次 Buffer Pool 中的空闲缓存页被用完时，就会释放 LRU 链表尾部的页面。</li>
</ul>
<p>InnoDB 中还存在两种特殊情况：</p>
<ul>
<li>预读<br>
预先将以后可能用到的页面加载到 Buffer Pool，根据加载方式还细分为线性预读和随机预读：<br>
线性预读：如果顺序访问了某个区（extent）的页面超过<code>innodb_read_ahead_threshold</code>这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，注意异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。<br>
随机预读：如果 Buffer Pool 中已经缓存了某个区的 13 个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool 的请求。<br>
如果预读的页面很常用，则可以极大地提高语句的执行效率，而如果并不常用的话，反而会将 LRU 链表尾部的缓存页被迅速淘汰掉，导致缓存命中率降低。</li>
<li>全表扫描<br>
全表扫描会导致大量页统统被加载到 Buffer Pool 内，这些页一般被使用到的频率也不高（全表扫描的执行频率不会太高），导致大大降低缓存命中率。</li>
</ul>
<p>因此 InnoDB 中 LRU 链表被分成了两部分：</p>
<ul>
<li>
<p>一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做热数据，或者称 young 区域。</p>
</li>
<li>
<p>另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做冷数据，或者称 old 区域。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2a3fffa3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
</li>
<li>
<p>针对预读的页面可能不进行后续访问情况的优化<br>
当磁盘上的某个页面在初次加载到 Buffer Pool 中的某个缓存页时，该缓存页对应的控制块会被放到 old 区域的头部。这样针对预读到 Buffer Pool 却不进行后续访问的页面就会被逐渐从 old 区域逐出，而不会影响 young 区域中被使用比较频繁的缓存页。</p>
</li>
<li>
<p>针对全表扫描时，短时间内访问大量使用频率非常低的页面情况的优化<br>
全表扫描的页面首次会按上一条规则被加载到 old 区域的头部，之后一小段时间内这些页面由于访问频繁而被带入了 young 区，导致热数据被挤出了 young 区。因此 InnoDB 规定，在对某个处在 old 区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔（<code>innodb_old_blocks_time</code>）内，那么该页面就不会被从 old 区域移动到 young 区域的头部，否则将它移动到 young 区域的头部。</p>
</li>
</ul>
<h1>Change Buffer</h1>
<p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些<strong>更新操作</strong>缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。<br>
访问数据页时，需要将 change buffer 中的操作应用到原始页中，这个操作被称为<strong>merge</strong>。另外，系统后台定时任务线程、数据库正常关闭过程也会执行 merge 操作。<br>
change buffer 的好处包括：</p>
<ol>
<li>更新操作先记录到 change buffer，减少了读磁盘操作；</li>
<li>数据的读入需要占用 buffer pool，因此 change buffer 也避免了占用内存。</li>
</ol>
<h2 id="使用-change-buffer-的条件"><a class="header-anchor" href="#使用-change-buffer-的条件">¶</a>使用 change buffer 的条件</h2>
<p>使用 cache buffer 时需要注意以下两点：</p>
<ol>
<li>唯一索引的更新不能使用 change buffer。<br>
唯一索引的更新需要先判断这个操作是否违反唯一性约束，而这必须要将数据页读入内存才能判断，而已经读入内存的话，就没必要再使用 change buffer 了。<br>
因此唯一索引不能使用 change buffer，只有普通索引可以使用。</li>
<li>大小有限<br>
change buffer 使用的是 buffer pool 里的内存。</li>
<li>写多读少<br>
读操作才会触发 merge 操作，在 merge 前记录的数据变更越多，change buffer 的收益也越大，因此 change buffer 适合<strong>写多读少</strong>的业务，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。比如账单、日志类的系统。</li>
</ol>
<h2 id="使用建议"><a class="header-anchor" href="#使用建议">¶</a>使用建议</h2>
<ol>
<li>更新性能普通索引比唯一索引更高，建议尽量选择普通索引。</li>
<li>如果所有的更新后面都伴随着对这个记录的查询，那么最好应该关闭 change buffer。</li>
</ol>
<h2 id="redo-log-和-change-buffer-之间的区别"><a class="header-anchor" href="#redo-log-和-change-buffer-之间的区别">¶</a>redo log 和 change buffer 之间的区别</h2>
<ol>
<li>redo log 是任何写入操作都会记录的；change buffer 是在写入时页没有在内存中时使用的，将写入操作记录到 change buffer，而不是立刻读页面到 buffer pool 中；</li>
<li>redo log 减少随机写磁盘开销，change buffer 减少随机读；</li>
</ol>
<h2 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into a values(1, 2), (3, 4);</span><br></pre></td></tr></table></figure>
<p>插入两条数据，第一条<strong>数据所在的数据页</strong>在内存中，第二条不在，因此执行写入操作时，第一条不会使用到 change buffer，当然，最后二者都需要写入 redo log。</p>
<h1>QA</h1>
<h2 id="为什么唯一索引上不能使用change-buffer优化？"><a class="header-anchor" href="#为什么唯一索引上不能使用change-buffer优化？">¶</a>为什么唯一索引上不能使用change buffer优化？</h2>
<p>因为唯一索引需要将页读入内存来检查唯一性约束。</p>
<h2 id="唯一索引会比普通索引更快吗？"><a class="header-anchor" href="#唯一索引会比普通索引更快吗？">¶</a>唯一索引会比普通索引更快吗？</h2>
<p>不一定。<br>
一种唯一索引比普通索引快的说法是唯一索引只要找到一行就直接返回了，而普通索引会继续匹配下一行，直到发现不匹配的情况，所以唯一索引比普通索引少查几行。<br>
但是唯一索引不能利用change buffer优化。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/37173fb7.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/37173fb7.html" itemprop="url">MyBatis 原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-21T11:14:01+08:00">
                2020-07-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>MyBatis 整体结构</h1>
<p><img src="http://47.88.24.11/imgs/MyBatis/MyBatis%E7%BB%93%E6%9E%84.png" alt="MyBatis结构" title="MyBatis结构"></p>
<h1>配置文件</h1>
<p>配置类提供的功能几乎贯穿了整个处理过程：</p>
<ol>
<li>解析 Xml 文件</li>
<li>创建 SQL 处理器 Executor</li>
<li>对语句进行缓存 MappedStatement</li>
</ol>
<h2 id="怎么定位路径"><a class="header-anchor" href="#怎么定位路径">¶</a>怎么定位路径</h2>
<ul>
<li>getResourceAsStream</li>
</ul>
<h2 id="怎么解析文件"><a class="header-anchor" href="#怎么解析文件">¶</a>怎么解析文件</h2>
<p>xml 文件的解析方式有两种，一种 DOM 是直接读入整个 xml 文件，根据标签的嵌套关系构建一棵文档树；另一种方式叫 SAX（Simple API for XML），是一种事件驱动的文档解析方式，什么是事件驱动呢？比如说 SAX 驱动扫描到了起始标签，就代表发生了一个事件，它会转而调用某个由用户定义的函数（startElement）执行逻辑。<br>
有一种设计原则叫好莱坞法则（Hollywood），形象地说就是“你不要 call 我，需要你时我会 call 你”，一个例子是异步调用，这是一种通信机制，客户端在发出请求后不必等待服务端处理完毕就可以返回处理自己的逻辑，等到服务端处理完毕后再将结果传回，这种方式一定程度上可以解决客户端长期阻塞的问题、改善用户体验，回调函数也是一个例子。<br>
据网上的说法，DOM 需要一次构建整棵 DOM 树，所以比较占内存，不适合大的 xml 文档解析，但是由于 DOM 树上可以任意遍历，所以自由度很高，相对来说，SAX 是读到什么就调用什么回调函数，所以内存占用小，但是编程多少会复杂一些。</p>
<h1>构建数据库连接</h1>
<h2 id="数据库连接"><a class="header-anchor" href="#数据库连接">¶</a>数据库连接</h2>
<h3 id="sqlsessionfactorybuilder"><a class="header-anchor" href="#sqlsessionfactorybuilder">¶</a>SqlSessionFactoryBuilder</h3>
<p>应用了建造者模式，根据配置文件来创建 SqlSessionFactory，创建后其任务就结束了，生命周期在一个方法内。</p>
<h3 id="sqlsessionfactory"><a class="header-anchor" href="#sqlsessionfactory">¶</a>SqlSessionFactory</h3>
<p>创建和数据库连接的工具，在整个应用运行期间应该作为一个单例存在，或者使用依赖注入管理其生命周期。</p>
<h3 id="sqlsession"><a class="header-anchor" href="#sqlsession">¶</a>SqlSession</h3>
<p>代表和数据库的一次连接，在 MyBatis 中其实现是线程不安全的，生命周期最好控制在一次请求之间。</p>
<h2 id="数据源"><a class="header-anchor" href="#数据源">¶</a>数据源</h2>
<ul>
<li>DBCP</li>
<li>C3P0</li>
<li>Druid</li>
<li>MyBatis 内置数据源（UNPOOLED、POOLED、JNDI）</li>
<li>自定义数据源</li>
</ul>
<h2 id="映射器"><a class="header-anchor" href="#映射器">¶</a>映射器</h2>
<ul>
<li>mapper 文件</li>
<li>注解</li>
</ul>
<h1>SQL 执行</h1>
<p>SqlSession 本身是可以直接执行 sql 语句的，它的所有 update、query 等方法都是对语句进行了包装（MappedStatement），然后再调用 Executor 的相应方法，Executor 是执行器，是 MyBatis 的核心。<br>
SQL 的执行是由 Executor 负责的，Executor 对象是和 SqlSession 同时创建的，SqlSessionFactory 会为 Executor 创建事务，事务类默认为 ManagedTransactionFactory，Executor 需要从事务对象获取数据库连接（包装上一层事务后扩展性更好），事务会从环境对象中获取 DataSource 对象，然后委托 DataSource 创建连接，并且可以根据事务等级来为连接设置事务。说白了，把 Config 对象传给新建的 Transaction，由 Transaction 创建连接。<br>
Executor 并不是直接执行 SQL 语句，SQL 语句由 MappedStatement 包装，再交给 StatementHandler 执行</p>
<h1>Executor�</h1>
<p>MyBatis 提供 4 种 Executor，他们都继承于 BaseExecutor  �<br>
<strong>BaseExecutor</strong> 是一个抽象类，实现了延迟加载、一级缓存（PerpetualCache）等功能  �<br>
<strong>SimpleExecutor</strong> 语句使用 PreparedStatement 保存，使用 StatementHandler 处理  �<br>
<strong>ReuseExecutor</strong> 与 SimpleExecutor 的区别是它使用一个 Map&lt;String, Statement&gt;来缓存 SQL 语句对应的 Statement，如果某些 Sql 复杂且使用频繁的话可以使用这个执行器，因为这个 Map 不是静态的，并且 MyBatis 实际上会为每个新建的 SqlSession 创建一个 Executor，所以这个缓存只在同一个 Session 内有效  �</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private final Map&lt;String, Statement&gt; statementMap = new HashMap&lt;String, Statement&gt;();</span><br><span class="line">if (hasStatementFor(sql)) &#123;</span><br><span class="line">    //如果缓存中已经有了，直接得到Statement</span><br><span class="line">    stmt = getStatement(sql);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    //如果缓存没有找到，则和SimpleExecutor处理完全一样，然后加入缓存</span><br><span class="line">    Connection connection = getConnection(statementLog);</span><br><span class="line">    stmt = handler.prepare(connection);</span><br><span class="line">    putStatement(sql, stmt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>BatchExecutor（批量执行器）</strong> 将一些 SQL 语句放在一个 List 中，最后 doFlushStatements 一块执行，并且如果两个相邻的 SQL 语句是相同的，还会复用前一个 Statement 对象。<br>
<strong>CachingExecutor（二级缓存执行器）</strong> 为什么说是二级缓存？一级缓存由 BaseExecutor 中的 PerpetualCache 实现，CachingExecutor 会先在二级缓存中查找，如果找不到再委托给 delegate 执行，delegate 是 BaseExecutor 的子类，当然有一级缓存的功能。  �<br>
�</p>
<h1>参数类型和返回值�</h1>
<p>我们很多时候会指定 parameterType 和 resultType 为复杂类型，怎么将这些类型和数据库表结构进行映射正是 orm 框架的任务之一。  �<br>
parameterType 表示传入参数类型，在 sql 语句中可以使用#{参数名}来调用，比如�</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlSession.selectOne(&quot;com.tallate.UserMapper.selectUser&quot;, 1); </span><br></pre></td></tr></table></figure>
<p>传入了一个 Integer 类型的参数 1，那么 PreparedStatementHandler 在准备语句时，应该对这个参数的类型进行判断，这个是由 ParameterHandler 负责的。  �<br>
resultType 表示返回值类型，PreparedStatementHandler 在获得 ResultSet 后应该将查询到的表记录转换为 Java 对象，这个是由 ResultSetHandler 负责的，它最终会调用对应类的构造函数将查询出的结果传入。  �<br>
�</p>
<h1>动态代理�</h1>
<p>我们平常使用 MyBatis 时都会定义一个 XXMapper 接口，对应 mapper.xml 中的一个 namespace，而且我们也不必显示写出其实现类，调用过程都是由动态代理实现的。  �<br>
一般来说，代理类和被代理类应该实现相同的接口，但是现在我们的被代理类是一个 xxmapper.xml 文件，所以问题现在变成了：怎么将 xxmapper.xml 文件转换成被代理类。  �<br>
查看源码中的 MapperProxyFactory 和 MapperProxy 可以知道，MyBatis 实现 Mapper 接口其实是调用了 SqlSession 中的方法（select、selectOne 等，已经实现了），但是它们的方法名并不相同，比如 selectUser 怎么和 selectOne 关联上呢？  �<br>
MapperProxy 的 invoke 方法并不是直接调用被代理对象的方法，而是使用 MapperMethod 来表示映射的方法，通过 MapperMethod 可以判断接口方法的返回值、方法名等来确定应该调用 SqlSession 的哪个方法  �</p>
<ol>
<li>启动时 XMLConfigBuilder 会为 config.xml 中所有 mapper 节点扫描包下所有映射器�</li>
<li>创建对应的映射 interface -&gt; MapperProxyFactory�</li>
<li>添加动态代理对象到 MapperRegistry 中（我为了方便，直接加到 Config 中了，其实是刚开始对 MapperRegistry 的功能理解错了…）�</li>
<li>之后每次 getMapper，都可以根据接口名来找到对应的动态代理对象，调用方法时实际上是调用了相应的 MapperMethod�<br>
�</li>
</ol>
<h3 id="并发"><a class="header-anchor" href="#并发">¶</a>并发�</h3>
<p>有哪些资源是中心化的？如果是，会不会被多线程同时访问？在 web 环境中，假设每个用户代表一个线程，当他们同时访问服务器就会出现并发问题。  �</p>
<ul>
<li>线程池（数据源）  �<br>
如果线程池是使用链表（LinkedList）实现的，可以使用 Collections.synchronizedList 进行包装，或者直接使用 Vector  �</li>
<li>Map&lt;String, MappedStatement&gt; MappedStatements�<br>
使用 Map 容器储存 MappedStatement，MappedStatement 表示调用语句到 sql 语句的映射，比如&quot;namespace.selectUser&quot;到 mapper.xml 中对应的 sql 语句（使用 SqlSource 包装）。  �</li>
<li>List<environment> environments�<br>
表示 config.xml 中注册的所有环境对象列表  �</environment></li>
<li>List<mapperregistry> mappers�<br>
表示 config.xml 中注册的所有 mapper 的列表  �</mapperregistry></li>
<li>Map&lt;Method, MapperMethod&gt; methodCache�<br>
MapperProxyFactory 中的映射器方法缓冲是使用 ConcurrentHashMap 实现的  �<br>
�<br>
�</li>
</ul>
<h1>QA</h1>
<ol>
<li>一级缓存不够吗？为什么要有二级缓存？<br>
一级缓存是会话级缓存，在 BaseExecutor 中，是成员变量，生命周期在一个 SqlSession 内，连接断开就没了；<br>
二级缓存是语句级缓存，在 MappedStatement 中，可以跨多个 SqlSession，当一些数据不常发生变化或者允许偶尔的并发的时候，二级缓存可能更有效率。</li>
<li>为什么不推荐使用 MyBatis 中的缓存？<br>
一级缓存会产生脏数据。因为作用范围是会话，如果有俩会话，会话 1 加载数据到缓存，会话 2 修改该条数据，之后会话 1 读到的是缓存里的老数据。<br>
二级缓存同样会产生脏数据。二级缓存作用范围是语句，需要手动刷新或在 xml 中配置需要刷新，一般在写入操作和事务提交后都需要刷新一下。但是如果表 A 的 Amapper.xml 中关联了表 B，即使表 B 的数据有变更，我们在 Amapper.xml 中执行查询语句仍然会读到缓存中的脏数据。</li>
<li>MyBatis 与 JDBC 对象之前的关联？<br>
ParameterStatement - ParameterStatementHandler<br>
SimpleStatement - SimpleStatementHandler<br>
ResultSet - ResultSetHandler</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/4eb3381c.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/4eb3381c.html" itemprop="url">分布式锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-06T16:32:14+08:00">
                2020-07-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  12 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>单机环境下的锁</h1>
<p>单机环境下，资源竞争者都是来自机器内部(进程/线程)，那么实现锁的方案只需要借助单机资源就可以了，比如借助磁盘、内存、寄存器来实现。</p>
<h2 id="竞态条件-race-condition"><a class="header-anchor" href="#竞态条件-race-condition">¶</a>竞态条件（Race Condition）</h2>
<p>计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。比如：</p>
<ol>
<li>先检测（查询）后执行。执行依赖于检测的结果，而检测结果依赖于多个线程的执行时序，而多个线程的执行时序通常情况下是不固定不可判断的，从而导致执行结果出现各种问题。</li>
<li>延迟初始化（如单例的实例化） <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class ObjFactory &#123;  </span><br><span class="line">    private Obj instance;  </span><br><span class="line"></span><br><span class="line">    public Obj getInstance()&#123;  </span><br><span class="line">        if(instance == null)&#123;  </span><br><span class="line">            instance = new Obj();  </span><br><span class="line">        &#125;  </span><br><span class="line">        return instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果两个线程同时调用 getInstance()就有可能出现：一个线程 A 创建了一个新对象 instance = obj1，立马被另一个线程 B 覆盖 instance = obj2，线程 A 返回了 obj1，线程 B 返回 obj2，于是 Obj 就相当于被实例化了两次。</p>
<h2 id="锁的分类"><a class="header-anchor" href="#锁的分类">¶</a>锁的分类</h2>
<ol>
<li>悲观锁，前提是，一定会有并发抢占资源，强行独占资源，在整个数据处理过程中将数据处于锁定状态。</li>
<li>乐观锁，前提是，不会发生并发抢占资源，只有在<strong>执行修改时</strong>检查是否违反数据完整性。<strong>只能防止脏读后数据的提交，不能解决脏读</strong>。</li>
</ol>
<h2 id="悲观锁"><a class="header-anchor" href="#悲观锁">¶</a>悲观锁</h2>
<h2 id="乐观锁"><a class="header-anchor" href="#乐观锁">¶</a>乐观锁</h2>
<p>乐观锁一般有以下两种实现方法：</p>
<ol>
<li>版本号：使用<strong>版本标识</strong>来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取<strong>丢弃</strong>或<strong>再次尝试</strong>的策略。</li>
<li>CAS：java 中的 compareandswap 即 cas，解决多线程并行情况下使用锁造成性能损耗的一种机制。CAS 操作包含三个操作数，内存位置（V）,预期原值（A）和新值（B）。如果内存位置的值与预期原值相匹配，那么处理器会西东将该位置值更新为新值。否则，处理器不做任何操作。</li>
</ol>
<h1>分布式锁</h1>
<p>目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的<strong>CAP 理论</strong>告诉我们“任何一个分布式系统都无法同时满足<strong>一致性（Consistency）</strong>、<strong>可用性（Availability）<strong>和</strong>分区容错性（Partition tolerance）</strong>，最多只能同时满足其中两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。<br>
有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java 中其实提供了很多并发处理相关的 API，但是这些 API 在分布式场景中就无能为力了。也就是说单纯的 Java Api 并不能提供分布式锁的能力。<br>
对于分布式环境下，资源竞争者生存环境更复杂了，原有依赖单机的方案不再发挥作用，这时候就需要一个大家都认可的协调者出来，帮助解决竞争问题，那这个协调者称之为分布式锁。</p>
<h2 id="实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的"><a class="header-anchor" href="#实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的">¶</a>实现分布式锁的需求（方法锁，以方法作为临界区，资源锁是类似的）</h2>
<ol>
<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li>
<li>这把锁要是一把可重入锁（单线程可重复获取同一把锁，避免死锁）</li>
<li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li>
<li>有高可用的获取锁和释放锁功能</li>
<li>获取锁和释放锁的性能要好</li>
</ol>
<h2 id="基于数据库表"><a class="header-anchor" href="#基于数据库表">¶</a>基于数据库表</h2>
<p>要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。<br>
当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。<br>
创建这样一张数据库表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `methodLock` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;,</span><br><span class="line">  `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;,</span><br><span class="line">  `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;,</span><br><span class="line">  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="使用锁表实现方法锁"><a class="header-anchor" href="#使用锁表实现方法锁">¶</a>使用锁表实现方法锁</h3>
<p>执行 SQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)</span><br></pre></td></tr></table></figure>
<p>因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。<br>
当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from methodLock where method_name =&apos;method_name&apos;</span><br></pre></td></tr></table></figure>
<p>上面这种简单的实现有以下几个问题：</p>
<ul>
<li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li>
<li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li>
<li>这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li>
<li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据库中数据已经存在了。</li>
</ul>
<p>当然，我们也可以有其他方式解决上面的问题。</p>
<ul>
<li>数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。</li>
<li>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。</li>
<li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li>
<li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li>
</ul>
<h3 id="使用数据库-x-锁-排他锁-实现分布式锁"><a class="header-anchor" href="#使用数据库-x-锁-排他锁-实现分布式锁">¶</a>使用数据库 X 锁（排他锁）实现分布式锁</h3>
<p>除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。<br>
我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。<br>
基于 MySQL 的 InnoDB 引擎，可以使用以下方法来实现加锁操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean lock()&#123;</span><br><span class="line">    connection.setAutoCommit(false)</span><br><span class="line">    while(true)&#123;</span><br><span class="line">        try&#123;</span><br><span class="line">            result = select * from methodLock where method_name = xxx for update;</span><br><span class="line">            if(result==null)&#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;catch(Exception e)&#123;</span><br><span class="line">            log.warn(&quot;加锁失败&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">        sleep(1000);</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。<br>
我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public void unlock()&#123;</span><br><span class="line">    connection.commit();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过 connection.commit()操作来释放锁。<br>
这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p>
<ul>
<li>阻塞锁？ for update 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li>
<li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。<br>
但是还是无法直接解决数据库单点和可重入问题。</li>
</ul>
<h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3>
<p>总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。<br>
数据库实现分布式锁的优点：</p>
<ol>
<li>直接借助数据库，容易理解。</li>
</ol>
<p>数据库实现分布式锁的缺点</p>
<ol>
<li>会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。</li>
<li>操作数据库需要一定的开销，性能问题需要考虑。</li>
</ol>
<h2 id="基于缓存"><a class="header-anchor" href="#基于缓存">¶</a>基于缓存</h2>
<p>使用缓存中间件实现分布式锁的方法我已经在<a href="https://tallate.github.io/d3d5fdbf.html#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">Redis 客户端</a>中有过分析。</p>
<h2 id="基于-zookeeper"><a class="header-anchor" href="#基于-zookeeper">¶</a>基于 ZooKeeper</h2>
<p>基于 zookeeper 临时有序节点可以实现的分布式锁。<br>
大致思想即为：每个客户端对某个方法加锁时，在 zookeeper 上的与该方法对应的指定节点的目录下，生成一个唯一的<strong>瞬时有序节点</strong>。<br>
判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。<br>
当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。<br>
来看下 Zookeeper 能不能解决前面提到的问题。</p>
<ul>
<li>锁无法释放？使用 Zookeeper 可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在 ZK 中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session 连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。</li>
<li>非阻塞锁？使用 Zookeeper 可以实现阻塞的锁，客户端可以通过在 ZK 中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper 会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。</li>
<li>不可重入？使用 Zookeeper 也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。</li>
<li>单点问题？使用 Zookeeper 可以有效的解决单点问题，ZK 是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</li>
</ul>
<h3 id="使用-curator-实现分布式锁"><a class="header-anchor" href="#使用-curator-实现分布式锁">¶</a>使用 Curator 实现分布式锁</h3>
<p>可以直接使用 zookeeper 第三方库 Curator 客户端，这个客户端中封装了一个可重入的锁服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        return interProcessMutex.acquire(timeout, unit);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line">public boolean unlock() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        interProcessMutex.release();</span><br><span class="line">    &#125; catch (Throwable e) &#123;</span><br><span class="line">        log.error(e.getMessage(), e);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Curator 提供的 InterProcessMutex 是分布式锁的实现。acquire 方法用户获取锁，release 方法用于释放锁。<br>
使用 ZK 实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper 实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK 中创建和删除节点只能通过<strong>Leader</strong>服务器来执行，然后将数据同步到所有的 Follower 机器上。</p>
<h3 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结</h3>
<p>使用 Zookeeper 实现分布式锁的优点</p>
<ol>
<li>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。</li>
<li>实现起来较为简单。</li>
</ol>
<p>使用 Zookeeper 实现分布式锁的缺点</p>
<ol>
<li>性能上不如使用缓存实现分布式锁。</li>
<li>需要对 ZK 的原理有所了解。</li>
</ol>
<h1>QA</h1>
<ol>
<li>怎么使用 Redis 实现分布式锁？<br>
set 命令带上 nx 和 ex 参数。</li>
<li>怎么使用 zk 实现分布式锁？<br>
先建一个代表锁的持久节点，然后每个线程要加锁就在该持久节点下创建临时有序节点，如果当前线程创建的节点是最小的，则说明可以获取到该锁，否则阻塞等待；释放锁就是将这个临时节点删除。</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/garfieldcgf/p/6380816.html" target="_blank" rel="noopener">分布式锁的几种实现方式</a></li>
<li><a href="https://www.cnblogs.com/dennyzhangdd/p/7133653.html#_label0" target="_blank" rel="noopener">终极锁实战：单 JVM 锁+分布式锁</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a87bf883.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/a87bf883.html" itemprop="url">MySQL 的其他主题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-30T10:18:28+08:00">
                2020-05-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>常用服务器配置</h1>
<ul>
<li>启动选项和系统变量<br>
启动选项是运维启动 MySQL 时传入的一些参数，包括命令行启动选项和配置文件 my.cnf<br>
系统变量会影响 MySQL 进程的运行行为，大部分是由启动选项初始化的，有些是运行时自动生成的</li>
<li>查看系统变量<br>
<code>show [GLOBAL|SESSION] variables [like 匹配的模式];</code></li>
<li>配置文件中配置组的概念</li>
<li>配置作用范围<br>
1、GLOBAL 指配置文件或命令行启动选项设置的系统变量<br>
2、SESSION（LOCAL）刚连接时会被初始化为 GLOBAL 的变量，可以通过以下命令来设置<br>
<code>SET [GLOBAL|SESSION] 系统变量名 = 值;</code></li>
<li>状态变量<br>
指关于程序运行状态的变量，是只读的，不能手动修改<br>
比方说 Threads_connected 表示当前有多少客户端与服务器建立了连接，Handler_update 表示已经更新了多少行记录<br>
SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];</li>
</ul>
<h1>InnoDB 统计数据</h1>
<h2 id="两种统计数据"><a class="header-anchor" href="#两种统计数据">¶</a>两种统计数据</h2>
<p>InnoDB 中有两种统计数据：<br>
1、永久性：服务器重启也不会消失，这些数据被存储到了<code>innodb_table_stats</code>和<code>innodb_index_stats</code>这两张表中；<br>
2、非永久性：重启即消失。<br>
可以通过服务器的<code>innodb_stats_persistent</code>变量来查看这个统计数据的方式。</p>
<h2 id="innodb-table-stats-统计方式"><a class="header-anchor" href="#innodb-table-stats-统计方式">¶</a>innodb_table_stats 统计方式</h2>
<p>1、n_rows(一个表中的记录行数)统计项的收集<br>
按照一定算法选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的 n_rows 值<br>
2、clustered_index_size 和 sum_of_other_index_sizes</p>
<ul>
<li>从数据字典里找到表的各个索引对应的根页面位置。<br>
系统表 SYS_INDEXES 里存储了各个索引对应的根页面信息。</li>
<li>从根页面的 Page Header 里找到叶子节点段和非叶子节点段对应的 Segment Header。<br>
在每个索引的根页面的 Page Header 部分都有两个字段：<br>
PAGE_BTR_SEG_LEAF：表示 B+树叶子段的 Segment Header 信息。<br>
PAGE_BTR_SEG_TOP：表示 B+树非叶子段的 Segment Header 信息。</li>
<li>从叶子节点段和非叶子节点段的 Segment Header 中找到这两个段对应的 INODE Entry 结构。<br>
这个是 Segment Header 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b165a91f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>从对应的 INODE Entry 结构中可以找到该段对应所有零散的页面地址以及 FREE、NOT_FULL、FULL 链表的基节点。<br>
这个是 INODE Entry 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b1e44524?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>直接统计零散的页面有多少个，然后从那三个链表的 List Length 字段中读出该段占用的区的大小，每个区占用 64 个页，所以就可以统计出整个段占用的页面。<br>
这个是链表基节点的示意图：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b17c24e3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>分别计算聚簇索引的叶子结点段和非叶子节点段占用的页面数，它们的和就是 clustered_index_size 的值，按照同样的套路把其余索引占用的页面数都算出来，加起来之后就是 sum_of_other_index_sizes 的值。</li>
</ul>
<h2 id="innodb-index-stats-统计方式"><a class="header-anchor" href="#innodb-index-stats-统计方式">¶</a>innodb_index_stats 统计方式</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM mysql.innodb_index_stats WHERE table_name = &apos;single_table&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>n_leaf_pages：表示该索引的叶子节点占用多少页面。</li>
<li>size：表示该索引共占用多少页面。</li>
<li>n_diff_pfxNN：表示对应的索引列不重复的值有多少。其中的 NN 长得有点儿怪呀，啥意思呢？<br>
其实 NN 可以被替换为 01、02、03… 这样的数字。比如对于 idx_key_part 来说：<br>
n_diff_pfx01 表示的是统计 key_part1 这单单一个列不重复的值有多少。<br>
n_diff_pfx02 表示的是统计 key_part1、key_part2 这两个列组合起来不重复的值有多少。<br>
n_diff_pfx03 表示的是统计 key_part1、key_part2、key_part3 这三个列组合起来不重复的值有多少。<br>
n_diff_pfx04 表示的是统计 key_part1、key_part2、key_part3、id 这四个列组合起来不重复的值有多少。</li>
<li>在计算某些索引列中包含多少不重复值时，需要对一些叶子节点页面进行采样，sample_size 列就表明了采样的页面数量是多少。</li>
</ul>
<h2 id="基于内存的非永久性统计数据"><a class="header-anchor" href="#基于内存的非永久性统计数据">¶</a>基于内存的非永久性统计数据</h2>
<p>开启非永久性统计数据的方法：<br>
1、将<code>innodb_stats_persistent</code>的值设置为 OFF；<br>
2、直接在创建表或修改表时设置<code>STATS_PERSISTENT</code>属性的值为 0；</p>
<h1>MySQL Server 统计数据</h1>
<p>Server 层而不是 InnoDB（存储引擎层）统计数据。<br>
1、查看连接数配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;%max_connections%&apos;</span><br></pre></td></tr></table></figure>
<p>2、查看当前连接数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show full processlist;</span><br></pre></td></tr></table></figure>
<h1>数据恢复</h1>
<p>数据的误删基本分以下几种情况：</p>
<ol>
<li>使用 delete 语句误删数据行；</li>
<li>使用 drop table 或 truncate table 误删表；</li>
<li>使用 drop database 误删数据库；</li>
<li>使用 rm 命令误删整个 MySQL 实例。</li>
</ol>
<h2 id="误删行"><a class="header-anchor" href="#误删行">¶</a>误删行</h2>
<p>使用 Flashback 工具通过闪回把数据恢复。<br>
Flashback 恢复数据的原理，是<strong>修改 binlog 的内容</strong>（事务里的语句顺序颠倒、语句的语义颠倒比如 insert 变成 delete），拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。</p>
<h2 id="误删库-表"><a class="header-anchor" href="#误删库-表">¶</a>误删库 / 表</h2>
<p>误删库表的情况不能使用 Flashback 恢复，因为即使配置 binlog_format=row，truncate/drop 语句在 binlog 中也只会记录一条对应的语句，而用这些信息是无法恢复数据的。<br>
这种情况下，恢复需要使用全量备份，加增量日志。这个方案要求线上有定期的全量备份，并且实时备份 binlog。</p>
<h2 id="rm-删除数据"><a class="header-anchor" href="#rm-删除数据">¶</a>rm 删除数据</h2>
<p>仅仅删除某个节点的数据的情况，HA 系统可以选出新的主库，从而保证整个集群的正常工作。<br>
之后，我们可以在这个被删节点上把数据恢复回来，再接入整个集群。</p>
<h1>中断查询</h1>
<p>有时候因为查询耗时过长，或出现死锁等待，我们不得不提早终止执行 SQL 的线程，可以通过<code>information_schema.processlist</code> 和 <code>performance_schema.threads</code>这两张表来查看正在执行的线程：</p>
<ul>
<li>processlist 表中每一行对应一个客户端连接，也对应一个线程；</li>
<li>threads 每一行对应一个线程。</li>
</ul>
<p><code>kill query pid</code>可以杀死线程，但是客户端的连接还在，可以看到被 kill 后该连接进入了 Sleep 状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Id, User, Host, db, Command, Time, State, Info</span><br><span class="line">&apos;494633&apos;, &apos;beta&apos;, &apos;192.168.19.142:56193&apos;, &apos;ds_0&apos;, &apos;Sleep&apos;, &apos;26&apos;, &apos;&apos;, NULL</span><br></pre></td></tr></table></figure>
<p><code>kill pid</code>可以中断连接，执行后再用<code>processlist</code>就找不到那个 pid 了。</p>
<p>在客户端 Ctrl + C 并不能中断服务器线程，只能中断客户端进程，</p>
<h1>大表查询</h1>
<h2 id="server-层"><a class="header-anchor" href="#server-层">¶</a>Server 层</h2>
<p>MySQL 使用缓存来保证一次性查询大量数据的情况下不会把服务器内存打满，服务器并不需要保存一个完整的结果集。取数据和发数据的流程如下：<br>
<img src="http://47.88.24.11/imgs/MySQL/MySQL-%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="MySQL-查询结果发送流程" title="MySQL-查询结果发送流程"></p>
<ol>
<li>获取一行，写到 <strong>net_buffer</strong> 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。</li>
<li>重复获取行，直到 net_buffer 写满，调用网络接口发出去。</li>
<li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。</li>
<li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示**本地网络栈（socket send buffer）**写满了，进入等待。直到网络栈重新可写，再继续发送。</li>
</ol>
<p>从上面的流程可知，MySQL 一次查询占用的内存是有限的，最大是<strong>min(net_buffer_length, socket send buffer)</strong>，即不能超过 net_buffer_length 和 socket send buffer；</p>
<h2 id="存储引擎层-innodb"><a class="header-anchor" href="#存储引擎层-innodb">¶</a>存储引擎层（InnoDB）</h2>
<p>InnoDB 使用 Buffer Pool 管理内存数据页，如果 Buffer Pool 命中率足够高，那么大部分时候是不需要读磁盘的，直接从内存拿结果，可以加快查询速度。<br>
执行 <code>show engine innodb status</code> ，可以看到“<code>Buffer pool hit rate</code>”字样，显示的就是当前的命中率，一般一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。<br>
Buffer Pool 的空间是有限的，新旧页面的更替是通过 LRU 算法控制的，但 InnoDB 中的 LRU 并不是单纯的新页面替换老页面（因为这样相当于每次大查询都会把整个 Buffer Pool 都刷新一遍），而是将 LRU 链表分成了 young 区和 old 区，页面第一次被访问时会被添加到 old 区，old 区的页面如果是短期内被多次访问，则其不会被移动到链表的头部（young 区），会很快被淘汰掉。</p>
<h1>临时表</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t like t1;</span><br><span class="line">alter table temp_t add index(b);</span><br><span class="line">insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;</span><br><span class="line">select * from t1 join temp_t on (t1.b=temp_t.b);</span><br></pre></td></tr></table></figure>
<p>临时表特性：</p>
<ol>
<li>不同 session 的临时表是可以重名的，常被用在复杂查询的优化过程中，比如有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</li>
<li>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。</li>
</ol>
<h2 id="临时表的使用场景"><a class="header-anchor" href="#临时表的使用场景">¶</a>临时表的使用场景</h2>
<h3 id="union-语句"><a class="header-anchor" href="#union-语句">¶</a>union 语句</h3>
<p>表 t1 在执行前已初始化插入了 1~1000 的数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure>
<p><img src="http://47.88.24.11/imgs/MySQL/MySQL-union%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-union执行流程" title="MySQL-union执行流程"><br>
上面语句将两个子查询的结果合并去重，union 合并时会生成临时表，这可以通过 explain 来验证。</p>
<h3 id="group-by"><a class="header-anchor" href="#group-by">¶</a>group by</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure>
<p><img src="http://47.88.24.11/imgs/MySQL/MySQL-groupby%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-groupby执行流程" title="MySQL-groupby执行流程"><br>
上面语句先创建内存临时表，表里有 m 和 c 两个字段，主键是 m，扫描 t1 索引 a，将<code>id%10</code>的结果插入临时表，如果出现主键冲突则计算 c 值+1。</p>
<ol>
<li>加索引<br>
默认情况下<code>id%10</code>是无序的，所以需要先在临时表中统计排序后再返回，但是如果原表本身就是有序的，则不需要临时表、也不需要额外排序了，实际上只要引入索引就可以解决这个问题，因为<strong>索引是有序的</strong>。</li>
<li>如果不能加索引，也可以加一列 generated column<br>
MySQL5.7 支持 generated column 机制，并可以在该列上创建索引：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);</span><br></pre></td></tr></table></figure>
<p>上面的 group by 语句可以改成如下的形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure>
<ol>
<li>如果不需要排序，可以显式声明忽略排序<br>
如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null</li>
<li>数据量小时使用内存临时表<br>
如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；</li>
<li>数据量大时使用磁盘临时表<br>
如果数据量较大，因为内存临时表的空间是有限的，当达到上限后就会转到磁盘内存表，与其这样转一下，不如直接使用磁盘内存表。<br>
因此，如果数据量实在太大，使用 <code>SQL_BIG_RESULT</code> 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。</li>
</ol>
<h1>Memory 引擎</h1>
<h2 id="memory-引擎与-innodb-引擎区别"><a class="header-anchor" href="#memory-引擎与-innodb-引擎区别">¶</a>Memory 引擎与 InnoDB 引擎区别</h2>
<ol>
<li>数据组织方式<br>
InnoDB 引擎采用 B+树来组织数据，主键是有序存储的。InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为<strong>索引组织表（Index Organizied Table）</strong>。<br>
Memory 引擎的数据和索引是分开的，数据以数组的方式单独存放，而主键索引是 hash 索引，存的是每个数据的位置，索引上的 key 并不是有序的：<br>
<img src="http://47.88.24.11/imgs/MySQL/MySQL-Memory%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87.png" alt="MySQL-Memory引擎数据组织" title="MySQL-Memory引擎数据组织"><br>
Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为<strong>堆组织表（Heap Organizied Table）</strong>。</li>
<li>存放顺序<br>
InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li>
<li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li>
<li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；</li>
<li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li>
<li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</li>
</ol>
<h2 id="hash-索引和-b-tree-索引"><a class="header-anchor" href="#hash-索引和-b-tree-索引">¶</a>hash 索引和 B-Tree 索引</h2>
<p>内存表也支持 B-Tree 索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure>
<p><img src="http://47.88.24.11/imgs/MySQL/MySQL-%E5%86%85%E5%AD%98%E8%A1%A8B-Tree%E7%B4%A2%E5%BC%95.png" alt="MySQL-内存表B-Tree索引" title="MySQL-内存表B-Tree索引"><br>
可以查看以下两个语句的输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 命中索引a_btree_index，因此输出结果是有序的</span><br><span class="line">select * from t1 where id &lt; 5;</span><br><span class="line">-- 强制使用主键id索引，因此是无序的</span><br><span class="line">select * from t1 force index (primary) where id &lt; 5;</span><br></pre></td></tr></table></figure>
<h2 id="不推荐在生产环境使用-memory-引擎"><a class="header-anchor" href="#不推荐在生产环境使用-memory-引擎">¶</a>不推荐在生产环境使用 Memory 引擎</h2>
<ol>
<li>锁粒度问题<br>
内存表不支持行锁，只支持表锁，只要这张表上有更新，就会堵住所有其他在这张表上的读写操作，因此在处理并发事务时性能也不会太好。</li>
<li>数据持久化问题<br>
因为数据被存放在内存中，数据库重启时所有的内存表都会被清空。</li>
</ol>
<p>虽然一般情况下不适合使用内存表，但是还有一种情况可以考虑使用内存表：用户临时表，只是临时数据，如果数据可控，不会消耗过多内存的情况下，可以考虑使用内存表。<br>
内存临时表（通过 create temporary table 语句创建）刚好可以无视内存表的两个不足，主要是下面的三个原因：</p>
<ol>
<li>临时表不会被其他线程访问，没有并发性的问题；</li>
<li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
</ol>
<h1>备份</h1>
<ul>
<li>将数据导出成一组 insert 语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where=&quot;a&gt;900&quot; --result-file=/client_tmp/t.sql</span><br></pre></td></tr></table></figure>
<p>恢复：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source /client_tmp/t.sql&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>导出 CSV 文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from db1.t where a&gt;900 into outfile &apos;/server_tmp/t.csv&apos;;</span><br></pre></td></tr></table></figure>
<p>恢复，将数据导入到目标表 db2.t 中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &apos;/server_tmp/t.csv&apos; into table db2.t;</span><br></pre></td></tr></table></figure>
<ul>
<li>物理拷贝<br>
不能通过直接拷贝表的.frm 文件和.ibd 文件来实现物理拷贝，因为一个 InnoDB 表除了包含这两个物理文件外，还需要在数据字典中注册，直接拷贝的情况下系统不会识别。<br>
在 MySQL 5.6 版本引入了<strong>可传输表空间(transportable tablespace)</strong> 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。
<ol>
<li>执行 create table r like t，创建一个相同表结构的空表；</li>
<li>执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；</li>
<li>执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；</li>
<li>在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；</li>
<li>这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；</li>
<li>执行 unlock tables，这时候 t.cfg 文件会被删除；</li>
<li>执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。</li>
</ol>
</li>
</ul>
<p>这三种方法各有优劣：</p>
<ol>
<li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
<ul>
<li>必须是全表拷贝，不能只拷贝部分数据；</li>
<li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；……</li>
<li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li>
</ul>
</li>
<li>用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。</li>
<li>用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</li>
</ol>
<h1>MySQL 中的自增 ID</h1>
<h2 id="表的自增-id"><a class="header-anchor" href="#表的自增-id">¶</a>表的自增 id</h2>
<p>我们经常给表的主键加上自增属性，用于唯一标识一条记录，但是因为自增值达到上限后再申请得到的值不变，因此自增字段的范围应该略大一些，尽可能创建成<code>bigint unsigned</code>。</p>
<h2 id="row-id"><a class="header-anchor" href="#row-id">¶</a>row_id</h2>
<p>如果没有指定主键，InnoDB 会创建一个不可见的、长度为 6 字节的 row_id，超过上限后再申请时会得到 0，<strong>如果新写入的行的 row_id 在表中已存在，则会直接覆盖原有的行</strong>，因此，最好优先使用自增 ID 而不是 row_id。</p>
<h2 id="xid"><a class="header-anchor" href="#xid">¶</a>Xid</h2>
<p>Xid 用于唯一标识一个事务。Xid 的值由一个内存变量 global_query_id 给出，重启后清零，但是因为每次重启时 binlog 都会重新生成，所以 binlog 中的 Xid 也不会重复。global_query_id 的长度为 8 个字节，除非 MySQL 实例一直执行了<code>2^64 - 1</code>次查询且期间没有重启，不然不会出现 Xid 重复的情况。</p>
<h2 id="max-trx-id"><a class="header-anchor" href="#max-trx-id">¶</a>max_trx_id</h2>
<p>Xid 由 server 层维护。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。<br>
InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。</p>
<blockquote>
<p>InnoDB 事务在读操作时不会申请 trx_id，trx_id 的值就是 0，只有在加锁或执行写操作时才会申请。<br>
只读事务不申请 trx_id 的原因是只读事务不影响事务的可见性判断，且能减少 trx_id 的申请次数、减少并发事务申请 trx_id 的锁冲突。</p>
</blockquote>
<p>MVCC 判断数据可见性的核心思想：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。</p>
<h2 id="thread-id"><a class="header-anchor" href="#thread-id">¶</a>thread_id</h2>
<p>系统保存一个全局变量 thread_id_counter，每新建一个连接就将 thread_id_counter 赋值给这个新连接的线程变量。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f2150593.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f2150593.html" itemprop="url">Netty 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-29T10:18:28+08:00">
                2020-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  30 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>为什么使用 Netty</h1>
<ol>
<li>实现协议的局限性<br>
今天，我们使用通用的应用程序或者类库来实现互相通讯，比如，我们经常使用一个 HTTP 客户端库来从 web 服务器上获取信息，或者通过 web 服务来执行一个远程的调用。<br>
然而，有时候一个通用的协议或他的实现并没有很好的满足需求。比如我们无法使用一个通用的 HTTP 服务器来处理大文件、电子邮件以及近实时消息，比如金融信息和多人游戏数据。我们需要一个高度优化的协议来处理一些特殊的场景。例如你可能想实现一个优化了的 Ajax 的聊天应用、媒体流传输或者是大文件传输器，你甚至可以自己设计和实现一个全新的协议来准确地实现你的需求。<br>
另一个不可避免的情况是当你不得不处理遗留的专有协议来确保与旧系统的互操作性。在这种情况下，重要的是我们如何才能快速实现协议而不牺牲应用的稳定性和性能。</li>
<li>使用 Netty 可以有效改善这种情况<br>
Netty 是一个提供 asynchronous event-driven （异步事件驱动）的网络应用框架，是一个用以快速开发高性能、高可靠性协议的服务器和客户端。<br>
换句话说，Netty 是一个 NIO 客户端服务器框架，使用它可以快速简单地开发网络应用程序，比如服务器和客户端的协议。Netty 大大简化了网络程序的开发过程比如 TCP 和 UDP 的 socket 服务的开发。<br>
“快速和简单”并不意味着应用程序会有难维护和性能低的问题，Netty 是一个精心设计的框架，它从许多协议的实现中吸收了很多的经验比如 FTP、SMTP、HTTP、许多二进制和基于文本的传统协议.因此，Netty 已经成功地找到一个方式,在不失灵活性的前提下来实现开发的简易性，高性能，稳定性。<br>
有一些用户可能已经发现其他的一些网络框架也声称自己有同样的优势，所以你可能会问是 Netty 和它们的不同之处。答案就是 Netty 的哲学设计理念。Netty 从开始就为用户提供了用户体验最好的 API 以及实现设计。正是因为 Netty 的哲学设计理念，才让您得以轻松地阅读本指南并使用 Netty。</li>
</ol>
<h1>架构总览</h1>
<p><img src="http://47.88.24.11/imgs/Netty/Netty%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88.png" alt="Netty架构总览" title="Netty架构总览"><br>
Netty 的架构由三部分组成——缓冲（buffer），通道（channel），事件模型（event model）——所有的高级特性都构建在这三个核心组件之上。</p>
<h1>NIO</h1>
<ol>
<li><a href="https://segmentfault.com/q/1010000010446129" target="_blank" rel="noopener">想了解 Aio 与 Nio 的利弊，为什么 Netty 没有采用 Aio 实现？</a></li>
</ol>
<p>NIO 基于传输层，可以自定义数据处理逻辑来作为应用层，或者基于现有的 HTTP 组件进行升级，在线上环境这样的升级会带来一些兼容性问题，HTTP 已有相应的协议升级机制：<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism" target="_blank" rel="noopener">Protocol upgrade mechanism</a>。</p>
<p>NIO 相对 BIO 优势：</p>
<ol>
<li>零拷贝<br>
零拷贝减少线程上下文切换次数，且数据直接拷贝到内核空间，不占用 JVM 堆空间；</li>
<li>减少线程资源浪费<br>
NIO 可以一个线程监听多个 Socket 的连接、读、写请求，而不是像 BIO 那样每个 Socket 创建一个线程，但是同时会有一个问题：</li>
</ol>
<h2 id="netty-核心组件"><a class="header-anchor" href="#netty-核心组件">¶</a>Netty 核心组件</h2>
<ol>
<li>Channel 和 ChannelHandler</li>
<li>ByteBuf</li>
<li>Pipeline</li>
</ol>
<h1>服务端</h1>
<h2 id="代码"><a class="header-anchor" href="#代码">¶</a>代码</h2>
<p>下面是一个启动Netty服务端的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ServerBootstrap bootstrap = new ServerBootstrap();</span><br><span class="line">        bootstrap.group(bossGroup(), workerGroup())</span><br><span class="line">                .channel(NioServerSocketChannel.class)</span><br><span class="line">                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                    @Override</span><br><span class="line">                    protected void initChannel(SocketChannel ch) throws Exception &#123;</span><br><span class="line">                        // 空闲检测</span><br><span class="line">                        ch.pipeline().addLast(&quot;idleStateHandler&quot;, new IdleStateHandler(15, 0, 0,</span><br><span class="line">                                TimeUnit.MINUTES));</span><br><span class="line"></span><br><span class="line">                        // 半包/粘包分解器</span><br><span class="line">                        ch.pipeline().addLast(</span><br><span class="line">                                new DelimiterBasedFrameDecoder(2048, true, getFirstBytes()</span><br><span class="line">                                ));</span><br><span class="line">                        ch.pipeline().addLast(其他Handler比如解码之类的);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).option(ChannelOption.SO_BACKLOG, 1024);</span><br><span class="line">bootstrap.bind(10885).sync()</span><br></pre></td></tr></table></figure>
<h2 id="创建eventloop"><a class="header-anchor" href="#创建eventloop">¶</a>创建EventLoop</h2>
<p>在上面的代码中，出现了<strong>bossGroup</strong>和<strong>workerGroup</strong>，bossGroup主要负责监听连接，拿到连接后，交给workerGroup中的线程来监听读或写事件。<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup</code><br>
<code>EventExecutorGroup</code>会给每个线程创建一个<code>EventLoop</code>。</p>
<p><code>io.netty.channel.nio.NioEventLoop#NioEventLoop</code><br>
<code>newChild()</code>创建EventLoop实例，其默认实现是<code>NioEventLoop</code>。</p>
<p><code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code><br>
服务器初始化过程中创建了个线程池<code>ThreadPerTaskExecutor</code>：</p>
<ul>
<li>每次执行任务都会构造一个线程执行<br>
<code>io.netty.util.concurrent.ThreadPerTaskExecutor#execute</code></li>
</ul>
<h2 id="创建及初始化-serversocketchannel"><a class="header-anchor" href="#创建及初始化-serversocketchannel">¶</a>创建及初始化 ServerSocketChannel</h2>
<p>Netty 有一个叫做 <strong>Channel</strong> 的统一的异步 I/O 编程接口，这个编程接口抽象了所有点对点的通信操作。也就是说，如果你的应用是基于 Netty 的某一种传输实现，那么同样的，你的应用也可以运行在 Netty 的另一种传输实现上。Netty 提供了几种拥有相同编程接口的基本传输实现：</p>
<ul>
<li>基于 NIO 的 TCP/IP 传输 (见 io.netty.channel.nio),</li>
<li>基于 OIO 的 TCP/IP 传输 (见 io.netty.channel.oio),</li>
<li>基于 OIO 的 UDP/IP 传输, 和</li>
<li>本地传输 (见 io.netty.channel.local).</li>
</ul>
<p>切换不同的传输实现通常只需对代码进行几行的修改调整，例如选择一个不同的 <strong>ChannelFactory</strong> 实现。<br>
此外，你甚至可以利用新的传输实现没有写入的优势，只需替换一些构造器的调用方法即可，例如串口通信。而且由于核心 API 具有高度的可扩展性，你还可以完成自己的传输实现。</p>
<ol>
<li>入口<br>
<code>io.netty.bootstrap.AbstractBootstrap#bind(int)</code><br>
用户代码调用bind绑定端口时会触发Channel的创建和初始化</li>
</ol>
<p><code>io.netty.bootstrap.ServerBootstrap#init</code><br>
对Channel的使用可以追溯到这个init方法，包括Channel的创建、属性等的设置。</p>
<ol>
<li>
<p>创建<br>
<code>NioServerSocketChannel</code>的构造方法 -&gt; <code>io.netty.channel.socket.nio.NioServerSocketChannel#newSocket</code><br>
可以看到，Netty中的<code>ServerSocketChannel</code>其实就对应JDK NIO中的<code>ServerSocketChannel</code>，在创建<code>NioServerSocketChannel</code>的同时创建了一个NIO中的<code>ServerSocketChannel</code>。</p>
</li>
<li>
<p>初始化<br>
中间包含对<code>childOptions</code>和<code>childAttrs</code>等的设置。</p>
</li>
<li>
<p>添加一个连接处理器<code>ServerBootstrapAcceptor</code>。</p>
</li>
</ol>
<h2 id="注册selector"><a class="header-anchor" href="#注册selector">¶</a>注册Selector</h2>
<p>紧接着上面的初始化过程，接下来是注册NIO中的Selector。<br>
<code>io.netty.channel.EventLoopGroup#register(io.netty.channel.Channel)</code><br>
总而言之最终还是使用NIO注册了 Selector。<br>
<code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
<h3 id="启动-nioeventloop"><a class="header-anchor" href="#启动-nioeventloop">¶</a>启动 NioEventLoop</h3>
<p><code>io.netty.bootstrap.AbstractBootstrap#doBind0</code><br>
绑定端口号的同时，执行一个线程。<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#startThread</code><br>
NioEventLoop启动流程的最终启动了一个线程。<br>
<code>io.netty.channel.nio.NioEventLoop#run</code><br>
该线程任务根据EventLoop的实现不同而有所不同，在<code>NioEventLoop</code>中，主要任务为以下3步：</p>
<ol>
<li>
<p>接收事件（selectionKey）<br>
<code>io.netty.channel.nio.NioEventLoop#select</code><br>
当检查没有需要处理的selectionKey时就会发生空轮询，Netty在轮询时会记录空轮询次数，<strong>当空轮询达到一定次数时，将之前注册的事件先取消，从而避免了NIO的空轮询Bug</strong>。</p>
</li>
<li>
<p>检测新连接并创建NioSocketChannel<br>
<code>io.netty.channel.nio.NioEventLoop#processSelectedKeys</code><br>
处理连接请求，并分发请求到<strong>pipeline</strong><br>
<code>io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe#read</code></p>
<ul>
<li>每个连接创建一个<strong>ServerSocketChannel</strong>。<br>
<code>io.netty.channel.socket.nio.NioServerSocketChannel#doReadMessages</code></li>
<li>读取数据并分发到<strong>pipeline</strong><br>
<code>io.netty.channel.ChannelPipeline#fireChannelReadComplete</code></li>
</ul>
</li>
<li>
<p>执行线程任务<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#runAllTasks(long)</code></p>
</li>
</ol>
<h2 id="pipeline中的第一个channelhandler"><a class="header-anchor" href="#pipeline中的第一个channelhandler">¶</a>pipeline中的第一个ChannelHandler</h2>
<p>pipeline的第一个Handler为ServerBootstrapAcceptor，它的主要任务包括：</p>
<ol>
<li>
<p>将用户自定义<code>ChannelHandler</code>添加到pipeline</p>
</li>
<li>
<p>选择一个<code>NioEventLoop</code>传播事件<br>
<code>io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel)</code></p>
</li>
<li>
<p>注册selector<br>
代码流程非常长，但是最终可以跟到<code>doRegister</code>这个方法，可以发现最后还是调用了JDK的SocketChannel注册Selector。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code> -&gt; <code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
</li>
<li>
<p>注册读事件<br>
代码最后判断第一次连接则触发连接激活事件，代码位置仍然是上边的<code>register0</code>。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code><br>
继续往下看可以看到最终将读事件（selectionKey）注册到了Selector<br>
<code>io.netty.channel.DefaultChannelPipeline.HeadContext#channelActive</code><br>
-&gt; <code>io.netty.channel.DefaultChannelPipeline.HeadContext#readIfIsAutoRead</code><br>
-&gt; <code>io.netty.channel.nio.AbstractNioChannel#doBeginRead</code></p>
</li>
</ol>
<p>选择EventLoop：<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#chooser</code><br>
每当有客户端连接进来时，Netty需要决定选择哪个EventLoop，这个工作是由<code>EventExecutorChooser</code>负责的：</p>
<ul>
<li><code>GenericEventExecutorChooser</code>：循环选择。</li>
<li><code>PowerOfTwoEventExecutorChooser</code>：也是循环选择，只不过<code>GenericEventExecutorChooser</code>使用了取模运算，而<code>PowerOfTwoEventExecutorChooser</code>是通过位运算实现的。</li>
</ul>
<h2 id="pipeline"><a class="header-anchor" href="#pipeline">¶</a>Pipeline</h2>
<ol>
<li>
<p>创建Pipeline<br>
创建NioSocketChannel时会创建Pipeline：<br>
<code>io.netty.channel.AbstractChannel#AbstractChannel</code><br>
Pipeline本身是一个<strong>双向链表</strong>的结构，且有两个哨兵节点<code>head</code>和<code>tail</code>。</p>
</li>
<li>
<p>添加Pipeline<br>
添加到链表<br>
<code>io.netty.channel.ChannelPipeline#addLast(io.netty.channel.ChannelHandler...)</code><br>
检查是否重复添加，如果加了<code>@Sharable</code>注解是可以重复添加的<br>
<code>io.netty.channel.DefaultChannelPipeline#checkMultiplicity</code><br>
添加到链表末尾，也就是添加到<code>tail</code>节点的前面。<br>
<code>io.netty.channel.DefaultChannelPipeline#addLast0</code></p>
</li>
<li>
<p>删除Pipeline<br>
有时候我们需要删除一个Pipeline上的某些ChannelHandler，比如已经进行过了授权校验，那下次就不需要再执行授权校验了，我们就可以直接把授权相关的那些ChannelHandler删除掉。<br>
首先遍历Pipeline找到目标ChannelHandler。<br>
<code>io.netty.channel.DefaultChannelPipeline#getContextOrDie</code><br>
然后从Pipeline中移除。<br>
<code>io.netty.channel.DefaultChannelPipeline#remove(AbstractChannelHandlerContext)</code></p>
</li>
<li>
<p>inBound事件传播<br>
ChannelHandler中每个事件都有一个接口，<code>ChannelInboundHandler</code>专门处理输入事件，以<code>channelRead</code>为例。<br>
EventLoop会将读事件传给Pipeline，然后按责任链模式的逻辑从<code>head</code>节点开始传播事件。<br>
<code>io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read</code></p>
</li>
<li>
<p>outBound事件传播<br>
<code>ChannelOutboundHandler</code>专门用于处理输出事件，以<code>write</code>为例。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class EchoServerOutHandler extends ChannelOutboundHandlerAdapter &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123;</span><br><span class="line">        ctx.channel().write(&quot;Hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们在Handler中调用Context的write方法时，就是将写事件传给了Pipeline，Pipeline会从<code>tail</code>节点开始往前传播。<br>
<code>io.netty.channel.AbstractChannelHandlerContext#write</code></p>
<h2 id="心跳检测"><a class="header-anchor" href="#心跳检测">¶</a>心跳检测</h2>
<p>应用协议层的心跳是必须的，它和 tcp keepalive 是完全不同的概念。应用层协议层的心跳检测的是连接双方的存活性，兼而连接质量，而 keepalive 检测的是连接本身的存活性。而且后者的超时时间默认过长，完全不能适应现代的网络环境。<br>
Netty 内置通过增加 <code>IdleStateHandler</code> 产生 IDLE 事件进行便捷的心跳控制。你要处理的，就是心跳超时的逻辑，比如延迟重连。但它的轮训时间是固定的，无法动态修改，高级功能需要自己定制。<br>
不同场景下需要切换不同的保活机制，在一些客户端比如 Android，频繁心跳的唤起会浪费大量的网络和电量，它的心跳策略会更加复杂一些。</p>
<h2 id="优雅退出"><a class="header-anchor" href="#优雅退出">¶</a>优雅退出</h2>
<p>Java 的优雅停机通常通过注册 JDK ShutdownHook 来实现。<br>
Runtime.getRuntime().addShutdownHook();<br>
一般通过 kill -15 进行 java 进程的关闭，以便在进程死亡之前进行一些清理工作。</p>
<blockquote>
<p>注意：kill -9 会立马杀死进程，不给遗言的机会，比较危险。</p>
</blockquote>
<p>虽然 netty 做了很多优雅退出的工作，通过 EventLoopGroup 的 shutdownGracefully 方法对 nio 进行了一些状态设置，但在很多情况下，这还不够多。它只负责单机环境的优雅关闭。<br>
流量可能还会通过外层的路由持续进入，造成无效请求。一种可行的做法是首先在外层路由进行一次本地实例的摘除，把流量截断，然后再进行 netty 本身的优雅关闭。</p>
<h2 id="示例协议实现"><a class="header-anchor" href="#示例协议实现">¶</a>示例协议实现</h2>
<p>不少中间件会实现自己的协议，比如 Redis、MySQL，MyCat、TiDB 用的就是 MySQL 协议。<br>
netty 默认实现了 dns、haproxy、http、http2、memcache、mqtt、redis、smtp、socks、stomp、xml 等协议。<br>
协议分为两种：</p>
<ul>
<li>文本协议在调试起来是比较直观和容易的，但安全性欠佳；</li>
<li>二进制协议就需要依赖日志、wireshark 等其他方式进行分析，增加了开发难度。</li>
</ul>
<ol>
<li><a href="https://netty.io/4.0/xref/io/netty/example/echo/package-summary.html" target="_blank" rel="noopener">示例协议 - echo</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/discard/package-summary.html" target="_blank" rel="noopener">示例协议 - discard</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/uptime/package-summary.html" target="_blank" rel="noopener">示例协议 - uptime</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/factorial/package-summary.html" target="_blank" rel="noopener">示例二进制协议 - factorial</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/telnet/package-summary.html" target="_blank" rel="noopener">示例文本协议 - telnet</a></li>
</ol>
<h1>数据结构 - ByteBuf</h1>
<p>Netty 使用自建的 buffer API，而不是使用 NIO 的 <a href="http://docs.oracle.com/javase/7/docs/api/java/nio/ByteBuffer.html?is-external=true" target="_blank" rel="noopener">ByteBuffer</a> 来表示一个连续的字节序列。与 ByteBuffer 相比这种方式拥有明显的优势。Netty 使用新的 buffer 类型 <a href="http://netty.io/4.0/api/io/netty/buffer/ByteBuf.html" target="_blank" rel="noopener">ByteBuf</a>，被设计为一个可从底层解决 ByteBuffer 问题，并可满足日常网络应用开发需要的缓冲类型。这些很酷的特性包括：</p>
<ul>
<li>如果需要，允许使用自定义的缓冲类型。</li>
<li>复合缓冲类型中内置的透明的零拷贝实现。</li>
<li>开箱即用的动态缓冲类型，具有像 StringBuffer 一样的动态缓冲能力。</li>
<li>不再需要调用的 flip()方法。</li>
<li>正常情况下具有比 ByteBuffer 更快的响应速度。</li>
</ul>
<p><img src="http://47.88.24.11/imgs/Netty/ByteBuf%E7%BB%93%E6%9E%84.png" alt="ByteBuf结构" title="ByteBuf结构"><br>
以上就是一个 ByteBuf 的结构图，从上面这幅图可以看到</p>
<ol>
<li>ByteBuf 是一个字节容器，容器里面的的数据分为三个部分，第一个部分是已经丢弃的字节，这部分数据是无效的；第二部分是可读字节，这部分数据是 ByteBuf 的主体数据， 从 ByteBuf 里面读取的数据都来自这一部分;最后一部分的数据是可写字节，所有写到 ByteBuf 的数据都会写到这一段。最后一部分虚线表示的是该 ByteBuf 最多还能扩容多少容量</li>
<li>以上三段内容是被两个指针给划分出来的，从左到右，依次是读指针（readerIndex）、写指针（writerIndex），然后还有一个变量 capacity，表示 ByteBuf 底层内存的总容量</li>
<li>从 ByteBuf 中每读取一个字节，readerIndex 自增 1，ByteBuf 里面总共有 writerIndex-readerIndex 个字节可读, 由此可以推论出当 readerIndex 与 writerIndex 相等的时候，ByteBuf 不可读</li>
<li>写数据是从 writerIndex 指向的部分开始写，每写一个字节，writerIndex 自增 1，直到增到 capacity，这个时候，表示 ByteBuf 已经不可写了</li>
<li>ByteBuf 里面其实还有一个参数 maxCapacity，当向 ByteBuf 写数据的时候，如果容量不足，那么这个时候可以进行扩容，直到 capacity 扩容到 maxCapacity，超过 maxCapacity 就会报错</li>
</ol>
<p>使用 ByteBuf 有以下好处：</p>
<ol>
<li>
<p>可以有效地区分可读数据和可写数据，读写之间相互没有冲突</p>
</li>
<li>
<p>Extensibility 可扩展性<br>
ByteBuf 具有丰富的操作集,可以快速的实现协议的优化。例如，ByteBuf 提供各种操作用于访问无符号值和字符串，以及在缓冲区搜索一定的字节序列。你也可以扩展或包装现有的缓冲类型用来提供方便的访问。自定义缓冲式仍然实现自 ByteBuf 接口，而不是引入一个不兼容的类型</p>
</li>
<li>
<p>Transparent Zero Copy 透明的零拷贝<br>
网络应用中需要减少内存拷贝操作次数。你可能有一组缓冲区可以被组合以形成一个完整的消息。网络提供了一种复合缓冲，允许你从现有的任意数的缓冲区创建一个新的缓冲区而无需内存拷贝。例如，一个信息可以由两部分组成：header 和 body。在一个模块化的应用，当消息发送出去时，这两部分可以由不同的模块生产和装配。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+--------+------+</span><br><span class="line">| header | body |</span><br><span class="line">+--------+------+</span><br></pre></td></tr></table></figure>
<p>如果你使用的是 ByteBuffer ，你必须要创建一个新的大缓存区用来拷贝这两部分到这个新缓存区中。或者，你可以在 NIO做一个收集写操作，但限制你将复合缓冲类型作为 ByteBuffer 的数组而不是一个单一的缓冲区，这样打破了抽象，并且引入了复杂的状态管理。此外，如果你不从 NIO channel 读或写，它是没有用的。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型不兼容。</span><br><span class="line">ByteBuffer[] message = new ByteBuffer[] &#123; header, body &#125;;</span><br></pre></td></tr></table></figure>
<p>通过对比， ByteBuf 不会有警告，因为它是完全可扩展并有一个内置的复合缓冲区。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型是兼容的。</span><br><span class="line">ByteBuf message = Unpooled.wrappedBuffer(header, body);</span><br><span class="line">// 因此，你甚至可以通过混合复合类型与普通缓冲区来创建一个复合类型。</span><br><span class="line">ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer);</span><br><span class="line">// 由于复合类型仍是 ByteBuf，访问其内容很容易，</span><br><span class="line">//并且访问方法的行为就像是访问一个单独的缓冲区，</span><br><span class="line">//即使你想访问的区域是跨多个组件。</span><br><span class="line">//这里的无符号整数读取位于 body 和 footer</span><br><span class="line">messageWithFooter.getUnsignedInt(</span><br><span class="line">     messageWithFooter.readableBytes() - footer.readableBytes() - 1);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Automatic Capacity Extension 自动容量扩展<br>
许多协议定义可变长度的消息，这意味着没有办法确定消息的长度，直到你构建的消息。或者，在计算长度的精确值时，带来了困难和不便。这就像当你建立一个字符串。你经常估计得到的字符串的长度，让 StringBuffer 扩大了其本身的需求。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 一种新的动态缓冲区被创建。在内部，实际缓冲区是被“懒”创建，从而避免潜在的浪费内存空间。</span><br><span class="line">ByteBuf b = Unpooled.buffer(4);</span><br><span class="line">// 当第一个执行写尝试，内部指定初始容量 4 的缓冲区被创建</span><br><span class="line">b.writeByte(&apos;1&apos;);</span><br><span class="line">b.writeByte(&apos;2&apos;);</span><br><span class="line">b.writeByte(&apos;3&apos;);</span><br><span class="line">b.writeByte(&apos;4&apos;);</span><br><span class="line">// 当写入的字节数超过初始容量 4 时，</span><br><span class="line">//内部缓冲区自动分配具有较大的容量</span><br><span class="line">b.writeByte(&apos;5&apos;);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Better Performance 更好的性能<br>
最频繁使用的缓冲区 ByteBuf 的实现是一个非常薄的字节数组包装器（比如，一个字节）。与 ByteBuffer 不同，它没有复杂的边界和索引检查补偿，因此对于 JVM 优化缓冲区的访问更加简单。更多复杂的缓冲区实现是用于拆分或者组合缓存，并且比 ByteBuffer 拥有更好的性能。</p>
</li>
</ol>
<h2 id="粘包拆包和半包合并"><a class="header-anchor" href="#粘包拆包和半包合并">¶</a>粘包拆包和半包合并</h2>
<p>基于流的传输比如 TCP/IP, 接收到数据是存在 socket 接收的 buffer 中。不幸的是，基于流的传输并不是一个数据包队列，而是一个字节队列。造成粘包的原因，主要是由于缓冲区的介入，所以需要严格约定去所传输的包的格式——何时开始何时结束。意味着，即使你发送了 2 个独立的数据包，操作系统也不会作为 2 个消息处理而仅仅是作为一连串的字节而言。因此这是不能保证你远程写入的数据就会准确地读取。举个例子，让我们假设操作系统的 TCP/TP 协议栈已经接收了 3 个数据包，在应用程序中读取数据的时候可能被分成下面的片段：<br>
<img src="http://47.88.24.11/imgs/Netty/%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85%E9%97%AE%E9%A2%98.png" alt="粘包和半包问题" title="粘包和半包问题"><br>
因此，一个接收方不管他是客户端还是服务端，都应该把接收到的数据整理成一个或者多个更有意义并且能够让程序的业务逻辑更好理解的数据。<br>
在没有 Netty 的情况下，用户如果自己需要拆包，基本原理就是不断从 TCP 缓冲区中读取数据，每次读取完都需要判断是否是一个完整的数据包</p>
<ul>
<li>半包：如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。</li>
<li>粘包：如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。</li>
</ul>
<h2 id="解码器-bytetomessagedecoder"><a class="header-anchor" href="#解码器-bytetomessagedecoder">¶</a>解码器 - ByteToMessageDecoder</h2>
<p>入口：<code>io.netty.handler.codec.ByteToMessageDecoder#channelRead</code></p>
<ol>
<li>累加字节流<br>
累加器累加已读入的字节数，如果超过<code>ByteBuf</code>当前可读入的空间大小，则执行扩容。<br>
<code>io.netty.handler.codec.ByteToMessageDecoder.Cumulator#cumulate</code></li>
<li>调用子类的decode方法进行解析（模板方法）<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#callDecode</code></li>
<li>将子类解析出的ByteBuf向下传播<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#fireChannelRead(io.netty.channel.ChannelHandlerContext, io.netty.handler.codec.CodecOutputList, int)</code></li>
</ol>
<h2 id="netty中的一些拆箱即用的解码器"><a class="header-anchor" href="#netty中的一些拆箱即用的解码器">¶</a>Netty中的一些拆箱即用的解码器</h2>
<p>如果要自己实现所有协议的拆包无疑是非常麻烦的，实际上 Netty 已经自带了一些开箱即用的拆包器：</p>
<ol>
<li>固定长度的拆包器 <code>FixedLengthFrameDecoder</code><br>
如果你的应用层协议非常简单，每个数据包的长度都是固定的，比如 100，那么只需要把这个拆包器加到 pipeline 中，Netty 会把一个个长度为 100 的数据包 (ByteBuf) 传递到下一个 channelHandler。</li>
<li>行拆包器 <code>LineBasedFrameDecoder</code><br>
从字面意思来看，发送端发送数据包的时候，每个数据包之间以<strong>换行符</strong>作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包。</li>
<li>分隔符拆包器 <code>DelimiterBasedFrameDecoder</code><br>
DelimiterBasedFrameDecoder 是行拆包器的通用版本，只不过我们可以自定义分隔符。</li>
<li>基于长度域拆包器 <code>LengthFieldBasedFrameDecoder</code><br>
最后一种拆包器是最通用的一种拆包器，只要你的自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包。由于上面三种拆包器比较简单，读者可以自行写出 demo，接下来，我们就结合我们小册的自定义协议，来学习一下如何使用基于长度域的拆包器来拆解我们的数据包。</li>
</ol>
<h2 id="编码-messagetobyteencoder"><a class="header-anchor" href="#编码-messagetobyteencoder">¶</a>编码 - MessageToByteEncoder</h2>
<p>编码器是一个ChannelHandler，一般是第一个添加到Pipeline内，然后write的最后会将数据进行编码再输出。</p>
<ol>
<li>匹配对象<br>
<code>io.netty.handler.codec.MessageToByteEncoder#acceptOutboundMessage</code></li>
<li>内存分配<br>
<code>io.netty.handler.codec.MessageToByteEncoder#allocateBuffer</code></li>
<li>调用子类的编码实现<br>
<code>io.netty.handler.codec.MessageToByteEncoder#encode</code></li>
<li>释放内存<br>
<code>io.netty.util.ReferenceCountUtil#release(java.lang.Object)</code></li>
<li>放到Pipeline里传播<br>
默认情况下会一直传播到<code>head</code>节点<br>
<code>io.netty.channel.ChannelHandlerContext#write(java.lang.Object, io.netty.channel.ChannelPromise)</code><br>
<code>io.netty.channel.Channel.Unsafe#write</code></li>
<li>输出<br>
将数据暂存到ByteBuf，将堆内对象转换为堆外内存<br>
<code>io.netty.channel.nio.AbstractNioByteChannel#filterOutboundMessage</code><br>
插入写队列<br>
<code>io.netty.channel.ChannelOutboundBuffer#addMessage</code><br>
TODO: 什么时候刷新buffer队列？</li>
</ol>
<h1>自定义数据处理逻辑</h1>
<h2 id="基于拦截链模式的事件模型-pipeline"><a class="header-anchor" href="#基于拦截链模式的事件模型-pipeline">¶</a>基于拦截链模式的事件模型 - pipeline</h2>
<p>一个定义良好并具有扩展能力的事件模型是事件驱动开发的必要条件。Netty 具有定义良好的 I/O 事件模型。由于严格的层次结构区分了不同的事件类型，因此 Netty 也允许你在不破坏现有代码的情况下实现自己的事件类型。这是与其他框架相比另一个不同的地方。很多 NIO 框架没有或者仅有有限的事件模型概念；在你试图添加一个新的事件类型的时候常常需要修改已有的代码，或者根本就不允许你进行这种扩展。<br>
在 Netty 中一条连接对应一个 Channel，该 Channel 的所有处理逻辑都在一个 ChannelPipeline 对象内，ChannelPipeline 是一个双向链表结构，在一个 ChannelPipeline 内部一个 <a href=".">ChannelEvent</a> 被一组 ChannelHandler 处理。这个管道是 Intercepting Filter (拦截过滤器)模式的一种高级形式的实现，因此对于一个事件如何被处理以及管道内部处理器间的交互过程，你都将拥有绝对的控制力。例如，你可以定义一个从 socket 读取到数据后的操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyReadHandler implements SimpleChannelHandler &#123;</span><br><span class="line">     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">         Object message = evt.getMessage();</span><br><span class="line">         // Do something with the received message.</span><br><span class="line">            ...</span><br><span class="line">         // And forward the event to the next handler.</span><br><span class="line">         ctx.sendUpstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时你也可以定义一种操作响应其他处理器的写操作请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyWriteHandler implements SimpleChannelHandler &#123;</span><br><span class="line">    public void writeRequested(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">        Object message = evt.getMessage();</span><br><span class="line">        // Do something with the message to be written.</span><br><span class="line">            ...</span><br><span class="line">        // And forward the event to the next handler.</span><br><span class="line">        ctx.sendDownstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ChannelHandler 分为两种：</p>
<ul>
<li>ChannelInboundHandler<br>
处理读数据逻辑，核心方法是 channelRead。</li>
<li>ChannelOutBoundHandler<br>
处理些数据逻辑，核心方法是 write，在链式处理中总是位于 ChannelInboundHandler 之后。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">serverBootstrap</span><br><span class="line">        .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">            protected void initChannel(NioSocketChannel ch) &#123;</span><br><span class="line">                // inBound，处理读数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerC());</span><br><span class="line">                </span><br><span class="line">                // outBound，处理写数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerC());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>
<p>其执行顺序如下图所示：<br>
<img src="http://47.88.24.11/imgs/Netty/pipeline%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.png" alt="pipeline执行顺序" title="pipeline执行顺序"></p>
<h2 id="异常处理"><a class="header-anchor" href="#异常处理">¶</a>异常处理</h2>
<p>netty 由于其异步化的开发方式，以及其事件机制，在异常处理方面就显得异常重要。为了保证连接的高可靠性，许多异常需要静悄悄的忽略，或者在用户态没有感知。<br>
netty 的异常会通过 pipeline 进行传播，所以在任何一层进行处理都是可行的，但编程习惯上，习惯性抛到最外层集中处理。<br>
为了最大限度的区别异常信息，通常会定义大量的异常类，不同的错误会抛出不同的异常。发生异常后，可以根据不同的类型选择断线重连（比如一些二进制协议的编解码紊乱问题)，或者调度到其他节点。</p>
<h2 id="codec-框架"><a class="header-anchor" href="#codec-框架">¶</a>Codec 框架</h2>
<p>我们可以使用 POJO 代替 ChannelBuffer，从业务逻辑代码中分离协议处理部分总是一个很不错的想法。然而如果一切从零开始便会遭遇到实现上的复杂性。你不得不处理分段的消息。一些协议是多层的（例如构建在其他低层协议之上的协议）。一些协议过于复杂以致难以在一台独立状态机上实现。<br>
因此，一个好的网络应用框架应该提供一种可扩展，可重用，可单元测试并且是多层的 codec 框架，为用户提供易维护的 codec 代码。<br>
Netty 提供了一组构建在其核心模块之上的 codec 实现，这些简单的或者高级的 codec 实现帮你解决了大部分在你进行协议处理开发过程会遇到的问题，无论这些协议是简单的还是复杂的，二进制的或是简单文本的。</p>
<h2 id="ssl-tls-支持"><a class="header-anchor" href="#ssl-tls-支持">¶</a>SSL / TLS 支持</h2>
<p>不同于传统阻塞式的 I/O 实现，在 NIO 模式下支持 SSL 功能是一个艰难的工作。你不能只是简单的包装一下流数据并进行加密或解密工作，你不得不借助于 javax.net.ssl.SSLEngine，SSLEngine 是一个有状态的实现，其复杂性不亚于 SSL 自身。你必须管理所有可能的状态，例如密码套件，密钥协商（或重新协商），证书交换以及认证等。此外，与通常期望情况相反的是 SSLEngine 甚至不是一个绝对的线程安全实现。<br>
在 Netty 内部，<a href="http://netty.io/4.0/api/io/netty/handler/ssl/SslHandler.html" target="_blank" rel="noopener">SslHandler</a> 封装了所有艰难的细节以及使用 SSLEngine 可 能带来的陷阱。你所做的仅是配置并将该 SslHandler 插入到你的 ChannelPipeline 中。同样 Netty 也允许你实现像 <a href="https://en.wikipedia.org/wiki/Opportunistic_TLS" target="_blank" rel="noopener">StartTlS</a> 那样所拥有的高级特性，这很容易。</p>
<h2 id="http-实现"><a class="header-anchor" href="#http-实现">¶</a>HTTP 实现</h2>
<p>HTTP 无 疑是互联网上最受欢迎的协议，并且已经有了一些例如 Servlet 容器这样的 HTTP 实现。因此，为什么 Netty 还要在其核心模块之上构建一套 HTTP 实现？<br>
与现有的 HTTP 实现相比 Netty 的 HTTP 实现是相当与众不同的。在 HTTP 消息的低层交互过程中你将拥有绝对的控制力。这是因为 Netty 的 HTTP 实现只是一些 HTTP codec 和 HTTP 消息类的简单组合，这里不存在任何限制——例如那种被迫选择的线程模型。你可以随心所欲的编写那种可以完全按照你期望的工作方式工作的客户端或服务器端代码。这包括线程模型，连接生命期，快编码，以及所有 HTTP 协议允许你做的，所有的一切，你都将拥有绝对的控制力。<br>
由于这种高度可定制化的特性，你可以开发一个非常高效的 HTTP 服务器，例如：</p>
<ul>
<li>要求持久化链接以及服务器端推送技术的聊天服务（如，<a href="http://en.wikipedia.org/wiki/Comet_%28programming%29" target="_blank" rel="noopener">Comet</a> )</li>
<li>需要保持链接直至整个文件下载完成的媒体流服务（如，2 小时长的电影）</li>
<li>需要上传大文件并且没有内存压力的文件服务（如，上传 1GB 文件的请求）</li>
<li>支持大规模混合客户端应用用于连接以万计的第三方异步 web 服务。</li>
</ul>
<h2 id="websockets-实现"><a class="header-anchor" href="#websockets-实现">¶</a>WebSockets 实现</h2>
<p><a href="http://en.wikipedia.org/wiki/WebSockets" target="_blank" rel="noopener">WebSockets</a> 允许双向，全双工通信信道，在 TCP socket 中。它被设计为允许一个 Web 浏览器和 Web 服务器之间通过数据流交互。<br>
WebSocket 协议已经被 IETF 列为 <a href="https://tools.ietf.org/html/rfc6455" target="_blank" rel="noopener">RFC 6455</a> 规范。<br>
Netty 已经实现了 WebSocket 和一些老版本的规范：<a href="http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html" target="_blank" rel="noopener">http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html</a></p>
<h2 id="google-protocol-buffer-整合"><a class="header-anchor" href="#google-protocol-buffer-整合">¶</a>Google Protocol Buffer 整合</h2>
<p><a href="http://code.google.com/apis/protocolbuffers/docs/overview.html" target="_blank" rel="noopener">Google Protocol Buffers</a> 是快速实现一个高效的二进制协议的理想方案。通过使用 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufEncoder.html" target="_blank" rel="noopener">ProtobufEncoder</a> 和 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufDecoder.html" target="_blank" rel="noopener">ProtobufDecoder</a>，你可以把 Google Protocol Buffers 编译器 (protoc) 生成的消息类放入到 Netty 的 codec 实现中。请参考“<a href="http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/localtime/package-summary.html" target="_blank" rel="noopener">LocalTime</a>”实例，这个例子也同时显示出开发一个由简单协议定义 的客户及服务端是多么的容易。</p>
<h1>性能优化</h1>
<h2 id="fastthreadlocal"><a class="header-anchor" href="#fastthreadlocal">¶</a>FastThreadLocal</h2>
<p>重写了JDK的ThreadLocal，但是速度更快</p>
<h2 id="recycle"><a class="header-anchor" href="#recycle">¶</a>Recycle</h2>
<p>对象池</p>
<h2 id="单机百万连接"><a class="header-anchor" href="#单机百万连接">¶</a>单机百万连接</h2>
<h2 id="netty应用级别性能优化"><a class="header-anchor" href="#netty应用级别性能优化">¶</a>Netty应用级别性能优化</h2>
<h1>QA</h1>
<h2 id="如何使用-netty"><a class="header-anchor" href="#如何使用-netty">¶</a>如何使用 Netty</h2>
<p>Netty 是 Java 中的一个 NIO 框架：</p>
<ol>
<li>易用的 API；</li>
<li>NIO 模型相对 BIO 更高效。</li>
<li>解决了 Java 原生 NIO 接口存在的一些问题。<br>
包括粘包半包问题、心跳检测等问题。</li>
</ol>
<h2 id="serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？"><a class="header-anchor" href="#serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？">¶</a>ServerBootstrap - 默认情况下Netty服务端会起多个线程？又是什么时候启动这些线程的？</h2>
<p>Netty中线程主要用于执行EventLoop的for循环任务，当ServerBootstrap<br>
默认情况下创建2倍CPU核心线程数的线程。<br>
<code>io.netty.channel.MultithreadEventLoopGroup#MultithreadEventLoopGroup(int, java.util.concurrent.Executor, java.lang.Object...)</code><br>
可以看到最终创建了个线程池<code>ThreadPerTaskExecutor</code><br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code></p>
<h2 id="serverbootstrap-netty是如何解决jdk的空轮询bug的？"><a class="header-anchor" href="#serverbootstrap-netty是如何解决jdk的空轮询bug的？">¶</a>ServerBootstrap - Netty是如何解决JDK的空轮询Bug的？</h2>
<p>NioEventLoop</p>
<h2 id="serverbootstrap-netty是如何保证异步串行无锁化的？"><a class="header-anchor" href="#serverbootstrap-netty是如何保证异步串行无锁化的？">¶</a>ServerBootstrap - Netty是如何保证异步串行无锁化的？</h2>
<p>执行需要保证并发安全的操作时先判断是否是刚开始创建的线程，如果不是则放入一个单线程的线程池中执行。<br>
线程创建位置：<code>SingleThreadEventExecutor</code>的构造方法<br>
判断位置：<code>io.netty.util.concurrent.AbstractEventExecutor#inEventLoop</code></p>
<h2 id="nioeventloop-netty如何检测新连接的接入？"><a class="header-anchor" href="#nioeventloop-netty如何检测新连接的接入？">¶</a>NioEventLoop - Netty如何检测新连接的接入？</h2>
<p>初始化ServerBootstrap时</p>
<h2 id="nioeventloop-新连接怎样被注册nioeventloop线程？"><a class="header-anchor" href="#nioeventloop-新连接怎样被注册nioeventloop线程？">¶</a>NioEventLoop - 新连接怎样被注册NioEventLoop线程？</h2>
<p>调用bind时会启动一个NioEventLoop线程，用于监听连接请求。</p>
<h2 id="pipeline-netty如何判断channelhandler类型？"><a class="header-anchor" href="#pipeline-netty如何判断channelhandler类型？">¶</a>pipeline - Netty如何判断ChannelHandler类型？</h2>
<p>ChannelHandler分为Inbound类型和Outbound类型，在Netty中将ChannelHandler添加到Pipeline时会判断这个ChannelHandler的类型，然后设置到一个bool类型的成员变量里，在传播时使用。<br>
<code>io.netty.channel.DefaultChannelHandlerContext#isInbound</code><br>
<code>io.netty.channel.DefaultChannelHandlerContext#isOutbound</code></p>
<h2 id="pipeline-对channelhandler的添加会遵循什么样的顺序？"><a class="header-anchor" href="#pipeline-对channelhandler的添加会遵循什么样的顺序？">¶</a>pipeline - 对ChannelHandler的添加会遵循什么样的顺序？</h2>
<p>根据Pipeline的传播逻辑可以看出，Inbound类型的ChannelHandler按添加顺序传播，而Outbound类型的ChannelHandler是按逆顺序传播的。</p>
<h2 id="pipeline-用户手动触发事件传播-不同的触发方式有什么区别？"><a class="header-anchor" href="#pipeline-用户手动触发事件传播-不同的触发方式有什么区别？">¶</a>pipeline - 用户手动触发事件传播，不同的触发方式有什么区别？</h2>
<p>如果是在Pipeline中间的某个ChannelHandler中调用了read，则就是从这个节点开始往后传播，如果是write，就是从这个节点开始往前传播。</p>
<h2 id="bytebuf-内存的类别有哪些？"><a class="header-anchor" href="#bytebuf-内存的类别有哪些？">¶</a>ByteBuf - 内存的类别有哪些？</h2>
<h2 id="bytebuf-如何减少多线程之间内存分配的竞争？"><a class="header-anchor" href="#bytebuf-如何减少多线程之间内存分配的竞争？">¶</a>ByteBuf - 如何减少多线程之间内存分配的竞争？</h2>
<h2 id="bytebuf-不同大小的内存是如何进行分配的？"><a class="header-anchor" href="#bytebuf-不同大小的内存是如何进行分配的？">¶</a>ByteBuf - 不同大小的内存是如何进行分配的？</h2>
<h2 id="bytebuf-粘包半包问题是什么"><a class="header-anchor" href="#bytebuf-粘包半包问题是什么">¶</a>ByteBuf - 粘包半包问题是什么</h2>
<h2 id="解码器抽象的解码过程？"><a class="header-anchor" href="#解码器抽象的解码过程？">¶</a>解码器抽象的解码过程？</h2>
<h2 id="netty里面有哪些拆箱即用的解码器？"><a class="header-anchor" href="#netty里面有哪些拆箱即用的解码器？">¶</a>Netty里面有哪些拆箱即用的解码器？</h2>
<h2 id="如何把对象变成字节流-并最终写到socket底层？"><a class="header-anchor" href="#如何把对象变成字节流-并最终写到socket底层？">¶</a>如何把对象变成字节流，并最终写到socket底层？</h2>
<h2 id="如何使用netty实现长短连接？"><a class="header-anchor" href="#如何使用netty实现长短连接？">¶</a>如何使用Netty实现长短连接？</h2>
<p>长连接是为了复用连接资源，长连接下，多个请求可以使用同一个连接传输数据包。</p>
<h2 id="如何使用netty实现长短轮询？"><a class="header-anchor" href="#如何使用netty实现长短轮询？">¶</a>如何使用Netty实现长短轮询？</h2>
<p>长轮询的特点是请求发到服务器上时若没有资源（比如库存），请求会被挂起，直到资源充足后才返回。</p>
<h1>参考</h1>
<ol>
<li><a href="https://wiki.jikexueyuan.com/project/netty-4-user-guide/" target="_blank" rel="noopener">Netty 4.x 用户指南</a></li>
<li><a href="https://netty.io/wiki/user-guide-for-4.x.html" target="_blank" rel="noopener">User guide for 4.x（上面这个文档的英文原版）</a></li>
<li><a href="https://github.com/netty/netty" target="_blank" rel="noopener">github - netty / netty</a></li>
<li><a href="https://netty.io/4.0/xref/overview-summary.html" target="_blank" rel="noopener">Netty Source Xref (4.0.56.Final)（同上为源码）</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">107</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">52</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
