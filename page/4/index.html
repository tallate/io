<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/page/4/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/page/4/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/1e6a7cbc.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/1e6a7cbc.html" itemprop="url">海量数据处理方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-07T22:01:47+08:00">
                2020-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  984 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1>海量数据处理方法</h1>
<p>当数据量特别大时，首先排除直接加载到内存中的算法，最核心的思路往往是<strong>分治</strong>，比如排序时先将大文件分割成多个足以加载到内存中的小文件，然后利用内存排序算法分别排序得到有序的一些小文件，最后通过归并排序得到最终的结果。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/1e6a7cbc.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/679dc1ee.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/679dc1ee.html" itemprop="url">MySQL 中的 CacheBuffer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-21T11:14:01+08:00">
                2020-07-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  16 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>Buffer Pool</h1>
<h2 id="buffer-pool-配置"><a class="header-anchor" href="#buffer-pool-配置">¶</a>Buffer Pool 配置</h2>
<ul>
<li><code>innodb_buffer_pool_size</code>：Buffer Pool 占用的总内存空间大小，单位是字节。</li>
<li><code>innodb_buffer_pool_instances</code>：访问 Buffer Pool 中的各种链表的时候都是需要加锁的，如果 Buffer Pool 特别大，且并发访问频率较高的情况下，会发生大量竞争，因此可以分配多个独立的小的 Buffer Pool。<br>
每个实例占用的内存空间为：<code>innodb_buffer_pool_size/innodb_buffer_pool_instances</code>。<br>
注意当<code>innodb_buffer_pool_size</code>的值小于 1G 的时候设置多个实例是无效的，InnoDB 会默认把 <code>innodb_buffer_pool_instances</code> 的值修改为 1。</li>
<li><code>innodb_buffer_pool_chunk_size</code>：出于对运行时可以方便调整 Buffer Pool 大小的考虑，每个 Buffer Pool 实例都是由若干 chunk 组成的。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2a5de8f2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
</ul>
<p>注意：</p>
<ul>
<li><code>innodb_buffer_pool_size</code>必须是<code>innodb_buffer_pool_chunk_size</code> × <code>innodb_buffer_pool_instances</code>的倍数</li>
<li>如果在服务器启动时，innodb_buffer_pool_chunk_size × innodb_buffer_pool_instances 的值已经大于 innodb_buffer_pool_size 的值，那么 innodb_buffer_pool_chunk_size 的值会被服务器自动设置为 innodb_buffer_pool_size/innodb_buffer_pool_instances 的值。</li>
</ul>
<h2 id="查看-buffer-pool-状态"><a class="header-anchor" href="#查看-buffer-pool-状态">¶</a>查看 Buffer Pool 状态</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINE INNODB STATUS</span><br></pre></td></tr></table></figure>
<ul>
<li>Total memory allocated：代表 Buffer Pool 向操作系统申请的连续内存空间大小，包括全部控制块、缓存页、以及碎片的大小。</li>
<li>Dictionary memory allocated：为数据字典信息分配的内存空间大小，注意这个内存空间和 Buffer Pool 没啥关系，不包括在 Total memory allocated 中。</li>
<li>Buffer pool size：代表该 Buffer Pool 可以容纳多少缓存页，注意，单位是页！</li>
<li>Free buffers：代表当前 Buffer Pool 还有多少空闲缓存页，也就是 free 链表中还有多少个节点。</li>
<li>Database pages：代表 LRU 链表中的页的数量，包含 young 和 old 两个区域的节点数量。</li>
<li>Old database pages：代表 LRU 链表 old 区域的节点数量。</li>
<li>Modified db pages：代表脏页数量，也就是 flush 链表中节点的数量。</li>
<li>Pending reads：正在等待从磁盘上加载到 Buffer Pool 中的页面数量。</li>
<li>当准备从磁盘中加载某个页面时，会先为这个页面在 Buffer Pool 中分配一个缓存页以及它对应的控制块，然后把这个控制块添加到 LRU 的 old 区域的头部，但是这个时候真正的磁盘页并没有被加载进来，Pending reads 的值会跟着加 1。</li>
<li>Pending writes LRU：即将从 LRU 链表中刷新到磁盘中的页面数量。</li>
<li>Pending writes flush list：即将从 flush 链表中刷新到磁盘中的页面数量。</li>
<li>Pending writes single page：即将以单个页面的形式刷新到磁盘中的页面数量。</li>
<li>Pages made young：代表 LRU 链表中曾经从 old 区域移动到 young 区域头部的节点数量。</li>
<li>这里需要注意，一个节点每次只有从 old 区域移动到 young 区域头部时才会将 Pages made young 的值加 1，也就是说如果该节点本来就在 young 区域，由于它符合在 young 区域 1/4 后边的要求，下一次访问这个页面时也会将它移动到 young 区域头部，但这个过程并不会导致 Pages made young 的值加 1。</li>
<li>Page made not young：在将 innodb_old_blocks_time 设置的值大于 0 时，首次访问或者后续访问某个处在 old 区域的节点时由于不符合时间间隔的限制而不能将其移动到 young 区域头部时，Page made not young 的值会加 1。</li>
<li>这里需要注意，对于处在 young 区域的节点，如果由于它在 young 区域的 1/4 处而导致它没有被移动到 young 区域头部，这样的访问并不会将 Page made not young 的值加 1。</li>
<li>youngs/s：代表每秒从 old 区域被移动到 young 区域头部的节点数量。</li>
<li>non-youngs/s：代表每秒由于不满足时间限制而不能从 old 区域移动到 young 区域头部的节点数量。</li>
<li>Pages read、created、written：代表读取，创建，写入了多少页。后边跟着读取、创建、写入的速率。</li>
<li>Buffer pool hit rate：表示在过去某段时间，平均访问 1000 次页面，有多少次该页面已经被缓存到 Buffer Pool 了。</li>
<li>young-making rate：表示在过去某段时间，平均访问 1000 次页面，有多少次访问使页面移动到 young 区域的头部了。</li>
<li>需要大家注意的一点是，这里统计的将页面移动到 young 区域的头部次数不仅仅包含从 old 区域移动到 young 区域头部的次数，还包括从 young 区域移动到 young 区域头部的次数（访问某个 young 区域的节点，只要该节点在 young 区域的 1/4 处往后，就会把它移动到 young 区域的头部）。</li>
<li>not (young-making rate)：表示在过去某段时间，平均访问 1000 次页面，有多少次访问没有使页面移动到 young 区域的头部。</li>
<li>需要大家注意的一点是，这里统计的没有将页面移动到 young 区域的头部次数不仅仅包含因为设置了 innodb_old_blocks_time 系统变量而导致访问了 old 区域中的节点但没把它们移动到 young 区域的次数，还包含因为该节点在 young 区域的前 1/4 处而没有被移动到 young 区域头部的次数。</li>
<li>LRU len：代表 LRU 链表中节点的数量。</li>
<li>unzip_LRU：代表 unzip_LRU 链表中节点的数量（由于我们没有具体唠叨过这个链表，现在可以忽略它的值）。</li>
<li>I/O sum：最近 50s 读取磁盘页的总数。</li>
<li>I/O cur：现在正在读取的磁盘页数量。</li>
<li>I/O unzip sum：最近 50s 解压的页面数量。</li>
<li>I/O unzip cur：正在解压的页面数量。</li>
</ul>
<h2 id="buffer-pool-的组成"><a class="header-anchor" href="#buffer-pool-的组成">¶</a>Buffer Pool 的组成</h2>
<h2 id="buffer-pool-的作用原理"><a class="header-anchor" href="#buffer-pool-的作用原理">¶</a>Buffer Pool 的作用原理</h2>
<h3 id="加载磁盘页面到-buffer-pool"><a class="header-anchor" href="#加载磁盘页面到-buffer-pool">¶</a>加载磁盘页面到 Buffer Pool</h3>
<p>当我们需要访问某页中的数据时，需要将该页加载到 Buffer Pool 内。<br>
InnoDB 中还存在两种特殊情况：</p>
<ul>
<li>预读<br>
预先将以后可能用到的页面加载到 Buffer Pool，根据加载方式还细分为线性预读和随机预读：<br>
线性预读：如果顺序访问了某个区（extent）的页面超过<code>innodb_read_ahead_threshold</code>这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，注意异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。<br>
随机预读：如果 Buffer Pool 中已经缓存了某个区的 13 个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool 的请求。<br>
如果预读的页面很常用，则可以极大地提高语句的执行效率，而如果并不常用的话，反而会将 LRU 链表尾部的缓存页被迅速淘汰掉，导致缓存命中率降低。</li>
<li>全表扫描<br>
全表扫描会导致大量页统统被加载到 Buffer Pool 内，这些页一般被使用到的频率也不高（全表扫描的执行频率不会太高），导致大大降低缓存命中率。</li>
</ul>
<h3 id="刷新脏页到磁盘"><a class="header-anchor" href="#刷新脏页到磁盘">¶</a>刷新脏页到磁盘</h3>
<p>后台有专门的线程每隔一段时间负责把脏页刷新到磁盘，这样可以不影响用户线程处理正常的请求。</p>
<ul>
<li>从<strong>LRU 链表</strong>的冷数据中刷新一部分页面到磁盘。<br>
后台线程会定时从 LRU 链表尾部开始扫描一些页面，扫描的页面数量可以通过系统变量<code>innodb_lru_scan_depth</code>来指定，如果从里边儿发现脏页，会把它们刷新到磁盘。这种刷新页面的方式被称之为<code>BUF_FLUSH_LRU</code>。</li>
<li>从<strong>flush 链表</strong>中刷新一部分页面到磁盘。<br>
后台线程也会定时从 flush 链表中刷新一部分页面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新页面的方式被称之为<code>BUF_FLUSH_LIST</code>。</li>
<li>同步刷新<br>
有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到 Buffer Pool 时没有可用的缓存页，这时就会尝试看看 LRU 链表尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将 LRU 链表尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为<code>BUF_FLUSH_SINGLE_PAGE</code>。</li>
</ul>
<h2 id="buffer-pool-内部组成"><a class="header-anchor" href="#buffer-pool-内部组成">¶</a>Buffer Pool 内部组成</h2>
<p>Buffer Pool 的基础组成部分是<strong>缓存页</strong>，大小和磁盘上的默认页大小一致都是 16KB，每一个缓存页都对应一个<strong>控制块</strong>。<br>
这些控制信息包括该页所属的表空间编号、页号、缓存页在 Buffer Pool 中的地址、链表节点信息、一些锁信息以及 LSN 信息，当然还有一些别的控制信息。<br>
每个页对应的控制信息占用的空间大小都是相同的，这块空间被称为<strong>控制块</strong>，控制块与缓存页之间是一一对应的关系，控制块被放到 Buffer Pool 的前面，而缓存页则被放到后面：<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2b9d6dd1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
中间碎片空间的产生是由于 Buffer Pool 中剩余的空间已经不够容纳一对控制块和缓存页的大小了。</p>
<h2 id="free-链表管理"><a class="header-anchor" href="#free-链表管理">¶</a>free 链表管理</h2>
<p>Buffer Pool 初始化时会被划分成若干对控制块和缓存页，随着程序的运行，会不断的有磁盘页被加载到 Buffer Pool 中、或从 Buffer Pool 中被释放，为了知道哪些页是空闲的、哪些页已经被占用了，MySQL 会将所有空闲的缓存页对应的控制块作为一个节点放到一个链表中，称为<strong>free 链表</strong>。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e300173c1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
注意 free 链表的结构中还有一个<strong>基节点</strong>，它是 Buffer Pool 外的一块空间，包含头节点（start）、尾节点（end）属性，主要用于定位这个 free 链表。</p>
<h2 id="缓存页的哈希表"><a class="header-anchor" href="#缓存页的哈希表">¶</a>缓存页的哈希表</h2>
<p>当我们需要访问某页中的数据时，需要将该页加载到 Buffer Pool 内，那么我们怎么知道该页是不是已经在 Buffer Pool 中了呢？其实是用一个<strong>哈希表</strong>来定位的，该哈希表的 key 为<code>表空间号 + 页号</code>、value 为缓存页。</p>
<h2 id="flush-链表管理"><a class="header-anchor" href="#flush-链表管理">¶</a>flush 链表管理</h2>
<p>当 Buffer Pool 中某个缓存页的内容被修改，则它和磁盘上的对应页就不一致了，这样的缓存页就被称为<code>脏页</code>，脏页并不会立刻被同步到磁盘上，而是会被加入到一个链表中，称为<code>flush链表</code>。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2ec4572a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<h2 id="lru-链表管理"><a class="header-anchor" href="#lru-链表管理">¶</a>LRU 链表管理</h2>
<p>当 Buffer Pool 中不再有空闲的缓存页时，我们需要淘汰掉部分最近很少使用的缓存页，所以 InnoDB 会使用一个<strong>LRU 链表</strong>来组织缓存页，并按<strong>最近最少使用</strong>原则来淘汰旧的缓存页：</p>
<ul>
<li>如果该页不在 Buffer Pool 中，在把该页从磁盘加载到 Buffer Pool 中的缓存页时，就把该缓存页对应的控制块作为节点塞到链表的头部。</li>
<li>如果该页已经缓存在 Buffer Pool 中，则直接把该页对应的控制块移动到 LRU 链表的头部。<br>
只要我们使用到某个缓存页，就把该缓存页调整到 LRU 链表的头部，这样 LRU 链表尾部就是最近最少使用的缓存页，每次 Buffer Pool 中的空闲缓存页被用完时，就会释放 LRU 链表尾部的页面。</li>
</ul>
<p>InnoDB 中还存在两种特殊情况：</p>
<ul>
<li>预读<br>
预先将以后可能用到的页面加载到 Buffer Pool，根据加载方式还细分为线性预读和随机预读：<br>
线性预读：如果顺序访问了某个区（extent）的页面超过<code>innodb_read_ahead_threshold</code>这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，注意异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。<br>
随机预读：如果 Buffer Pool 中已经缓存了某个区的 13 个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool 的请求。<br>
如果预读的页面很常用，则可以极大地提高语句的执行效率，而如果并不常用的话，反而会将 LRU 链表尾部的缓存页被迅速淘汰掉，导致缓存命中率降低。</li>
<li>全表扫描<br>
全表扫描会导致大量页统统被加载到 Buffer Pool 内，这些页一般被使用到的频率也不高（全表扫描的执行频率不会太高），导致大大降低缓存命中率。</li>
</ul>
<p>因此 InnoDB 中 LRU 链表被分成了两部分：</p>
<ul>
<li>
<p>一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做热数据，或者称 young 区域。</p>
</li>
<li>
<p>另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做冷数据，或者称 old 区域。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/2/1693e86e2a3fffa3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
</li>
<li>
<p>针对预读的页面可能不进行后续访问情况的优化<br>
当磁盘上的某个页面在初次加载到 Buffer Pool 中的某个缓存页时，该缓存页对应的控制块会被放到 old 区域的头部。这样针对预读到 Buffer Pool 却不进行后续访问的页面就会被逐渐从 old 区域逐出，而不会影响 young 区域中被使用比较频繁的缓存页。</p>
</li>
<li>
<p>针对全表扫描时，短时间内访问大量使用频率非常低的页面情况的优化<br>
全表扫描的页面首次会按上一条规则被加载到 old 区域的头部，之后一小段时间内这些页面由于访问频繁而被带入了 young 区，导致热数据被挤出了 young 区。因此 InnoDB 规定，在对某个处在 old 区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔（<code>innodb_old_blocks_time</code>）内，那么该页面就不会被从 old 区域移动到 young 区域的头部，否则将它移动到 young 区域的头部。</p>
</li>
</ul>
<h1>Change Buffer</h1>
<p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些<strong>更新操作</strong>缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。<br>
访问数据页时，需要将 change buffer 中的操作应用到原始页中，这个操作被称为<strong>merge</strong>。另外，系统后台定时任务线程、数据库正常关闭过程也会执行 merge 操作。<br>
change buffer 的好处包括：</p>
<ol>
<li>更新操作先记录到 change buffer，减少了读磁盘操作；</li>
<li>数据的读入需要占用 buffer pool，因此 change buffer 也避免了占用内存。</li>
</ol>
<h2 id="使用-change-buffer-的条件"><a class="header-anchor" href="#使用-change-buffer-的条件">¶</a>使用 change buffer 的条件</h2>
<p>使用 cache buffer 时需要注意以下两点：</p>
<ol>
<li>唯一索引的更新不能使用 change buffer。<br>
唯一索引的更新需要先判断这个操作是否违反唯一性约束，而这必须要将数据页读入内存才能判断，而已经读入内存的话，就没必要再使用 change buffer 了。<br>
因此唯一索引不能使用 change buffer，只有普通索引可以使用。</li>
<li>大小有限<br>
change buffer 使用的是 buffer pool 里的内存。</li>
<li>写多读少<br>
读操作才会触发 merge 操作，在 merge 前记录的数据变更越多，change buffer 的收益也越大，因此 change buffer 适合<strong>写多读少</strong>的业务，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。比如账单、日志类的系统。</li>
</ol>
<h2 id="使用建议"><a class="header-anchor" href="#使用建议">¶</a>使用建议</h2>
<ol>
<li>更新性能普通索引比唯一索引更高，建议尽量选择普通索引。</li>
<li>如果所有的更新后面都伴随着对这个记录的查询，那么最好应该关闭 change buffer。</li>
</ol>
<h2 id="redo-log-和-change-buffer-之间的区别"><a class="header-anchor" href="#redo-log-和-change-buffer-之间的区别">¶</a>redo log 和 change buffer 之间的区别</h2>
<ol>
<li>redo log 是任何写入操作都会记录的；change buffer 是在写入时页没有在内存中时使用的，将写入操作记录到 change buffer，而不是立刻读页面到 buffer pool 中；</li>
<li>redo log 减少随机写磁盘开销，change buffer 减少随机读；</li>
</ol>
<h2 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into a values(1, 2), (3, 4);</span><br></pre></td></tr></table></figure>
<p>插入两条数据，第一条<strong>数据所在的数据页</strong>在内存中，第二条不在，因此执行写入操作时，第一条不会使用到 change buffer，当然，最后二者都需要写入 redo log。</p>
<h1>QA</h1>
<h2 id="为什么唯一索引上不能使用change-buffer优化？"><a class="header-anchor" href="#为什么唯一索引上不能使用change-buffer优化？">¶</a>为什么唯一索引上不能使用change buffer优化？</h2>
<p>因为唯一索引需要将页读入内存来检查唯一性约束。</p>
<h2 id="唯一索引会比普通索引更快吗？"><a class="header-anchor" href="#唯一索引会比普通索引更快吗？">¶</a>唯一索引会比普通索引更快吗？</h2>
<p>不一定。<br>
一种唯一索引比普通索引快的说法是唯一索引只要找到一行就直接返回了，而普通索引会继续匹配下一行，直到发现不匹配的情况，所以唯一索引比普通索引少查几行。<br>
但是唯一索引不能利用change buffer优化。</p>
<h2 id="某次写入change-buffer后-系统重启了-change-buffer会丢失吗？"><a class="header-anchor" href="#某次写入change-buffer后-系统重启了-change-buffer会丢失吗？">¶</a>某次写入change buffer后，系统重启了，change buffer会丢失吗？</h2>
<p>不会丢失，因为事务提交的时候change buffer操作已经记录到redo log里了，因此崩溃恢复后change buffer能找回来。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/37173fb7.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/37173fb7.html" itemprop="url">MyBatis 原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-21T11:14:01+08:00">
                2020-07-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>MyBatis 整体结构</h1>
<p><img src="https://tallate.top/imgs/MyBatis/MyBatis%E7%BB%93%E6%9E%84.png" alt="MyBatis结构" title="MyBatis结构"></p>
<h1>配置文件</h1>
<p>配置类提供的功能几乎贯穿了整个处理过程：</p>
<ol>
<li>解析 Xml 文件</li>
<li>创建 SQL 处理器 Executor</li>
<li>对语句进行缓存 MappedStatement</li>
</ol>
<h2 id="怎么定位路径"><a class="header-anchor" href="#怎么定位路径">¶</a>怎么定位路径</h2>
<ul>
<li>getResourceAsStream</li>
</ul>
<h2 id="怎么解析文件"><a class="header-anchor" href="#怎么解析文件">¶</a>怎么解析文件</h2>
<p>xml 文件的解析方式有两种，一种 DOM 是直接读入整个 xml 文件，根据标签的嵌套关系构建一棵文档树；另一种方式叫 SAX（Simple API for XML），是一种事件驱动的文档解析方式，什么是事件驱动呢？比如说 SAX 驱动扫描到了起始标签，就代表发生了一个事件，它会转而调用某个由用户定义的函数（startElement）执行逻辑。<br>
有一种设计原则叫好莱坞法则（Hollywood），形象地说就是“你不要 call 我，需要你时我会 call 你”，一个例子是异步调用，这是一种通信机制，客户端在发出请求后不必等待服务端处理完毕就可以返回处理自己的逻辑，等到服务端处理完毕后再将结果传回，这种方式一定程度上可以解决客户端长期阻塞的问题、改善用户体验，回调函数也是一个例子。<br>
据网上的说法，DOM 需要一次构建整棵 DOM 树，所以比较占内存，不适合大的 xml 文档解析，但是由于 DOM 树上可以任意遍历，所以自由度很高，相对来说，SAX 是读到什么就调用什么回调函数，所以内存占用小，但是编程多少会复杂一些。</p>
<h1>构建数据库连接</h1>
<h2 id="数据库连接"><a class="header-anchor" href="#数据库连接">¶</a>数据库连接</h2>
<h3 id="sqlsessionfactorybuilder"><a class="header-anchor" href="#sqlsessionfactorybuilder">¶</a>SqlSessionFactoryBuilder</h3>
<p>应用了建造者模式，根据配置文件来创建 SqlSessionFactory，创建后其任务就结束了，生命周期在一个方法内。</p>
<h3 id="sqlsessionfactory"><a class="header-anchor" href="#sqlsessionfactory">¶</a>SqlSessionFactory</h3>
<p>创建和数据库连接的工具，在整个应用运行期间应该作为一个单例存在，或者使用依赖注入管理其生命周期。</p>
<h3 id="sqlsession"><a class="header-anchor" href="#sqlsession">¶</a>SqlSession</h3>
<p>代表和数据库的一次连接，在 MyBatis 中其实现是线程不安全的，生命周期最好控制在一次请求之间。</p>
<h2 id="数据源"><a class="header-anchor" href="#数据源">¶</a>数据源</h2>
<ul>
<li>DBCP</li>
<li>C3P0</li>
<li>Druid</li>
<li>MyBatis 内置数据源（UNPOOLED、POOLED、JNDI）</li>
<li>自定义数据源</li>
</ul>
<h2 id="映射器"><a class="header-anchor" href="#映射器">¶</a>映射器</h2>
<ul>
<li>mapper 文件</li>
<li>注解</li>
</ul>
<h1>SQL 执行</h1>
<p>SqlSession 本身是可以直接执行 sql 语句的，它的所有 update、query 等方法都是对语句进行了包装（MappedStatement），然后再调用 Executor 的相应方法，Executor 是执行器，是 MyBatis 的核心。<br>
SQL 的执行是由 Executor 负责的，Executor 对象是和 SqlSession 同时创建的，SqlSessionFactory 会为 Executor 创建事务，事务类默认为 ManagedTransactionFactory，Executor 需要从事务对象获取数据库连接（包装上一层事务后扩展性更好），事务会从环境对象中获取 DataSource 对象，然后委托 DataSource 创建连接，并且可以根据事务等级来为连接设置事务。说白了，把 Config 对象传给新建的 Transaction，由 Transaction 创建连接。<br>
Executor 并不是直接执行 SQL 语句，SQL 语句由 MappedStatement 包装，再交给 StatementHandler 执行</p>
<h1>Executor�</h1>
<p>MyBatis 提供 4 种 Executor，他们都继承于 BaseExecutor  �<br>
<strong>BaseExecutor</strong> 是一个抽象类，实现了延迟加载、一级缓存（PerpetualCache）等功能  �<br>
<strong>SimpleExecutor</strong> 语句使用 PreparedStatement 保存，使用 StatementHandler 处理  �<br>
<strong>ReuseExecutor</strong> 与 SimpleExecutor 的区别是它使用一个 Map&lt;String, Statement&gt;来缓存 SQL 语句对应的 Statement，如果某些 Sql 复杂且使用频繁的话可以使用这个执行器，因为这个 Map 不是静态的，并且 MyBatis 实际上会为每个新建的 SqlSession 创建一个 Executor，所以这个缓存只在同一个 Session 内有效  �</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private final Map&lt;String, Statement&gt; statementMap = new HashMap&lt;String, Statement&gt;();</span><br><span class="line">if (hasStatementFor(sql)) &#123;</span><br><span class="line">    //如果缓存中已经有了，直接得到Statement</span><br><span class="line">    stmt = getStatement(sql);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    //如果缓存没有找到，则和SimpleExecutor处理完全一样，然后加入缓存</span><br><span class="line">    Connection connection = getConnection(statementLog);</span><br><span class="line">    stmt = handler.prepare(connection);</span><br><span class="line">    putStatement(sql, stmt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>BatchExecutor（批量执行器）</strong> 将一些 SQL 语句放在一个 List 中，最后 doFlushStatements 一块执行，并且如果两个相邻的 SQL 语句是相同的，还会复用前一个 Statement 对象。<br>
<strong>CachingExecutor（二级缓存执行器）</strong> 为什么说是二级缓存？一级缓存由 BaseExecutor 中的 PerpetualCache 实现，CachingExecutor 会先在二级缓存中查找，如果找不到再委托给 delegate 执行，delegate 是 BaseExecutor 的子类，当然有一级缓存的功能。  �<br>
�</p>
<h1>参数类型和返回值�</h1>
<p>我们很多时候会指定 parameterType 和 resultType 为复杂类型，怎么将这些类型和数据库表结构进行映射正是 orm 框架的任务之一。  �<br>
parameterType 表示传入参数类型，在 sql 语句中可以使用#{参数名}来调用，比如�</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlSession.selectOne(&quot;com.tallate.UserMapper.selectUser&quot;, 1); </span><br></pre></td></tr></table></figure>
<p>传入了一个 Integer 类型的参数 1，那么 PreparedStatementHandler 在准备语句时，应该对这个参数的类型进行判断，这个是由 ParameterHandler 负责的。  �<br>
resultType 表示返回值类型，PreparedStatementHandler 在获得 ResultSet 后应该将查询到的表记录转换为 Java 对象，这个是由 ResultSetHandler 负责的，它最终会调用对应类的构造函数将查询出的结果传入。  �<br>
�</p>
<h1>动态代理�</h1>
<p>我们平常使用 MyBatis 时都会定义一个 XXMapper 接口，对应 mapper.xml 中的一个 namespace，而且我们也不必显示写出其实现类，调用过程都是由动态代理实现的。  �<br>
一般来说，代理类和被代理类应该实现相同的接口，但是现在我们的被代理类是一个 xxmapper.xml 文件，所以问题现在变成了：怎么将 xxmapper.xml 文件转换成被代理类。  �<br>
查看源码中的 MapperProxyFactory 和 MapperProxy 可以知道，MyBatis 实现 Mapper 接口其实是调用了 SqlSession 中的方法（select、selectOne 等，已经实现了），但是它们的方法名并不相同，比如 selectUser 怎么和 selectOne 关联上呢？  �<br>
MapperProxy 的 invoke 方法并不是直接调用被代理对象的方法，而是使用 MapperMethod 来表示映射的方法，通过 MapperMethod 可以判断接口方法的返回值、方法名等来确定应该调用 SqlSession 的哪个方法  �</p>
<ol>
<li>启动时 XMLConfigBuilder 会为 config.xml 中所有 mapper 节点扫描包下所有映射器�</li>
<li>创建对应的映射 interface -&gt; MapperProxyFactory�</li>
<li>添加动态代理对象到 MapperRegistry 中（我为了方便，直接加到 Config 中了，其实是刚开始对 MapperRegistry 的功能理解错了…）�</li>
<li>之后每次 getMapper，都可以根据接口名来找到对应的动态代理对象，调用方法时实际上是调用了相应的 MapperMethod�<br>
�</li>
</ol>
<h3 id="并发"><a class="header-anchor" href="#并发">¶</a>并发�</h3>
<p>有哪些资源是中心化的？如果是，会不会被多线程同时访问？在 web 环境中，假设每个用户代表一个线程，当他们同时访问服务器就会出现并发问题。  �</p>
<ul>
<li>线程池（数据源）  �<br>
如果线程池是使用链表（LinkedList）实现的，可以使用 Collections.synchronizedList 进行包装，或者直接使用 Vector  �</li>
<li>Map&lt;String, MappedStatement&gt; MappedStatements�<br>
使用 Map 容器储存 MappedStatement，MappedStatement 表示调用语句到 sql 语句的映射，比如&quot;namespace.selectUser&quot;到 mapper.xml 中对应的 sql 语句（使用 SqlSource 包装）。  �</li>
<li>List<environment> environments�<br>
表示 config.xml 中注册的所有环境对象列表  �</environment></li>
<li>List<mapperregistry> mappers�<br>
表示 config.xml 中注册的所有 mapper 的列表  �</mapperregistry></li>
<li>Map&lt;Method, MapperMethod&gt; methodCache�<br>
MapperProxyFactory 中的映射器方法缓冲是使用 ConcurrentHashMap 实现的  �<br>
�<br>
�</li>
</ul>
<h1>QA</h1>
<ol>
<li>一级缓存不够吗？为什么要有二级缓存？<br>
一级缓存是会话级缓存，在 BaseExecutor 中，是成员变量，生命周期在一个 SqlSession 内，连接断开就没了；<br>
二级缓存是语句级缓存，在 MappedStatement 中，可以跨多个 SqlSession，当一些数据不常发生变化或者允许偶尔的并发的时候，二级缓存可能更有效率。</li>
<li>为什么不推荐使用 MyBatis 中的缓存？<br>
一级缓存会产生脏数据。因为作用范围是会话，如果有俩会话，会话 1 加载数据到缓存，会话 2 修改该条数据，之后会话 1 读到的是缓存里的老数据。<br>
二级缓存同样会产生脏数据。二级缓存作用范围是语句，需要手动刷新或在 xml 中配置需要刷新，一般在写入操作和事务提交后都需要刷新一下。但是如果表 A 的 Amapper.xml 中关联了表 B，即使表 B 的数据有变更，我们在 Amapper.xml 中执行查询语句仍然会读到缓存中的脏数据。</li>
<li>MyBatis 与 JDBC 对象之前的关联？<br>
ParameterStatement - ParameterStatementHandler<br>
SimpleStatement - SimpleStatementHandler<br>
ResultSet - ResultSetHandler</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/4eb3381c.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/4eb3381c.html" itemprop="url">分布式锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-06T16:32:14+08:00">
                2020-07-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  12 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>单机环境下的锁</h1>
<p>单机环境下，资源竞争者都是来自机器内部(进程/线程)，那么实现锁的方案只需要借助单机资源就可以了，比如借助磁盘、内存、寄存器来实现。</p>
<h2 id="竞态条件-race-condition"><a class="header-anchor" href="#竞态条件-race-condition">¶</a>竞态条件（Race Condition）</h2>
<p>计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。比如：</p>
<ol>
<li>先检测（查询）后执行。执行依赖于检测的结果，而检测结果依赖于多个线程的执行时序，而多个线程的执行时序通常情况下是不固定不可判断的，从而导致执行结果出现各种问题。</li>
<li>延迟初始化（如单例的实例化） <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class ObjFactory &#123;  </span><br><span class="line">    private Obj instance;  </span><br><span class="line"></span><br><span class="line">    public Obj getInstance()&#123;  </span><br><span class="line">        if(instance == null)&#123;  </span><br><span class="line">            instance = new Obj();  </span><br><span class="line">        &#125;  </span><br><span class="line">        return instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果两个线程同时调用 getInstance()就有可能出现：一个线程 A 创建了一个新对象 instance = obj1，立马被另一个线程 B 覆盖 instance = obj2，线程 A 返回了 obj1，线程 B 返回 obj2，于是 Obj 就相当于被实例化了两次。</p>
<h2 id="锁的分类"><a class="header-anchor" href="#锁的分类">¶</a>锁的分类</h2>
<ol>
<li>悲观锁，前提是，一定会有并发抢占资源，强行独占资源，在整个数据处理过程中将数据处于锁定状态。</li>
<li>乐观锁，前提是，不会发生并发抢占资源，只有在<strong>执行修改时</strong>检查是否违反数据完整性。<strong>只能防止脏读后数据的提交，不能解决脏读</strong>。</li>
</ol>
<h2 id="悲观锁"><a class="header-anchor" href="#悲观锁">¶</a>悲观锁</h2>
<h2 id="乐观锁"><a class="header-anchor" href="#乐观锁">¶</a>乐观锁</h2>
<p>乐观锁一般有以下两种实现方法：</p>
<ol>
<li>版本号：使用<strong>版本标识</strong>来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取<strong>丢弃</strong>或<strong>再次尝试</strong>的策略。</li>
<li>CAS：java 中的 compareandswap 即 cas，解决多线程并行情况下使用锁造成性能损耗的一种机制。CAS 操作包含三个操作数，内存位置（V）,预期原值（A）和新值（B）。如果内存位置的值与预期原值相匹配，那么处理器会西东将该位置值更新为新值。否则，处理器不做任何操作。</li>
</ol>
<h1>分布式锁</h1>
<p>目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的<strong>CAP 理论</strong>告诉我们“任何一个分布式系统都无法同时满足<strong>一致性（Consistency）</strong>、<strong>可用性（Availability）<strong>和</strong>分区容错性（Partition tolerance）</strong>，最多只能同时满足其中两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。<br>
有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java 中其实提供了很多并发处理相关的 API，但是这些 API 在分布式场景中就无能为力了。也就是说单纯的 Java Api 并不能提供分布式锁的能力。<br>
对于分布式环境下，资源竞争者生存环境更复杂了，原有依赖单机的方案不再发挥作用，这时候就需要一个大家都认可的协调者出来，帮助解决竞争问题，那这个协调者称之为分布式锁。</p>
<h2 id="实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的"><a class="header-anchor" href="#实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的">¶</a>实现分布式锁的需求（方法锁，以方法作为临界区，资源锁是类似的）</h2>
<ol>
<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li>
<li>这把锁要是一把可重入锁（单线程可重复获取同一把锁，避免死锁）</li>
<li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li>
<li>有高可用的获取锁和释放锁功能</li>
<li>获取锁和释放锁的性能要好</li>
</ol>
<h2 id="基于数据库表"><a class="header-anchor" href="#基于数据库表">¶</a>基于数据库表</h2>
<p>要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。<br>
当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。<br>
创建这样一张数据库表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `methodLock` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;,</span><br><span class="line">  `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;,</span><br><span class="line">  `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;,</span><br><span class="line">  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="使用锁表实现方法锁"><a class="header-anchor" href="#使用锁表实现方法锁">¶</a>使用锁表实现方法锁</h3>
<p>执行 SQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)</span><br></pre></td></tr></table></figure>
<p>因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。<br>
当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from methodLock where method_name =&apos;method_name&apos;</span><br></pre></td></tr></table></figure>
<p>上面这种简单的实现有以下几个问题：</p>
<ul>
<li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li>
<li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li>
<li>这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li>
<li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据库中数据已经存在了。</li>
</ul>
<p>当然，我们也可以有其他方式解决上面的问题。</p>
<ul>
<li>数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。</li>
<li>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。</li>
<li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li>
<li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li>
</ul>
<h3 id="使用数据库-x-锁-排他锁-实现分布式锁"><a class="header-anchor" href="#使用数据库-x-锁-排他锁-实现分布式锁">¶</a>使用数据库 X 锁（排他锁）实现分布式锁</h3>
<p>除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。<br>
我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。<br>
基于 MySQL 的 InnoDB 引擎，可以使用以下方法来实现加锁操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean lock()&#123;</span><br><span class="line">    connection.setAutoCommit(false)</span><br><span class="line">    while(true)&#123;</span><br><span class="line">        try&#123;</span><br><span class="line">            result = select * from methodLock where method_name = xxx for update;</span><br><span class="line">            if(result==null)&#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;catch(Exception e)&#123;</span><br><span class="line">            log.warn(&quot;加锁失败&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">        sleep(1000);</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。<br>
我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public void unlock()&#123;</span><br><span class="line">    connection.commit();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过 connection.commit()操作来释放锁。<br>
这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p>
<ul>
<li>阻塞锁？ for update 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li>
<li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。<br>
但是还是无法直接解决数据库单点和可重入问题。</li>
</ul>
<h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3>
<p>总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。<br>
数据库实现分布式锁的优点：</p>
<ol>
<li>直接借助数据库，容易理解。</li>
</ol>
<p>数据库实现分布式锁的缺点</p>
<ol>
<li>会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。</li>
<li>操作数据库需要一定的开销，性能问题需要考虑。</li>
</ol>
<h2 id="基于缓存"><a class="header-anchor" href="#基于缓存">¶</a>基于缓存</h2>
<p>使用缓存中间件实现分布式锁的方法我已经在<a href="https://tallate.github.io/d3d5fdbf.html#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">Redis 客户端</a>中有过分析。</p>
<h2 id="基于-zookeeper"><a class="header-anchor" href="#基于-zookeeper">¶</a>基于 ZooKeeper</h2>
<p>基于 zookeeper 临时有序节点可以实现的分布式锁。<br>
大致思想即为：每个客户端对某个方法加锁时，在 zookeeper 上的与该方法对应的指定节点的目录下，生成一个唯一的<strong>瞬时有序节点</strong>。<br>
判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。<br>
当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。<br>
来看下 Zookeeper 能不能解决前面提到的问题。</p>
<ul>
<li>锁无法释放？使用 Zookeeper 可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在 ZK 中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session 连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。</li>
<li>非阻塞锁？使用 Zookeeper 可以实现阻塞的锁，客户端可以通过在 ZK 中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper 会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。</li>
<li>不可重入？使用 Zookeeper 也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。</li>
<li>单点问题？使用 Zookeeper 可以有效的解决单点问题，ZK 是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</li>
</ul>
<h3 id="使用-curator-实现分布式锁"><a class="header-anchor" href="#使用-curator-实现分布式锁">¶</a>使用 Curator 实现分布式锁</h3>
<p>可以直接使用 zookeeper 第三方库 Curator 客户端，这个客户端中封装了一个可重入的锁服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        return interProcessMutex.acquire(timeout, unit);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line">public boolean unlock() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        interProcessMutex.release();</span><br><span class="line">    &#125; catch (Throwable e) &#123;</span><br><span class="line">        log.error(e.getMessage(), e);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Curator 提供的 InterProcessMutex 是分布式锁的实现。acquire 方法用户获取锁，release 方法用于释放锁。<br>
使用 ZK 实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper 实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK 中创建和删除节点只能通过<strong>Leader</strong>服务器来执行，然后将数据同步到所有的 Follower 机器上。</p>
<h3 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结</h3>
<p>使用 Zookeeper 实现分布式锁的优点</p>
<ol>
<li>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。</li>
<li>实现起来较为简单。</li>
</ol>
<p>使用 Zookeeper 实现分布式锁的缺点</p>
<ol>
<li>性能上不如使用缓存实现分布式锁。</li>
<li>需要对 ZK 的原理有所了解。</li>
</ol>
<p>分布式锁实现需要根据实际需要来选择，比如红锁是AP的，而ZooKeeper是CP的。</p>
<h1>QA</h1>
<ol>
<li>怎么使用 Redis 实现分布式锁？<br>
set 命令带上 nx 和 ex 参数。</li>
<li>怎么使用 zk 实现分布式锁？<br>
先建一个代表锁的持久节点，然后每个线程要加锁就在该持久节点下创建临时有序节点，如果当前线程创建的节点是最小的，则说明可以获取到该锁，否则阻塞等待；释放锁就是将这个临时节点删除。</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/garfieldcgf/p/6380816.html" target="_blank" rel="noopener">分布式锁的几种实现方式</a></li>
<li><a href="https://www.cnblogs.com/dennyzhangdd/p/7133653.html#_label0" target="_blank" rel="noopener">终极锁实战：单 JVM 锁+分布式锁</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a87bf883.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/a87bf883.html" itemprop="url">MySQL 的其他主题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-30T10:18:28+08:00">
                2020-05-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>常用服务器配置</h1>
<ul>
<li>启动选项和系统变量<br>
启动选项是运维启动 MySQL 时传入的一些参数，包括命令行启动选项和配置文件 my.cnf<br>
系统变量会影响 MySQL 进程的运行行为，大部分是由启动选项初始化的，有些是运行时自动生成的</li>
<li>查看系统变量<br>
<code>show [GLOBAL|SESSION] variables [like 匹配的模式];</code></li>
<li>配置文件中配置组的概念</li>
<li>配置作用范围<br>
1、GLOBAL 指配置文件或命令行启动选项设置的系统变量<br>
2、SESSION（LOCAL）刚连接时会被初始化为 GLOBAL 的变量，可以通过以下命令来设置<br>
<code>SET [GLOBAL|SESSION] 系统变量名 = 值;</code></li>
<li>状态变量<br>
指关于程序运行状态的变量，是只读的，不能手动修改<br>
比方说 Threads_connected 表示当前有多少客户端与服务器建立了连接，Handler_update 表示已经更新了多少行记录<br>
SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];</li>
</ul>
<h1>InnoDB 统计数据</h1>
<h2 id="两种统计数据"><a class="header-anchor" href="#两种统计数据">¶</a>两种统计数据</h2>
<p>InnoDB 中有两种统计数据：<br>
1、永久性：服务器重启也不会消失，这些数据被存储到了<code>innodb_table_stats</code>和<code>innodb_index_stats</code>这两张表中；<br>
2、非永久性：重启即消失。<br>
可以通过服务器的<code>innodb_stats_persistent</code>变量来查看这个统计数据的方式。</p>
<h2 id="innodb-table-stats-统计方式"><a class="header-anchor" href="#innodb-table-stats-统计方式">¶</a>innodb_table_stats 统计方式</h2>
<p>1、n_rows(一个表中的记录行数)统计项的收集<br>
按照一定算法选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的 n_rows 值<br>
2、clustered_index_size 和 sum_of_other_index_sizes</p>
<ul>
<li>从数据字典里找到表的各个索引对应的根页面位置。<br>
系统表 SYS_INDEXES 里存储了各个索引对应的根页面信息。</li>
<li>从根页面的 Page Header 里找到叶子节点段和非叶子节点段对应的 Segment Header。<br>
在每个索引的根页面的 Page Header 部分都有两个字段：<br>
PAGE_BTR_SEG_LEAF：表示 B+树叶子段的 Segment Header 信息。<br>
PAGE_BTR_SEG_TOP：表示 B+树非叶子段的 Segment Header 信息。</li>
<li>从叶子节点段和非叶子节点段的 Segment Header 中找到这两个段对应的 INODE Entry 结构。<br>
这个是 Segment Header 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b165a91f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>从对应的 INODE Entry 结构中可以找到该段对应所有零散的页面地址以及 FREE、NOT_FULL、FULL 链表的基节点。<br>
这个是 INODE Entry 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b1e44524?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>直接统计零散的页面有多少个，然后从那三个链表的 List Length 字段中读出该段占用的区的大小，每个区占用 64 个页，所以就可以统计出整个段占用的页面。<br>
这个是链表基节点的示意图：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b17c24e3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>分别计算聚簇索引的叶子结点段和非叶子节点段占用的页面数，它们的和就是 clustered_index_size 的值，按照同样的套路把其余索引占用的页面数都算出来，加起来之后就是 sum_of_other_index_sizes 的值。</li>
</ul>
<h2 id="innodb-index-stats-统计方式"><a class="header-anchor" href="#innodb-index-stats-统计方式">¶</a>innodb_index_stats 统计方式</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM mysql.innodb_index_stats WHERE table_name = &apos;single_table&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>n_leaf_pages：表示该索引的叶子节点占用多少页面。</li>
<li>size：表示该索引共占用多少页面。</li>
<li>n_diff_pfxNN：表示对应的索引列不重复的值有多少。其中的 NN 长得有点儿怪呀，啥意思呢？<br>
其实 NN 可以被替换为 01、02、03… 这样的数字。比如对于 idx_key_part 来说：<br>
n_diff_pfx01 表示的是统计 key_part1 这单单一个列不重复的值有多少。<br>
n_diff_pfx02 表示的是统计 key_part1、key_part2 这两个列组合起来不重复的值有多少。<br>
n_diff_pfx03 表示的是统计 key_part1、key_part2、key_part3 这三个列组合起来不重复的值有多少。<br>
n_diff_pfx04 表示的是统计 key_part1、key_part2、key_part3、id 这四个列组合起来不重复的值有多少。</li>
<li>在计算某些索引列中包含多少不重复值时，需要对一些叶子节点页面进行采样，sample_size 列就表明了采样的页面数量是多少。</li>
</ul>
<h2 id="基于内存的非永久性统计数据"><a class="header-anchor" href="#基于内存的非永久性统计数据">¶</a>基于内存的非永久性统计数据</h2>
<p>开启非永久性统计数据的方法：<br>
1、将<code>innodb_stats_persistent</code>的值设置为 OFF；<br>
2、直接在创建表或修改表时设置<code>STATS_PERSISTENT</code>属性的值为 0；</p>
<h1>MySQL Server 统计数据</h1>
<p>Server 层而不是 InnoDB（存储引擎层）统计数据。<br>
1、查看连接数配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;%max_connections%&apos;</span><br></pre></td></tr></table></figure>
<p>2、查看当前连接数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show full processlist;</span><br></pre></td></tr></table></figure>
<h1>数据恢复</h1>
<p>数据的误删基本分以下几种情况：</p>
<ol>
<li>使用 delete 语句误删数据行；</li>
<li>使用 drop table 或 truncate table 误删表；</li>
<li>使用 drop database 误删数据库；</li>
<li>使用 rm 命令误删整个 MySQL 实例。</li>
</ol>
<h2 id="误删行"><a class="header-anchor" href="#误删行">¶</a>误删行</h2>
<p>使用 Flashback 工具通过闪回把数据恢复。<br>
Flashback 恢复数据的原理，是<strong>修改 binlog 的内容</strong>（事务里的语句顺序颠倒、语句的语义颠倒比如 insert 变成 delete），拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。</p>
<h2 id="误删库-表"><a class="header-anchor" href="#误删库-表">¶</a>误删库 / 表</h2>
<p>误删库表的情况不能使用 Flashback 恢复，因为即使配置 binlog_format=row，truncate/drop 语句在 binlog 中也只会记录一条对应的语句，而用这些信息是无法恢复数据的。<br>
这种情况下，恢复需要使用全量备份，加增量日志。这个方案要求线上有定期的全量备份，并且实时备份 binlog。</p>
<h2 id="rm-删除数据"><a class="header-anchor" href="#rm-删除数据">¶</a>rm 删除数据</h2>
<p>仅仅删除某个节点的数据的情况，HA 系统可以选出新的主库，从而保证整个集群的正常工作。<br>
之后，我们可以在这个被删节点上把数据恢复回来，再接入整个集群。</p>
<h1>中断查询</h1>
<p>有时候因为查询耗时过长，或出现死锁等待，我们不得不提早终止执行 SQL 的线程，可以通过<code>information_schema.processlist</code> 和 <code>performance_schema.threads</code>这两张表来查看正在执行的线程：</p>
<ul>
<li>processlist 表中每一行对应一个客户端连接，也对应一个线程；</li>
<li>threads 每一行对应一个线程。</li>
</ul>
<p><code>kill query pid</code>可以杀死线程，但是客户端的连接还在，可以看到被 kill 后该连接进入了 Sleep 状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Id, User, Host, db, Command, Time, State, Info</span><br><span class="line">&apos;494633&apos;, &apos;beta&apos;, &apos;192.168.19.142:56193&apos;, &apos;ds_0&apos;, &apos;Sleep&apos;, &apos;26&apos;, &apos;&apos;, NULL</span><br></pre></td></tr></table></figure>
<p><code>kill pid</code>可以中断连接，执行后再用<code>processlist</code>就找不到那个 pid 了。</p>
<p>在客户端 Ctrl + C 并不能中断服务器线程，只能中断客户端进程，</p>
<h1>大表查询</h1>
<h2 id="server-层"><a class="header-anchor" href="#server-层">¶</a>Server 层</h2>
<p>MySQL 使用缓存来保证一次性查询大量数据的情况下不会把服务器内存打满，服务器并不需要保存一个完整的结果集。取数据和发数据的流程如下：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="MySQL-查询结果发送流程" title="MySQL-查询结果发送流程"></p>
<ol>
<li>获取一行，写到 <strong>net_buffer</strong> 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。</li>
<li>重复获取行，直到 net_buffer 写满，调用网络接口发出去。</li>
<li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。</li>
<li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示**本地网络栈（socket send buffer）**写满了，进入等待。直到网络栈重新可写，再继续发送。</li>
</ol>
<p>从上面的流程可知，MySQL 一次查询占用的内存是有限的，最大是<strong>min(net_buffer_length, socket send buffer)</strong>，即不能超过 net_buffer_length 和 socket send buffer；</p>
<h2 id="存储引擎层-innodb"><a class="header-anchor" href="#存储引擎层-innodb">¶</a>存储引擎层（InnoDB）</h2>
<p>InnoDB 使用 Buffer Pool 管理内存数据页，如果 Buffer Pool 命中率足够高，那么大部分时候是不需要读磁盘的，直接从内存拿结果，可以加快查询速度。<br>
执行 <code>show engine innodb status</code> ，可以看到“<code>Buffer pool hit rate</code>”字样，显示的就是当前的命中率，一般一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。<br>
Buffer Pool 的空间是有限的，新旧页面的更替是通过 LRU 算法控制的，但 InnoDB 中的 LRU 并不是单纯的新页面替换老页面（因为这样相当于每次大查询都会把整个 Buffer Pool 都刷新一遍），而是将 LRU 链表分成了 young 区和 old 区，页面第一次被访问时会被添加到 old 区，old 区的页面如果是短期内被多次访问，则其不会被移动到链表的头部（young 区），会很快被淘汰掉。</p>
<h1>临时表</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t like t1;</span><br><span class="line">alter table temp_t add index(b);</span><br><span class="line">insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;</span><br><span class="line">select * from t1 join temp_t on (t1.b=temp_t.b);</span><br></pre></td></tr></table></figure>
<p>临时表特性：</p>
<ol>
<li>不同 session 的临时表是可以重名的，常被用在复杂查询的优化过程中，比如有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</li>
<li>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。</li>
</ol>
<h2 id="临时表的使用场景"><a class="header-anchor" href="#临时表的使用场景">¶</a>临时表的使用场景</h2>
<h3 id="union-语句"><a class="header-anchor" href="#union-语句">¶</a>union 语句</h3>
<p>表 t1 在执行前已初始化插入了 1~1000 的数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-union%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-union执行流程" title="MySQL-union执行流程"><br>
上面语句将两个子查询的结果合并去重，union 合并时会生成临时表，这可以通过 explain 来验证。</p>
<h3 id="group-by"><a class="header-anchor" href="#group-by">¶</a>group by</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-groupby%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-groupby执行流程" title="MySQL-groupby执行流程"><br>
上面语句先创建内存临时表，表里有 m 和 c 两个字段，主键是 m，扫描 t1 索引 a，将<code>id%10</code>的结果插入临时表，如果出现主键冲突则计算 c 值+1。</p>
<ol>
<li>加索引<br>
默认情况下<code>id%10</code>是无序的，所以需要先在临时表中统计排序后再返回，但是如果原表本身就是有序的，则不需要临时表、也不需要额外排序了，实际上只要引入索引就可以解决这个问题，因为<strong>索引是有序的</strong>。</li>
<li>如果不能加索引，也可以加一列 generated column<br>
MySQL5.7 支持 generated column 机制，并可以在该列上创建索引：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);</span><br></pre></td></tr></table></figure>
<p>上面的 group by 语句可以改成如下的形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure>
<ol>
<li>如果不需要排序，可以显式声明忽略排序<br>
如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null</li>
<li>数据量小时使用内存临时表<br>
如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；</li>
<li>数据量大时使用磁盘临时表<br>
如果数据量较大，因为内存临时表的空间是有限的，当达到上限后就会转到磁盘内存表，与其这样转一下，不如直接使用磁盘内存表。<br>
因此，如果数据量实在太大，使用 <code>SQL_BIG_RESULT</code> 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。</li>
</ol>
<h1>Memory 引擎</h1>
<h2 id="memory-引擎与-innodb-引擎区别"><a class="header-anchor" href="#memory-引擎与-innodb-引擎区别">¶</a>Memory 引擎与 InnoDB 引擎区别</h2>
<ol>
<li>数据组织方式<br>
InnoDB 引擎采用 B+树来组织数据，主键是有序存储的。InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为<strong>索引组织表（Index Organizied Table）</strong>。<br>
Memory 引擎的数据和索引是分开的，数据以数组的方式单独存放，而主键索引是 hash 索引，存的是每个数据的位置，索引上的 key 并不是有序的：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-Memory%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87.png" alt="MySQL-Memory引擎数据组织" title="MySQL-Memory引擎数据组织"><br>
Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为<strong>堆组织表（Heap Organizied Table）</strong>。</li>
<li>存放顺序<br>
InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li>
<li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li>
<li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；</li>
<li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li>
<li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</li>
</ol>
<h2 id="hash-索引和-b-tree-索引"><a class="header-anchor" href="#hash-索引和-b-tree-索引">¶</a>hash 索引和 B-Tree 索引</h2>
<p>内存表也支持 B-Tree 索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E5%86%85%E5%AD%98%E8%A1%A8B-Tree%E7%B4%A2%E5%BC%95.png" alt="MySQL-内存表B-Tree索引" title="MySQL-内存表B-Tree索引"><br>
可以查看以下两个语句的输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 命中索引a_btree_index，因此输出结果是有序的</span><br><span class="line">select * from t1 where id &lt; 5;</span><br><span class="line">-- 强制使用主键id索引，因此是无序的</span><br><span class="line">select * from t1 force index (primary) where id &lt; 5;</span><br></pre></td></tr></table></figure>
<h2 id="不推荐在生产环境使用-memory-引擎"><a class="header-anchor" href="#不推荐在生产环境使用-memory-引擎">¶</a>不推荐在生产环境使用 Memory 引擎</h2>
<ol>
<li>锁粒度问题<br>
内存表不支持行锁，只支持表锁，只要这张表上有更新，就会堵住所有其他在这张表上的读写操作，因此在处理并发事务时性能也不会太好。</li>
<li>数据持久化问题<br>
因为数据被存放在内存中，数据库重启时所有的内存表都会被清空。</li>
</ol>
<p>虽然一般情况下不适合使用内存表，但是还有一种情况可以考虑使用内存表：用户临时表，只是临时数据，如果数据可控，不会消耗过多内存的情况下，可以考虑使用内存表。<br>
内存临时表（通过 create temporary table 语句创建）刚好可以无视内存表的两个不足，主要是下面的三个原因：</p>
<ol>
<li>临时表不会被其他线程访问，没有并发性的问题；</li>
<li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
</ol>
<h1>备份</h1>
<ul>
<li>将数据导出成一组 insert 语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where=&quot;a&gt;900&quot; --result-file=/client_tmp/t.sql</span><br></pre></td></tr></table></figure>
<p>恢复：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source /client_tmp/t.sql&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>导出 CSV 文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from db1.t where a&gt;900 into outfile &apos;/server_tmp/t.csv&apos;;</span><br></pre></td></tr></table></figure>
<p>恢复，将数据导入到目标表 db2.t 中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &apos;/server_tmp/t.csv&apos; into table db2.t;</span><br></pre></td></tr></table></figure>
<ul>
<li>物理拷贝<br>
不能通过直接拷贝表的.frm 文件和.ibd 文件来实现物理拷贝，因为一个 InnoDB 表除了包含这两个物理文件外，还需要在数据字典中注册，直接拷贝的情况下系统不会识别。<br>
在 MySQL 5.6 版本引入了<strong>可传输表空间(transportable tablespace)</strong> 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。
<ol>
<li>执行 create table r like t，创建一个相同表结构的空表；</li>
<li>执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；</li>
<li>执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；</li>
<li>在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；</li>
<li>这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；</li>
<li>执行 unlock tables，这时候 t.cfg 文件会被删除；</li>
<li>执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。</li>
</ol>
</li>
</ul>
<p>这三种方法各有优劣：</p>
<ol>
<li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
<ul>
<li>必须是全表拷贝，不能只拷贝部分数据；</li>
<li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；……</li>
<li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li>
</ul>
</li>
<li>用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。</li>
<li>用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</li>
</ol>
<h1>MySQL 中的自增 ID</h1>
<h2 id="表的自增-id"><a class="header-anchor" href="#表的自增-id">¶</a>表的自增 id</h2>
<p>我们经常给表的主键加上自增属性，用于唯一标识一条记录，但是因为自增值达到上限后再申请得到的值不变，因此自增字段的范围应该略大一些，尽可能创建成<code>bigint unsigned</code>。</p>
<h2 id="row-id"><a class="header-anchor" href="#row-id">¶</a>row_id</h2>
<p>如果没有指定主键，InnoDB 会创建一个不可见的、长度为 6 字节的 row_id，超过上限后再申请时会得到 0，<strong>如果新写入的行的 row_id 在表中已存在，则会直接覆盖原有的行</strong>，因此，最好优先使用自增 ID 而不是 row_id。</p>
<h2 id="xid"><a class="header-anchor" href="#xid">¶</a>Xid</h2>
<p>Xid 用于唯一标识一个事务。Xid 的值由一个内存变量 global_query_id 给出，重启后清零，但是因为每次重启时 binlog 都会重新生成，所以 binlog 中的 Xid 也不会重复。global_query_id 的长度为 8 个字节，除非 MySQL 实例一直执行了<code>2^64 - 1</code>次查询且期间没有重启，不然不会出现 Xid 重复的情况。</p>
<h2 id="max-trx-id"><a class="header-anchor" href="#max-trx-id">¶</a>max_trx_id</h2>
<p>Xid 由 server 层维护。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。<br>
InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。</p>
<blockquote>
<p>InnoDB 事务在读操作时不会申请 trx_id，trx_id 的值就是 0，只有在加锁或执行写操作时才会申请。<br>
只读事务不申请 trx_id 的原因是只读事务不影响事务的可见性判断，且能减少 trx_id 的申请次数、减少并发事务申请 trx_id 的锁冲突。</p>
</blockquote>
<p>MVCC 判断数据可见性的核心思想：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。</p>
<h2 id="thread-id"><a class="header-anchor" href="#thread-id">¶</a>thread_id</h2>
<p>系统保存一个全局变量 thread_id_counter，每新建一个连接就将 thread_id_counter 赋值给这个新连接的线程变量。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f2150593.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f2150593.html" itemprop="url">Netty 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-29T10:18:28+08:00">
                2020-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Netty/" itemprop="url" rel="index">
                    <span itemprop="name">Netty</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  30 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>为什么使用 Netty</h1>
<ol>
<li>实现协议的局限性<br>
今天，我们使用通用的应用程序或者类库来实现互相通讯，比如，我们经常使用一个 HTTP 客户端库来从 web 服务器上获取信息，或者通过 web 服务来执行一个远程的调用。<br>
然而，有时候一个通用的协议或他的实现并没有很好的满足需求。比如我们无法使用一个通用的 HTTP 服务器来处理大文件、电子邮件以及近实时消息，比如金融信息和多人游戏数据。我们需要一个高度优化的协议来处理一些特殊的场景。例如你可能想实现一个优化了的 Ajax 的聊天应用、媒体流传输或者是大文件传输器，你甚至可以自己设计和实现一个全新的协议来准确地实现你的需求。<br>
另一个不可避免的情况是当你不得不处理遗留的专有协议来确保与旧系统的互操作性。在这种情况下，重要的是我们如何才能快速实现协议而不牺牲应用的稳定性和性能。</li>
<li>使用 Netty 可以有效改善这种情况<br>
Netty 是一个提供 asynchronous event-driven （异步事件驱动）的网络应用框架，是一个用以快速开发高性能、高可靠性协议的服务器和客户端。<br>
换句话说，Netty 是一个 NIO 客户端服务器框架，使用它可以快速简单地开发网络应用程序，比如服务器和客户端的协议。Netty 大大简化了网络程序的开发过程比如 TCP 和 UDP 的 socket 服务的开发。<br>
“快速和简单”并不意味着应用程序会有难维护和性能低的问题，Netty 是一个精心设计的框架，它从许多协议的实现中吸收了很多的经验比如 FTP、SMTP、HTTP、许多二进制和基于文本的传统协议.因此，Netty 已经成功地找到一个方式,在不失灵活性的前提下来实现开发的简易性，高性能，稳定性。<br>
有一些用户可能已经发现其他的一些网络框架也声称自己有同样的优势，所以你可能会问是 Netty 和它们的不同之处。答案就是 Netty 的哲学设计理念。Netty 从开始就为用户提供了用户体验最好的 API 以及实现设计。正是因为 Netty 的哲学设计理念，才让您得以轻松地阅读本指南并使用 Netty。</li>
</ol>
<h1>架构总览</h1>
<p><img src="https://tallate.top/imgs/Netty/Netty%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88.png" alt="Netty架构总览" title="Netty架构总览"><br>
Netty 的架构由三部分组成——缓冲（buffer），通道（channel），事件模型（event model）——所有的高级特性都构建在这三个核心组件之上。</p>
<h2 id="nio"><a class="header-anchor" href="#nio">¶</a>NIO</h2>
<ol>
<li><a href="https://segmentfault.com/q/1010000010446129" target="_blank" rel="noopener">想了解 Aio 与 Nio 的利弊，为什么 Netty 没有采用 Aio 实现？</a></li>
</ol>
<p>NIO 基于传输层，可以自定义数据处理逻辑来作为应用层，或者基于现有的 HTTP 组件进行升级，在线上环境这样的升级会带来一些兼容性问题，HTTP 已有相应的协议升级机制：<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism" target="_blank" rel="noopener">Protocol upgrade mechanism</a>。</p>
<p>NIO 相对 BIO 优势：</p>
<ol>
<li>零拷贝<br>
零拷贝减少线程上下文切换次数，且数据直接拷贝到内核空间，不占用 JVM 堆空间；</li>
<li>减少线程资源浪费<br>
NIO 可以一个线程监听多个 Socket 的连接、读、写请求，而不是像 BIO 那样每个 Socket 创建一个线程，但是同时会有一个问题：</li>
</ol>
<h2 id="netty-核心组件"><a class="header-anchor" href="#netty-核心组件">¶</a>Netty 核心组件</h2>
<ol>
<li>Channel 和 ChannelHandler</li>
<li>ByteBuf</li>
<li>Pipeline</li>
</ol>
<h1>服务端</h1>
<p><img src="https://tallate.top/imgs/Netty/Netty%E6%B5%81%E7%A8%8B.png" alt="Netty流程" title="Netty流程"></p>
<h2 id="代码"><a class="header-anchor" href="#代码">¶</a>代码</h2>
<p>下面是一个启动Netty服务端的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ServerBootstrap bootstrap = new ServerBootstrap();</span><br><span class="line">        bootstrap.group(bossGroup(), workerGroup())</span><br><span class="line">                .channel(NioServerSocketChannel.class)</span><br><span class="line">                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                    @Override</span><br><span class="line">                    protected void initChannel(SocketChannel ch) throws Exception &#123;</span><br><span class="line">                        // 空闲检测</span><br><span class="line">                        ch.pipeline().addLast(&quot;idleStateHandler&quot;, new IdleStateHandler(15, 0, 0,</span><br><span class="line">                                TimeUnit.MINUTES));</span><br><span class="line"></span><br><span class="line">                        // 半包/粘包分解器</span><br><span class="line">                        ch.pipeline().addLast(</span><br><span class="line">                                new DelimiterBasedFrameDecoder(2048, true, getFirstBytes()</span><br><span class="line">                                ));</span><br><span class="line">                        ch.pipeline().addLast(其他Handler比如解码之类的);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).option(ChannelOption.SO_BACKLOG, 1024);</span><br><span class="line">bootstrap.bind(10885).sync()</span><br></pre></td></tr></table></figure>
<h2 id="创建eventloop"><a class="header-anchor" href="#创建eventloop">¶</a>创建EventLoop</h2>
<p>在上面的代码中，出现了<strong>bossGroup</strong>和<strong>workerGroup</strong>，bossGroup主要负责监听连接，拿到连接后，交给workerGroup中的线程来监听读或写事件。<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup</code><br>
<code>EventExecutorGroup</code>会给每个线程创建一个<code>EventLoop</code>。</p>
<p><code>io.netty.channel.nio.NioEventLoop#NioEventLoop</code><br>
<code>newChild()</code>创建EventLoop实例，其默认实现是<code>NioEventLoop</code>。</p>
<p><code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code><br>
服务器初始化过程中创建了个线程池<code>ThreadPerTaskExecutor</code>：</p>
<ul>
<li>每次执行任务都会构造一个线程执行<br>
<code>io.netty.util.concurrent.ThreadPerTaskExecutor#execute</code></li>
</ul>
<h2 id="创建及初始化-serversocketchannel"><a class="header-anchor" href="#创建及初始化-serversocketchannel">¶</a>创建及初始化 ServerSocketChannel</h2>
<p>Netty 有一个叫做 <strong>Channel</strong> 的统一的异步 I/O 编程接口，这个编程接口抽象了所有点对点的通信操作。也就是说，如果你的应用是基于 Netty 的某一种传输实现，那么同样的，你的应用也可以运行在 Netty 的另一种传输实现上。Netty 提供了几种拥有相同编程接口的基本传输实现：</p>
<ul>
<li>基于 NIO 的 TCP/IP 传输 (见 io.netty.channel.nio),</li>
<li>基于 OIO 的 TCP/IP 传输 (见 io.netty.channel.oio),</li>
<li>基于 OIO 的 UDP/IP 传输, 和</li>
<li>本地传输 (见 io.netty.channel.local).</li>
</ul>
<p>切换不同的传输实现通常只需对代码进行几行的修改调整，例如选择一个不同的 <strong>ChannelFactory</strong> 实现。<br>
此外，你甚至可以利用新的传输实现没有写入的优势，只需替换一些构造器的调用方法即可，例如串口通信。而且由于核心 API 具有高度的可扩展性，你还可以完成自己的传输实现。</p>
<ol>
<li>入口<br>
<code>io.netty.bootstrap.AbstractBootstrap#bind(int)</code><br>
用户代码调用bind绑定端口时会触发Channel的创建和初始化</li>
</ol>
<p><code>io.netty.bootstrap.ServerBootstrap#init</code><br>
对Channel的使用可以追溯到这个init方法，包括Channel的创建、属性等的设置。</p>
<ol>
<li>
<p>创建<br>
<code>NioServerSocketChannel</code>的构造方法 -&gt; <code>io.netty.channel.socket.nio.NioServerSocketChannel#newSocket</code><br>
可以看到，Netty中的<code>ServerSocketChannel</code>其实就对应JDK NIO中的<code>ServerSocketChannel</code>，在创建<code>NioServerSocketChannel</code>的同时创建了一个NIO中的<code>ServerSocketChannel</code>。</p>
</li>
<li>
<p>初始化<br>
中间包含对<code>childOptions</code>和<code>childAttrs</code>等的设置。</p>
</li>
<li>
<p>添加一个连接处理器<code>ServerBootstrapAcceptor</code>。</p>
</li>
</ol>
<h2 id="注册selector"><a class="header-anchor" href="#注册selector">¶</a>注册Selector</h2>
<p>紧接着上面的初始化过程，接下来是注册NIO中的Selector。<br>
<code>io.netty.channel.EventLoopGroup#register(io.netty.channel.Channel)</code><br>
总而言之最终还是使用NIO注册了 Selector。<br>
<code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
<h3 id="启动-nioeventloop"><a class="header-anchor" href="#启动-nioeventloop">¶</a>启动 NioEventLoop</h3>
<p><code>io.netty.bootstrap.AbstractBootstrap#doBind0</code><br>
绑定端口号的同时，执行一个线程。<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#startThread</code><br>
NioEventLoop启动流程的最终启动了一个线程。<br>
<code>io.netty.channel.nio.NioEventLoop#run</code><br>
该线程任务根据EventLoop的实现不同而有所不同，在<code>NioEventLoop</code>中，主要任务为以下3步：</p>
<ol>
<li>
<p>接收事件（selectionKey）<br>
<code>io.netty.channel.nio.NioEventLoop#select</code><br>
当检查没有需要处理的selectionKey时就会发生空轮询，Netty在轮询时会记录空轮询次数，<strong>当空轮询达到一定次数时，将之前注册的事件先取消，从而避免了NIO的空轮询Bug</strong>。</p>
</li>
<li>
<p>检测新连接并创建NioSocketChannel<br>
<code>io.netty.channel.nio.NioEventLoop#processSelectedKeys</code><br>
处理连接请求，并分发请求到<strong>pipeline</strong><br>
<code>io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe#read</code></p>
<ul>
<li>每个连接创建一个<strong>ServerSocketChannel</strong>。<br>
<code>io.netty.channel.socket.nio.NioServerSocketChannel#doReadMessages</code></li>
<li>读取数据并分发到<strong>pipeline</strong><br>
<code>io.netty.channel.ChannelPipeline#fireChannelReadComplete</code></li>
</ul>
</li>
<li>
<p>执行线程任务<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#runAllTasks(long)</code></p>
</li>
</ol>
<h2 id="pipeline中的第一个channelhandler"><a class="header-anchor" href="#pipeline中的第一个channelhandler">¶</a>pipeline中的第一个ChannelHandler</h2>
<p>pipeline的第一个Handler为<code>ServerBootstrapAcceptor</code>，它的主要任务包括：</p>
<ol>
<li>
<p>将用户自定义<code>ChannelHandler</code>添加到pipeline</p>
</li>
<li>
<p>选择一个<code>NioEventLoop</code>传播事件<br>
<code>io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel)</code></p>
</li>
<li>
<p>注册selector<br>
代码流程非常长，但是最终可以跟到<code>doRegister</code>这个方法，可以发现最后还是调用了JDK的SocketChannel注册Selector。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code> -&gt; <code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
</li>
<li>
<p>注册读事件<br>
代码最后判断第一次连接则触发连接激活事件，代码位置仍然是上边的<code>register0</code>。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code><br>
继续往下看可以看到最终将读事件（selectionKey）注册到了Selector<br>
<code>io.netty.channel.DefaultChannelPipeline.HeadContext#channelActive</code><br>
-&gt; <code>io.netty.channel.DefaultChannelPipeline.HeadContext#readIfIsAutoRead</code><br>
-&gt; <code>io.netty.channel.nio.AbstractNioChannel#doBeginRead</code></p>
</li>
</ol>
<p>选择EventLoop：<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#chooser</code><br>
每当有客户端连接进来时，Netty需要决定选择哪个EventLoop，这个工作是由<code>EventExecutorChooser</code>负责的：</p>
<ul>
<li><code>GenericEventExecutorChooser</code>：循环选择。</li>
<li><code>PowerOfTwoEventExecutorChooser</code>：也是循环选择，只不过<code>GenericEventExecutorChooser</code>使用了取模运算，而<code>PowerOfTwoEventExecutorChooser</code>是通过位运算实现的。</li>
</ul>
<h2 id="pipeline"><a class="header-anchor" href="#pipeline">¶</a>Pipeline</h2>
<ol>
<li>
<p>创建Pipeline<br>
创建NioSocketChannel时会创建Pipeline：<br>
<code>io.netty.channel.AbstractChannel#AbstractChannel</code><br>
Pipeline本身是一个<strong>双向链表</strong>的结构，且有两个哨兵节点<code>head</code>和<code>tail</code>。</p>
</li>
<li>
<p>添加Pipeline<br>
添加到链表<br>
<code>io.netty.channel.ChannelPipeline#addLast(io.netty.channel.ChannelHandler...)</code><br>
检查是否重复添加，如果加了<code>@Sharable</code>注解是可以重复添加的<br>
<code>io.netty.channel.DefaultChannelPipeline#checkMultiplicity</code><br>
添加到链表末尾，也就是添加到<code>tail</code>节点的前面。<br>
<code>io.netty.channel.DefaultChannelPipeline#addLast0</code></p>
</li>
<li>
<p>删除Pipeline<br>
有时候我们需要删除一个Pipeline上的某些ChannelHandler，比如已经进行过了授权校验，那下次就不需要再执行授权校验了，我们就可以直接把授权相关的那些ChannelHandler删除掉。<br>
首先遍历Pipeline找到目标ChannelHandler。<br>
<code>io.netty.channel.DefaultChannelPipeline#getContextOrDie</code><br>
然后从Pipeline中移除。<br>
<code>io.netty.channel.DefaultChannelPipeline#remove(AbstractChannelHandlerContext)</code></p>
</li>
<li>
<p>inBound事件传播<br>
ChannelHandler中每个事件都有一个接口，<code>ChannelInboundHandler</code>专门处理输入事件，以<code>channelRead</code>为例。<br>
EventLoop会将读事件传给Pipeline，然后按责任链模式的逻辑从<code>head</code>节点开始传播事件。<br>
<code>io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read</code></p>
</li>
<li>
<p>outBound事件传播<br>
<code>ChannelOutboundHandler</code>专门用于处理输出事件，以<code>write</code>为例。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class EchoServerOutHandler extends ChannelOutboundHandlerAdapter &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123;</span><br><span class="line">        ctx.channel().write(&quot;Hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们在Handler中调用Context的write方法时，就是将写事件传给了Pipeline，Pipeline会从<code>tail</code>节点开始往前传播。<br>
<code>io.netty.channel.AbstractChannelHandlerContext#write</code></p>
<h2 id="心跳检测"><a class="header-anchor" href="#心跳检测">¶</a>心跳检测</h2>
<p>应用协议层的心跳是必须的，它和 tcp keepalive 是完全不同的概念。应用层协议层的心跳检测的是连接双方的存活性，兼而连接质量，而 keepalive 检测的是连接本身的存活性。而且后者的超时时间默认过长，完全不能适应现代的网络环境。<br>
Netty 内置通过增加 <code>IdleStateHandler</code> 产生 IDLE 事件进行便捷的心跳控制。你要处理的，就是心跳超时的逻辑，比如延迟重连。但它的轮训时间是固定的，无法动态修改，高级功能需要自己定制。<br>
不同场景下需要切换不同的保活机制，在一些客户端比如 Android，频繁心跳的唤起会浪费大量的网络和电量，它的心跳策略会更加复杂一些。</p>
<h2 id="优雅退出"><a class="header-anchor" href="#优雅退出">¶</a>优雅退出</h2>
<p>Java 的优雅停机通常通过注册 JDK ShutdownHook 来实现。<br>
Runtime.getRuntime().addShutdownHook();<br>
一般通过 kill -15 进行 java 进程的关闭，以便在进程死亡之前进行一些清理工作。</p>
<blockquote>
<p>注意：kill -9 会立马杀死进程，不给遗言的机会，比较危险。</p>
</blockquote>
<p>虽然 netty 做了很多优雅退出的工作，通过 EventLoopGroup 的 shutdownGracefully 方法对 nio 进行了一些状态设置，但在很多情况下，这还不够多。它只负责单机环境的优雅关闭。<br>
流量可能还会通过外层的路由持续进入，造成无效请求。一种可行的做法是首先在外层路由进行一次本地实例的摘除，把流量截断，然后再进行 netty 本身的优雅关闭。</p>
<h2 id="示例协议实现"><a class="header-anchor" href="#示例协议实现">¶</a>示例协议实现</h2>
<p>不少中间件会实现自己的协议，比如 Redis、MySQL，MyCat、TiDB 用的就是 MySQL 协议。<br>
netty 默认实现了 dns、haproxy、http、http2、memcache、mqtt、redis、smtp、socks、stomp、xml 等协议。<br>
协议分为两种：</p>
<ul>
<li>文本协议在调试起来是比较直观和容易的，但安全性欠佳；</li>
<li>二进制协议就需要依赖日志、wireshark 等其他方式进行分析，增加了开发难度。</li>
</ul>
<ol>
<li><a href="https://netty.io/4.0/xref/io/netty/example/echo/package-summary.html" target="_blank" rel="noopener">示例协议 - echo</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/discard/package-summary.html" target="_blank" rel="noopener">示例协议 - discard</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/uptime/package-summary.html" target="_blank" rel="noopener">示例协议 - uptime</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/factorial/package-summary.html" target="_blank" rel="noopener">示例二进制协议 - factorial</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/telnet/package-summary.html" target="_blank" rel="noopener">示例文本协议 - telnet</a></li>
</ol>
<h1>数据结构 - ByteBuf</h1>
<p>Netty 使用自建的 buffer API，而不是使用 NIO 的 <a href="http://docs.oracle.com/javase/7/docs/api/java/nio/ByteBuffer.html?is-external=true" target="_blank" rel="noopener">ByteBuffer</a> 来表示一个连续的字节序列。与 ByteBuffer 相比这种方式拥有明显的优势。Netty 使用新的 buffer 类型 <a href="http://netty.io/4.0/api/io/netty/buffer/ByteBuf.html" target="_blank" rel="noopener">ByteBuf</a>，被设计为一个可从底层解决 ByteBuffer 问题，并可满足日常网络应用开发需要的缓冲类型。这些很酷的特性包括：</p>
<ul>
<li>如果需要，允许使用自定义的缓冲类型。</li>
<li>复合缓冲类型中内置的透明的零拷贝实现。</li>
<li>开箱即用的动态缓冲类型，具有像 StringBuffer 一样的动态缓冲能力。</li>
<li>不再需要调用的 flip()方法。</li>
<li>正常情况下具有比 ByteBuffer 更快的响应速度。</li>
</ul>
<p><img src="https://tallate.top/imgs/Netty/ByteBuf%E7%BB%93%E6%9E%84.png" alt="ByteBuf结构" title="ByteBuf结构"><br>
以上就是一个 ByteBuf 的结构图，从上面这幅图可以看到</p>
<ol>
<li>ByteBuf 是一个字节容器，容器里面的的数据分为三个部分，第一个部分是已经丢弃的字节，这部分数据是无效的；第二部分是可读字节，这部分数据是 ByteBuf 的主体数据， 从 ByteBuf 里面读取的数据都来自这一部分;最后一部分的数据是可写字节，所有写到 ByteBuf 的数据都会写到这一段。最后一部分虚线表示的是该 ByteBuf 最多还能扩容多少容量</li>
<li>以上三段内容是被两个指针给划分出来的，从左到右，依次是读指针（readerIndex）、写指针（writerIndex），然后还有一个变量 capacity，表示 ByteBuf 底层内存的总容量</li>
<li>从 ByteBuf 中每读取一个字节，readerIndex 自增 1，ByteBuf 里面总共有 writerIndex-readerIndex 个字节可读, 由此可以推论出当 readerIndex 与 writerIndex 相等的时候，ByteBuf 不可读</li>
<li>写数据是从 writerIndex 指向的部分开始写，每写一个字节，writerIndex 自增 1，直到增到 capacity，这个时候，表示 ByteBuf 已经不可写了</li>
<li>ByteBuf 里面其实还有一个参数 maxCapacity，当向 ByteBuf 写数据的时候，如果容量不足，那么这个时候可以进行扩容，直到 capacity 扩容到 maxCapacity，超过 maxCapacity 就会报错</li>
</ol>
<p>使用 ByteBuf 有以下好处：</p>
<ol>
<li>
<p>可以有效地区分可读数据和可写数据，读写之间相互没有冲突</p>
</li>
<li>
<p>Extensibility 可扩展性<br>
ByteBuf 具有丰富的操作集,可以快速的实现协议的优化。例如，ByteBuf 提供各种操作用于访问无符号值和字符串，以及在缓冲区搜索一定的字节序列。你也可以扩展或包装现有的缓冲类型用来提供方便的访问。自定义缓冲式仍然实现自 ByteBuf 接口，而不是引入一个不兼容的类型</p>
</li>
<li>
<p>Transparent Zero Copy 透明的零拷贝<br>
网络应用中需要减少内存拷贝操作次数。你可能有一组缓冲区可以被组合以形成一个完整的消息。网络提供了一种复合缓冲，允许你从现有的任意数的缓冲区创建一个新的缓冲区而无需内存拷贝。例如，一个信息可以由两部分组成：header 和 body。在一个模块化的应用，当消息发送出去时，这两部分可以由不同的模块生产和装配。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+--------+------+</span><br><span class="line">| header | body |</span><br><span class="line">+--------+------+</span><br></pre></td></tr></table></figure>
<p>如果你使用的是 ByteBuffer ，你必须要创建一个新的大缓存区用来拷贝这两部分到这个新缓存区中。或者，你可以在 NIO做一个收集写操作，但限制你将复合缓冲类型作为 ByteBuffer 的数组而不是一个单一的缓冲区，这样打破了抽象，并且引入了复杂的状态管理。此外，如果你不从 NIO channel 读或写，它是没有用的。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型不兼容。</span><br><span class="line">ByteBuffer[] message = new ByteBuffer[] &#123; header, body &#125;;</span><br></pre></td></tr></table></figure>
<p>通过对比， ByteBuf 不会有警告，因为它是完全可扩展并有一个内置的复合缓冲区。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型是兼容的。</span><br><span class="line">ByteBuf message = Unpooled.wrappedBuffer(header, body);</span><br><span class="line">// 因此，你甚至可以通过混合复合类型与普通缓冲区来创建一个复合类型。</span><br><span class="line">ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer);</span><br><span class="line">// 由于复合类型仍是 ByteBuf，访问其内容很容易，</span><br><span class="line">//并且访问方法的行为就像是访问一个单独的缓冲区，</span><br><span class="line">//即使你想访问的区域是跨多个组件。</span><br><span class="line">//这里的无符号整数读取位于 body 和 footer</span><br><span class="line">messageWithFooter.getUnsignedInt(</span><br><span class="line">     messageWithFooter.readableBytes() - footer.readableBytes() - 1);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Automatic Capacity Extension 自动容量扩展<br>
许多协议定义可变长度的消息，这意味着没有办法确定消息的长度，直到你构建的消息。或者，在计算长度的精确值时，带来了困难和不便。这就像当你建立一个字符串。你经常估计得到的字符串的长度，让 StringBuffer 扩大了其本身的需求。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 一种新的动态缓冲区被创建。在内部，实际缓冲区是被“懒”创建，从而避免潜在的浪费内存空间。</span><br><span class="line">ByteBuf b = Unpooled.buffer(4);</span><br><span class="line">// 当第一个执行写尝试，内部指定初始容量 4 的缓冲区被创建</span><br><span class="line">b.writeByte(&apos;1&apos;);</span><br><span class="line">b.writeByte(&apos;2&apos;);</span><br><span class="line">b.writeByte(&apos;3&apos;);</span><br><span class="line">b.writeByte(&apos;4&apos;);</span><br><span class="line">// 当写入的字节数超过初始容量 4 时，</span><br><span class="line">//内部缓冲区自动分配具有较大的容量</span><br><span class="line">b.writeByte(&apos;5&apos;);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Better Performance 更好的性能<br>
最频繁使用的缓冲区 ByteBuf 的实现是一个非常薄的字节数组包装器（比如，一个字节）。与 ByteBuffer 不同，它没有复杂的边界和索引检查补偿，因此对于 JVM 优化缓冲区的访问更加简单。更多复杂的缓冲区实现是用于拆分或者组合缓存，并且比 ByteBuffer 拥有更好的性能。</p>
</li>
</ol>
<h2 id="粘包拆包和半包合并"><a class="header-anchor" href="#粘包拆包和半包合并">¶</a>粘包拆包和半包合并</h2>
<p>基于流的传输比如 TCP/IP, 接收到数据是存在 socket 接收的 buffer 中。不幸的是，基于流的传输并不是一个数据包队列，而是一个字节队列。造成粘包的原因，主要是由于缓冲区的介入，所以需要严格约定去所传输的包的格式——何时开始何时结束。意味着，即使你发送了 2 个独立的数据包，操作系统也不会作为 2 个消息处理而仅仅是作为一连串的字节而言。因此这是不能保证你远程写入的数据就会准确地读取。举个例子，让我们假设操作系统的 TCP/TP 协议栈已经接收了 3 个数据包，在应用程序中读取数据的时候可能被分成下面的片段：<br>
<img src="https://tallate.top/imgs/Netty/%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85%E9%97%AE%E9%A2%98.png" alt="粘包和半包问题" title="粘包和半包问题"><br>
因此，一个接收方不管他是客户端还是服务端，都应该把接收到的数据整理成一个或者多个更有意义并且能够让程序的业务逻辑更好理解的数据。<br>
在没有 Netty 的情况下，用户如果自己需要拆包，基本原理就是不断从 TCP 缓冲区中读取数据，每次读取完都需要判断是否是一个完整的数据包</p>
<ul>
<li>半包：如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。</li>
<li>粘包：如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。</li>
</ul>
<h2 id="解码器-bytetomessagedecoder"><a class="header-anchor" href="#解码器-bytetomessagedecoder">¶</a>解码器 - ByteToMessageDecoder</h2>
<p>入口：<code>io.netty.handler.codec.ByteToMessageDecoder#channelRead</code></p>
<ol>
<li>累加字节流<br>
累加器累加已读入的字节数，如果超过<code>ByteBuf</code>当前可读入的空间大小，则执行扩容。<br>
<code>io.netty.handler.codec.ByteToMessageDecoder.Cumulator#cumulate</code></li>
<li>调用子类的decode方法进行解析（模板方法）<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#callDecode</code></li>
<li>将子类解析出的ByteBuf向下传播<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#fireChannelRead(io.netty.channel.ChannelHandlerContext, io.netty.handler.codec.CodecOutputList, int)</code></li>
</ol>
<h2 id="netty中的一些拆箱即用的解码器"><a class="header-anchor" href="#netty中的一些拆箱即用的解码器">¶</a>Netty中的一些拆箱即用的解码器</h2>
<p>如果要自己实现所有协议的拆包无疑是非常麻烦的，实际上 Netty 已经自带了一些开箱即用的拆包器：</p>
<ol>
<li>固定长度的拆包器 <code>FixedLengthFrameDecoder</code><br>
如果你的应用层协议非常简单，每个数据包的长度都是固定的，比如 100，那么只需要把这个拆包器加到 pipeline 中，Netty 会把一个个长度为 100 的数据包 (ByteBuf) 传递到下一个 channelHandler。</li>
<li>行拆包器 <code>LineBasedFrameDecoder</code><br>
从字面意思来看，发送端发送数据包的时候，每个数据包之间以<strong>换行符</strong>作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包。</li>
<li>分隔符拆包器 <code>DelimiterBasedFrameDecoder</code><br>
DelimiterBasedFrameDecoder 是行拆包器的通用版本，只不过我们可以自定义分隔符。</li>
<li>基于长度域拆包器 <code>LengthFieldBasedFrameDecoder</code><br>
最后一种拆包器是最通用的一种拆包器，只要你的自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包。由于上面三种拆包器比较简单，读者可以自行写出 demo，接下来，我们就结合我们小册的自定义协议，来学习一下如何使用基于长度域的拆包器来拆解我们的数据包。</li>
</ol>
<h2 id="编码-messagetobyteencoder"><a class="header-anchor" href="#编码-messagetobyteencoder">¶</a>编码 - MessageToByteEncoder</h2>
<p>编码器是一个ChannelHandler，一般是第一个添加到Pipeline内，然后write的最后会将数据进行编码再输出。</p>
<ol>
<li>匹配对象<br>
<code>io.netty.handler.codec.MessageToByteEncoder#acceptOutboundMessage</code></li>
<li>内存分配<br>
<code>io.netty.handler.codec.MessageToByteEncoder#allocateBuffer</code></li>
<li>调用子类的编码实现<br>
<code>io.netty.handler.codec.MessageToByteEncoder#encode</code></li>
<li>释放内存<br>
<code>io.netty.util.ReferenceCountUtil#release(java.lang.Object)</code></li>
<li>放到Pipeline里传播<br>
默认情况下会一直传播到<code>head</code>节点<br>
<code>io.netty.channel.ChannelHandlerContext#write(java.lang.Object, io.netty.channel.ChannelPromise)</code><br>
<code>io.netty.channel.Channel.Unsafe#write</code></li>
<li>输出<br>
将数据暂存到ByteBuf，将堆内对象转换为堆外内存<br>
<code>io.netty.channel.nio.AbstractNioByteChannel#filterOutboundMessage</code><br>
插入写队列<br>
<code>io.netty.channel.ChannelOutboundBuffer#addMessage</code><br>
TODO: 什么时候刷新buffer队列？</li>
</ol>
<h1>自定义数据处理逻辑</h1>
<h2 id="基于拦截链模式的事件模型-pipeline"><a class="header-anchor" href="#基于拦截链模式的事件模型-pipeline">¶</a>基于拦截链模式的事件模型 - pipeline</h2>
<p>一个定义良好并具有扩展能力的事件模型是事件驱动开发的必要条件。Netty 具有定义良好的 I/O 事件模型。由于严格的层次结构区分了不同的事件类型，因此 Netty 也允许你在不破坏现有代码的情况下实现自己的事件类型。这是与其他框架相比另一个不同的地方。很多 NIO 框架没有或者仅有有限的事件模型概念；在你试图添加一个新的事件类型的时候常常需要修改已有的代码，或者根本就不允许你进行这种扩展。<br>
在 Netty 中一条连接对应一个 Channel，该 Channel 的所有处理逻辑都在一个 ChannelPipeline 对象内，ChannelPipeline 是一个双向链表结构，在一个 ChannelPipeline 内部一个 <a href="../%E6%8A%80%E6%9C%AF%E7%82%B9%E6%80%BB%E7%BB%93">ChannelEvent</a> 被一组 ChannelHandler 处理。这个管道是 Intercepting Filter (拦截过滤器)模式的一种高级形式的实现，因此对于一个事件如何被处理以及管道内部处理器间的交互过程，你都将拥有绝对的控制力。例如，你可以定义一个从 socket 读取到数据后的操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyReadHandler implements SimpleChannelHandler &#123;</span><br><span class="line">     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">         Object message = evt.getMessage();</span><br><span class="line">         // Do something with the received message.</span><br><span class="line">            ...</span><br><span class="line">         // And forward the event to the next handler.</span><br><span class="line">         ctx.sendUpstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时你也可以定义一种操作响应其他处理器的写操作请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyWriteHandler implements SimpleChannelHandler &#123;</span><br><span class="line">    public void writeRequested(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">        Object message = evt.getMessage();</span><br><span class="line">        // Do something with the message to be written.</span><br><span class="line">            ...</span><br><span class="line">        // And forward the event to the next handler.</span><br><span class="line">        ctx.sendDownstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ChannelHandler 分为两种：</p>
<ul>
<li>ChannelInboundHandler<br>
处理读数据逻辑，核心方法是 channelRead。</li>
<li>ChannelOutBoundHandler<br>
处理些数据逻辑，核心方法是 write，在链式处理中总是位于 ChannelInboundHandler 之后。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">serverBootstrap</span><br><span class="line">        .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">            protected void initChannel(NioSocketChannel ch) &#123;</span><br><span class="line">                // inBound，处理读数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerC());</span><br><span class="line">                </span><br><span class="line">                // outBound，处理写数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerC());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>
<p>其执行顺序如下图所示：<br>
<img src="https://tallate.top/imgs/Netty/pipeline%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.png" alt="pipeline执行顺序" title="pipeline执行顺序"></p>
<h2 id="异常处理"><a class="header-anchor" href="#异常处理">¶</a>异常处理</h2>
<p>netty 由于其异步化的开发方式，以及其事件机制，在异常处理方面就显得异常重要。为了保证连接的高可靠性，许多异常需要静悄悄的忽略，或者在用户态没有感知。<br>
netty 的异常会通过 pipeline 进行传播，所以在任何一层进行处理都是可行的，但编程习惯上，习惯性抛到最外层集中处理。<br>
为了最大限度的区别异常信息，通常会定义大量的异常类，不同的错误会抛出不同的异常。发生异常后，可以根据不同的类型选择断线重连（比如一些二进制协议的编解码紊乱问题)，或者调度到其他节点。</p>
<h2 id="codec-框架"><a class="header-anchor" href="#codec-框架">¶</a>Codec 框架</h2>
<p>我们可以使用 POJO 代替 ChannelBuffer，从业务逻辑代码中分离协议处理部分总是一个很不错的想法。然而如果一切从零开始便会遭遇到实现上的复杂性。你不得不处理分段的消息。一些协议是多层的（例如构建在其他低层协议之上的协议）。一些协议过于复杂以致难以在一台独立状态机上实现。<br>
因此，一个好的网络应用框架应该提供一种可扩展，可重用，可单元测试并且是多层的 codec 框架，为用户提供易维护的 codec 代码。<br>
Netty 提供了一组构建在其核心模块之上的 codec 实现，这些简单的或者高级的 codec 实现帮你解决了大部分在你进行协议处理开发过程会遇到的问题，无论这些协议是简单的还是复杂的，二进制的或是简单文本的。</p>
<h2 id="ssl-tls-支持"><a class="header-anchor" href="#ssl-tls-支持">¶</a>SSL / TLS 支持</h2>
<p>不同于传统阻塞式的 I/O 实现，在 NIO 模式下支持 SSL 功能是一个艰难的工作。你不能只是简单的包装一下流数据并进行加密或解密工作，你不得不借助于 javax.net.ssl.SSLEngine，SSLEngine 是一个有状态的实现，其复杂性不亚于 SSL 自身。你必须管理所有可能的状态，例如密码套件，密钥协商（或重新协商），证书交换以及认证等。此外，与通常期望情况相反的是 SSLEngine 甚至不是一个绝对的线程安全实现。<br>
在 Netty 内部，<a href="http://netty.io/4.0/api/io/netty/handler/ssl/SslHandler.html" target="_blank" rel="noopener">SslHandler</a> 封装了所有艰难的细节以及使用 SSLEngine 可 能带来的陷阱。你所做的仅是配置并将该 SslHandler 插入到你的 ChannelPipeline 中。同样 Netty 也允许你实现像 <a href="https://en.wikipedia.org/wiki/Opportunistic_TLS" target="_blank" rel="noopener">StartTlS</a> 那样所拥有的高级特性，这很容易。</p>
<h2 id="http-实现"><a class="header-anchor" href="#http-实现">¶</a>HTTP 实现</h2>
<p>HTTP 无 疑是互联网上最受欢迎的协议，并且已经有了一些例如 Servlet 容器这样的 HTTP 实现。因此，为什么 Netty 还要在其核心模块之上构建一套 HTTP 实现？<br>
与现有的 HTTP 实现相比 Netty 的 HTTP 实现是相当与众不同的。在 HTTP 消息的低层交互过程中你将拥有绝对的控制力。这是因为 Netty 的 HTTP 实现只是一些 HTTP codec 和 HTTP 消息类的简单组合，这里不存在任何限制——例如那种被迫选择的线程模型。你可以随心所欲的编写那种可以完全按照你期望的工作方式工作的客户端或服务器端代码。这包括线程模型，连接生命期，快编码，以及所有 HTTP 协议允许你做的，所有的一切，你都将拥有绝对的控制力。<br>
由于这种高度可定制化的特性，你可以开发一个非常高效的 HTTP 服务器，例如：</p>
<ul>
<li>要求持久化链接以及服务器端推送技术的聊天服务（如，<a href="http://en.wikipedia.org/wiki/Comet_%28programming%29" target="_blank" rel="noopener">Comet</a> )</li>
<li>需要保持链接直至整个文件下载完成的媒体流服务（如，2 小时长的电影）</li>
<li>需要上传大文件并且没有内存压力的文件服务（如，上传 1GB 文件的请求）</li>
<li>支持大规模混合客户端应用用于连接以万计的第三方异步 web 服务。</li>
</ul>
<h2 id="websockets-实现"><a class="header-anchor" href="#websockets-实现">¶</a>WebSockets 实现</h2>
<p><a href="http://en.wikipedia.org/wiki/WebSockets" target="_blank" rel="noopener">WebSockets</a> 允许双向，全双工通信信道，在 TCP socket 中。它被设计为允许一个 Web 浏览器和 Web 服务器之间通过数据流交互。<br>
WebSocket 协议已经被 IETF 列为 <a href="https://tools.ietf.org/html/rfc6455" target="_blank" rel="noopener">RFC 6455</a> 规范。<br>
Netty 已经实现了 WebSocket 和一些老版本的规范：<a href="http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html" target="_blank" rel="noopener">http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html</a></p>
<h2 id="google-protocol-buffer-整合"><a class="header-anchor" href="#google-protocol-buffer-整合">¶</a>Google Protocol Buffer 整合</h2>
<p><a href="http://code.google.com/apis/protocolbuffers/docs/overview.html" target="_blank" rel="noopener">Google Protocol Buffers</a> 是快速实现一个高效的二进制协议的理想方案。通过使用 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufEncoder.html" target="_blank" rel="noopener">ProtobufEncoder</a> 和 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufDecoder.html" target="_blank" rel="noopener">ProtobufDecoder</a>，你可以把 Google Protocol Buffers 编译器 (protoc) 生成的消息类放入到 Netty 的 codec 实现中。请参考“<a href="http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/localtime/package-summary.html" target="_blank" rel="noopener">LocalTime</a>”实例，这个例子也同时显示出开发一个由简单协议定义 的客户及服务端是多么的容易。</p>
<h1>性能优化</h1>
<h2 id="fastthreadlocal"><a class="header-anchor" href="#fastthreadlocal">¶</a>FastThreadLocal</h2>
<p>重写了JDK的ThreadLocal，但是速度更快</p>
<h2 id="recycle"><a class="header-anchor" href="#recycle">¶</a>Recycle</h2>
<p>对象池</p>
<h2 id="单机百万连接"><a class="header-anchor" href="#单机百万连接">¶</a>单机百万连接</h2>
<h2 id="netty应用级别性能优化"><a class="header-anchor" href="#netty应用级别性能优化">¶</a>Netty应用级别性能优化</h2>
<h1>QA</h1>
<h2 id="如何使用-netty"><a class="header-anchor" href="#如何使用-netty">¶</a>如何使用 Netty</h2>
<p>Netty 是 Java 中的一个 NIO 框架：</p>
<ol>
<li>易用的 API；</li>
<li>NIO 模型相对 BIO 更高效。</li>
<li>解决了 Java 原生 NIO 接口存在的一些问题。<br>
包括粘包半包问题、心跳检测等问题。</li>
</ol>
<h2 id="serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？"><a class="header-anchor" href="#serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？">¶</a>ServerBootstrap - 默认情况下Netty服务端会起多个线程？又是什么时候启动这些线程的？</h2>
<p>Netty中线程主要用于执行EventLoop的for循环任务，当ServerBootstrap<br>
默认情况下创建2倍CPU核心线程数的线程。<br>
<code>io.netty.channel.MultithreadEventLoopGroup#MultithreadEventLoopGroup(int, java.util.concurrent.Executor, java.lang.Object...)</code><br>
可以看到最终创建了个线程池<code>ThreadPerTaskExecutor</code><br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code></p>
<h2 id="serverbootstrap-netty是如何解决jdk的空轮询bug的？"><a class="header-anchor" href="#serverbootstrap-netty是如何解决jdk的空轮询bug的？">¶</a>ServerBootstrap - Netty是如何解决JDK的空轮询Bug的？</h2>
<p>NioEventLoop</p>
<h2 id="serverbootstrap-netty是如何保证异步串行无锁化的？"><a class="header-anchor" href="#serverbootstrap-netty是如何保证异步串行无锁化的？">¶</a>ServerBootstrap - Netty是如何保证异步串行无锁化的？</h2>
<p>执行需要保证并发安全的操作时先判断是否是刚开始创建的线程，如果不是则放入一个单线程的线程池中执行。<br>
线程创建位置：<code>SingleThreadEventExecutor</code>的构造方法<br>
判断位置：<code>io.netty.util.concurrent.AbstractEventExecutor#inEventLoop</code></p>
<h2 id="nioeventloop-netty如何检测新连接的接入？"><a class="header-anchor" href="#nioeventloop-netty如何检测新连接的接入？">¶</a>NioEventLoop - Netty如何检测新连接的接入？</h2>
<p>初始化ServerBootstrap时</p>
<h2 id="nioeventloop-新连接怎样被注册nioeventloop线程？"><a class="header-anchor" href="#nioeventloop-新连接怎样被注册nioeventloop线程？">¶</a>NioEventLoop - 新连接怎样被注册NioEventLoop线程？</h2>
<p>调用bind时会启动一个NioEventLoop线程，用于监听连接请求。</p>
<h2 id="pipeline-netty如何判断channelhandler类型？"><a class="header-anchor" href="#pipeline-netty如何判断channelhandler类型？">¶</a>pipeline - Netty如何判断ChannelHandler类型？</h2>
<p>ChannelHandler分为Inbound类型和Outbound类型，在Netty中将ChannelHandler添加到Pipeline时会判断这个ChannelHandler的类型，然后设置到一个bool类型的成员变量里，在传播时使用。<br>
<code>io.netty.channel.DefaultChannelHandlerContext#isInbound</code><br>
<code>io.netty.channel.DefaultChannelHandlerContext#isOutbound</code></p>
<h2 id="pipeline-对channelhandler的添加会遵循什么样的顺序？"><a class="header-anchor" href="#pipeline-对channelhandler的添加会遵循什么样的顺序？">¶</a>pipeline - 对ChannelHandler的添加会遵循什么样的顺序？</h2>
<p>根据Pipeline的传播逻辑可以看出，Inbound类型的ChannelHandler按添加顺序传播，而Outbound类型的ChannelHandler是按逆顺序传播的。</p>
<h2 id="pipeline-用户手动触发事件传播-不同的触发方式有什么区别？"><a class="header-anchor" href="#pipeline-用户手动触发事件传播-不同的触发方式有什么区别？">¶</a>pipeline - 用户手动触发事件传播，不同的触发方式有什么区别？</h2>
<p>如果是在Pipeline中间的某个ChannelHandler中调用了read，则就是从这个节点开始往后传播，如果是write，就是从这个节点开始往前传播。</p>
<h2 id="bytebuf-内存的类别有哪些？"><a class="header-anchor" href="#bytebuf-内存的类别有哪些？">¶</a>ByteBuf - 内存的类别有哪些？</h2>
<h2 id="bytebuf-如何减少多线程之间内存分配的竞争？"><a class="header-anchor" href="#bytebuf-如何减少多线程之间内存分配的竞争？">¶</a>ByteBuf - 如何减少多线程之间内存分配的竞争？</h2>
<h2 id="bytebuf-不同大小的内存是如何进行分配的？"><a class="header-anchor" href="#bytebuf-不同大小的内存是如何进行分配的？">¶</a>ByteBuf - 不同大小的内存是如何进行分配的？</h2>
<h2 id="bytebuf-粘包半包问题是什么"><a class="header-anchor" href="#bytebuf-粘包半包问题是什么">¶</a>ByteBuf - 粘包半包问题是什么</h2>
<h2 id="解码器抽象的解码过程？"><a class="header-anchor" href="#解码器抽象的解码过程？">¶</a>解码器抽象的解码过程？</h2>
<h2 id="netty里面有哪些拆箱即用的解码器？"><a class="header-anchor" href="#netty里面有哪些拆箱即用的解码器？">¶</a>Netty里面有哪些拆箱即用的解码器？</h2>
<h2 id="如何把对象变成字节流-并最终写到socket底层？"><a class="header-anchor" href="#如何把对象变成字节流-并最终写到socket底层？">¶</a>如何把对象变成字节流，并最终写到socket底层？</h2>
<h2 id="如何使用netty实现长短连接？"><a class="header-anchor" href="#如何使用netty实现长短连接？">¶</a>如何使用Netty实现长短连接？</h2>
<p>长连接是为了复用连接资源，长连接下，多个请求可以使用同一个连接传输数据包。</p>
<h2 id="如何使用netty实现长短轮询？"><a class="header-anchor" href="#如何使用netty实现长短轮询？">¶</a>如何使用Netty实现长短轮询？</h2>
<p>长轮询的特点是请求发到服务器上时若没有资源（比如库存），请求会被挂起，直到资源充足后才返回。</p>
<h1>参考</h1>
<ol>
<li><a href="https://wiki.jikexueyuan.com/project/netty-4-user-guide/" target="_blank" rel="noopener">Netty 4.x 用户指南</a></li>
<li><a href="https://netty.io/wiki/user-guide-for-4.x.html" target="_blank" rel="noopener">User guide for 4.x（上面这个文档的英文原版）</a></li>
<li><a href="https://github.com/netty/netty" target="_blank" rel="noopener">github - netty / netty</a></li>
<li><a href="https://netty.io/4.0/xref/overview-summary.html" target="_blank" rel="noopener">Netty Source Xref (4.0.56.Final)（同上为源码）</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e13f9e03.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/e13f9e03.html" itemprop="url">MySQL 的集群</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-29T10:18:28+08:00">
                2020-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>主从同步</h1>
<p>MySQL的主从同步是基于bin log实现的。</p>
<h2 id="bin-log-同步流程"><a class="header-anchor" href="#bin-log-同步流程">¶</a>bin log 同步流程</h2>
<p>备库 B 和主库 A 之间维持了一个长连接，主库 A 内部有一个线程专门服务于与 B 的 bin log 同步，一个事务日志同步的过程如下：</p>
<ol>
<li>在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量；</li>
<li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 <code>io_thread</code> 和 <code>sql_thread</code>。其中 io_thread 负责与主库建立连接。</li>
<li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 bin log，发给 B。</li>
<li>备库 B 拿到 bin log 后，写到本地文件，称为中转日志（relay log）。</li>
<li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li>
</ol>
<h2 id="主备延迟"><a class="header-anchor" href="#主备延迟">¶</a>主备延迟</h2>
<p>产生主备延迟的可能情况：</p>
<ol>
<li>备库所在的机器性能较主库差；</li>
<li>备库的压力较大，比如因为备库不跑业务，所以很多人会随意执行一些特别耗时的操作，这些查询耗费大量的 CPU 资源，影响了同步速度，造成主备延迟。</li>
<li>出现了大事务，比如，一次性用 delete 语句删除大量数据，或者大表的 DDL。</li>
</ol>
<h2 id="并行复制策略"><a class="header-anchor" href="#并行复制策略">¶</a>并行复制策略</h2>
<p>为了避免备库追不上主库的情况，MySQL 利用并行复制策略提高复制的效率，从上面的<strong>主备同步流程图</strong>可知，并行化可以加到客户端连接和写入数据两个过程中。</p>
<ol>
<li>按表分发策略<br>
如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。<br>
当然，如果有跨表的事务，还是要把两张表放在一起考虑的。</li>
<li>按行分发策略<br>
按表复制存在热点表的并行复制问题，即热点表会被分配给一个 worker 执行复制，这样就会退化成单线程复制。<br>
按行复制的核心思路是：如果两个事务没有更新相同的行，则它们在备库上可以并行执行，为了知道具体修改了哪些行，这种模式需要设置 binlog 的格式为 row（因为 statement 格式直接记录更新语句，row 记录的是受影响的具体数据的 ID）。</li>
</ol>
<h2 id="半同步"><a class="header-anchor" href="#半同步">¶</a>半同步</h2>
<p>在 MySQL 5.5 版本之前一直采用的是上述的异步复制方案，主库的事务执行不会管备库的同步进度，如果备库落后，主库不幸 crash，那么就会导致数据丢失。<br>
于是在 MySQL 在 5.5 中就顺其自然地引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到 relay log 中。</p>
<h3 id="异步-半同步-全同步"><a class="header-anchor" href="#异步-半同步-全同步">¶</a>异步 &amp; 半同步 &amp; 全同步</h3>
<ul>
<li>对于异步复制，主库将事务 Binlog 事件写入到 bin log 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作，而此时不会保证这些 Binlog 传到任何一个从库节点上。</li>
<li>对于全同步复制，当主库提交事务之后，所有的从库节点必须收到，APPLY 并且提交这些事务，然后主库线程才能继续做后续操作。这里面有一个很明显的缺点就是，主库完成一个事务的时间被拉长，性能降低。</li>
<li>对于半同步复制，是介于全同步复制和异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全执行并且提交的反馈，这样就节省了很多时间。</li>
</ul>
<h1>主备切换</h1>
<p>主备功能主要是通过 bin log 实现的。</p>
<h2 id="主备切换流程"><a class="header-anchor" href="#主备切换流程">¶</a>主备切换流程</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" alt="MySQL-主备切换流程" title="MySQL-主备切换流程"><br>
如图示，客户端的读写都是直接访问的节点 A，而节点 B 是 A 的备库，通常是只读的，只是将 A 的更新同步过来到本地执行，节点 A 的 update 同步到节点 B 的流程图如下所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="MySQL-主备同步流程图" title="MySQL-主备同步流程图"></p>
<ol>
<li>主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog；</li>
<li>备库 B 跟主库 A 之间维持了一个长连接，专门用于服务备库 B 的事务日志同步；</li>
</ol>
<p>当需要切换时，切换到状态 2，这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库；</p>
<h2 id="双-m-架构"><a class="header-anchor" href="#双-m-架构">¶</a>双 M 架构</h2>
<p>实际生产中更多采用的是双 M 架构：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E5%8F%8CM%E6%9E%B6%E6%9E%84%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" alt="MySQL-双M架构主备切换流程" title="MySQL-双M架构主备切换流程"><br>
与原先的方案相比，只是节点 A 和 B 之间多了一条线，这样，节点 A 和 B 之间总是互为主备关系，在切换的时候就不用再修改主备关系。</p>
<h3 id="可靠性优先策略"><a class="header-anchor" href="#可靠性优先策略">¶</a>可靠性优先策略</h3>
<p>双 M 结构的可靠性优先主备切换流程如下：</p>
<ol>
<li>判断备库 B 现在的 <code>seconds_behind_master</code>，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li>
<li>把主库 A 改成只读状态，即把 readonly 设置为 true；</li>
<li>判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；</li>
<li>把备库 B 改成可读写状态，也就是把 readonly 设置为 false；</li>
<li>把业务请求切到备库 B。</li>
</ol>
<p>这个切换流程一般由专门的 HA 系统来完成，称为<strong>可靠性优先流程</strong>。<br>
注意：</p>
<ol>
<li>这个过程中，比较耗时的是第 3 步，可能会耗费好几秒的时间，因此一般会先在第 1 步中做判断，确保 seconds_behind_master 足够小后才执行。</li>
</ol>
<h3 id="可用性优先策略"><a class="header-anchor" href="#可用性优先策略">¶</a>可用性优先策略</h3>
<p>可靠性优先策略中，同步流程中存在一段系统不可用的时间，如果强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了，这个流程称为可用性优先策略。</p>
<h2 id="一主多从"><a class="header-anchor" href="#一主多从">¶</a>一主多从</h2>
<p>平时使用数据库一般都是读多写少，在发展过程中很可能会先遇到读性能问题，为了解决读性能问题，在架构上的解决方式是<strong>一主多从</strong>。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84.png" alt="MySQL-一主多从基本结构" title="MySQL-一主多从基本结构"><br>
其中：</p>
<ul>
<li>A 和 A’互为主备；</li>
<li>从库 B、C、D 指向主库 A，主库负责所有写入和一部分读，其他的读请求由从库分担。</li>
</ul>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E7%9A%84%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2.png" alt="MySQL-一主多从的主备切换" title="MySQL-一主多从的主备切换"></p>
<ul>
<li>主备切换后，A’将成为新的主库；</li>
<li>从库 B、C、D 改成连接到 A’。</li>
</ul>
<h1>读写分离</h1>
<p>上述的主从结构其实形成了一种读写分离的架构，连接信息一般保存到客户端，由客户端执行负载均衡。<br>
另一种读写分离架构在客户端和服务器之间架设了一个代理层 proxy，客户端全部连接到这个 proxy，由 proxy 根据请求类型和上下文执行请求的路由分发。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E5%B8%A6proxy%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84.png" alt="MySQL-带proxy的读写分离架构" title="MySQL-带proxy的读写分离架构"></p>
<ul>
<li>直连的架构，少了一层 proxy，因此性能稍微更好一点，排查问题也更方便，但是主备切换库迁移时客户端会感知到，所以客户端需要一个后端管理组件，比如 Zookeeper。</li>
<li>带 proxy 架构，对客户端友好，但是同时 proxy 架构也更加复杂。</li>
</ul>
<h2 id="过期读-问题"><a class="header-anchor" href="#过期读-问题">¶</a>“过期读”问题</h2>
<p>当客户端先写入再读取时可能会读到修改前的值，因为写入是对主库写入，读取是对从库读，而主从同步存在延迟，刚写入主库的数据可能还没有同步到所有的从库。<br>
解决过期读问题的方案：</p>
<ul>
<li>强制走主库方案；<br>
一些必须拿到最新结果的请求，可以强制将其发到主库上，比如用户支付后需要马上看到商品是否已经购买成功，这个请求需要马上拿到最新的结果，因此最好走主库；<br>
一些请求没有必要立刻拿到最新的结果，比如商户发布商品后，用户即使没有马上看到商品也是可以的，因此用户读取商品列表的请求完全可以路由到从库上去。</li>
<li>sleep 方案；<br>
不大靠谱，但是一定程度上还是可以解决问题的。</li>
<li>判断主备无延迟方案；<br>
判断 <code>show slave status</code> 结果里的 <code>seconds_behind_master</code> 参数的值，等于 0 才执行查询请求，这个参数可以表明从库是否已经完全同步。</li>
<li>配合 semi-sync 方案；</li>
<li>等主库位点方案；</li>
<li>等 GTID 方案。</li>
</ul>
<h1>探活</h1>
<p>在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。<br>
主备切换有两种场景：主动切换和被动切换，其中被动切换往往是因为主库出问题而由 HA 系统发起的。</p>
<h2 id="select-1"><a class="header-anchor" href="#select-1">¶</a>select 1</h2>
<p><code>select 1</code>只能用于判断该数据库进程仍能执行，但是<strong>不能说明主库没有问题</strong>，比如，数据库线程池（由参数 innodb_thread_concurrency 控制）被打满的情况下，虽然<code>select 1</code>能执行，但是线程池还是会被堵住。</p>
<blockquote>
<p>innodb_thread_concurrency 控制的是并发查询，而不是并发连接，因为并发连接多只是多占用一些内存空间，并不会占用 CPU 资源。</p>
</blockquote>
<h2 id="查表判断"><a class="header-anchor" href="#查表判断">¶</a>查表判断</h2>
<p>为了知道线程池是否被打满，我们可以创建一张<code>health_check</code>表，里面只放一条数据，然后定时执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from mysql.health_check;</span><br></pre></td></tr></table></figure>
<p>这种方法的缺点是，<strong>不能用于判断磁盘空间是否满了</strong>，因为如果磁盘空间满了，所有的更新语句和事务提交语句都会被堵塞，但是查询语句仍能执行。</p>
<h2 id="更新判断"><a class="header-anchor" href="#更新判断">¶</a>更新判断</h2>
<p>更新一行数据，一般会放一个 timestamp 字段，用来表示最后一次执行检测的时间。<br>
但是要注意如果主备都要检测，就不能只有一行数据了，因为会产生<strong>行冲突</strong>，导致主备同步的停止。一般会采用数据库实例的 server_id 作为主键，因为 MySQL 规定了主备服务器的 server_id 必须不同，这样就能保证主备的检测命令不会冲突了。<br>
这种方式仍然存在一种问题：这种更新语句占用的 IO 资源很少，即使当时 IO 已经 100%，检测语句仍可以获得 IO 资源来执行，但系统可能已经出问题了，也就是说，这种检测存在随机性。</p>
<h2 id="内部统计"><a class="header-anchor" href="#内部统计">¶</a>内部统计</h2>
<p>前面几种方法都是通过外部调用来发现问题的，更好的方式是利用 MySQL 本身的统计数据：<code>performance_schema</code>库的<code>file_summary_by_event_name</code>表。</p>
<h1>QA</h1>
<h2 id="主从同步的流程"><a class="header-anchor" href="#主从同步的流程">¶</a>主从同步的流程</h2>
<p>主备服务器之间维持了一个长连接，备库上回启动两个线程，一个 io_thread 负责与主库建立连接并读取 bin log，另一个 sql_thread 负责解析命令并执行。</p>
<h2 id="mysql-是怎么保证数据不丢失的"><a class="header-anchor" href="#mysql-是怎么保证数据不丢失的">¶</a>MySQL 是怎么保证数据不丢失的</h2>
<h2 id="mysql-是怎么保证高可用的"><a class="header-anchor" href="#mysql-是怎么保证高可用的">¶</a>MySQL 是怎么保证高可用的</h2>
<h2 id="mysql如何优化千万级的大表？"><a class="header-anchor" href="#mysql如何优化千万级的大表？">¶</a>MySQL如何优化千万级的大表？</h2>
<ol>
<li>优化SQL和索引；</li>
<li>加缓存，比如Memcached或Redis；</li>
<li>主从复制或主主复制，实现读写分离<br>
可以在应用层做，效率高<br>
也可以用三方工具，如360的atlas</li>
<li>使用MySQL自带的分区表<br>
优点是对应用透明，但是SQL需要针对分区表做一些优化，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区。</li>
<li>垂直拆分，根据模块耦合情况将一个大系统分为多个小系统</li>
<li>水平切分，选择合适的sharding key将大表数据拆分到多个小表上</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/zero-gg/p/9057092.html" target="_blank" rel="noopener">MySQL 5.7 半同步复制技术</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f312680c.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f312680c.html" itemprop="url">MySQL 中的锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-28T10:18:28+08:00">
                2020-05-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  10.3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  37 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>解决并发冲突</h1>
<h2 id="mysql-中并发安全组件"><a class="header-anchor" href="#mysql-中并发安全组件">¶</a>MySQL 中并发安全组件</h2>
<h3 id="latch-和-lock"><a class="header-anchor" href="#latch-和-lock">¶</a>latch 和 lock</h3>
<p>MySQL 中的锁主要分为<strong>闩锁（latch）<strong>和</strong>锁（lock）</strong>。<br>
latch 主要用于保护临界资源的线程安全，lock。</p>
<table>
<thead>
<tr>
<th>-</th>
<th>lock</th>
<th>latch</th>
</tr>
</thead>
<tbody>
<tr>
<td>对象</td>
<td>事务</td>
<td>线程</td>
</tr>
<tr>
<td>保护</td>
<td>数据库内容</td>
<td>内存数据结构</td>
</tr>
<tr>
<td>持续时间</td>
<td>整个事务过程</td>
<td>临界资源</td>
</tr>
<tr>
<td>模式</td>
<td>行锁、表锁、意向锁</td>
<td>读写锁、互斥量</td>
</tr>
<tr>
<td>死锁</td>
<td>通过 waits-for graph、time out 等机制进行死锁检测与处理</td>
<td>无死锁检测与处理机制，仅通过控制应用程序加锁顺序（lock leveling）来保证无死锁发生</td>
</tr>
<tr>
<td>存在位置</td>
<td>Lock Manager 的哈希表中</td>
<td>每个数据结构的对象中</td>
</tr>
</tbody>
</table>
<p>latch 不能显式添加，而是线程在获取行锁时前，先对行所在的页面添加 latch，然后再对行添加 lock，添加完行 lock 后再释放页面的 latch。<br>
如果行被其他线程占有，则线程会先释放页面 latch，等待行锁，待获取行锁后会再次对页面添加 latch，查看页面数据是否有改动，再次获取改动后的行。<br>
这种机制主要是为了保证线程获取的行数据的一致性和完整性。</p>
<h3 id="多粒度锁-行锁和表锁"><a class="header-anchor" href="#多粒度锁-行锁和表锁">¶</a>多粒度锁 - 行锁和表锁</h3>
<p>除了使用行锁对记录进行加锁，事务还可以在表级别进行加锁，称为表锁，对一个表加锁会影响整个表中的记录，表锁也分共享锁（S 锁）和独占锁（X 锁）：<br>
1、如果一个事务给表加了 S 锁，那么：<br>
别的事务可以继续获得该表的 S 锁<br>
别的事务可以继续获得该表中的某些记录的 S 锁<br>
别的事务不可以继续获得该表的 X 锁<br>
别的事务不可以继续获得该表中的某些记录的 X 锁<br>
给表加 X 锁：<br>
2、如果一个事务给表加了 X 锁（意味着该事务要独占这个表），那么：<br>
别的事务不可以继续获得该表的 S 锁<br>
别的事务不可以继续获得该表中的某些记录的 S 锁<br>
别的事务不可以继续获得该表的 X 锁<br>
别的事务不可以继续获得该表中的某些记录的 X 锁</p>
<h3 id="封锁-blockade"><a class="header-anchor" href="#封锁-blockade">¶</a>封锁（Blockade）</h3>
<p>上面提到的 lock，在 MySQL 中正式地讲应该称为<strong>封锁（Blockade）</strong>，所谓封锁就是事务在对某个数据对象例如表、记录等操作之前，先向系统发出请求对其加锁，注意表锁和行锁其实都属于封锁。<br>
加锁后事务 T 就对该数据对象有了一定的控制，在事务 T 释放它的锁之前，其他事务不能更新此数据对象。例如，事务 T1 要修改 A，若在读出 A 之前先锁住 A，其他事务就不能再读取和修改 A 了，直到 T1 修改并写回 A 后解除了对 A 的封锁为止。这样，就不会丢失 T1 的修改。<br>
确切的控制由封锁的类型决定。基本的封锁类型有两种：排他锁(exclusive locks,简称 X 锁)和共享锁(share locks,简称 S 锁)</p>
<ul>
<li><strong>X 锁(排他写锁)</strong>：若事务 T1 对数据对象 A 加上 X 锁，则只允许 T 读取和修改 A，其他任何事物都不能再对 A 加任何类型的锁，直到 T 释放 A 上的锁为止。这就保证了其他事务在 T 释放 A 上的锁之前不能再读取和修改 A；</li>
<li><strong>S 锁(共享读锁)</strong>：若事务 T 对数据 A 加上 S 锁，则事务 T 可以读 A 但是不能修改 A，其他事务只能对 A 加 S 锁而不能加 X 锁，直到 T 释放 A 上的 S 锁为止。这就保证了其他食物可以读 A，但在 T 释放 A 上的 S 锁之前不能对 A 进行任何修改。</li>
</ul>
<p>封锁有 3 级的封锁协议：</p>
<ol>
<li>一级封锁协议<br>
事务 T 在对数据对象 A 进行修改之前，必须对其加 X 锁，直至事务结束才释放。事务结束包括正常结束(COMMIT)和非正常结束(ROLLBACK);<br>
在一级加锁协议中，如果仅仅是对数据进行读操作而不进行修改，是不需要进行加锁的。所以只能避免修改丢失而不能避免不可重复读和脏读。</li>
<li>二级封锁协议<br>
在一级加锁协议的基础上增加事务 T 在读取数据 R 之前必须先对其加 S 锁，读完后即可释放 S 锁；<br>
二级加锁协议除防止了丢失修改，还可进一步防止读脏数据。例如：事务 T1 正在对数据对象 R 进行修改，此前已经对 R 加上了 X 锁，此时事务 T2 想读取 R，就必须对 R 加上 S 锁，但是 T2 发现 R 已经被 T1 加上了 X 锁，于是 T2 只能等待 T1 释放了在 R 上加的锁之后才能对 R 加 S 锁并读取。这能防止 T2 读取到 T1 未提交的数据，从而避免了脏读。<br>
但是在二级封锁协议中，由于读完数据后即可释放 S 锁，所以它不能保证可重复读。</li>
<li>三级封锁协议<br>
三级封锁协议是指，在一级封锁协议的基础上增加事务 T 在读取数据 R 之前对其加 S 锁直至事务结束才释放。<br>
三级封锁协议除了防止丢失修改和读“脏”数据之外，还进一步防止了不可重复读。<br>
上述三级协议的主要区别在于什么操作需要申请加锁，以及何时释放锁(即锁的持有时间)。不同的封锁协议使事务达到的一致性是不同的，封锁协议越高，一致性程度越强。</li>
</ol>
<p>封锁与 MVCC 之间的关系：<br>
封锁与 MVCC 并不是互斥的，MySQL 实现隔离级别时结合了这二者，比如：</p>
<ul>
<li>读已提交：二级封锁协议+MVCC，二级封锁协议在读之前加 S 锁，读完之后就释放 S 锁，所以不能保证不可重复读与幻读；</li>
<li>可重复读：三级封锁协议+MVCC，读完之后不会立刻释放 S 锁，直到事务提交时才会释放，可以解决可重复读。</li>
</ul>
<p>封锁协议+MVCC 并不能解决幻读问题，在 MVCC 中是通过 Next-Key Lock 解决的。</p>
<h3 id="意向锁"><a class="header-anchor" href="#意向锁">¶</a>意向锁</h3>
<p>加表锁时怎么知道该表上有没有行锁？InnoDB 通过<strong>意向锁（Intention Locks）<strong>来解决这个问题：<br>
1、<strong>意向共享锁</strong>，英文名：Intention Shared Lock，简称</strong>IS 锁</strong>。当事务准备在某条记录上加 S 锁时，需要先在<strong>表级别</strong>加一个 IS 锁。<br>
2、<strong>意向独占锁</strong>，英文名：Intention Exclusive Lock，简称<strong>IX 锁</strong>。当事务准备在某条记录上加 X 锁时，需要先在<strong>表级别</strong>加一个 IX 锁。</p>
<p>IS、IX 锁是表级锁，它们的提出仅仅为了在之后加表级别的 S 锁和 X 锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实 IS 锁和 IX 锁是兼容的，IX 锁和 IX 锁是兼容的。</p>
<table>
<thead>
<tr>
<th>兼容性</th>
<th>X</th>
<th>IX</th>
<th>S</th>
<th>IS</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td>IX</td>
<td>不兼容</td>
<td>兼容</td>
<td>不兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>S</td>
<td>不兼容</td>
<td>不兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>IS</td>
<td>不兼容</td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<h3 id="mvcc"><a class="header-anchor" href="#mvcc">¶</a>MVCC</h3>
<p>MySQL 的特色之一是提供了 **MVCC（多版本并发控制）**机制，MVCC 给每行数据增加了版本号，事务在执行读操作时只能读到数据的历史版本，因此可以避免脏读等问题。<br>
MVCC 与事务紧密关联，因此我放到<a href="https://tallate.github.io//86b66af2.html">事务小节</a>中去论述了。</p>
<h2 id="innodb-的加锁规则"><a class="header-anchor" href="#innodb-的加锁规则">¶</a>InnoDB 的加锁规则</h2>
<ol>
<li>原则 1：加锁的基本单位是 next-key lock。</li>
</ol>
<blockquote>
<p>next-key lock 是前开后闭区间。</p>
</blockquote>
<ol>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>原则 3：只有明确指定主键时 InnoDB 才会使用行锁，否则会使用表锁</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ol>
<h3 id="例-1-等值查询间隙锁"><a class="header-anchor" href="#例-1-等值查询间隙锁">¶</a>例 1、等值查询间隙锁</h3>
<ol>
<li>根据原则 1，通过 next-key lock 加锁范围<code>(5, 10]</code>；</li>
<li>因为第一个查询是等值查询（id = 7），而 id = 10 不满足查询条件，因此 next-key lock 退化为间隙锁，因此最终加锁范围是<code>(5, 10)</code>。</li>
</ol>
<p>因此 Session B 要往这个间隙中插入 id = 8 会被锁住，但是 Session C 修改 id = 10 这行是可以的。</p>
<h3 id="例-2-主键不明确导致锁表"><a class="header-anchor" href="#例-2-主键不明确导致锁表">¶</a>例 2、主键不明确导致锁表</h3>
<p>下面的情况不会锁表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">明确指定主键，并且有此行数据，row lock</span><br><span class="line">SELECT * FROM products WHERE id = &apos;3&apos; FOR UPDATE;</span><br><span class="line">SELECT * FROM products WHERE id = &apos;3&apos; and type = 1 FOR UPDATE;</span><br><span class="line">明确指定主键，若查无此行数据，无lock</span><br><span class="line">SELECT * FROM products WHERE id = &apos;-1&apos; FOR UPDATE;</span><br></pre></td></tr></table></figure>
<p>下面的情况会锁表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">非索引字段，table lock</span><br><span class="line">SELECT * FROM products WHERE name = &apos;Mouse&apos; FOR UPDATE;</span><br><span class="line">主键不明确，table lock</span><br><span class="line">SELECT * FROM products WHERE id &lt;&gt; &apos;3&apos; FOR UPDATE;</span><br><span class="line">主键不明确，table lock</span><br><span class="line">SELECT * FROM products WHERE id LIKE &apos;3&apos; FOR UPDATE;</span><br></pre></td></tr></table></figure>
<h3 id="例-3-update未命中行触发间隙锁"><a class="header-anchor" href="#例-3-update未命中行触发间隙锁">¶</a>例 3、update未命中行触发间隙锁</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `hgc_test` (</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `b` int(11) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">insert into hgc_test values(1, 0), (5, 0), (10, 0);</span><br></pre></td></tr></table></figure>
<p>事务S1执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">update hgc_test set b = 10 where a = 7;</span><br></pre></td></tr></table></figure>
<p>事务S2执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">insert into hgc_test values(8, 1);</span><br></pre></td></tr></table></figure>
<p>由于事务S1已经锁住了<code>(5, 10]</code>这个区间，因此S2执行插入时会被阻塞。</p>
<h2 id="解决并发冲突的两种方式"><a class="header-anchor" href="#解决并发冲突的两种方式">¶</a>解决并发冲突的两种方式</h2>
<p>有以下两种方式：<br>
1、一致性读 - 读操作利用 MVCC（多版本并发控制），写操作进行加锁<br>
读操作只能读取记录的历史版本：读操作时生成一个 ReadView，记录当时正在执行的事务 ID，记录的每个版本都有事务 ID，查询数据时只能读到在生成 ReadView 之前已提交事务所做的修改，在生成 ReadView 之前未提交的事务或之前才开启的事务所做的修改都看不到。<br>
写操作只能针对最新版本的记录，因此写操作前需要加锁。<br>
2、锁定读 - 读写操作均采用加锁的方式<br>
利用 MVCC 的方式，读写操作彼此并不冲突，性能更高。而加锁的方式读写操作之间都是互斥的，需要排队执行，比较影响性能。</p>
<p>下面我们会分别描述这两种方案。</p>
<h2 id="一致性读-consistent-reads-一致性无锁读-快照读"><a class="header-anchor" href="#一致性读-consistent-reads-一致性无锁读-快照读">¶</a>一致性读（Consistent Reads、一致性无锁读、快照读）</h2>
<p>事务利用 MVCC 进行的读取操作称之为一致性读，所有普通的 SELECT 语句在 READ COMMITTED、REPEATABLE READ 隔离级别下都算是一致性读。<br>
也就是上面提到的“读操作利用 MVCC”。</p>
<h2 id="锁定读-locking-reads"><a class="header-anchor" href="#锁定读-locking-reads">¶</a>锁定读（Locking Reads）</h2>
<p>读-读的情况并不会引起并发冲突，我们不希望对这种情况造成影响，因此 MySQL 给锁分了几个类：<br>
1、共享锁（Shared Locks、S 锁）：在事务要读取一条记录时，需要先获取该记录的 S 锁。<br>
2、独占锁（排他锁、Exclusive Locks、X 锁）：在事务要改动一条记录时，需要先获取该记录的 X 锁。</p>
<table>
<thead>
<tr>
<th>兼容性</th>
<th>X</th>
<th>S</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td>S</td>
<td>不兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<p>一般读取一条记录时我们会获取这条记录的 S 锁，但是如果我们想在读取记录时就获取记录的 X 锁，来禁止别的事务读写该记录，则需要使用一些特殊的 SELECT 语句格式：<br>
1、对读取的记录加 S 锁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ... LOCK IN SHARE MODE;</span><br></pre></td></tr></table></figure>
<p>上面语句为记录加 S 锁，允许多个事务同时发起读请求，但是当别的事务尝试获取 X 锁（SELECT … FOR UPDATE 或修改这些记录）则会阻塞，直到当前事务提交之后将这些记录上的 S 锁释放掉。<br>
2、对读取的记录加 X 锁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ... FOR UPDATE;</span><br></pre></td></tr></table></figure>
<p>上面语句为记录加 X 锁，之后别的事务来获取该记录的 S 锁或 X 锁时都会被阻塞，直到当前事务提交之后将这些记录上的 X 锁释放掉。</p>
<h2 id="写操作-write-如何利用锁"><a class="header-anchor" href="#写操作-write-如何利用锁">¶</a>写操作（write）如何利用锁</h2>
<h3 id="delete"><a class="header-anchor" href="#delete">¶</a>DELETE</h3>
<p>DELETE 操作会先在 B+树中定位到这条记录，然后获取这条记录的 X 锁，并执行 delete mark 操作（逻辑删除）。</p>
<h3 id="update"><a class="header-anchor" href="#update">¶</a>UPDATE</h3>
<p>如果未修改该记录的键值并且被更新的列占用的存储空间在修改前后未发生变化，则先在 B+树种定位到这条记录然后获取该记录的 X 锁，最后在原记录的位置执行修改操作。<br>
如果未修改该记录的键值并且至少有一个被更新的列占用的存储空间在修改前后发生变化，则先在 B+树种定位到这条记录后获取 X 锁，将这条记录彻底删除（移入垃圾链表），最后插入一条记录。<br>
如果修改了该记录的键值，则相当于在原记录上 DELETE 后 INSERT。</p>
<h3 id="insert"><a class="header-anchor" href="#insert">¶</a>INSERT</h3>
<p>一般 INSERT 操作并不加锁，MySQL 引入了一种称为<strong>隐式锁</strong>的技术来保护这条新插入的记录在本事务提交之前不被其他事务访问。</p>
<blockquote>
<p>显式锁即 select … for update 语句，从语法上就能看出这个语句加了锁。</p>
</blockquote>
<p>让我们分几种情况来分析 insert 语句的锁。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  `d` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `c` (`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into t values(null, 1,1);</span><br><span class="line">insert into t values(null, 2,2);</span><br><span class="line">insert into t values(null, 3,3);</span><br><span class="line">insert into t values(null, 4,4);</span><br><span class="line"></span><br><span class="line">create table t2 like t</span><br></pre></td></tr></table></figure>
<h4 id="insert-select-语句"><a class="header-anchor" href="#insert-select-语句">¶</a>insert … select 语句</h4>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure>
<p>上面Session A语句需要对表 t 的所有行和间隙加锁。原因见下面的例子：</p>
<table>
<thead>
<tr>
<th>session A</th>
<th>session B</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>insert into t values(-1, -1, -1);</code></td>
<td><code>insert into t2(c, d) select c, d from t;</code></td>
</tr>
</tbody>
</table>
<p>上面的两个session，如果过session B先执行，由于对表t的主键索引加了<code>(-∞, 1]</code>这个next-key lock，会在语句执行完毕后，才允许session A的insert语句执行。<br>
但如果没有锁，就有可能出现session B的insert语句先执行，但是后写入binlog的情况，于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(-1,-1,-1);</span><br><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure>
<p>这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。</p>
<h4 id="insert-唯一键冲突"><a class="header-anchor" href="#insert-唯一键冲突">¶</a>insert 唯一键冲突</h4>
<p>insert 发生唯一键冲突时可能引起死锁，例：</p>
<table>
<thead>
<tr>
<th>T</th>
<th>session A</th>
<th>session B</th>
<th>session C</th>
</tr>
</thead>
<tbody>
<tr>
<td>T1</td>
<td><code>begin; insert into t values(null, 5, 5)</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>T2</td>
<td></td>
<td><code>insert into t values(null, 5, 5)</code></td>
<td><code>insert into t values(null, 5, 5)</code></td>
</tr>
<tr>
<td>T3</td>
<td><code>rollback;</code></td>
<td></td>
<td>(Deadlock fount)</td>
</tr>
</tbody>
</table>
<ul>
<li>正如前面的《加锁规则》所述，session A执行insert语句时，会在所以c的c=5这行上加记录锁，由于这个索引是唯一索引，因此会退化为记录锁；</li>
<li>session B要执行相同的insert语句，发现了唯一键冲突，加上<strong>读锁</strong>，同时session C也会在同一个记录上加上读锁；</li>
</ul>
<blockquote>
<p>为什么加读锁？应该是为了保证不被删掉的同时，可以不影响读操作。</p>
</blockquote>
<ul>
<li>T3时刻，session A 回滚。这时候，session B 和 session C 都试图继续执行插入操作，都要加上写锁。两个 session 都要等待对方的行锁，所以就出现了死锁。</li>
</ul>
<h4 id="insert-into-on-duplicate-key-update"><a class="header-anchor" href="#insert-into-on-duplicate-key-update">¶</a>insert into … on duplicate key update</h4>
<p>上面的例子是主键冲突后直接报错，如果写成如下形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(11,10,10) on duplicate key update d=100;</span><br></pre></td></tr></table></figure>
<p>则会给索引c上<code>(5, 10]</code>加一个排他的next-key lock（写锁）。</p>
<h2 id="锁结构"><a class="header-anchor" href="#锁结构">¶</a>锁结构</h2>
<p>MySQL 中锁是通过共享内存实现的，当一个事务希望对一条记录做修改操作时，首先会看看内存中有没有与这条记录关联的锁结构，当没有的时候就会在内存中生成一个锁结构与之关联，这个锁结构中有两个主要属性：</p>
<ul>
<li>trx：代表生成该锁结构的事务；</li>
<li>is_waiting：代表当前事务是否在等待。</li>
</ul>
<p>获取锁成功（加锁成功）可以描述为：修改一条记录前生成了一个锁结构与之关联，因为之前没有别的记录为这条记录加锁，所以 is_waiting 为 false；<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105d9425c2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
获取锁失败可以描述为：在事务对一条记录进行修改前，已经有另一个事务创建了锁结构与之关联，那么当前事务需要生成一个锁结构且 is_waiting 为 true，表示当前事务需要等待。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105e955d9a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
释放锁时，就是把当前事务的锁结构释放掉，然后看有没有其他事务正在等待获取锁，并把正在等待的事务对应的锁结构的 is_waiting 置为 false，然后将该事务对应的线程唤醒。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105f387885?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<p>总结地说：</p>
<ul>
<li>不加锁<br>
意思就是不需要在内存中生成对应的锁结构，可以直接执行操作。</li>
<li>获取锁成功，或者加锁成功<br>
意思就是在内存中生成了对应的锁结构，而且锁结构的 is_waiting 属性为 false，也就是事务可以继续执行操作。</li>
<li>获取锁失败，或者加锁失败，或者没有获取到锁<br>
意思就是在内存中生成了对应的锁结构，不过锁结构的 is_waiting 属性为 true，也就是事务需要等待，不可以继续执行操作。</li>
</ul>
<h2 id="自增长与锁"><a class="header-anchor" href="#自增长与锁">¶</a>自增长与锁</h2>
<p>InnoDB 中，对每个含有自增长值的表都有一个自增长计数器。</p>
<ul>
<li>初始化：当对这样的表进行插入操作时，这个计数器会被初始化。</li>
<li>更新：插入操作根据这个自增长计数器值加 1 赋予自增长列，对该计数器的更新需要保证线程安全，这可以通过设置使用<strong>表锁</strong>还是<strong>互斥量</strong>来实现。</li>
</ul>
<h1>MySQL 全局锁</h1>
<p>全库逻辑备份</p>
<ol>
<li>Flush tables with read lock（FTWRL）<br>
这个命令不保证备份时数据库是否处于一个一致性视图，可能有的事务刚执行一半。</li>
<li>mysqldump<br>
在导数据前会启动事务，确保可以拿到一致性视图，前提是数据库中所有表都使用了支持事务的引擎，否则就只能使用<code>FTWRL</code>来备份了。</li>
</ol>
<h1>InnoDB 存储引擎中的表锁</h1>
<h2 id="表锁种类"><a class="header-anchor" href="#表锁种类">¶</a>表锁种类</h2>
<ol>
<li>lock tables …… read/write<br>
锁住整个表会对数据库效率产生比较大的影响。</li>
<li>MDL（metadata lock)<br>
MDL 不需要显式使用，在访问一个表的时候会被自动加上，表结构变更操作之间、表结构变更操作与读表操作之间都是互斥的，保证表结构变更的正确性。<br>
MDL 可能会导致表的锁死，比如一个 alter 语句正在等待一个长事务（该事务中有 select 语句）释放读 MDL，这时 alter 会加上写 MDL，因此之后的所有事务都需要等待该写 MDL 释放了，因此在变更表结构时最好先将长事务终止，或者给 alter 语句设置等待时间：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
<h2 id="不会加表锁的情况"><a class="header-anchor" href="#不会加表锁的情况">¶</a>不会加表锁的情况</h2>
<p>1、在对某个表执行 SELECT、INSERT、DELETE、UPDATE 语句时，InnoDB 存储引擎是不会为这个表添加表级别的 S 锁或者 X 锁的；<br>
2、执行 DDL 语句时（ALTER TABLE、DROP TABLE）时，使用的是 Server 层的<strong>元数据锁（Metadata Locks）</strong>。</p>
<p>手动获取表级 S 锁和 X 锁的方式：<br>
1、LOCK TABLES t READ：InnoDB 存储引擎会对表 t 加表级别的 S 锁。<br>
2、LOCK TABLES t WRITE：InnoDB 存储引擎会对表 t 加表级别的 X 锁。</p>
<p>不过一般表锁不会用到，只会在崩溃恢复之类的场景下会用到。</p>
<p>表级 IS 锁、IX 锁，和之前的描述一致。</p>
<p>如果实现自增列：<br>
1、表级别 AUTO-INC 锁：当表中某列设置了 auto_increment 属性，那么该列的值是会自动生成的，插入时会在表级加一个 AUTO-INC 锁，保证这个字段是严格递增的；当插入语句执行完毕后，该锁会自动释放，而不是在事务结束后再释放。<br>
2、一个轻量级锁：生成 auto_increment 列的值后马上释放。</p>
<blockquote>
<p>InnoDB 提供了一个称之为 innodb_autoinc_lock_mode 的系统变量来控制到底使用上述两种方式中的哪种来为 AUTO_INCREMENT 修饰的列进行赋值，当 innodb_autoinc_lock_mode 值为 0 时，一律采用 AUTO-INC 锁；当 innodb_autoinc_lock_mode 值为 2 时，一律采用轻量级锁；当 innodb_autoinc_lock_mode 值为 1 时，两种方式混着来（也就是在插入记录数量确定时采用轻量级锁，不确定时使用 AUTO-INC 锁）。不过当 innodb_autoinc_lock_mode 值为 2 时，可能会造成不同事务中的插入语句为 AUTO_INCREMENT 修饰的列生成的值是交叉的，在有主从复制的场景中是不安全的。</p>
</blockquote>
<h1>InnoDB 存储引擎中的行锁</h1>
<h2 id="两阶段锁协议"><a class="header-anchor" href="#两阶段锁协议">¶</a>两阶段锁协议</h2>
<p>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束（commit）时才释放。这个就是两阶段锁协议。<br>
由于两阶段锁协议的存在，如果我们的事务中需要锁住多个行，最好把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<h2 id="锁的种类"><a class="header-anchor" href="#锁的种类">¶</a>锁的种类</h2>
<p>1、Record Locks（行锁）<br>
该锁的官方类型名为 LOCK_REC_NOT_GAP。<br>
和前面提到的表锁一样，分 S 锁和 X 锁，只是作用粒度精确到行了。<br>
2、Gap Locks（间隙锁）<br>
该锁的官方类型名为 LOCK_GAP。<br>
MySQL 解决幻读问题有两种方案：<br>
第一种是 MVCC，因为新插入的数据事务 ID 必然不在 ReadView 内，因此读取这些记录后会被直接忽略，但是快照读只在普通读操作中生效，如果发生了当前读仍然会有幻读问题；<br>
第二种是加锁，但是加锁有一个问题，就是事务没法给尚不存在的记录加锁。<br>
如果我们希望为 number 值为 8 的记录加 gap 锁，则该记录的前后间隙都不允许别的事务立即插入记录：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-gap%E9%94%81.png" alt="MySQL-gap锁" title="MySQL-gap锁"><br>
如图中为 number 值为 8 的记录加了 gap 锁，意味着不允许别的事务在 number 值为 8 的记录前边的间隙插入新记录，其实就是 number 列的值(3, 8)这个区间的新记录是不允许立即插入的。比方说有另外一个事务再想插入一条 number 值为 4 的新记录，它定位到该条新记录的下一条记录的 number 值为 8，而这条记录上又有一个 gap 锁，所以就会阻塞插入操作，直到拥有这个 gap 锁的事务提交了之后，number 列的值在区间(3, 8)中的新记录才可以被插入。<br>
另外，如何为(20, +∞)这个区间加 gap 锁？其实是为数据页中的 Infimum 和 Supremum 记录加上了 gap 锁。<br>
比如假设此时表里有 5、25 这两条数据，则<code>SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE</code>查询 10 到 20 范围内的记录，并加上范围<code>(5, 10)</code>、<code>[10, 20]</code>、<code>(20, 25]</code>以内的 gap 锁。<br>
比如假设此时表里有 102、105、107 三个值，则<code>select * from test where n = 105 for update;</code>这个语句会对<code>(102, 105)</code>、<code>(105, 107]</code>这两个区间加 gap 锁。<br>
3、Next-Key Locks<br>
该锁的官方类型名为 LOCK_ORDINARY。<br>
Next-Key Lock 其实是<strong>Record Lock 和 Gap Lock 的组合</strong>，它既会保护该条记录，又能阻止别的事务将新记录插入被保护记录的前后间隙。<br>
4、Insert Intention Locks（插入意向锁）<br>
该锁的官方类型名为 LOCK_INSERT_INTENTION。<br>
InnoDB 中事务在等待<strong>gap 锁</strong>的释放时，还需要在内存里生成一个锁结构，表示事务现在正想往某个间隙中插入记录，但是现在正在等待。<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a72bf8133eb1dc?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
如上图所示，有 3 个事务，其中 T1 持有 gap 锁，所以 T2 和 T3 需要生成一个插入意向锁的锁结构，等待 T1 释放后才能获取到插入意向锁（本质上是将 is_waiting 属性改成了 false），然后再继续执行插入操作。<br>
5、隐式锁<br>
一般来说间隙锁可以避免 gap 锁锁住的区间被其他事务修改（当要插入的记录所在的区间有 gap 锁，事务会先再该间隙上加一个插入意向锁），但是还有一种情况正好是反过来的：如果一个事务首先插入了一条记录，别的记录如果直接读（SELECT … LOCK IN SHARE MODE 或 SELECT … FOR UPDATE）则会产生脏读问题，如果直接修改则又会产生脏写问题。<br>
这个问题在 InnoDB 中是通过事务 ID 解决的：</p>
<ul>
<li>聚簇索引中有一个隐藏列 trx_id，存储的是最后改动该记录的事务 ID，新插入记录的 trx_id 当然就是当前事务的事务 ID，如果别的事务想对该记录添加 S 锁或 X 锁，<strong>会首先看一下该记录 trx_id 是否是当前正活跃的事务</strong>，如果是的话就会创建一个 X 锁然后进入等待状态；</li>
<li>二级索引本身没有 trx_id 列，但是在二级索引页面的 Page Header 部分有一个 PAGE_MAX_TRX_ID 属性，该属性代表对该页面做改动的最大的事务 id，如果 PAGE_MAX_TRX_ID 属性值小于当前最小的活跃事务 id，那么说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记录，然后再重复聚簇索引的做法。</li>
</ul>
<h2 id="活锁-死锁与死锁检测"><a class="header-anchor" href="#活锁-死锁与死锁检测">¶</a>活锁、死锁与死锁检测</h2>
<h3 id="活锁"><a class="header-anchor" href="#活锁">¶</a>活锁</h3>
<p>活锁：如果事务 T1 封锁了数据 R，事务 T2 又请求封锁 R，于是 T2 等待。T3 也请求封锁 R，当 T1 释放了 R 上的锁之后系统首先批准了 T3 的请求，T2 继续等待；然后 T4 又请求封锁 R，T3 在释放 R 上的锁之后系统又批准了 T4 的请求，T2 有可能永远等待，这就是活锁的情形。<br>
避免活锁的简单方法就是采用先来先服务的策略。当多个事务请求封锁同一数据对象时，封锁子系统按请求锁的先后次序对事务进行排队，数据对象上的锁一旦释放就批准批准申请队列中第一个事务获得锁。</p>
<h3 id="死锁"><a class="header-anchor" href="#死锁">¶</a>死锁</h3>
<p>死锁在许多操作系统书中都有描述，简而言之，就是多个线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，都会导致这些线程都进入无限等待的状态，称为死锁。<br>
在 InnoDB 中，也会出现两个事务互相等待对方释放某条记录的行锁的情况，从而导致进入死锁状态。死锁可以预防，也可以等发生死锁后再作处理。</p>
<h3 id="死锁预防"><a class="header-anchor" href="#死锁预防">¶</a>死锁预防</h3>
<p>在数据库中，产生死锁的原因是两个或多个事务都已经封锁了一些数据对象，然后又都请求对已被事务封锁的对象加锁，从而出现死锁。防止死锁的发生其实就是要破坏产生死锁的条件。预防死锁发生通常有以下两种方法。</p>
<ul>
<li><strong>一次封锁法</strong>：一次封锁法要求每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行下去。一次封锁法虽然可以有效防止死锁的发生，但是<strong>增加了锁的粒度，从而降低了系统的并发性</strong>。并且数据库是不断变化的，所以事先很难精确地确定每个事务所需进行加锁的对象，为此只能扩大封锁范围，将事务在执行过程中可能需要封锁的数据对象全部加锁，这就进一步降低了并发度；</li>
<li><strong>顺序封锁法</strong>：顺序封锁法是预先对数据对象规定一个封锁顺序，所有事务都按这个顺序实施封锁。例如在 B 树结构的索引中，可规定封锁的顺序必须是从根节点开始，然后是下一级的子节点，逐级封锁。顺序封锁法可以有效地避免死锁，但是要实现顺序封锁法十分的困难，因为<strong>很难事先确定每一个事务要封锁哪些对象，因此也就很难按规定的顺序去实施加锁</strong>。</li>
</ul>
<p>由此可见数据库中不适合预防死锁，只适合进行死锁的诊断与解除。</p>
<h3 id="死锁检测与解除"><a class="header-anchor" href="#死锁检测与解除">¶</a>死锁检测与解除</h3>
<ul>
<li>设置最大等待时间，等待超过目标时间后自动释放之前获取到的锁，让别的事务先执行；<br>
可以通过参数<code>innodb_lock_wait_timeout</code>来设置<br>
超时法实现简单，但其不足也十分明显，一是有可能误判了死锁，如事务因为其他原因而使等待时间超过时限，系统就会误认为发生了死锁；二是若时限设置得太长，则不能及时发现死锁。</li>
<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行<br>
将参数 <code>innodb_deadlock_detect</code> 设置为 on 即表示开启死锁检测。<br>
死锁检测是一个耗时操作，因为每当一个事务被锁的时候，都要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。<br>
死锁检测的基础是<strong>事务等待图</strong>，事务等待图是一个有向图 G=(T,U),T 为结点的集合，每个结点表示正在运行的事务；U 为边的集合，每条边表示事务等待的情况。若 T1 等待 T2，则在 T1,T2 之间画一条有向边，从 T1 指向 T2。事务等待图动态地反应了所有事务的等待情况。并发控制子系统周期性(比如每隔数秒)生成事务等待图，并进行检测。如果发现图中存在回路，则表示系统中出现了死锁。</li>
</ul>
<p>数据库管理系统的并发控制系统一旦检测到系统中存在死锁，就要设法<strong>解除死锁</strong>。通常采用的方法是选择一个处理死锁代价最小的事务，将其撤销，释放此事务持有的所有的锁，使其他事务得以继续运行下去。当然，对撤销的事务所进行的数据修改必须加以恢复。</p>
<p>死锁的检测会产生一定的性能损耗，因此解决热点行更新导致的性能问题需要结合业务来进行权衡：</p>
<ol>
<li>如果能确保业务一定不会出现死锁，可以临时把死锁检测关掉。<br>
但是需要注意的是，死锁检测可以保证出现死锁后可以通过业务回滚然后重试来解决，这是业务无损的，而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</li>
<li>控制并发度<br>
保证对于相同行的更新，在进入引擎之前排队，这样就可以避免大量的死锁检测工作了。</li>
<li>将对同一行的操作改成多行<br>
比如，将库存分成多份，减库存时随机取出一份来操作，这样冲突的概率就会变成原本的 1/10 了，既减少了锁等待个数，又减少了死锁检测的 CPU 消耗。</li>
</ol>
<h3 id="可能发生死锁的情况"><a class="header-anchor" href="#可能发生死锁的情况">¶</a>可能发生死锁的情况</h3>
<ol>
<li>注意加锁顺序<br>
比如下面语句查3行数据，而且由于<code>desc</code>，该查询语句是<strong>倒序</strong>在索引树上遍历的，遍历过程中会给查到的记录和区间加行锁和间隙锁。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from t where c in(5,20,10) order by c desc for update;</span><br></pre></td></tr></table></figure>
<p>在上面这条语句执行期间，如果有另外一条语句是正序遍历并加锁的，就很有可能会导致死锁，比如如下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from t where c in(5,20,10) lock in share mode;</span><br></pre></td></tr></table></figure>
<p>因此对同一组咨询，要<strong>尽量按照相同的顺序访问</strong>。</p>
<h3 id="如何查看死锁"><a class="header-anchor" href="#如何查看死锁">¶</a>如何查看死锁</h3>
<p>出现死锁后，执行 <code>show engine innodb status</code> 命令，这个命令会输出很多信息，有一节 <code>LATESTDETECTED DEADLOCK</code>。</p>
<h2 id="锁的内存结构"><a class="header-anchor" href="#锁的内存结构">¶</a>锁的内存结构</h2>
<p>InnoDB 中，不是获取多少记录就给多少记录加锁，如果符合下边这些条件则这些记录的锁就会被放到一个锁结构中：<br>
1、在同一个事务中进行加锁操作<br>
2、被加锁的记录在同一个页面中<br>
3、加锁的类型是一样的<br>
4、等待状态是一样的</p>
<p>具体的，InnoDB 中的锁结构如下所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a68cda54348429?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<ul>
<li>锁所在的事务信息：<br>
不论是表锁还是行锁，都是在事务执行过程中生成的，哪个事务生成了这个锁结构，这里就记载着这个事务的信息。</li>
<li>索引信息：<br>
对于行锁来说，需要记录一下加锁的记录是属于哪个索引的。</li>
<li>表锁／行锁信息：<br>
表锁结构和行锁结构在这个位置的内容是不同的：<br>
表锁：记载着这是对哪个表加的锁，还有其他的一些信息。<br>
行锁记载了三个重要的信息：<br>
Space ID：记录所在表空间。<br>
Page Number：记录所在页号。<br>
n_bits：对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了一堆比特位，这个 n_bits 属性代表使用了多少比特位，n_bits 一般会比实际数据量大一些，避免每次插入记录都需要重新分配内存。</li>
<li>type_mode：<br>
这是一个 32 位的数，被分成了 lock_mode、lock_type 和 rec_lock_type 三个部分，如图所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/5/16a864f3298df751?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="">
<ul>
<li>锁的模式（lock_mode），占用低 4 位，可选的值如下：<br>
LOCK_IS（十进制的 0）：表示共享意向锁，也就是 IS 锁，属于表级锁。<br>
LOCK_IX（十进制的 1）：表示独占意向锁，也就是 IX 锁，属于表级锁。<br>
LOCK_S（十进制的 2）：表示共享锁，也就是 S 锁，既可以属于表级锁也可以属于行级锁。<br>
LOCK_X（十进制的 3）：表示独占锁，也就是 X 锁，既可以属于表级锁也可以属于行级锁。<br>
LOCK_AUTO_INC（十进制的 4）：表示 AUTO-INC 锁，属于表级锁。</li>
<li>锁的类型（lock_type），占用第 5～8 位，不过现阶段只有第 5 位和第 6 位被使用：<br>
LOCK_TABLE（十进制的 16），也就是当第 5 个比特位置为 1 时，表示表级锁。<br>
LOCK_REC（十进制的 32），也就是当第 6 个比特位置为 1 时，表示行级锁。</li>
<li>行锁的具体类型（rec_lock_type），使用其余的位来表示。只有在 lock_type 的值为 LOCK_REC 时，也就是只有在该锁为行级锁时，才会被细分为更多的类型：<br>
LOCK_ORDINARY（十进制的 0）：表示 next-key 锁。<br>
LOCK_GAP（十进制的 512）：也就是当第 10 个比特位置为 1 时，表示 gap 锁。<br>
LOCK_REC_NOT_GAP（十进制的 1024）：也就是当第 11 个比特位置为 1 时，表示正经记录锁。<br>
LOCK_INSERT_INTENTION（十进制的 2048）：也就是当第 12 个比特位置为 1 时，表示插入意向锁。<br>
其他的类型：还有一些不常用的类型我们就不多说了。<br>
怎么还没看见 is_waiting 属性呢？这主要还是设计 InnoDB 的大叔太抠门了，一个比特位也不想浪费，所以他们把 is_waiting 属性也放到了 type_mode 这个 32 位的数字中：<br>
LOCK_WAIT（十进制的 256） ：也就是当第 9 个比特位置为 1 时，表示 is_waiting 为 true，也就是当前事务尚未获取到锁，处在等待状态；当这个比特位为 0 时，表示 is_waiting 为 false，也就是当前事务获取锁成功。</li>
</ul>
</li>
<li>其他信息</li>
<li>一堆比特位<br>
如果是行锁结构的话，在该结构末尾还放置了一堆比特位，比特位的数量是由上边提到的 n_bits 属性表示的。我们前边唠叨 InnoDB 记录结构的时候说过，页面中的每条记录在记录头信息中都包含一个 heap_no 属性，伪记录 Infimum 的 heap_no 值为 0，Supremum 的 heap_no 值为 1，之后每插入一条记录，heap_no 值就增 1。锁结构最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个 heap_no，不过为了编码方便，映射方式有点怪。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a69c2f7b413698?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
</ul>
<h2 id="锁优化"><a class="header-anchor" href="#锁优化">¶</a>锁优化</h2>
<ol>
<li>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。<br>
比如用户买电影票的场景中，扣减用户账户余额和给影院账户余额加钱，显然后者的竞争更加频繁，因此对其的加锁应该放在事务更靠后的位置。</li>
</ol>
<h1>其他存储引擎中的锁</h1>
<p>MyISAM、MEMORY、MERGE 这些引擎不支持事务，因此加锁一般都是针对当前会话来说的，比如 Session1 先对表加 S 锁，之后 Session2 再对该表执行 UPDATE 操作时，获取 X 锁的过程就会被阻塞了。<br>
相当于这些存储引擎同一时刻只允许一个会话对表执行写操作，因此这些存储引擎最好用于读多写少的场景下。</p>
<h1>QA</h1>
<h2 id="如何安全地给表加字段"><a class="header-anchor" href="#如何安全地给表加字段">¶</a>如何安全地给表加字段</h2>
<p>首先需要处理掉长事务，因为长事务不提交的话会一直占用 MDL 锁。</p>
<blockquote>
<p>information_schema 库的 innodb_trx 表中可以看到当前执行中的长事务。<br>
但是如果这样的事务比较多，kill 掉并不一定管用，因为新的请求总是会源源不断地到来，所以最好的方法是在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
<h2 id="mysql-如何处理死锁"><a class="header-anchor" href="#mysql-如何处理死锁">¶</a>MySQL 如何处理死锁</h2>
<p>MySQL 有两种死锁处理方式：</p>
<ol>
<li>等待直到超时（<code>show variables like 'innodb_lock_wait_timeout'</code>）</li>
<li>发起死锁检测，主动回滚一条事务，让其他事务继续执行（<code>show variables like 'innodb_deadlock_detect'</code>）</li>
</ol>
<h2 id="mysql-如何检测死锁"><a class="header-anchor" href="#mysql-如何检测死锁">¶</a>MySQL 如何检测死锁</h2>
<p>死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。</p>
<h2 id="mysql-连接池被打满怎么办"><a class="header-anchor" href="#mysql-连接池被打满怎么办">¶</a>MySQL 连接池被打满怎么办</h2>
<p>这里的连接池指的是应用服务器里访问 MySQL 服务的连接池，比如 Druid，</p>
<h2 id="以下哪些场景会导致语句q1-select-from-t1-limit-1被堵住？"><a class="header-anchor" href="#以下哪些场景会导致语句q1-select-from-t1-limit-1被堵住？">¶</a>以下哪些场景会导致语句<code>Q1: select * from t1 limit 1</code>被堵住？</h2>
<ol>
<li>另一个线程在Q1执行前，执行了<code>alter table t1 add index(f1)</code>，当前正处于拷贝数据到临时表阶段。</li>
</ol>
<h2 id="以下什么情况会发生-等待行锁-的状态？"><a class="header-anchor" href="#以下什么情况会发生-等待行锁-的状态？">¶</a>以下什么情况会发生&quot;等待行锁&quot;的状态？</h2>
<p>RR隔离级别下，表t的建表结构和初始化数据如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table t (id int primary key, c int) engine = innoDB;</span><br><span class="line">insert into t values (1, 1), (11, 11), (21, 21);</span><br></pre></td></tr></table></figure>
<p>在会话1中执行如下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">select * from t lock in share mode;</span><br></pre></td></tr></table></figure>
<p>可见这条语句希望对表t加一个表级的读锁。</p>
<ol>
<li>会进入&quot;等待行锁&quot;的情况1<br>
<code>insert into t values (15, 15);</code><br>
插入时会先给表加IX意向锁，IX意向锁是和会话1中对表t加上的读锁互斥的，因此会导致阻塞。</li>
<li>不会进入&quot;等待行锁&quot;的情况1<br>
<code>update t set c = c + 1 where id = 15;</code><br>
因为id = 15这条数据不存在，因此这条语句实际上不会加锁。</li>
<li>不会进入&quot;等待行锁&quot;的情况2<br>
<code>delete from t where id = 15;</code><br>
因为找不到id = 15这条数据，因此也不会加锁。</li>
<li>不会进入&quot;等待行锁&quot;的情况3<br>
<code>alter table t add d int;</code><br>
alter table 会加MDL，这并不是行锁。</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/jay-huaxiao/p/11456921.html" target="_blank" rel="noopener">Mysql 死锁如何排查：insert on duplicate 死锁一次排查分析过程</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b7a6e835.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b7a6e835.html" itemprop="url">MySQL 中的查询</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-27T10:18:28+08:00">
                2020-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  10.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  38 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>查询缓存</h1>
<p>缓存失效的情况：</p>
<ol>
<li>如果两个查询请求<strong>在任何字符上的不同</strong>（例如：空格、注释、大小写），都会导致缓存不会命中</li>
<li>如果查询请求中<strong>包含某些系统函数、用户自定义变量和函数、一些系统表</strong>，如 mysql 、information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存</li>
<li>MySQL 的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了 INSERT、 UPDATE、DELETE、TRUNCATE TABLE、ALTER TABLE、DROP TABLE 或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除。</li>
</ol>
<p>查询缓存的维护开销大、且容易引起数据一致性问题，因此在 MySQL8.0 中已经被删除。</p>
<h1>查询 - 单表查询方法</h1>
<p>MySQL 查询优化器会解析 SQL 得到执行计划，然后按照执行计划中的顺序调用 InnoDB 的接口来执行查询。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `single_table` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `key1` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key2` int(11) DEFAULT NULL,</span><br><span class="line">  `key3` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part1` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part2` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part3` varchar(100) DEFAULT NULL,</span><br><span class="line">  `common_field` varchar(100) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `idx_key2` (`key2`),</span><br><span class="line">  KEY `idx_key1` (`key1`),</span><br><span class="line">  KEY `idx_key3` (`key3`),</span><br><span class="line">  KEY `idx_key_part` (`key_part1`,`key_part2`,`key_part3`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=73 DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure>
<h2 id="索引查询方法"><a class="header-anchor" href="#索引查询方法">¶</a>索引查询方法</h2>
<p>根据优化器的结果不同，可能会生成多种查询方法，可以使用 explain 来查看一个 SQL 使用了哪种查询方法。</p>
<h3 id="const"><a class="header-anchor" href="#const">¶</a>const</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e05c8e33?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE id = 1438;</span><br></pre></td></tr></table></figure>
<p>这种查询因为命中了聚簇索引，所以会直接用主键到聚簇索引中去查找。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 = 3841;</span><br></pre></td></tr></table></figure>
<p>这种通过**唯一(unique)**二级索引直接定位某几条数据的查询语句同样是非常快的，因此被称为 const。<br>
但是等值的查询还有一个例外，如果查询的是 NULL 值的记录，则可能访问到多条记录而导致无法使用 const 查询方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 IS NULL;</span><br></pre></td></tr></table></figure>
<h3 id="ref"><a class="header-anchor" href="#ref">¶</a>ref</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e5e227f1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
普通二级索引不限制索引列的唯一性，因此可能会检索到多条记录，然后再回表得到具体数据，这种情况相对 const 来说会稍微耗时一些，因此被称为 ref。<br>
注意：<br>
1、就算是唯一索引，NULL 值的匹配仍可能会匹配到多条，因此 key is null 这种形式的搜索会采用 ref 的访问方式。<br>
2、如果查询中包含范围查询则不是 ref：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key_part1 = &apos;god like&apos; AND key_part2 &gt; &apos;legendary&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="ref-or-null"><a class="header-anchor" href="#ref-or-null">¶</a>ref_or_null</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e8927bee?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
当使用二级索引而且既查某个常数又查 NULL 值记录时，会采用 ref_or_null 查询方式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;abc&apos; OR key1 IS NULL;</span><br></pre></td></tr></table></figure>
<h3 id="range"><a class="header-anchor" href="#range">¶</a>range</h3>
<p>对索引进行范围查询：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79);</span><br></pre></td></tr></table></figure>
<h3 id="index"><a class="header-anchor" href="#index">¶</a>index</h3>
<p>要查询的列在二级索引内，但是又不是最左索引列，因此就算不能高效使用索引，InnoDB 也会优先从索引中遍历获取数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="all"><a class="header-anchor" href="#all">¶</a>all</h3>
<p>扫描聚簇索引，即全表扫描。</p>
<h2 id="确定范围区间"><a class="header-anchor" href="#确定范围区间">¶</a>确定范围区间</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 AND common_field = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<p>如上 SQL，因为 common_field 字段没有索引，因此确定范围时没有作用，优化器会先使用 idx_key2 索引确定范围，然后回表查到数据后再用<code>common_field = 'abc'</code>过滤。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 OR common_field = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<p>其中关联条件被我们改成了 OR，这会导致全表扫描。<br>
为了直观地确定范围区间，我们可以把用不到索引的搜索条件直接替换成 TRUE：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 OR TRUE;</span><br></pre></td></tr></table></figure>
<p>显然，这条语句会触发全表扫描。<br>
这种方法也可以应用到一些比较复杂的查询语句中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE </span><br><span class="line">        (key1 &gt; &apos;xyz&apos; AND key2 = 748 ) OR</span><br><span class="line">        (key1 &lt; &apos;abc&apos; AND key1 &gt; &apos;lmn&apos;) OR</span><br><span class="line">        (key1 LIKE &apos;%suf&apos; AND key1 &gt; &apos;zzz&apos; AND (key2 &lt; 8000 OR common_field = &apos;abc&apos;)) ;</span><br></pre></td></tr></table></figure>
<p>1、因为 where 语句中 key1、key2 都可以命中索引，因此候选的索引包括 idx_key1 和 idx_key2<br>
2、假设使用 idx_key1 执行查询，将不涉及该索引的条件都化简：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &gt; &apos;xyz&apos;;</span><br></pre></td></tr></table></figure>
<p>3、假设使用 idx_key2 执行查询，同理可化简：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE TRUE;</span><br></pre></td></tr></table></figure>
<p>因此优化器最终会采用 idx_key1。</p>
<h2 id="索引合并"><a class="header-anchor" href="#索引合并">¶</a>索引合并</h2>
<p>使用到多个索引来完成一次查询的执行方法被称为<strong>index merge</strong>，分 3 种情况：</p>
<h3 id="intersection-合并"><a class="header-anchor" href="#intersection-合并">¶</a>Intersection 合并</h3>
<p>某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;a&apos; AND key3 = &apos;b&apos;;</span><br></pre></td></tr></table></figure>
<p>为什么使用 2 个索引查询 merge 而不是一个查完后再过滤其他条件？主要是因为二级索引的操作是<strong>顺序 I/O</strong>，而回表操作是<strong>随机 I/O</strong>，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数相对更少，因此当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低。<br>
发生 Intersection 合并的条件：<br>
1、针对主键的范围查询；<br>
2、针对二级索引的等值匹配；<br>
为什么范围查询不行？因为二级索引中是按索引列排序的，只有等值匹配时结果才会按 id 列排序，而求并集时<br>
3、单独使用某个二级索引获取到的记录数太多，导致回表开销太大。</p>
<h3 id="union-合并"><a class="header-anchor" href="#union-合并">¶</a>Union 合并</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;a&apos; OR key3 = &apos;b&apos;</span><br></pre></td></tr></table></figure>
<p>OR 相连的不同查询条件可能会使用到不同的索引，这种情况可能会使用到 Union 索引合并，具体的还分以下几种情况：<br>
1、二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。<br>
比如范围查询就无法使用 Union 合并。<br>
2、主键列可以是范围匹配；<br>
3、使用 Intersection 索引合并的搜索条件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key_part1 = &apos;a&apos; AND key_part2 = &apos;b&apos; AND key_part3 = &apos;c&apos; OR (key1 = &apos;a&apos; AND key3 = &apos;b&apos;);</span><br></pre></td></tr></table></figure>
<p>Intersection 索引合并得到的是一个主键的集合，Union 合并可以将多个这样的主键集合取交集。</p>
<h3 id="sort-union"><a class="header-anchor" href="#sort-union">¶</a>Sort-Union</h3>
<p>Union 合并的条件比较苛刻，要求全部查询条件都是等值查询，比如下面的查询语句就无法使用 Union 索引合并：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &lt; &apos;a&apos; OR key3 &gt; &apos;z&apos;;</span><br></pre></td></tr></table></figure>
<p>因为按照两种查询条件得到的主键值并不是有序的，如果这两批主键值数量并不大，InnoDB 会再对这两批主键值进行排序，最后按照 Union 合并的方式进行合并。</p>
<h3 id="联合索引"><a class="header-anchor" href="#联合索引">¶</a>联合索引</h3>
<p>上面这个例子中，key1 和 key3 分别属于两个索引，如果把这两个列合一块搞一个联合索引，效率会更高。</p>
<h1>count</h1>
<h2 id="count-的实现方式"><a class="header-anchor" href="#count-的实现方式">¶</a>count(*) 的实现方式</h2>
<p>不同引擎对<code>count(*)</code>有不同的实现方式：</p>
<ul>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</li>
<li>而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>
</ul>
<h3 id="为什么-innodb-不把数字存起来？"><a class="header-anchor" href="#为什么-innodb-不把数字存起来？">¶</a>为什么 InnoDB 不把数字存起来？</h3>
<p>因为<strong>MVCC</strong>的存在，对每个事务来说返回多少行都是不确定的。</p>
<h3 id="innodb对count-的优化"><a class="header-anchor" href="#innodb对count-的优化">¶</a>InnoDB对count(*)的优化</h3>
<p>普通索引树比主键索引树小很多，因此对于<code>count(*)</code>这样的操作，MySQL更倾向于找到最小的那棵树来遍历。</p>
<h3 id="table-rows能替代count-吗？"><a class="header-anchor" href="#table-rows能替代count-吗？">¶</a>table_rows能替代count(*)吗？</h3>
<p><code>show table status</code>命令结果里也有一个table_rows用于显示这个表当前有多少行，但是这个值其实只是一个估计值，并不准。</p>
<h3 id="有什么办法能替代count-？"><a class="header-anchor" href="#有什么办法能替代count-？">¶</a>有什么办法能替代count(*)？</h3>
<p>为了替代<code>count(*)</code>，我们只能自己计数，也就是找一个地方存储表的行数。</p>
<ol>
<li>用缓存计数<br>
优点是速度快，但是缺点是缓存系统可能会丢失更新，比如两个事务都读了一遍Redis的值，然后在操作后将最新的值覆盖上，但是先写入的事务所做的更新会被后来的事务覆盖，也就是说发生了丢失更新。<br>
而且，Redis的重启、宕机都是不可避免的，发生这种情况后，怎么保证计数不丢失呢？<br>
一般来说需要将数据再持久化到DB上，但是如果写DB成功、同步Redis失败了，又会导致二者的不一致。这种情况当然是有解决的办法，比如Redis异常重启后就到数据库里面单独执行一次<code>count(*)</code>获取真实的行数，再把这个值写回到Redis里就可以了。<br>
总而言之，因为与数据库并不在一个事务内，不能保证Redis与数据库的绝对一致，因此Redis并不能提供精确的计数，只能供粗略的计数。</li>
<li>用数据库计数<br>
不同于Redis，只要保证计数和插入/删除数据命令处于同一条SQL内，基于数据库的计数就是精确的。</li>
</ol>
<h2 id="不同count的区别"><a class="header-anchor" href="#不同count的区别">¶</a>不同count的区别</h2>
<ol>
<li><code>count(*)</code><br>
<code>count(*)</code>并不会把全部字段取出来，而是专门做了优化，不取值，因为<code>count(*)</code>肯定不是null，直接按行累加即可。</li>
<li><code>count(主键ID)</code><br>
InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</li>
<li><code>count(1)</code><br>
InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</li>
<li><code>count(字段)</code><br>
表示返回满足条件的数据行里面，参数<code>字段</code>不为NULL的总个数。<br>
如果<code>字段</code>被定义成了<code>null</code>，则这个操作相对<code>count(主键ID)</code>会更慢一些，因为server层还需要一行一行判断值是否为null，只有不是null的才累加。</li>
</ol>
<p>所以结论是：按照效率排序的话，<code>count(字段)</code> &lt; <code>count(主键 id)</code> &lt; <code>count(1)</code> ≈ <code>count(*)</code>，所以建议尽量使用 <code>count(*)</code>。</p>
<h1>连接（Join）</h1>
<h2 id="连接查询的大致执行过程"><a class="header-anchor" href="#连接查询的大致执行过程">¶</a>连接查询的大致执行过程</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &apos;d&apos;;</span><br></pre></td></tr></table></figure>
<p>这个查询语句包含 3 个过滤条件，大致执行过程如下：<br>
1、确定第一个需要查询的表，称之为<strong>驱动表</strong>，InnoDB 会选取代价最小的方法去执行查询（从 const、ref、ref_or_null、range、index、all 这些执行方法中选取代价最小的去执行查询）；<br>
2、针对从驱动表中查询出的每一条记录，<strong>分别</strong>到其他表中查询匹配的记录，这些表称为<strong>被驱动表</strong>。<br>
因此，驱动表只会被查询一次，而被驱动表则会被查询多次。</p>
<h2 id="内连接和外连接"><a class="header-anchor" href="#内连接和外连接">¶</a>内连接和外连接</h2>
<p>内连接<br>
左连接（左外连接）：左侧的表为驱动表。<br>
右连接（右外连接）：右侧的表为驱动表。</p>
<p>对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合 ON 子句条件的记录时也会被加入到结果集，所以左连接和右连接的驱动表和被驱动表的位置不能轻易互换。</p>
<h2 id="连接的原理"><a class="header-anchor" href="#连接的原理">¶</a>连接的原理</h2>
<h3 id="嵌套循环连接-nested-loop-join"><a class="header-anchor" href="#嵌套循环连接-nested-loop-join">¶</a>嵌套循环连接（Nested-Loop Join）</h3>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-NestedLoopJoin%E7%AE%97%E6%B3%95.png" alt="MySQL-NestedLoopJoin算法" title="MySQL-NestedLoopJoin算法"><br>
驱动表中查询到的每条记录都需要分别到被驱动表中查找匹配的记录，当有 3 张表进行连接时，上一步得到的结果集就会成为新的驱动表，第 3 张表则成为了新的被驱动表，重复这个过程。<br>
这个过程就像是一个嵌套的循环，所以这种驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为<strong>嵌套循环连接（Nested-Loop Join）</strong>。</p>
<h3 id="simple-nested-loop-join"><a class="header-anchor" href="#simple-nested-loop-join">¶</a>Simple Nested-Loop Join</h3>
<p>到被驱动表上查询的时候没有命中索引，导致每次查询都是全表扫描，时间复杂度退化为<code>N * M</code>。<br>
实际上，MySQL 并没有使用这么简单粗暴的算法，而是<code>Block Nested-Loop Join</code>。</p>
<h3 id="基于块的嵌套循环连接-block-nested-loop-join"><a class="header-anchor" href="#基于块的嵌套循环连接-block-nested-loop-join">¶</a>基于块的嵌套循环连接（Block Nested-Loop Join）</h3>
<p>因为嵌套循环连接中，被驱动表可能被访问非常多次（现实中单表的数据量是非常大的），这个过程中涉及到随机磁盘扫描，因此效率并不高，为了减少这个 IO 代价，所以我们应该尽量减少访问被驱动表的次数。<br>
当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。<br>
优化方法是在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价了。<strong>join buffer</strong>就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个 join buffer 中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和 join buffer 中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的 I/O 代价。<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/25/167e43ab3e5fa2f6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
这种加入了 join buffer 的嵌套循环连接算法被称为<strong>基于块的嵌套循环连接（Block Nested-Loop Join）</strong>。</p>
<ul>
<li>另外需要注意的是，驱动表的记录并不是所有列都会被放到 join buffer 中，只有查询列表中的列和过滤条件中的列才会被放到 join buffer 中，所以最好不要把*作为查询列表。</li>
<li>相对<code>Simple Nested-Loop Join</code>来说，<code>Block Nested-Loop Join</code>在时间复杂度上并没有提高，但是由于所有匹配操作都是内存操作，速度会快很多，性能也更好。</li>
<li>join buffer 的空间是有限的，如果放不下所有数据，则每次只放入一批，匹配完后清空 join buffer，再放另一批。</li>
</ul>
<h3 id="连接优化"><a class="header-anchor" href="#连接优化">¶</a>连接优化</h3>
<ol>
<li>索引<br>
对每一步得到的结果集（第一步时，这个结果集就是第一张驱动表），到被驱动表中匹配记录时，相当于执行等值查询，因此我们可以在被驱动表上的这个被关联字段上加索引来提高效率。这种在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：<strong>eq_ref</strong>。</li>
<li>用小表作驱动表（能命中索引的情况下）<br>
假设驱动表的行数是 N，则遍历驱动表时间复杂度为<code>N</code>，假设被驱动表的行数是 M，则在被驱动表上查一行数据的时间复杂度是<code>2 * log2(M)</code>（这里假设索引树的基为 2，<code>2 *</code>是因为要先从二级索引找到记录的主键，然后再用主键从聚簇索引找到记录的其他字段），因此，join 查询的近似复杂度为<code>N + N*2*log2M</code>。<br>
显然，N 对扫描行数的影响更大，因此最好使用小表作为驱动表。</li>
<li>用小表作驱动表（不能命中索引，即 Block Nested-Loop Join 的情况）<br>
驱动表会被放入 join_buffer 中和被驱动表匹配，总的时间复杂度仍为<code>N * M</code>，N 被分成 K 段，K 与 N 成正比，可以表示为<code>K = λ * N</code>，因此，这个算法的扫描行数是<code>N + λ * N * M</code>，由于<code>N * M</code>的值不变，因此 N 越小这个算式的结果也会越小，所以，应该用小表作为驱动表。</li>
</ol>
<blockquote>
<p>小表的定义：各表按查询条件过滤，最终得到的总数据量中较小的那个。</p>
</blockquote>
<ol>
<li>调大<code>join_buffer_size</code><br>
上式中，除了 N 外，<code>λ</code>也是关键，这里<code>λ</code>其实主要与<code>join_buffer_size</code>有关，<code>join_buffer_size</code>越大，一次性放入 join_buffer 的行数越大，分成的段数也越少，对被驱动表的全表扫描次数也越少。</li>
</ol>
<h3 id="什么情况下可以使用-join"><a class="header-anchor" href="#什么情况下可以使用-join">¶</a>什么情况下可以使用 join</h3>
<p>查看 explain 结果里 Extra 字段里有没有出现<code>Block Nested Loop</code>：</p>
<ul>
<li>如果出现，则该 join 查询属于<code>Block Nested-Loop Join</code>，扫描行数过多，会占用大量资源，因此这种 join 尽量不要使用；</li>
<li>如果没有出现，说明该 join 查询属于<code>Index Nested-Loop Join</code>，这种 join 查询是没有问题的。</li>
</ul>
<h3 id="join-的进一步优化"><a class="header-anchor" href="#join-的进一步优化">¶</a>join 的进一步优化</h3>
<ol>
<li>
<p>MRR（Multi-Range Read）<br>
普通回表过程是一行一行地查数据——普通索引上定位到主键 id、然后从主键索引上查到整行数据，一般来说这个过程是随机读磁盘的，性能比较差。<br>
MRR 的核心思路是将 id 先保存到<code>read_rnd_buffer</code>，批量、按顺序地回表，这样排序后能达到接近顺序读磁盘的效果。</p>
</li>
<li>
<p>BKA（Batched Key Access）<br>
BKA 是对 NLJ 的优化。<br>
类似 MRR，从驱动表取值到被驱动表上执行 join 时，BKA 会先将驱动表上的记录先放到<code>join_buffer</code>，然后批量到执行 join 操作。<br>
如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set optimizer_switch=&apos;mrr=on,mrr_cost_based=off,batched_key_access=on&apos;;</span><br></pre></td></tr></table></figure>
<p>其中前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于 MRR。</p>
</li>
</ol>
<h1>基于成本的优化</h1>
<p>MySQL 的查询优化器会比较多种查询方案，得到成本最低的方案，即所谓<strong>执行计划</strong>，之后才会调用存储引擎提供的接口来执行查询，这个过程大致如下：<br>
1、根据搜索条件，找出所有可能使用的索引（<strong>possible keys</strong>）；<br>
2、计算全表扫描的代价；<br>
3、计算使用不同索引执行查询的代价；<br>
4、对比各种执行方案的代价，找出成本最低的那一个。</p>
<h2 id="计算代价"><a class="header-anchor" href="#计算代价">¶</a>计算代价</h2>
<p>1、全表扫描的代价<br>
全表扫描需要将聚簇索引所有页面加载到内存然后一一匹配，对全表扫描的性能统计涉及到聚簇索引占用的页面数和该表中的记录数，可以使用<code>SHOW TABLE STATUS</code>来统计这个信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW TABLE STATUS LIKE &apos;ad_content&apos;;</span><br></pre></td></tr></table></figure>
<p>结果中的<strong>Rows</strong>表示记录条数，在 MyISAM 中是准确的，而在 InnoDB 中则是一个估计值。因为全表扫描时需要判断每条记录是否满足条件，因此该值能粗略代表对该表执行全表扫描所需的<strong>CPU 成本</strong>。<br>
<strong>Data_length</strong>表示表占用的存储空间字节数，对于 MyISAM 来说就是数据文件的大小，对于 InnoDB 来说就是聚簇索引占用的存储空间大小。因为默认页面大小为 16KB，因此可以推导出聚簇索引的页面数量是<code>Data_length / 16 / 1024</code>，实际上可以粗略代表对该表执行全表扫描所需的<strong>IO 成本</strong>。<br>
2、二级索引的代价<br>
从二级索引中定位数据的 ID，<strong>回表</strong>（到聚簇索引）根据上一步的 ID 值找到完整的记录。<br>
另外，统计记录数量时，还会用到一个<strong>index dive</strong>的方法（MySQL 自创的一个方法），比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 IN (&apos;aa1&apos;, &apos;aa2&apos;, &apos;aa3&apos;, ... , &apos;zzz&apos;);</span><br></pre></td></tr></table></figure>
<p>由于 idx_key1 并不是唯一（unique）索引，因此<code>key1='aa1'</code>这些条件并不一定能唯一确定一条记录，查询优化器会先获取索引对应的 B+树的<strong>区间最左记录</strong>和<strong>区间最右记录</strong>，然后估算这两条记录之间有多少条记录，这种方式被称为<strong>index dive</strong>。<br>
当然<strong>index dive</strong>并不是一定会生效，如果 in 条件中的参数超过了<strong>阈值</strong>就不能生效，这个阈值可以通过<code>SHOW VARIABLES LIKE '%dive%';</code>查到。<br>
如果因为超过阈值（默认 200）而无法生效，则需要改用所谓的索引统计数据来进行估算，MySQL 也会为表中的每一个索引维护一份统计数据，可以使用<code>show index from 表名</code>来查看，其中有一个比较关键的字段<code>Cardinality</code>表示基数，即索引列中不重复值的个数，计算平均一个值重复次数即<code>Rows / Cardinality</code>，比如表里现在有 100 行数据，表基数为 2，则最终计算出的每个值会有的记录条数就是 50，对于上面那条 sql，如果<code>IN</code>条件中有 10000 个参数，则统计结果约需要回表的记录数就是<code>50 * 10000 = 500000</code>，不过这种方式相对<code>index dive</code>来说虽然简单，但是并不精确。<br>
3、多个二级索引的代价（索引合并 Index Merge）<br>
将多个搜索条件用 AND 连接之后，查询优化器还需要判断一下是否满足 Intersection 索引合并的条件，简而言之，如果查询出的记录都是按主键排序的，则可以采用 Intersection 索引合并。<br>
4、对比多种执行方案，找出成本最低的一种<br>
查询优化器在统计每种查询方式的代价时都会给一个<strong>代价常量</strong>，用于计算每一种方式的代价值，最后比较选取代价最小的那个。</p>
<h2 id="连接查询的成本"><a class="header-anchor" href="#连接查询的成本">¶</a>连接查询的成本</h2>
<h3 id="单表连接"><a class="header-anchor" href="#单表连接">¶</a>单表连接</h3>
<p>对两表的连接查询来说，查询成本主要包括：<br>
1、单次查询驱动表的成本；<br>
2、根据第一步查出的结果（称为<strong>扇出</strong>）多次查询被驱动表的成本。</p>
<p>所以，判断连接查询成本的方法是计算扇出值的大小：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本</span><br></pre></td></tr></table></figure>
<p>当连接方式为外连接，则驱动表是固定的，因此查询时只要为驱动表和被驱动表选择最优访问方式即可，但是如果是内连接，驱动表和被驱动表的位置是可以互换的，那么优化器会使用索引统计数据来进行比较选择。</p>
<h3 id="多表连接"><a class="header-anchor" href="#多表连接">¶</a>多表连接</h3>
<p>如果是 n 张表的内连接，计算的时间复杂度将是单表连接的 n!倍，当然优化器并不是老老实实地这么做：<br>
1、预先设定最小连接成本，只要少于这个值就采用这种连接方式；<br>
2、只对<code>optimizer_search_depth</code>张表执行连接顺序成本的分析，这个值是一个系统变量，显然越大则成本分析越精确；<br>
3、启发式规则：如果满足一些规则则直接不分析，这些规则被称为启发式规则。</p>
<h1>Explain</h1>
<h2 id="explain-各列的含义"><a class="header-anchor" href="#explain-各列的含义">¶</a>Explain 各列的含义</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select * from auth_user;</span><br><span class="line"></span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |</span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">| 1 | SIMPLE | auth_user | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL |</span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>列名	描述<br>
id	在一个大的查询语句中每个 SELECT 关键字都对应一个唯一的 id<br>
select_type	SELECT 关键字对应的那个查询的类型<br>
table	表名<br>
partitions	匹配的分区信息<br>
type	针对单表的访问方法<br>
possible_keys	可能用到的索引<br>
key	实际上使用的索引<br>
key_len	实际使用到的索引长度<br>
ref	当使用索引列等值查询时，与索引列进行等值匹配的对象信息<br>
rows	预估的需要读取的记录条数<br>
filtered	某个表经过搜索条件过滤后剩余记录条数的百分比<br>
Extra	一些额外的信息</p>
<h2 id="explain-各列描述"><a class="header-anchor" href="#explain-各列描述">¶</a>Explain 各列描述</h2>
<h3 id="table"><a class="header-anchor" href="#table">¶</a>table</h3>
<p>表示该查询的目标表，当涉及到连接时会有多行分别表示对各张表的访问方式。</p>
<h3 id="id"><a class="header-anchor" href="#id">¶</a>id</h3>
<p>查询语句中每有一个 select 关键字，MySQL 就会为其分配一个唯一的 id 值，如果 select 中包含多张表的连接，则每张表都会有一条记录、且这些记录中的 id 值都是相同的。</p>
<h3 id="select-type"><a class="header-anchor" href="#select-type">¶</a>select_type</h3>
<ul>
<li>SIMPLE<br>
查询语句中不包含 UNION 或者子查询的查询都算作是 SIMPLE 类型。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1;</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2;</span><br></pre></td></tr></table></figure>
<ul>
<li>PRIMARY<br>
对于包含 UNION、UNION ALL 或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的 select_type 值就是 PRIMARY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2;</span><br></pre></td></tr></table></figure>
<ul>
<li>UNION<br>
对于包含 UNION 或者 UNION ALL 的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的 select_type 值就是 UNION。</li>
<li>UNION RESULT<br>
MySQL 选择使用临时表来完成 UNION 查询的去重工作，针对该临时表的查询的 select_type 就是 UNION RESULT。</li>
<li>SUBQUERY<br>
如果包含子查询的查询语句不能够转为对应的 semi-join 的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个 SELECT 关键字代表的那个查询的 select_type 就是 SUBQUERY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>DEPENDENT SUBQUERY<br>
如果包含子查询的查询语句不能够转为对应的 semi-join 的形式，并且该子查询是相关子查询，则该子查询的第一个 SELECT 关键字代表的那个查询的 select_type 就是 DEPENDENT SUBQUERY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE s1.key2 = s2.key2) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>DEPENDENT UNION<br>
在包含 UNION 或者 UNION ALL 的大查询中，如果各个小查询都依赖于外层查询的话，那除了最左边的那个小查询之外，其余的小查询的 select_type 的值就是 DEPENDENT UNION。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE key1 = &apos;a&apos; UNION SELECT key1 FROM s1 WHERE key1 = &apos;b&apos;);</span><br></pre></td></tr></table></figure>
<p>其中<code>SELECT key1 FROM s2 WHERE key1 = 'a'</code>这个查询是 DEPENDENT SUBQUERY，而<code>UNION</code>后面的那个查询就是 DEPENDENT UNION。</p>
<ul>
<li>DERIVED<br>
对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的 select_type 就是 DERIVED。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM (SELECT key1, count(*) as c FROM s1 GROUP BY key1) AS derived_s1 where c &gt; 1;</span><br></pre></td></tr></table></figure>
<ul>
<li>MATERIALIZED<br>
当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的 select_type 属性就是 MATERIALIZED。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2);</span><br></pre></td></tr></table></figure>
<ul>
<li>UNCACHEABLE SUBQUERY<br>
不常用</li>
<li>UNCACHEABLE UNION<br>
不常用</li>
</ul>
<h3 id="partitions"><a class="header-anchor" href="#partitions">¶</a>partitions</h3>
<p>分区，一般查询计划中的该字段都是 NULL。</p>
<h3 id="type"><a class="header-anchor" href="#type">¶</a>type</h3>
<p>对某张表执行查询时的访问方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>由于 idx_key1 二级索引的存在，因此这个等值查询的 type 列的值为 ref。具体的访问方法如下所示：</p>
<ul>
<li>system<br>
当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如<strong>MyISAM</strong>、<strong>Memory</strong>，那么对该表的访问方法就是 system。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM t;</span><br></pre></td></tr></table></figure>
<ul>
<li>const<br>
当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是 const。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE id = 5;</span><br></pre></td></tr></table></figure>
<ul>
<li>eq_ref<br>
在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是 eq_ref。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;</span><br></pre></td></tr></table></figure>
<ul>
<li>ref<br>
当通过普通的二级索引列与常量进行等值匹配时来查询某个表，那么对该表的访问方法就可能是 ref。</li>
<li>fulltext<br>
全文索引。</li>
<li>ref_or_null<br>
当对普通二级索引进行等值匹配查询，该索引列的值也可以是 NULL 值时，那么对该表的访问方法就可能是 ref_or_null。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; OR key1 IS NULL;</span><br></pre></td></tr></table></figure>
<ul>
<li>index_merge<br>
包括 Intersection、Union、Sort-Union 这三种索引合并方式</li>
<li>unique_subquery<br>
类似于两表连接中被驱动表的 eq_ref 访问方法，unique_subquery 是针对在一些包含 IN 子查询的查询语句中，如果查询优化器决定将 IN 子查询转换为 EXISTS 子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的 type 列的值就是 unique_subquery，比如下边的这个查询语句：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>index_subquery<br>
index_subquery 与 unique_subquery 类似，只不过访问子查询中的表时使用的是普通的索引</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key3 FROM s2 where s1.key1 = s2.key1) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>range<br>
如果使用索引获取某些范围区间的记录，那么就可能使用到 range 访问方法。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;);</span><br><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 &gt; &apos;a&apos; AND key1 &lt; &apos;b&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>index<br>
当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是 index。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT key_part2 FROM s1 WHERE key_part3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>ALL<br>
全表扫描。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1;</span><br></pre></td></tr></table></figure>
<h3 id="possible-keys-和-key"><a class="header-anchor" href="#possible-keys-和-key">¶</a>possible_keys 和 key</h3>
<p>possible_keys 列表示在某个查询语句中，对某个表执行单表查询时可能用到的索引有哪些，key 列表示实际用到的索引有哪些。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这条 sql，因为 key1 和 key3 分别可以命中 idx_key1 和 idx_key3 这两个索引，因此 possible_keys 列的值包含这二者。</p>
<h3 id="key-len"><a class="header-anchor" href="#key-len">¶</a>key_len</h3>
<p>key_len 列表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度。</p>
<h3 id="ref-v2"><a class="header-anchor" href="#ref-v2">¶</a>ref</h3>
<p>当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是 const、eq_ref、ref、ref_or_null、unique_subquery、index_subquery 其中之一时，ref 列表示与索引列进行匹配的目标类型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 因为与key1进行匹配的&apos;a&apos;是常量，因此ref列的值为const</span><br><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos;;</span><br><span class="line">-- 与id列比较，ref值为对应库.对应表.id</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;</span><br><span class="line">-- 与函数进行比较，ref值为func</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s2.key1 = UPPER(s1.key1);</span><br></pre></td></tr></table></figure>
<h3 id="rows"><a class="header-anchor" href="#rows">¶</a>rows</h3>
<p>如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的 rows 列就代表预计需要扫描的行数，如果使用索引来执行查询时，执行计划的 rows 列就代表预计扫描的索引记录行数。</p>
<h3 id="filtered"><a class="header-anchor" href="#filtered">¶</a>filtered</h3>
<p>优化器估算 rows 中满足搜索条件的记录的百分比。</p>
<h3 id="extra"><a class="header-anchor" href="#extra">¶</a>Extra</h3>
<p>额外信息的种类比较多：</p>
<ul>
<li>No tables used<br>
当查询语句的没有 FROM 子句时将会提示该额外信息</li>
<li>Impossible WHERE<br>
查询语句的 WHERE 子句永远为 FALSE 时将会提示该额外信息：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE 1 != 1;</span><br></pre></td></tr></table></figure>
<ul>
<li>No matching min/max row<br>
当查询列表处有 MIN 或者 MAX 聚集函数，但是并没有符合 WHERE 子句中的搜索条件的记录时，将会提示该额外信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT MIN(key1) FROM s1 WHERE key1 = &apos;abcdefg&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using index<br>
当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用<strong>索引覆盖</strong>的情况下，在 Extra 列将会提示该额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT key1 FROM s1 WHERE key1 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using index condition<br>
有些搜索条件中虽然出现了索引列，但却不能使用到索引</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key1 LIKE &apos;%a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这个条件中，优化器会先根据<code>key1 &gt; 'z'</code>从二级索引<code>idx_key1</code>中定位到符合的二级索引记录，但是不会直接回表，而是先根据<code>key1 LIKE '%a'</code>找到匹配的记录再回表，这被称为<strong>索引条件下推</strong>。<br>
索引下推应用于多条件查询上，5.6之前，查了一个条件后就会尝试回表得到结果，然后再对结果过滤其他字段，比如上面查完<code>key1 &gt; 'z'</code>后就会回表；而5.6之后，如果有多个条件会先尝试在联合索引上进行过滤再回表，比如上面先根据<code>key1 &gt; 'z'</code>查询，再使用<code>key1 LIKE '%a'</code>过滤，最后才回表。</p>
<ul>
<li>Using Where<br>
当我们使用全表扫描来执行对某个表的查询，并且该语句的 WHERE 子句中有针对该表的搜索条件时，在 Extra 列中会提示上述额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>当使用索引访问来执行对某个表的查询，并且该语句的 WHERE 子句中有除了该索引包含的列之外的其他搜索条件时，在 Extra 列中也会提示上述额外信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; AND common_field = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using join buffer (Block Nested Loop)<br>
在连接查询执行过程中，当被驱动表不能有效的利用索引加快访问速度，MySQL 一般会为其分配一块名叫<strong>join buffer</strong>的内存块来加快查询速度，也就是我们所讲的<strong>基于块的嵌套循环算法</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.common_field = s2.common_field;</span><br></pre></td></tr></table></figure>
<ul>
<li>Not exists<br>
当我们使用左（外）连接时，如果 WHERE 子句中包含要求被驱动表的某个列等于 NULL 值的搜索条件，而且那个列又是不允许存储 NULL 值的，那么在该表的执行计划的 Extra 列就会提示 Not exists 额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 LEFT JOIN s2 ON s1.key1 = s2.key1 WHERE s2.id IS NULL;</span><br></pre></td></tr></table></figure>
<p>左外连接时如果被驱动表中匹配不到驱动表的某条记录，则该条记录对应的 <a href="http://s2.id" target="_blank" rel="noopener">s2.id</a> 就为 NULL。</p>
<ul>
<li>Using intersect(…)、Using union(…)和 Using sort_union(…)<br>
如果执行计划的 Extra 列出现了 Using intersect(…)提示，说明准备使用 Intersect 索引合并的方式执行查询，括号中的…表示需要进行索引合并的索引名称；如果出现了 Using union(…)提示，说明准备使用 Union 索引合并的方式执行查询；出现了 Using sort_union(…)提示，说明准备使用 Sort-Union 索引合并的方式执行查询。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; AND key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Zero limit<br>
当我们的 LIMIT 子句的参数为 0 时，表示压根儿不打算从表中读出任何记录，将会提示该额外信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 LIMIT 0;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using filesort<br>
有一些情况下对结果集中的记录进行排序是可以使用到索引的。但是很多情况下排序操作无法使用到索引，只能在内存中（记录较少的时候）或者磁盘中（记录较多的时候）进行排序，这种在内存中或者磁盘上进行排序的方式统称为文件排序（filesort）。如果某个查询需要使用<strong>文件排序</strong>的方式执行查询，就会在执行计划的 Extra 列中显示 Using filesort 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 ORDER BY key1 LIMIT 10;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using temporary<br>
在许多查询的执行过程中，MySQL 可能会借助临时表来完成一些功能，比如去重、排序之类的，比如我们在执行许多包含 DISTINCT、GROUP BY、UNION 等子句的查询过程中，如果不能有效利用索引来完成查询，MySQL 很有可能寻求通过建立内部的<strong>临时表</strong>来执行查询。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT DISTINCT common_field FROM s1;</span><br></pre></td></tr></table></figure>
<ul>
<li>Start temporary, End temporary<br>
我们前边唠叨子查询的时候说过，查询优化器会优先尝试将 IN 子查询转换成 semi-join，而 semi-join 又有好多种执行策略，当执行策略为 DuplicateWeedout 时，也就是通过建立临时表来实现为外层查询中的记录进行去重操作时，驱动表查询执行计划的 Extra 列将显示 Start temporary 提示，被驱动表查询执行计划的 Extra 列将显示 End temporary 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 WHERE common_field = &apos;a&apos;);</span><br></pre></td></tr></table></figure>
<ul>
<li>LooseScan<br>
在将 In 子查询转为 semi-join 时，如果采用的是 LooseScan 执行策略，则在驱动表执行计划的 Extra 列就是显示 LooseScan 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key3 IN (SELECT key1 FROM s2 WHERE key1 &gt; &apos;z&apos;);</span><br></pre></td></tr></table></figure>
<ul>
<li>FirstMatch(tbl_name)<br>
在将 In 子查询转为 semi-join 时，如果采用的是 FirstMatch 执行策略，则在被驱动表执行计划的 Extra 列就是显示 FirstMatch(tbl_name)提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key1 FROM s2 where s1.key3 = s2.key3);</span><br></pre></td></tr></table></figure>
<h2 id="optimizer-trace"><a class="header-anchor" href="#optimizer-trace">¶</a>optimizer trace</h2>
<p>查看优化器生成执行计划的整个过程，这个功能的开启与关闭由系统变量 optimizer_trace 决定：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &apos;optimizer_trace&apos;;</span><br></pre></td></tr></table></figure>
<p>这个 optimizer_trace 表中有 4 个列：</p>
<ul>
<li>QUERY：表示我们的查询语句。</li>
<li>TRACE：表示优化过程的 JSON 格式文本。</li>
<li>MISSING_BYTES_BEYOND_MAX_MEM_SIZE：由于优化过程可能会输出很多，如果超过某个限制时，多余的文本将不会被显示，这个字段展示了被忽略的文本字节数。</li>
<li>INSUFFICIENT_PRIVILEGES：表示是否没有权限查看优化过程，默认值是 0，只有某些特殊情况下才会是 1，我们暂时不关心这个字段的值。</li>
</ul>
<p>optimizer trace 使用步骤如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 1. 打开optimizer trace功能 (默认情况下它是关闭的):</span><br><span class="line">SET optimizer_trace=&quot;enabled=on&quot;;</span><br><span class="line"></span><br><span class="line"># 2. 这里输入你自己的查询语句</span><br><span class="line">SELECT ...; </span><br><span class="line"></span><br><span class="line"># 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程</span><br><span class="line">SELECT * FROM information_schema.OPTIMIZER_TRACE;</span><br><span class="line"></span><br><span class="line"># 4. 可能你还要观察其他语句执行的优化过程，重复上边的第2、3步</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># 5. 当你停止查看语句的优化过程时，把optimizer trace功能关闭</span><br><span class="line">SET optimizer_trace=&quot;enabled=off&quot;;</span><br></pre></td></tr></table></figure>
<p>优化过程大致分为了三个阶段：<br>
1、prepare 阶段<br>
2、optimize 阶段<br>
单表查询需要重点关注 rows_estimation 这个过程，因为分析了对单表查询的各种执行方案的成本；<br>
对于夺标连接查询，更多的需要关注 considered_execution_plans 这个过程，因为这个过程里会写明各种不同的连接方式所对应的成本。<br>
3、execute 阶段</p>
<h1>QA</h1>
<h2 id="什么时候会发生文件排序？如何优化"><a class="header-anchor" href="#什么时候会发生文件排序？如何优化">¶</a>什么时候会发生文件排序？如何优化</h2>
<p>如果没有用到索引，InnoDB 排序前一般会先将数据加载到内存的<strong>sort_buffer</strong>中，或者由于数据量太大需要借助磁盘空间来存放中间结果，排序完后再将结果集返回给客户端，在 MySQL 中，这种在内存或磁盘上进行排序的方式被称为<strong>文件排序（filesort）</strong>。<br>
order by 语句最好能使用到覆盖索引，因为索引本身就对记录进行了排序，并且需要注意索引字段的顺序。</p>
<h2 id="什么是索引下推"><a class="header-anchor" href="#什么是索引下推">¶</a>什么是索引下推</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key1 LIKE &apos;%a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这个条件中，优化器会先根据<code>key1 &gt; 'z'</code>从二级索引<code>idx_key1</code>中定位到符合的二级索引记录，但是不会直接回表，而是先根据<code>key1 LIKE '%a'</code>找到匹配的记录再回表，这被称为<strong>索引条件下推</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/937fe6d5.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/937fe6d5.html" itemprop="url">MySQL 中的日志</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-26T10:18:28+08:00">
                2020-05-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>redo log</h1>
<p>实现持久性的方式：<br>
1、在事务提交完成之前把该事务所修改的所有页面都刷新到磁盘；<br>
但是只修改了一点数据也刷新整个页比较浪费，且一次写入可能涉及到很多不连续的页，这样随机 IO 效率比较低。<br>
2、把修改了哪些东西记录一下就好，即使系统崩溃也能恢复<br>
即 redo log，优点是占用空间小、顺序写入。</p>
<h2 id="wal-write-ahead-logging"><a class="header-anchor" href="#wal-write-ahead-logging">¶</a>WAL（Write-Ahead Logging）</h2>
<p>先写日志，再写磁盘，同时，InnoDB 引擎会在系统相对空闲的时候将操作记录同步到磁盘上。<br>
WAL 保证了 InnoDB 是<strong>crash-safe</strong>的，因为即使数据库发生异常重启，之前提交的记录都不会丢失。</p>
<h2 id="redo-log-的结构"><a class="header-anchor" href="#redo-log-的结构">¶</a>redo log 的结构</h2>
<p>每条 redo log 会记录以下属性：</p>
<ul>
<li>type：该条 redo 日志的类型。</li>
<li>space ID：表空间 ID。</li>
<li>page number：页号。</li>
<li>data：该条 redo 日志的具体内容。</li>
</ul>
<p>对不同类型字段作修改时会记录不同类型的 redo log，比如：</p>
<ul>
<li>表中没有主键时，会生成一个<code>row_id</code>隐藏列保存到 data 字段里；</li>
<li>涉及变长字符串类型的 redo log 因为不确定具体占用多少字段空间，因此 data 字段中还有一个<code>len</code>字段。</li>
</ul>
<h2 id="mini-transaction"><a class="header-anchor" href="#mini-transaction">¶</a>Mini-Transaction</h2>
<p>在 MySQL 中对底层页面中的一次原子访问的过程称之为一个<code>Mini-Transaction</code>，简称<code>mtr</code>，一个 mtr 可以包含一组 redo log，在进行崩溃恢复时这一组 redo log 是一个不可分割的整体。<br>
比如插入一条记录的时候，如果数据页的空闲空间不足，需要进行页分裂操作：新建一个叶子节点，然后把原先数据页中的一部分记录复制到这个新的数据页中，然后再把记录插入进去，把这个叶子节点插入到叶子节点链表中，最后还要在内节点中添加一条目录项记录指向这个新创建的页面。这个过程中需要对多个页面进行改改，因此会产生多条 redo log，这个过程必须是原子的，InnoDB 会以组的形式来记录 redo log，崩溃恢复时要么整组恢复、要么一条也不恢复，因此被称为<strong>悲观插入</strong>。</p>
<blockquote>
<p>如果数据页的空闲空间充足则可以直接插入，这种方式被称为<strong>乐观插入</strong>。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-MiniTransaction.png" alt="MySQL-MiniTransaction" title="MySQL-MiniTransaction"></p>
</blockquote>
<h2 id="redo-日志的存储结构"><a class="header-anchor" href="#redo-日志的存储结构">¶</a>redo 日志的存储结构</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-redolog.png" alt="MySQL-redolog" title="MySQL-redolog"><br>
MySQL 会向操作系统申请一块<strong>redo log buffer</strong>连续内存空间，这块内存空间之后被划分为若干连续 redo log block。<br>
InnoDB 会维护一个全局变量<code>buf_free</code>，指示后续 redo 日志应该写入到 log buffer 中的哪个位置。<br>
最终 redo log 会被刷新到磁盘中被称为<strong>block</strong>的页中，其中关键字段包括：</p>
<ul>
<li>该 block 的唯一标识；</li>
<li>第一条 redo 日志偏移量：一个 mtr 会生成多条 redo 日志记录（redo log record），这些日志被统称为一个 redo 日志记录组（redo log record group），block 会记录这个 redo 日志记录组第一条记录的偏移量。</li>
<li>checkpoint 的序号。</li>
<li>lsn：每条日志都有一个序列号<strong>Log Sequence Number</strong>，简称为<strong>lsn</strong>，它的值是不断增长的，初始值为 8704，lsn 值越小，则说明该 redo log 生成的时间越早。</li>
</ul>
<h2 id="redo-log-刷盘时机"><a class="header-anchor" href="#redo-log-刷盘时机">¶</a>redo log 刷盘时机</h2>
<p>当内存数据页和磁盘数据页内容不一致时，我们称这个内存页为&quot;脏页&quot;，内存数据写入到磁盘后，内存和磁盘上的数据页内容就一致了称为&quot;干净页&quot;，，redo log 就是内存数据页，而 B+树结构的聚簇索引就是磁盘数据页。<br>
redo log 会被复制到 log buffer 中，但是 log buffer 的空间是有限的，当满足一定条件时需要被刷新到磁盘里：</p>
<ul>
<li>log buffer 空间不足时<br>
log buffer 的大小是有限的（通过系统变量<code>innodb_log_buffer_size</code>指定），当要读入的数据页没有在内存中的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页就必须将脏页先刷到磁盘，变成干净页后才能复用。</li>
<li>事务提交时<br>
我们前边说过之所以使用 redo 日志主要是因为它占用的空间少，还是顺序写，在事务提交时可以不把修改过的 Buffer Pool 页面刷新到磁盘，但是为了保证持久性，必须要把修改这些页面对应的 redo 日志刷新到磁盘。</li>
<li>后台线程的执行<br>
后台有一个线程，大约每秒都会刷新一次 log buffer 中的 redo 日志到磁盘。</li>
<li>正常关闭服务器时</li>
<li>做<strong>checkpoint</strong>时</li>
</ul>
<h3 id="批量从-flush-链表中刷出脏页"><a class="header-anchor" href="#批量从-flush-链表中刷出脏页">¶</a>批量从 flush 链表中刷出脏页</h3>
<p>我们在介绍 Buffer Pool 的时候说过，一般情况下都是后台的线程在对 LRU 链表和 flush 链表进行刷脏操作，这主要因为刷脏操作比较慢，不想影响用户线程处理请求。但是如果当前系统修改页面的操作十分频繁，这样就导致写日志操作十分频繁，系统 lsn 值增长过快。如果后台的刷脏操作不能将脏页刷出，那么系统无法及时做 checkpoint，可能就需要用户线程同步的从 flush 链表中把那些最早修改的脏页（oldest_modification 最小的脏页）刷新到磁盘，这样这些脏页对应的 redo 日志就没用了，然后就可以去做 checkpoint 了。</p>
<h3 id="查看各种-lsn-值"><a class="header-anchor" href="#查看各种-lsn-值">¶</a>查看各种 LSN 值</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINE INNODB STATUS</span><br></pre></td></tr></table></figure>
<ul>
<li>Log sequence number：代表系统中的 lsn 值，也就是当前系统已经写入的 redo 日志量，包括写入 log buffer 中的日志。</li>
<li>Log flushed up to：代表 flushed_to_disk_lsn 的值，也就是当前系统已经写入磁盘的 redo 日志量。</li>
<li>Pages flushed up to：代表 flush 链表中被最早修改的那个页面对应的 oldest_modification 属性值。</li>
<li>Last checkpoint at：当前系统的 checkpoint_lsn 值。</li>
</ul>
<h3 id="innodb-flush-log-at-trx-commit"><a class="header-anchor" href="#innodb-flush-log-at-trx-commit">¶</a>innodb_flush_log_at_trx_commit</h3>
<p>为了保证事务的持久性，一般来说用户线程在事务提交时需要将该事务执行过程中产生的所有 redo 日志都刷新到磁盘上。<br>
但是出于效率上的考虑，可以修改<code>innodb_flush_log_at_trx_commit</code>的取值来调整这个过程：</p>
<ul>
<li>0：当该系统变量值为 0 时，表示在事务提交时不立即向磁盘中同步 redo 日志，这个任务是交给后台线程做的。<br>
这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将 redo 日志刷新到磁盘，那么该事务对页面的修改会丢失。</li>
<li>1：当该系统变量值为 1 时，表示在事务提交时需要将 redo 日志同步到磁盘，可以保证事务的持久性。1 也是<code>innodb_flush_log_at_trx_commit</code>的默认值。</li>
<li>2：当该系统变量值为 2 时，表示在事务提交时需要将 redo 日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。<br>
这种情况下如果数据库挂了，操作系统没挂的话，事务的持久性还是可以保证的，但是操作系统也挂了的话，那就不能保证持久性了。</li>
</ul>
<h2 id="崩溃恢复"><a class="header-anchor" href="#崩溃恢复">¶</a>崩溃恢复</h2>
<p>1、确定恢复的起点<br>
<code>checkpoint_lsn</code>之前的 redo 日志都可以被覆盖，也就是说这些 redo 日志对应的脏页都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。对于<code>checkpoint_lsn</code>之后的 redo 日志，它们对应的脏页可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从<code>checkpoint_lsn</code>开始读取 redo 日志来恢复页面。<br>
redo 日志文件组的第一个文件的管理信息中有两个 block 都存储了 checkpoint_lsn 的信息，我们当然是要选取最近发生的那次 checkpoint 的信息。衡量 checkpoint 发生时间早晚的信息就是所谓的 checkpoint_no，我们只要把 checkpoint1 和 checkpoint2 这两个 block 中的 checkpoint_no 值读出来比一下大小，哪个的 checkpoint_no 值更大，说明哪个 block 存储的就是最近的一次 checkpoint 信息。这样我们就能拿到最近发生的 checkpoint 对应的 checkpoint_lsn 值以及它在 redo 日志文件组中的偏移量 checkpoint_offset。<br>
2、确定恢复的终点<br>
普通 block 的 log block header 部分有一个称之为 LOG_BLOCK_HDR_DATA_LEN 的属性，该属性值记录了当前 block 里使用了多少字节的空间。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/26/169b8990b6d085cd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
对于已经填满的 block 来说，该值就是 512，也就是说如果该值不是 512，那么它就是这次崩溃恢复中需要扫描的最后一个 block 了。<br>
3、恢复<br>
确定起点和终点后，我们就可以按照 redo log 的顺序依次扫描<code>checkpoint_lsn</code>之后的各条 redo 日志来执行恢复了。</p>
<h2 id="redo-log-flush"><a class="header-anchor" href="#redo-log-flush">¶</a>redo log flush</h2>
<p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“<strong>脏页</strong>”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“<strong>干净页</strong>”。<br>
MySQL 偶尔的<strong>抖动</strong>，很有可能就是在<strong>刷脏页（flush）</strong>。<br>
有以下几种情况都会引起 flush：</p>
<ul>
<li>redo log 写满了，需要释放一些空间，将 checkpoint 往前推进，并将之间的日志对应的脏页都 flush 到磁盘上。</li>
<li>系统内存不足，需要新的内存页时内存不够用了，需要淘汰一些数据页，空出内存来给其他数据页使用，如果淘汰的是脏页，则需要先将脏页写入到磁盘。</li>
<li>空闲期间，MySQL 会自动用过剩的计算能力执行 flush 任务。</li>
<li>正常关闭时，MySQL 会将内存的脏页都 flush 到磁盘。</li>
</ul>
<h1>bin log</h1>
<p>WAL 机制保证了 MySQL 数据不会丢失，WAL 的核心是 <strong>bin log</strong> 和 <strong>redo log</strong>。</p>
<h2 id="bin-log-与-redo-log-区别"><a class="header-anchor" href="#bin-log-与-redo-log-区别">¶</a>bin log 与 redo log 区别</h2>
<p>1、redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。<br>
2、redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。<br>
3、redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>
<ol>
<li>bin log 只能用于归档，没有 crash-safe 能力，而 redo log 是 InnoDB 的，可以提供 crash-safe 能力。</li>
</ol>
<h2 id="binlog-写入机制"><a class="header-anchor" href="#binlog-写入机制">¶</a>binlog 写入机制</h2>
<ol>
<li>事务执行过程中，先把日志写到 binlog cache；</li>
<li>事务提交的时候，再把 binlog cache 写入到 binlog 文件中。</li>
</ol>
<p>binlog 写入的关键是要保证原子性：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-binlog%E5%86%99%E7%9B%98.png" alt="MySQL-binlog写盘" title="MySQL-binlog写盘"></p>
<ol>
<li>每个线程有自己的 binlog cache，但是共用同一份 binlog 文件；</li>
<li>上图的<code>write</code>指的是把日志写入文件系统的<code>page cache</code>，并没有把数据持久化到磁盘，所以速度较快；</li>
<li>上图的<code>fsync</code>才是将数据持久化到磁盘的操作。</li>
</ol>
<p>redo log 会被先写入到 <strong>redo log buffer</strong> 内，分以下几种情况：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-redolog%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81.png" alt="MySQL-redolog存储状态" title="MySQL-redolog存储状态"></p>
<ol>
<li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；</li>
<li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；</li>
<li>持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。</li>
</ol>
<p>redo log buffer 写入磁盘的时机：</p>
<ol>
<li>后台线程每秒轮询，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘；</li>
<li>redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。</li>
<li>并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。</li>
</ol>
<h2 id="bin-log-格式"><a class="header-anchor" href="#bin-log-格式">¶</a>bin log 格式</h2>
<p>bin log 有 3 种格式：</p>
<ul>
<li>statement: 存的是语句原文，可能会导致主备不一致，比如在主库和之后在备库上执行时选取的索引不一样；</li>
<li>row: 会记录具体作用的目标数据，比较占用空间、且会消耗大量 IO 资源；<br>
比如一条 delete 语句，statement 格式的 bin log 会直接记录该语句，而 row 格式会记录具体删除的记录的 ID。</li>
<li>mixed: 自动判断 SQL 语句是否可能导致主备不一致，若有可能则采用 row，否则 statement。</li>
</ul>
<h2 id="查看-bin-log"><a class="header-anchor" href="#查看-bin-log">¶</a>查看 bin log</h2>
<p>本地创建配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line">[mysqld]</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">expire-logs-days=14</span><br><span class="line">server-id=1</span><br><span class="line">binlog_format=statement</span><br></pre></td></tr></table></figure>
<p>使用 Docker 启动 MySQL 进程，注意-v 前面是宿主机的配置文件所在目录，后面是容器内的配置文件目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -v /Users/huanggaochi/Downloads/mysql:/etc/mysql/conf.d -d mysql:5.7</span><br></pre></td></tr></table></figure>
<p>连接时如果遇到文件，可以使用<code>docker logs [CONTAINER ID]</code>查看容器启动日志。</p>
<p>连接 MySQL 后查看 bin log 是否有被开启：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;log_bin&apos;;</span><br></pre></td></tr></table></figure>
<p>下面是测试用 SQL 语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `a` (`a`),</span><br><span class="line">  KEY `t_modified`(`t_modified`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into t values(1,1,&apos;2018-11-13&apos;);</span><br><span class="line">insert into t values(2,2,&apos;2018-11-12&apos;);</span><br><span class="line">insert into t values(3,3,&apos;2018-11-11&apos;);</span><br><span class="line">insert into t values(4,4,&apos;2018-11-10&apos;);</span><br><span class="line">insert into t values(5,5,&apos;2018-11-09&apos;);</span><br><span class="line"></span><br><span class="line">delete from t /*comment*/  where a&gt;=4 and t_modified&lt;=&apos;2018-11-10&apos; limit 1;</span><br></pre></td></tr></table></figure>
<p>运行后，查看 bin log：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show binlog events in &apos;mysql-bin.000001&apos;;</span><br></pre></td></tr></table></figure>
<h1>undo log</h1>
<p>需要回滚的情况：<br>
1、事务执行过程中可能遇到各种错误，比如服务器本身的错误，操作系统错误，甚至是突然断电导致的错误。<br>
2、程序员可以在事务执行过程中手动输入 ROLLBACK 语句结束当前的事务的执行。<br>
为了有需要时能够回滚，每当我们要对一条记录做改动时都需要将回滚时所需的东西都记录一下，包括：<br>
1、插入记录时，记录主键，这样回滚时直接删除这条记录即可；<br>
2、删除记录时，将这条记录的内容记录下来，回滚时重新插入即可；<br>
3、修改记录时，将旧值记录下来，回滚时重新更新回旧值。</p>
<h2 id="事务-id-trx-id"><a class="header-anchor" href="#事务-id-trx-id">¶</a>事务 ID（trx_id）</h2>
<h3 id="分配时机"><a class="header-anchor" href="#分配时机">¶</a>分配时机</h3>
<p>如果某个事务执行过程中对某个表执行了增、删、改操作，那么 InnoDB 存储引擎就会给它分配一个独一无二的事务 id。<br>
1、只读事务（START TRANSACTION READ ONLY）<br>
只读事务中不可以对普通的表进行增删改操作，但可以对临时表做增、删、改操作。<br>
对于只读事务来说，只有在它第一次对某个用户创建的临时表执行增、删、改操作时才会为这个事务分配一个事务 id，否则的话是不分配事务 id 的。<br>
2、读写事务（START TRANSACTION READ WRITE、BEGIN、START TRANSACTION）<br>
在读写事务中可以对表执行增删改查操作。<br>
对于读写事务来说，只有在它第一次对某个表（包括用户创建的临时表）执行增、删、改操作时才会为这个事务分配一个事务 id，否则的话也不会分配事务 id</p>
<p>总而言之，<strong>只有在事务对表中的记录做改动时才会为这个事务分配一个唯一的事务 id</strong>。</p>
<h3 id="生成方式"><a class="header-anchor" href="#生成方式">¶</a>生成方式</h3>
<p>和 row_id 的生成方式类似：</p>
<ul>
<li>服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个事务 id 时，就会把该变量的值当作事务 id 分配给该事务，并且把该变量自增 1。</li>
<li>每当这个变量的值为 256 的倍数时，就会将该变量的值刷新到系统表空间的页号为 5 的页面中一个称之为 Max Trx ID 的属性处，这个属性占用 8 个字节的存储空间。</li>
<li>当系统下一次重新启动时，会将上边提到的 Max Trx ID 属性加载到内存中，将该值加上 256 之后赋值给我们前边提到的全局变量（因为在上次关机时该全局变量的值可能大于 Max Trx ID 属性值）。</li>
</ul>
<h2 id="undo-log-格式"><a class="header-anchor" href="#undo-log-格式">¶</a>undo log 格式</h2>
<p>1、查看 table id<br>
记录 undo log 时会使用到表的 table id，这个值可以通过<code>SELECT * FROM information_schema.innodb_sys_tables WHERE name = 'database_name/undo_demo';</code>这条命令来查看<br>
2、INSERT 操作的 undo log<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afa8857a9e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
undo no 在一个事务中是从 0 开始递增的，也就是说只要事务没提交，每生成一条 undo 日志，那么该条日志的 undo no 就增 1。<br>
主键可能是有多个列组成的，如果有多个列，则每个列占用的存储空间大小和对应的真实值都需要记录下来。<br>
比如对下面这条插入了两条记录的 SQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BEGIN;  # 显式开启一个事务，假设该事务的id为100</span><br><span class="line"></span><br><span class="line"># 插入两条记录</span><br><span class="line">INSERT INTO undo_demo(id, key1, col) </span><br><span class="line">    VALUES (1, &apos;AWM&apos;, &apos;狙击枪&apos;), (2, &apos;M416&apos;, &apos;步枪&apos;);</span><br></pre></td></tr></table></figure>
<p>针对这两条数据生成的 undo log 如下所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af96301bdd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af943ce197?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
3、DELETE 操作对应的 undo log<br>
插入到页面中的记录会通过头信息中的<code>next_record</code>属性组成一个单向链表，而被删除的记录则会组成另一个链表，<code>Page Header</code>中的<code>PAGE_FREE</code>属性指向了这个链表的头节点。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af99f1eb4e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
删除时会先将记录的<code>delete_mask</code>标识位设置为 1，表示已经被逻辑删除了。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afc12f5533?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
当该删除语句所在的事务提交之后，会有专门线程将记录真正地清除掉：将该记录从链表中移除并移入自由链表中。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afc377e08f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
由上可知，在事务执行完毕之前，记录并不会被真正地清除，所以回滚时也只需要将这个删除标识清除即可。<br>
3、UPDATE 操作的 undo log<br>
不更新主键的情况下，如果更新后的列和更新前的列值占用的存储空间一样大，那么就可以执行<code>就地更新</code>，直接在原记录上修改对应列的值；但是如果有任何一个列更新后占用的存储空间大小有变化，那么就需要将旧的记录从聚簇索引页面中删除（这是真正的删除，不是逻辑删除），然后创建一条新的记录插入到页面中。<br>
更新主键的情况下，旧记录会执行<code>delete mark</code>操作，由一个后台线程做 purge 操作，将其加入到垃圾链表中。</p>
<h2 id="roll-pointer-隐藏列"><a class="header-anchor" href="#roll-pointer-隐藏列">¶</a>roll_pointer 隐藏列</h2>
<p>每条记录的结构中都包含了一个 roll_pointer 隐藏列，其实这个字段是指向该记录对应 undo log 的指针。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af986df5c6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<h2 id="undo-log-写入过程"><a class="header-anchor" href="#undo-log-写入过程">¶</a>undo log 写入过程</h2>
<p><a href="https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c923cf3f265da60fb3bea67" target="_blank" rel="noopener">https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c923cf3f265da60fb3bea67</a></p>
<h1>slow log</h1>
<h2 id="查看慢查询日志"><a class="header-anchor" href="#查看慢查询日志">¶</a>查看慢查询日志</h2>
<p>查看是否开启慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &quot;%slow%&quot;;</span><br></pre></td></tr></table></figure>
<p>使用 sql 命令开启慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set global slow_query_log=1</span><br></pre></td></tr></table></figure>
<p>设置慢查询阈值，执行超过该时间的 sql 将被视作慢查询：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set global long_query_time=4</span><br></pre></td></tr></table></figure>
<p>注意修改这个阈值后需要重新连接或新开一个会话才能看到修改值。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">138</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">72</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
