<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/page/4/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/page/4/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/4eb3381c.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/4eb3381c.html" itemprop="url">分布式锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-06T16:32:14+08:00">
                2020-07-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  12 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>单机环境下的锁</h1>
<p>单机环境下，资源竞争者都是来自机器内部(进程/线程)，那么实现锁的方案只需要借助单机资源就可以了，比如借助磁盘、内存、寄存器来实现。</p>
<h2 id="竞态条件-race-condition"><a class="header-anchor" href="#竞态条件-race-condition">¶</a>竞态条件（Race Condition）</h2>
<p>计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。比如：</p>
<ol>
<li>先检测（查询）后执行。执行依赖于检测的结果，而检测结果依赖于多个线程的执行时序，而多个线程的执行时序通常情况下是不固定不可判断的，从而导致执行结果出现各种问题。</li>
<li>延迟初始化（如单例的实例化） <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class ObjFactory &#123;  </span><br><span class="line">    private Obj instance;  </span><br><span class="line"></span><br><span class="line">    public Obj getInstance()&#123;  </span><br><span class="line">        if(instance == null)&#123;  </span><br><span class="line">            instance = new Obj();  </span><br><span class="line">        &#125;  </span><br><span class="line">        return instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果两个线程同时调用 getInstance()就有可能出现：一个线程 A 创建了一个新对象 instance = obj1，立马被另一个线程 B 覆盖 instance = obj2，线程 A 返回了 obj1，线程 B 返回 obj2，于是 Obj 就相当于被实例化了两次。</p>
<h2 id="锁的分类"><a class="header-anchor" href="#锁的分类">¶</a>锁的分类</h2>
<ol>
<li>悲观锁，前提是，一定会有并发抢占资源，强行独占资源，在整个数据处理过程中将数据处于锁定状态。</li>
<li>乐观锁，前提是，不会发生并发抢占资源，只有在<strong>执行修改时</strong>检查是否违反数据完整性。<strong>只能防止脏读后数据的提交，不能解决脏读</strong>。</li>
</ol>
<h2 id="悲观锁"><a class="header-anchor" href="#悲观锁">¶</a>悲观锁</h2>
<h2 id="乐观锁"><a class="header-anchor" href="#乐观锁">¶</a>乐观锁</h2>
<p>乐观锁一般有以下两种实现方法：</p>
<ol>
<li>版本号：使用<strong>版本标识</strong>来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取<strong>丢弃</strong>或<strong>再次尝试</strong>的策略。</li>
<li>CAS：java 中的 compareandswap 即 cas，解决多线程并行情况下使用锁造成性能损耗的一种机制。CAS 操作包含三个操作数，内存位置（V）,预期原值（A）和新值（B）。如果内存位置的值与预期原值相匹配，那么处理器会西东将该位置值更新为新值。否则，处理器不做任何操作。</li>
</ol>
<h1>分布式锁</h1>
<p>目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的<strong>CAP 理论</strong>告诉我们“任何一个分布式系统都无法同时满足<strong>一致性（Consistency）</strong>、<strong>可用性（Availability）<strong>和</strong>分区容错性（Partition tolerance）</strong>，最多只能同时满足其中两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。<br>
有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java 中其实提供了很多并发处理相关的 API，但是这些 API 在分布式场景中就无能为力了。也就是说单纯的 Java Api 并不能提供分布式锁的能力。<br>
对于分布式环境下，资源竞争者生存环境更复杂了，原有依赖单机的方案不再发挥作用，这时候就需要一个大家都认可的协调者出来，帮助解决竞争问题，那这个协调者称之为分布式锁。</p>
<h2 id="实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的"><a class="header-anchor" href="#实现分布式锁的需求-方法锁-以方法作为临界区-资源锁是类似的">¶</a>实现分布式锁的需求（方法锁，以方法作为临界区，资源锁是类似的）</h2>
<ol>
<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。</li>
<li>这把锁要是一把可重入锁（单线程可重复获取同一把锁，避免死锁）</li>
<li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li>
<li>有高可用的获取锁和释放锁功能</li>
<li>获取锁和释放锁的性能要好</li>
</ol>
<h2 id="基于数据库表"><a class="header-anchor" href="#基于数据库表">¶</a>基于数据库表</h2>
<p>要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。<br>
当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。<br>
创建这样一张数据库表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `methodLock` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;,</span><br><span class="line">  `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;,</span><br><span class="line">  `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;,</span><br><span class="line">  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="使用锁表实现方法锁"><a class="header-anchor" href="#使用锁表实现方法锁">¶</a>使用锁表实现方法锁</h3>
<p>执行 SQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)</span><br></pre></td></tr></table></figure>
<p>因为我们对 method_name 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。<br>
当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from methodLock where method_name =&apos;method_name&apos;</span><br></pre></td></tr></table></figure>
<p>上面这种简单的实现有以下几个问题：</p>
<ul>
<li>这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li>
<li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li>
<li>这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li>
<li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据库中数据已经存在了。</li>
</ul>
<p>当然，我们也可以有其他方式解决上面的问题。</p>
<ul>
<li>数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。</li>
<li>没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。</li>
<li>非阻塞的？搞一个 while 循环，直到 insert 成功再返回成功。</li>
<li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li>
</ul>
<h3 id="使用数据库-x-锁-排他锁-实现分布式锁"><a class="header-anchor" href="#使用数据库-x-锁-排他锁-实现分布式锁">¶</a>使用数据库 X 锁（排他锁）实现分布式锁</h3>
<p>除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。<br>
我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。<br>
基于 MySQL 的 InnoDB 引擎，可以使用以下方法来实现加锁操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean lock()&#123;</span><br><span class="line">    connection.setAutoCommit(false)</span><br><span class="line">    while(true)&#123;</span><br><span class="line">        try&#123;</span><br><span class="line">            result = select * from methodLock where method_name = xxx for update;</span><br><span class="line">            if(result==null)&#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;catch(Exception e)&#123;</span><br><span class="line">            log.warn(&quot;加锁失败&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">        sleep(1000);</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。<br>
我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public void unlock()&#123;</span><br><span class="line">    connection.commit();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过 connection.commit()操作来释放锁。<br>
这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p>
<ul>
<li>阻塞锁？ for update 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li>
<li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。<br>
但是还是无法直接解决数据库单点和可重入问题。</li>
</ul>
<h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3>
<p>总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。<br>
数据库实现分布式锁的优点：</p>
<ol>
<li>直接借助数据库，容易理解。</li>
</ol>
<p>数据库实现分布式锁的缺点</p>
<ol>
<li>会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。</li>
<li>操作数据库需要一定的开销，性能问题需要考虑。</li>
</ol>
<h2 id="基于缓存"><a class="header-anchor" href="#基于缓存">¶</a>基于缓存</h2>
<p>使用缓存中间件实现分布式锁的方法我已经在<a href="https://tallate.github.io/d3d5fdbf.html#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">Redis 客户端</a>中有过分析。</p>
<h2 id="基于-zookeeper"><a class="header-anchor" href="#基于-zookeeper">¶</a>基于 ZooKeeper</h2>
<p>基于 zookeeper 临时有序节点可以实现的分布式锁。<br>
大致思想即为：每个客户端对某个方法加锁时，在 zookeeper 上的与该方法对应的指定节点的目录下，生成一个唯一的<strong>瞬时有序节点</strong>。<br>
判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。<br>
当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。<br>
来看下 Zookeeper 能不能解决前面提到的问题。</p>
<ul>
<li>锁无法释放？使用 Zookeeper 可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在 ZK 中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session 连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。</li>
<li>非阻塞锁？使用 Zookeeper 可以实现阻塞的锁，客户端可以通过在 ZK 中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper 会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。</li>
<li>不可重入？使用 Zookeeper 也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。</li>
<li>单点问题？使用 Zookeeper 可以有效的解决单点问题，ZK 是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</li>
</ul>
<h3 id="使用-curator-实现分布式锁"><a class="header-anchor" href="#使用-curator-实现分布式锁">¶</a>使用 Curator 实现分布式锁</h3>
<p>可以直接使用 zookeeper 第三方库 Curator 客户端，这个客户端中封装了一个可重入的锁服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        return interProcessMutex.acquire(timeout, unit);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line">public boolean unlock() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        interProcessMutex.release();</span><br><span class="line">    &#125; catch (Throwable e) &#123;</span><br><span class="line">        log.error(e.getMessage(), e);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Curator 提供的 InterProcessMutex 是分布式锁的实现。acquire 方法用户获取锁，release 方法用于释放锁。<br>
使用 ZK 实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper 实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK 中创建和删除节点只能通过<strong>Leader</strong>服务器来执行，然后将数据同步到所有的 Follower 机器上。</p>
<h3 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结</h3>
<p>使用 Zookeeper 实现分布式锁的优点</p>
<ol>
<li>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。</li>
<li>实现起来较为简单。</li>
</ol>
<p>使用 Zookeeper 实现分布式锁的缺点</p>
<ol>
<li>性能上不如使用缓存实现分布式锁。</li>
<li>需要对 ZK 的原理有所了解。</li>
</ol>
<p>分布式锁实现需要根据实际需要来选择，比如红锁是AP的，而ZooKeeper是CP的。</p>
<h1>QA</h1>
<ol>
<li>怎么使用 Redis 实现分布式锁？<br>
set 命令带上 nx 和 ex 参数。</li>
<li>怎么使用 zk 实现分布式锁？<br>
先建一个代表锁的持久节点，然后每个线程要加锁就在该持久节点下创建临时有序节点，如果当前线程创建的节点是最小的，则说明可以获取到该锁，否则阻塞等待；释放锁就是将这个临时节点删除。</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/garfieldcgf/p/6380816.html" target="_blank" rel="noopener">分布式锁的几种实现方式</a></li>
<li><a href="https://www.cnblogs.com/dennyzhangdd/p/7133653.html#_label0" target="_blank" rel="noopener">终极锁实战：单 JVM 锁+分布式锁</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a87bf883.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/a87bf883.html" itemprop="url">MySQL 的其他主题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-30T10:18:28+08:00">
                2020-05-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>常用服务器配置</h1>
<ul>
<li>启动选项和系统变量<br>
启动选项是运维启动 MySQL 时传入的一些参数，包括命令行启动选项和配置文件 my.cnf<br>
系统变量会影响 MySQL 进程的运行行为，大部分是由启动选项初始化的，有些是运行时自动生成的</li>
<li>查看系统变量<br>
<code>show [GLOBAL|SESSION] variables [like 匹配的模式];</code></li>
<li>配置文件中配置组的概念</li>
<li>配置作用范围<br>
1、GLOBAL 指配置文件或命令行启动选项设置的系统变量<br>
2、SESSION（LOCAL）刚连接时会被初始化为 GLOBAL 的变量，可以通过以下命令来设置<br>
<code>SET [GLOBAL|SESSION] 系统变量名 = 值;</code></li>
<li>状态变量<br>
指关于程序运行状态的变量，是只读的，不能手动修改<br>
比方说 Threads_connected 表示当前有多少客户端与服务器建立了连接，Handler_update 表示已经更新了多少行记录<br>
SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];</li>
</ul>
<h1>InnoDB 统计数据</h1>
<h2 id="两种统计数据"><a class="header-anchor" href="#两种统计数据">¶</a>两种统计数据</h2>
<p>InnoDB 中有两种统计数据：<br>
1、永久性：服务器重启也不会消失，这些数据被存储到了<code>innodb_table_stats</code>和<code>innodb_index_stats</code>这两张表中；<br>
2、非永久性：重启即消失。<br>
可以通过服务器的<code>innodb_stats_persistent</code>变量来查看这个统计数据的方式。</p>
<h2 id="innodb-table-stats-统计方式"><a class="header-anchor" href="#innodb-table-stats-统计方式">¶</a>innodb_table_stats 统计方式</h2>
<p>1、n_rows(一个表中的记录行数)统计项的收集<br>
按照一定算法选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的 n_rows 值<br>
2、clustered_index_size 和 sum_of_other_index_sizes</p>
<ul>
<li>从数据字典里找到表的各个索引对应的根页面位置。<br>
系统表 SYS_INDEXES 里存储了各个索引对应的根页面信息。</li>
<li>从根页面的 Page Header 里找到叶子节点段和非叶子节点段对应的 Segment Header。<br>
在每个索引的根页面的 Page Header 部分都有两个字段：<br>
PAGE_BTR_SEG_LEAF：表示 B+树叶子段的 Segment Header 信息。<br>
PAGE_BTR_SEG_TOP：表示 B+树非叶子段的 Segment Header 信息。</li>
<li>从叶子节点段和非叶子节点段的 Segment Header 中找到这两个段对应的 INODE Entry 结构。<br>
这个是 Segment Header 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b165a91f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>从对应的 INODE Entry 结构中可以找到该段对应所有零散的页面地址以及 FREE、NOT_FULL、FULL 链表的基节点。<br>
这个是 INODE Entry 结构：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b1e44524?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>直接统计零散的页面有多少个，然后从那三个链表的 List Length 字段中读出该段占用的区的大小，每个区占用 64 个页，所以就可以统计出整个段占用的页面。<br>
这个是链表基节点的示意图：<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/26/167e94d5b17c24e3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
<li>分别计算聚簇索引的叶子结点段和非叶子节点段占用的页面数，它们的和就是 clustered_index_size 的值，按照同样的套路把其余索引占用的页面数都算出来，加起来之后就是 sum_of_other_index_sizes 的值。</li>
</ul>
<h2 id="innodb-index-stats-统计方式"><a class="header-anchor" href="#innodb-index-stats-统计方式">¶</a>innodb_index_stats 统计方式</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM mysql.innodb_index_stats WHERE table_name = &apos;single_table&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>n_leaf_pages：表示该索引的叶子节点占用多少页面。</li>
<li>size：表示该索引共占用多少页面。</li>
<li>n_diff_pfxNN：表示对应的索引列不重复的值有多少。其中的 NN 长得有点儿怪呀，啥意思呢？<br>
其实 NN 可以被替换为 01、02、03… 这样的数字。比如对于 idx_key_part 来说：<br>
n_diff_pfx01 表示的是统计 key_part1 这单单一个列不重复的值有多少。<br>
n_diff_pfx02 表示的是统计 key_part1、key_part2 这两个列组合起来不重复的值有多少。<br>
n_diff_pfx03 表示的是统计 key_part1、key_part2、key_part3 这三个列组合起来不重复的值有多少。<br>
n_diff_pfx04 表示的是统计 key_part1、key_part2、key_part3、id 这四个列组合起来不重复的值有多少。</li>
<li>在计算某些索引列中包含多少不重复值时，需要对一些叶子节点页面进行采样，sample_size 列就表明了采样的页面数量是多少。</li>
</ul>
<h2 id="基于内存的非永久性统计数据"><a class="header-anchor" href="#基于内存的非永久性统计数据">¶</a>基于内存的非永久性统计数据</h2>
<p>开启非永久性统计数据的方法：<br>
1、将<code>innodb_stats_persistent</code>的值设置为 OFF；<br>
2、直接在创建表或修改表时设置<code>STATS_PERSISTENT</code>属性的值为 0；</p>
<h1>MySQL Server 统计数据</h1>
<p>Server 层而不是 InnoDB（存储引擎层）统计数据。<br>
1、查看连接数配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;%max_connections%&apos;</span><br></pre></td></tr></table></figure>
<p>2、查看当前连接数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show full processlist;</span><br></pre></td></tr></table></figure>
<h1>数据恢复</h1>
<p>数据的误删基本分以下几种情况：</p>
<ol>
<li>使用 delete 语句误删数据行；</li>
<li>使用 drop table 或 truncate table 误删表；</li>
<li>使用 drop database 误删数据库；</li>
<li>使用 rm 命令误删整个 MySQL 实例。</li>
</ol>
<h2 id="误删行"><a class="header-anchor" href="#误删行">¶</a>误删行</h2>
<p>使用 Flashback 工具通过闪回把数据恢复。<br>
Flashback 恢复数据的原理，是<strong>修改 binlog 的内容</strong>（事务里的语句顺序颠倒、语句的语义颠倒比如 insert 变成 delete），拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。</p>
<h2 id="误删库-表"><a class="header-anchor" href="#误删库-表">¶</a>误删库 / 表</h2>
<p>误删库表的情况不能使用 Flashback 恢复，因为即使配置 binlog_format=row，truncate/drop 语句在 binlog 中也只会记录一条对应的语句，而用这些信息是无法恢复数据的。<br>
这种情况下，恢复需要使用全量备份，加增量日志。这个方案要求线上有定期的全量备份，并且实时备份 binlog。</p>
<h2 id="rm-删除数据"><a class="header-anchor" href="#rm-删除数据">¶</a>rm 删除数据</h2>
<p>仅仅删除某个节点的数据的情况，HA 系统可以选出新的主库，从而保证整个集群的正常工作。<br>
之后，我们可以在这个被删节点上把数据恢复回来，再接入整个集群。</p>
<h1>中断查询</h1>
<p>有时候因为查询耗时过长，或出现死锁等待，我们不得不提早终止执行 SQL 的线程，可以通过<code>information_schema.processlist</code> 和 <code>performance_schema.threads</code>这两张表来查看正在执行的线程：</p>
<ul>
<li>processlist 表中每一行对应一个客户端连接，也对应一个线程；</li>
<li>threads 每一行对应一个线程。</li>
</ul>
<p><code>kill query pid</code>可以杀死线程，但是客户端的连接还在，可以看到被 kill 后该连接进入了 Sleep 状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Id, User, Host, db, Command, Time, State, Info</span><br><span class="line">&apos;494633&apos;, &apos;beta&apos;, &apos;192.168.19.142:56193&apos;, &apos;ds_0&apos;, &apos;Sleep&apos;, &apos;26&apos;, &apos;&apos;, NULL</span><br></pre></td></tr></table></figure>
<p><code>kill pid</code>可以中断连接，执行后再用<code>processlist</code>就找不到那个 pid 了。</p>
<p>在客户端 Ctrl + C 并不能中断服务器线程，只能中断客户端进程，</p>
<h1>大表查询</h1>
<h2 id="server-层"><a class="header-anchor" href="#server-层">¶</a>Server 层</h2>
<p>MySQL 使用缓存来保证一次性查询大量数据的情况下不会把服务器内存打满，服务器并不需要保存一个完整的结果集。取数据和发数据的流程如下：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="MySQL-查询结果发送流程" title="MySQL-查询结果发送流程"></p>
<ol>
<li>获取一行，写到 <strong>net_buffer</strong> 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。</li>
<li>重复获取行，直到 net_buffer 写满，调用网络接口发出去。</li>
<li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。</li>
<li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示**本地网络栈（socket send buffer）**写满了，进入等待。直到网络栈重新可写，再继续发送。</li>
</ol>
<p>从上面的流程可知，MySQL 一次查询占用的内存是有限的，最大是<strong>min(net_buffer_length, socket send buffer)</strong>，即不能超过 net_buffer_length 和 socket send buffer；</p>
<h2 id="存储引擎层-innodb"><a class="header-anchor" href="#存储引擎层-innodb">¶</a>存储引擎层（InnoDB）</h2>
<p>InnoDB 使用 Buffer Pool 管理内存数据页，如果 Buffer Pool 命中率足够高，那么大部分时候是不需要读磁盘的，直接从内存拿结果，可以加快查询速度。<br>
执行 <code>show engine innodb status</code> ，可以看到“<code>Buffer pool hit rate</code>”字样，显示的就是当前的命中率，一般一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。<br>
Buffer Pool 的空间是有限的，新旧页面的更替是通过 LRU 算法控制的，但 InnoDB 中的 LRU 并不是单纯的新页面替换老页面（因为这样相当于每次大查询都会把整个 Buffer Pool 都刷新一遍），而是将 LRU 链表分成了 young 区和 old 区，页面第一次被访问时会被添加到 old 区，old 区的页面如果是短期内被多次访问，则其不会被移动到链表的头部（young 区），会很快被淘汰掉。</p>
<h1>临时表</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create temporary table temp_t like t1;</span><br><span class="line">alter table temp_t add index(b);</span><br><span class="line">insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;</span><br><span class="line">select * from t1 join temp_t on (t1.b=temp_t.b);</span><br></pre></td></tr></table></figure>
<p>临时表特性：</p>
<ol>
<li>不同 session 的临时表是可以重名的，常被用在复杂查询的优化过程中，比如有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</li>
<li>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。</li>
</ol>
<h2 id="临时表的使用场景"><a class="header-anchor" href="#临时表的使用场景">¶</a>临时表的使用场景</h2>
<h3 id="union-语句"><a class="header-anchor" href="#union-语句">¶</a>union 语句</h3>
<p>表 t1 在执行前已初始化插入了 1~1000 的数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(select 1000 as f) union (select id from t1 order by id desc limit 2);</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-union%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-union执行流程" title="MySQL-union执行流程"><br>
上面语句将两个子查询的结果合并去重，union 合并时会生成临时表，这可以通过 explain 来验证。</p>
<h3 id="group-by"><a class="header-anchor" href="#group-by">¶</a>group by</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id%10 as m, count(*) as c from t1 group by m;</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-groupby%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-groupby执行流程" title="MySQL-groupby执行流程"><br>
上面语句先创建内存临时表，表里有 m 和 c 两个字段，主键是 m，扫描 t1 索引 a，将<code>id%10</code>的结果插入临时表，如果出现主键冲突则计算 c 值+1。</p>
<ol>
<li>加索引<br>
默认情况下<code>id%10</code>是无序的，所以需要先在临时表中统计排序后再返回，但是如果原表本身就是有序的，则不需要临时表、也不需要额外排序了，实际上只要引入索引就可以解决这个问题，因为<strong>索引是有序的</strong>。</li>
<li>如果不能加索引，也可以加一列 generated column<br>
MySQL5.7 支持 generated column 机制，并可以在该列上创建索引：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add column z int generated always as(id % 100), add index(z);</span><br></pre></td></tr></table></figure>
<p>上面的 group by 语句可以改成如下的形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select z, count(*) as c from t1 group by z;</span><br></pre></td></tr></table></figure>
<ol>
<li>如果不需要排序，可以显式声明忽略排序<br>
如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null</li>
<li>数据量小时使用内存临时表<br>
如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；</li>
<li>数据量大时使用磁盘临时表<br>
如果数据量较大，因为内存临时表的空间是有限的，当达到上限后就会转到磁盘内存表，与其这样转一下，不如直接使用磁盘内存表。<br>
因此，如果数据量实在太大，使用 <code>SQL_BIG_RESULT</code> 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。</li>
</ol>
<h1>Memory 引擎</h1>
<h2 id="memory-引擎与-innodb-引擎区别"><a class="header-anchor" href="#memory-引擎与-innodb-引擎区别">¶</a>Memory 引擎与 InnoDB 引擎区别</h2>
<ol>
<li>数据组织方式<br>
InnoDB 引擎采用 B+树来组织数据，主键是有序存储的。InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为<strong>索引组织表（Index Organizied Table）</strong>。<br>
Memory 引擎的数据和索引是分开的，数据以数组的方式单独存放，而主键索引是 hash 索引，存的是每个数据的位置，索引上的 key 并不是有序的：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-Memory%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%84%E7%BB%87.png" alt="MySQL-Memory引擎数据组织" title="MySQL-Memory引擎数据组织"><br>
Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为<strong>堆组织表（Heap Organizied Table）</strong>。</li>
<li>存放顺序<br>
InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li>
<li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li>
<li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；</li>
<li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li>
<li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</li>
</ol>
<h2 id="hash-索引和-b-tree-索引"><a class="header-anchor" href="#hash-索引和-b-tree-索引">¶</a>hash 索引和 B-Tree 索引</h2>
<p>内存表也支持 B-Tree 索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t1 add index a_btree_index using btree (id);</span><br></pre></td></tr></table></figure>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E5%86%85%E5%AD%98%E8%A1%A8B-Tree%E7%B4%A2%E5%BC%95.png" alt="MySQL-内存表B-Tree索引" title="MySQL-内存表B-Tree索引"><br>
可以查看以下两个语句的输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 命中索引a_btree_index，因此输出结果是有序的</span><br><span class="line">select * from t1 where id &lt; 5;</span><br><span class="line">-- 强制使用主键id索引，因此是无序的</span><br><span class="line">select * from t1 force index (primary) where id &lt; 5;</span><br></pre></td></tr></table></figure>
<h2 id="不推荐在生产环境使用-memory-引擎"><a class="header-anchor" href="#不推荐在生产环境使用-memory-引擎">¶</a>不推荐在生产环境使用 Memory 引擎</h2>
<ol>
<li>锁粒度问题<br>
内存表不支持行锁，只支持表锁，只要这张表上有更新，就会堵住所有其他在这张表上的读写操作，因此在处理并发事务时性能也不会太好。</li>
<li>数据持久化问题<br>
因为数据被存放在内存中，数据库重启时所有的内存表都会被清空。</li>
</ol>
<p>虽然一般情况下不适合使用内存表，但是还有一种情况可以考虑使用内存表：用户临时表，只是临时数据，如果数据可控，不会消耗过多内存的情况下，可以考虑使用内存表。<br>
内存临时表（通过 create temporary table 语句创建）刚好可以无视内存表的两个不足，主要是下面的三个原因：</p>
<ol>
<li>临时表不会被其他线程访问，没有并发性的问题；</li>
<li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
</ol>
<h1>备份</h1>
<ul>
<li>将数据导出成一组 insert 语句</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where=&quot;a&gt;900&quot; --result-file=/client_tmp/t.sql</span><br></pre></td></tr></table></figure>
<p>恢复：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source /client_tmp/t.sql&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>导出 CSV 文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from db1.t where a&gt;900 into outfile &apos;/server_tmp/t.csv&apos;;</span><br></pre></td></tr></table></figure>
<p>恢复，将数据导入到目标表 db2.t 中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &apos;/server_tmp/t.csv&apos; into table db2.t;</span><br></pre></td></tr></table></figure>
<ul>
<li>物理拷贝<br>
不能通过直接拷贝表的.frm 文件和.ibd 文件来实现物理拷贝，因为一个 InnoDB 表除了包含这两个物理文件外，还需要在数据字典中注册，直接拷贝的情况下系统不会识别。<br>
在 MySQL 5.6 版本引入了<strong>可传输表空间(transportable tablespace)</strong> 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。
<ol>
<li>执行 create table r like t，创建一个相同表结构的空表；</li>
<li>执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；</li>
<li>执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；</li>
<li>在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；</li>
<li>这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；</li>
<li>执行 unlock tables，这时候 t.cfg 文件会被删除；</li>
<li>执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。</li>
</ol>
</li>
</ul>
<p>这三种方法各有优劣：</p>
<ol>
<li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
<ul>
<li>必须是全表拷贝，不能只拷贝部分数据；</li>
<li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；……</li>
<li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li>
</ul>
</li>
<li>用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。</li>
<li>用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</li>
</ol>
<h1>MySQL 中的自增 ID</h1>
<h2 id="表的自增-id"><a class="header-anchor" href="#表的自增-id">¶</a>表的自增 id</h2>
<p>我们经常给表的主键加上自增属性，用于唯一标识一条记录，但是因为自增值达到上限后再申请得到的值不变，因此自增字段的范围应该略大一些，尽可能创建成<code>bigint unsigned</code>。</p>
<h2 id="row-id"><a class="header-anchor" href="#row-id">¶</a>row_id</h2>
<p>如果没有指定主键，InnoDB 会创建一个不可见的、长度为 6 字节的 row_id，超过上限后再申请时会得到 0，<strong>如果新写入的行的 row_id 在表中已存在，则会直接覆盖原有的行</strong>，因此，最好优先使用自增 ID 而不是 row_id。</p>
<h2 id="xid"><a class="header-anchor" href="#xid">¶</a>Xid</h2>
<p>Xid 用于唯一标识一个事务。Xid 的值由一个内存变量 global_query_id 给出，重启后清零，但是因为每次重启时 binlog 都会重新生成，所以 binlog 中的 Xid 也不会重复。global_query_id 的长度为 8 个字节，除非 MySQL 实例一直执行了<code>2^64 - 1</code>次查询且期间没有重启，不然不会出现 Xid 重复的情况。</p>
<h2 id="max-trx-id"><a class="header-anchor" href="#max-trx-id">¶</a>max_trx_id</h2>
<p>Xid 由 server 层维护。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。<br>
InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。</p>
<blockquote>
<p>InnoDB 事务在读操作时不会申请 trx_id，trx_id 的值就是 0，只有在加锁或执行写操作时才会申请。<br>
只读事务不申请 trx_id 的原因是只读事务不影响事务的可见性判断，且能减少 trx_id 的申请次数、减少并发事务申请 trx_id 的锁冲突。</p>
</blockquote>
<p>MVCC 判断数据可见性的核心思想：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。</p>
<h2 id="thread-id"><a class="header-anchor" href="#thread-id">¶</a>thread_id</h2>
<p>系统保存一个全局变量 thread_id_counter，每新建一个连接就将 thread_id_counter 赋值给这个新连接的线程变量。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f2150593.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f2150593.html" itemprop="url">Netty 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-29T10:18:28+08:00">
                2020-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Netty/" itemprop="url" rel="index">
                    <span itemprop="name">Netty</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  30 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>为什么使用 Netty</h1>
<ol>
<li>实现协议的局限性<br>
今天，我们使用通用的应用程序或者类库来实现互相通讯，比如，我们经常使用一个 HTTP 客户端库来从 web 服务器上获取信息，或者通过 web 服务来执行一个远程的调用。<br>
然而，有时候一个通用的协议或他的实现并没有很好的满足需求。比如我们无法使用一个通用的 HTTP 服务器来处理大文件、电子邮件以及近实时消息，比如金融信息和多人游戏数据。我们需要一个高度优化的协议来处理一些特殊的场景。例如你可能想实现一个优化了的 Ajax 的聊天应用、媒体流传输或者是大文件传输器，你甚至可以自己设计和实现一个全新的协议来准确地实现你的需求。<br>
另一个不可避免的情况是当你不得不处理遗留的专有协议来确保与旧系统的互操作性。在这种情况下，重要的是我们如何才能快速实现协议而不牺牲应用的稳定性和性能。</li>
<li>使用 Netty 可以有效改善这种情况<br>
Netty 是一个提供 asynchronous event-driven （异步事件驱动）的网络应用框架，是一个用以快速开发高性能、高可靠性协议的服务器和客户端。<br>
换句话说，Netty 是一个 NIO 客户端服务器框架，使用它可以快速简单地开发网络应用程序，比如服务器和客户端的协议。Netty 大大简化了网络程序的开发过程比如 TCP 和 UDP 的 socket 服务的开发。<br>
“快速和简单”并不意味着应用程序会有难维护和性能低的问题，Netty 是一个精心设计的框架，它从许多协议的实现中吸收了很多的经验比如 FTP、SMTP、HTTP、许多二进制和基于文本的传统协议.因此，Netty 已经成功地找到一个方式,在不失灵活性的前提下来实现开发的简易性，高性能，稳定性。<br>
有一些用户可能已经发现其他的一些网络框架也声称自己有同样的优势，所以你可能会问是 Netty 和它们的不同之处。答案就是 Netty 的哲学设计理念。Netty 从开始就为用户提供了用户体验最好的 API 以及实现设计。正是因为 Netty 的哲学设计理念，才让您得以轻松地阅读本指南并使用 Netty。</li>
</ol>
<h1>架构总览</h1>
<p><img src="https://tallate.top/imgs/Netty/Netty%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88.png" alt="Netty架构总览" title="Netty架构总览"><br>
Netty 的架构由三部分组成——缓冲（buffer），通道（channel），事件模型（event model）——所有的高级特性都构建在这三个核心组件之上。</p>
<h2 id="nio"><a class="header-anchor" href="#nio">¶</a>NIO</h2>
<ol>
<li><a href="https://segmentfault.com/q/1010000010446129" target="_blank" rel="noopener">想了解 Aio 与 Nio 的利弊，为什么 Netty 没有采用 Aio 实现？</a></li>
</ol>
<p>NIO 基于传输层，可以自定义数据处理逻辑来作为应用层，或者基于现有的 HTTP 组件进行升级，在线上环境这样的升级会带来一些兼容性问题，HTTP 已有相应的协议升级机制：<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism" target="_blank" rel="noopener">Protocol upgrade mechanism</a>。</p>
<p>NIO 相对 BIO 优势：</p>
<ol>
<li>零拷贝<br>
零拷贝减少线程上下文切换次数，且数据直接拷贝到内核空间，不占用 JVM 堆空间；</li>
<li>减少线程资源浪费<br>
NIO 可以一个线程监听多个 Socket 的连接、读、写请求，而不是像 BIO 那样每个 Socket 创建一个线程，但是同时会有一个问题：</li>
</ol>
<h2 id="netty-核心组件"><a class="header-anchor" href="#netty-核心组件">¶</a>Netty 核心组件</h2>
<ol>
<li>Channel 和 ChannelHandler</li>
<li>ByteBuf</li>
<li>Pipeline</li>
</ol>
<h1>服务端</h1>
<p><img src="https://tallate.top/imgs/Netty/Netty%E6%B5%81%E7%A8%8B.png" alt="Netty流程" title="Netty流程"></p>
<h2 id="代码"><a class="header-anchor" href="#代码">¶</a>代码</h2>
<p>下面是一个启动Netty服务端的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">ServerBootstrap bootstrap = new ServerBootstrap();</span><br><span class="line">        bootstrap.group(bossGroup(), workerGroup())</span><br><span class="line">                .channel(NioServerSocketChannel.class)</span><br><span class="line">                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                    @Override</span><br><span class="line">                    protected void initChannel(SocketChannel ch) throws Exception &#123;</span><br><span class="line">                        // 空闲检测</span><br><span class="line">                        ch.pipeline().addLast(&quot;idleStateHandler&quot;, new IdleStateHandler(15, 0, 0,</span><br><span class="line">                                TimeUnit.MINUTES));</span><br><span class="line"></span><br><span class="line">                        // 半包/粘包分解器</span><br><span class="line">                        ch.pipeline().addLast(</span><br><span class="line">                                new DelimiterBasedFrameDecoder(2048, true, getFirstBytes()</span><br><span class="line">                                ));</span><br><span class="line">                        ch.pipeline().addLast(其他Handler比如解码之类的);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).option(ChannelOption.SO_BACKLOG, 1024);</span><br><span class="line">bootstrap.bind(10885).sync()</span><br></pre></td></tr></table></figure>
<h2 id="创建eventloop"><a class="header-anchor" href="#创建eventloop">¶</a>创建EventLoop</h2>
<p>在上面的代码中，出现了<strong>bossGroup</strong>和<strong>workerGroup</strong>，bossGroup主要负责监听连接，拿到连接后，交给workerGroup中的线程来监听读或写事件。<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup</code><br>
<code>EventExecutorGroup</code>会给每个线程创建一个<code>EventLoop</code>。</p>
<p><code>io.netty.channel.nio.NioEventLoop#NioEventLoop</code><br>
<code>newChild()</code>创建EventLoop实例，其默认实现是<code>NioEventLoop</code>。</p>
<p><code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code><br>
服务器初始化过程中创建了个线程池<code>ThreadPerTaskExecutor</code>：</p>
<ul>
<li>每次执行任务都会构造一个线程执行<br>
<code>io.netty.util.concurrent.ThreadPerTaskExecutor#execute</code></li>
</ul>
<h2 id="创建及初始化-serversocketchannel"><a class="header-anchor" href="#创建及初始化-serversocketchannel">¶</a>创建及初始化 ServerSocketChannel</h2>
<p>Netty 有一个叫做 <strong>Channel</strong> 的统一的异步 I/O 编程接口，这个编程接口抽象了所有点对点的通信操作。也就是说，如果你的应用是基于 Netty 的某一种传输实现，那么同样的，你的应用也可以运行在 Netty 的另一种传输实现上。Netty 提供了几种拥有相同编程接口的基本传输实现：</p>
<ul>
<li>基于 NIO 的 TCP/IP 传输 (见 io.netty.channel.nio),</li>
<li>基于 OIO 的 TCP/IP 传输 (见 io.netty.channel.oio),</li>
<li>基于 OIO 的 UDP/IP 传输, 和</li>
<li>本地传输 (见 io.netty.channel.local).</li>
</ul>
<p>切换不同的传输实现通常只需对代码进行几行的修改调整，例如选择一个不同的 <strong>ChannelFactory</strong> 实现。<br>
此外，你甚至可以利用新的传输实现没有写入的优势，只需替换一些构造器的调用方法即可，例如串口通信。而且由于核心 API 具有高度的可扩展性，你还可以完成自己的传输实现。</p>
<ol>
<li>入口<br>
<code>io.netty.bootstrap.AbstractBootstrap#bind(int)</code><br>
用户代码调用bind绑定端口时会触发Channel的创建和初始化</li>
</ol>
<p><code>io.netty.bootstrap.ServerBootstrap#init</code><br>
对Channel的使用可以追溯到这个init方法，包括Channel的创建、属性等的设置。</p>
<ol>
<li>
<p>创建<br>
<code>NioServerSocketChannel</code>的构造方法 -&gt; <code>io.netty.channel.socket.nio.NioServerSocketChannel#newSocket</code><br>
可以看到，Netty中的<code>ServerSocketChannel</code>其实就对应JDK NIO中的<code>ServerSocketChannel</code>，在创建<code>NioServerSocketChannel</code>的同时创建了一个NIO中的<code>ServerSocketChannel</code>。</p>
</li>
<li>
<p>初始化<br>
中间包含对<code>childOptions</code>和<code>childAttrs</code>等的设置。</p>
</li>
<li>
<p>添加一个连接处理器<code>ServerBootstrapAcceptor</code>。</p>
</li>
</ol>
<h2 id="注册selector"><a class="header-anchor" href="#注册selector">¶</a>注册Selector</h2>
<p>紧接着上面的初始化过程，接下来是注册NIO中的Selector。<br>
<code>io.netty.channel.EventLoopGroup#register(io.netty.channel.Channel)</code><br>
总而言之最终还是使用NIO注册了 Selector。<br>
<code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
<h3 id="启动-nioeventloop"><a class="header-anchor" href="#启动-nioeventloop">¶</a>启动 NioEventLoop</h3>
<p><code>io.netty.bootstrap.AbstractBootstrap#doBind0</code><br>
绑定端口号的同时，执行一个线程。<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#startThread</code><br>
NioEventLoop启动流程的最终启动了一个线程。<br>
<code>io.netty.channel.nio.NioEventLoop#run</code><br>
该线程任务根据EventLoop的实现不同而有所不同，在<code>NioEventLoop</code>中，主要任务为以下3步：</p>
<ol>
<li>
<p>接收事件（selectionKey）<br>
<code>io.netty.channel.nio.NioEventLoop#select</code><br>
当检查没有需要处理的selectionKey时就会发生空轮询，Netty在轮询时会记录空轮询次数，<strong>当空轮询达到一定次数时，将之前注册的事件先取消，从而避免了NIO的空轮询Bug</strong>。</p>
</li>
<li>
<p>检测新连接并创建NioSocketChannel<br>
<code>io.netty.channel.nio.NioEventLoop#processSelectedKeys</code><br>
处理连接请求，并分发请求到<strong>pipeline</strong><br>
<code>io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe#read</code></p>
<ul>
<li>每个连接创建一个<strong>ServerSocketChannel</strong>。<br>
<code>io.netty.channel.socket.nio.NioServerSocketChannel#doReadMessages</code></li>
<li>读取数据并分发到<strong>pipeline</strong><br>
<code>io.netty.channel.ChannelPipeline#fireChannelReadComplete</code></li>
</ul>
</li>
<li>
<p>执行线程任务<br>
<code>io.netty.util.concurrent.SingleThreadEventExecutor#runAllTasks(long)</code></p>
</li>
</ol>
<h2 id="pipeline中的第一个channelhandler"><a class="header-anchor" href="#pipeline中的第一个channelhandler">¶</a>pipeline中的第一个ChannelHandler</h2>
<p>pipeline的第一个Handler为<code>ServerBootstrapAcceptor</code>，它的主要任务包括：</p>
<ol>
<li>
<p>将用户自定义<code>ChannelHandler</code>添加到pipeline</p>
</li>
<li>
<p>选择一个<code>NioEventLoop</code>传播事件<br>
<code>io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel)</code></p>
</li>
<li>
<p>注册selector<br>
代码流程非常长，但是最终可以跟到<code>doRegister</code>这个方法，可以发现最后还是调用了JDK的SocketChannel注册Selector。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code> -&gt; <code>io.netty.channel.nio.AbstractNioChannel#doRegister</code></p>
</li>
<li>
<p>注册读事件<br>
代码最后判断第一次连接则触发连接激活事件，代码位置仍然是上边的<code>register0</code>。<br>
<code>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</code><br>
继续往下看可以看到最终将读事件（selectionKey）注册到了Selector<br>
<code>io.netty.channel.DefaultChannelPipeline.HeadContext#channelActive</code><br>
-&gt; <code>io.netty.channel.DefaultChannelPipeline.HeadContext#readIfIsAutoRead</code><br>
-&gt; <code>io.netty.channel.nio.AbstractNioChannel#doBeginRead</code></p>
</li>
</ol>
<p>选择EventLoop：<br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#chooser</code><br>
每当有客户端连接进来时，Netty需要决定选择哪个EventLoop，这个工作是由<code>EventExecutorChooser</code>负责的：</p>
<ul>
<li><code>GenericEventExecutorChooser</code>：循环选择。</li>
<li><code>PowerOfTwoEventExecutorChooser</code>：也是循环选择，只不过<code>GenericEventExecutorChooser</code>使用了取模运算，而<code>PowerOfTwoEventExecutorChooser</code>是通过位运算实现的。</li>
</ul>
<h2 id="pipeline"><a class="header-anchor" href="#pipeline">¶</a>Pipeline</h2>
<ol>
<li>
<p>创建Pipeline<br>
创建NioSocketChannel时会创建Pipeline：<br>
<code>io.netty.channel.AbstractChannel#AbstractChannel</code><br>
Pipeline本身是一个<strong>双向链表</strong>的结构，且有两个哨兵节点<code>head</code>和<code>tail</code>。</p>
</li>
<li>
<p>添加Pipeline<br>
添加到链表<br>
<code>io.netty.channel.ChannelPipeline#addLast(io.netty.channel.ChannelHandler...)</code><br>
检查是否重复添加，如果加了<code>@Sharable</code>注解是可以重复添加的<br>
<code>io.netty.channel.DefaultChannelPipeline#checkMultiplicity</code><br>
添加到链表末尾，也就是添加到<code>tail</code>节点的前面。<br>
<code>io.netty.channel.DefaultChannelPipeline#addLast0</code></p>
</li>
<li>
<p>删除Pipeline<br>
有时候我们需要删除一个Pipeline上的某些ChannelHandler，比如已经进行过了授权校验，那下次就不需要再执行授权校验了，我们就可以直接把授权相关的那些ChannelHandler删除掉。<br>
首先遍历Pipeline找到目标ChannelHandler。<br>
<code>io.netty.channel.DefaultChannelPipeline#getContextOrDie</code><br>
然后从Pipeline中移除。<br>
<code>io.netty.channel.DefaultChannelPipeline#remove(AbstractChannelHandlerContext)</code></p>
</li>
<li>
<p>inBound事件传播<br>
ChannelHandler中每个事件都有一个接口，<code>ChannelInboundHandler</code>专门处理输入事件，以<code>channelRead</code>为例。<br>
EventLoop会将读事件传给Pipeline，然后按责任链模式的逻辑从<code>head</code>节点开始传播事件。<br>
<code>io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read</code></p>
</li>
<li>
<p>outBound事件传播<br>
<code>ChannelOutboundHandler</code>专门用于处理输出事件，以<code>write</code>为例。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class EchoServerOutHandler extends ChannelOutboundHandlerAdapter &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123;</span><br><span class="line">        ctx.channel().write(&quot;Hello&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们在Handler中调用Context的write方法时，就是将写事件传给了Pipeline，Pipeline会从<code>tail</code>节点开始往前传播。<br>
<code>io.netty.channel.AbstractChannelHandlerContext#write</code></p>
<h2 id="心跳检测"><a class="header-anchor" href="#心跳检测">¶</a>心跳检测</h2>
<p>应用协议层的心跳是必须的，它和 tcp keepalive 是完全不同的概念。应用层协议层的心跳检测的是连接双方的存活性，兼而连接质量，而 keepalive 检测的是连接本身的存活性。而且后者的超时时间默认过长，完全不能适应现代的网络环境。<br>
Netty 内置通过增加 <code>IdleStateHandler</code> 产生 IDLE 事件进行便捷的心跳控制。你要处理的，就是心跳超时的逻辑，比如延迟重连。但它的轮训时间是固定的，无法动态修改，高级功能需要自己定制。<br>
不同场景下需要切换不同的保活机制，在一些客户端比如 Android，频繁心跳的唤起会浪费大量的网络和电量，它的心跳策略会更加复杂一些。</p>
<h2 id="优雅退出"><a class="header-anchor" href="#优雅退出">¶</a>优雅退出</h2>
<p>Java 的优雅停机通常通过注册 JDK ShutdownHook 来实现。<br>
Runtime.getRuntime().addShutdownHook();<br>
一般通过 kill -15 进行 java 进程的关闭，以便在进程死亡之前进行一些清理工作。</p>
<blockquote>
<p>注意：kill -9 会立马杀死进程，不给遗言的机会，比较危险。</p>
</blockquote>
<p>虽然 netty 做了很多优雅退出的工作，通过 EventLoopGroup 的 shutdownGracefully 方法对 nio 进行了一些状态设置，但在很多情况下，这还不够多。它只负责单机环境的优雅关闭。<br>
流量可能还会通过外层的路由持续进入，造成无效请求。一种可行的做法是首先在外层路由进行一次本地实例的摘除，把流量截断，然后再进行 netty 本身的优雅关闭。</p>
<h2 id="示例协议实现"><a class="header-anchor" href="#示例协议实现">¶</a>示例协议实现</h2>
<p>不少中间件会实现自己的协议，比如 Redis、MySQL，MyCat、TiDB 用的就是 MySQL 协议。<br>
netty 默认实现了 dns、haproxy、http、http2、memcache、mqtt、redis、smtp、socks、stomp、xml 等协议。<br>
协议分为两种：</p>
<ul>
<li>文本协议在调试起来是比较直观和容易的，但安全性欠佳；</li>
<li>二进制协议就需要依赖日志、wireshark 等其他方式进行分析，增加了开发难度。</li>
</ul>
<ol>
<li><a href="https://netty.io/4.0/xref/io/netty/example/echo/package-summary.html" target="_blank" rel="noopener">示例协议 - echo</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/discard/package-summary.html" target="_blank" rel="noopener">示例协议 - discard</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/uptime/package-summary.html" target="_blank" rel="noopener">示例协议 - uptime</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/factorial/package-summary.html" target="_blank" rel="noopener">示例二进制协议 - factorial</a></li>
<li><a href="https://netty.io/4.0/xref/io/netty/example/telnet/package-summary.html" target="_blank" rel="noopener">示例文本协议 - telnet</a></li>
</ol>
<h1>数据结构 - ByteBuf</h1>
<p>Netty 使用自建的 buffer API，而不是使用 NIO 的 <a href="http://docs.oracle.com/javase/7/docs/api/java/nio/ByteBuffer.html?is-external=true" target="_blank" rel="noopener">ByteBuffer</a> 来表示一个连续的字节序列。与 ByteBuffer 相比这种方式拥有明显的优势。Netty 使用新的 buffer 类型 <a href="http://netty.io/4.0/api/io/netty/buffer/ByteBuf.html" target="_blank" rel="noopener">ByteBuf</a>，被设计为一个可从底层解决 ByteBuffer 问题，并可满足日常网络应用开发需要的缓冲类型。这些很酷的特性包括：</p>
<ul>
<li>如果需要，允许使用自定义的缓冲类型。</li>
<li>复合缓冲类型中内置的透明的零拷贝实现。</li>
<li>开箱即用的动态缓冲类型，具有像 StringBuffer 一样的动态缓冲能力。</li>
<li>不再需要调用的 flip()方法。</li>
<li>正常情况下具有比 ByteBuffer 更快的响应速度。</li>
</ul>
<p><img src="https://tallate.top/imgs/Netty/ByteBuf%E7%BB%93%E6%9E%84.png" alt="ByteBuf结构" title="ByteBuf结构"><br>
以上就是一个 ByteBuf 的结构图，从上面这幅图可以看到</p>
<ol>
<li>ByteBuf 是一个字节容器，容器里面的的数据分为三个部分，第一个部分是已经丢弃的字节，这部分数据是无效的；第二部分是可读字节，这部分数据是 ByteBuf 的主体数据， 从 ByteBuf 里面读取的数据都来自这一部分;最后一部分的数据是可写字节，所有写到 ByteBuf 的数据都会写到这一段。最后一部分虚线表示的是该 ByteBuf 最多还能扩容多少容量</li>
<li>以上三段内容是被两个指针给划分出来的，从左到右，依次是读指针（readerIndex）、写指针（writerIndex），然后还有一个变量 capacity，表示 ByteBuf 底层内存的总容量</li>
<li>从 ByteBuf 中每读取一个字节，readerIndex 自增 1，ByteBuf 里面总共有 writerIndex-readerIndex 个字节可读, 由此可以推论出当 readerIndex 与 writerIndex 相等的时候，ByteBuf 不可读</li>
<li>写数据是从 writerIndex 指向的部分开始写，每写一个字节，writerIndex 自增 1，直到增到 capacity，这个时候，表示 ByteBuf 已经不可写了</li>
<li>ByteBuf 里面其实还有一个参数 maxCapacity，当向 ByteBuf 写数据的时候，如果容量不足，那么这个时候可以进行扩容，直到 capacity 扩容到 maxCapacity，超过 maxCapacity 就会报错</li>
</ol>
<p>使用 ByteBuf 有以下好处：</p>
<ol>
<li>
<p>可以有效地区分可读数据和可写数据，读写之间相互没有冲突</p>
</li>
<li>
<p>Extensibility 可扩展性<br>
ByteBuf 具有丰富的操作集,可以快速的实现协议的优化。例如，ByteBuf 提供各种操作用于访问无符号值和字符串，以及在缓冲区搜索一定的字节序列。你也可以扩展或包装现有的缓冲类型用来提供方便的访问。自定义缓冲式仍然实现自 ByteBuf 接口，而不是引入一个不兼容的类型</p>
</li>
<li>
<p>Transparent Zero Copy 透明的零拷贝<br>
网络应用中需要减少内存拷贝操作次数。你可能有一组缓冲区可以被组合以形成一个完整的消息。网络提供了一种复合缓冲，允许你从现有的任意数的缓冲区创建一个新的缓冲区而无需内存拷贝。例如，一个信息可以由两部分组成：header 和 body。在一个模块化的应用，当消息发送出去时，这两部分可以由不同的模块生产和装配。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+--------+------+</span><br><span class="line">| header | body |</span><br><span class="line">+--------+------+</span><br></pre></td></tr></table></figure>
<p>如果你使用的是 ByteBuffer ，你必须要创建一个新的大缓存区用来拷贝这两部分到这个新缓存区中。或者，你可以在 NIO做一个收集写操作，但限制你将复合缓冲类型作为 ByteBuffer 的数组而不是一个单一的缓冲区，这样打破了抽象，并且引入了复杂的状态管理。此外，如果你不从 NIO channel 读或写，它是没有用的。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型不兼容。</span><br><span class="line">ByteBuffer[] message = new ByteBuffer[] &#123; header, body &#125;;</span><br></pre></td></tr></table></figure>
<p>通过对比， ByteBuf 不会有警告，因为它是完全可扩展并有一个内置的复合缓冲区。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 复合类型与组件类型是兼容的。</span><br><span class="line">ByteBuf message = Unpooled.wrappedBuffer(header, body);</span><br><span class="line">// 因此，你甚至可以通过混合复合类型与普通缓冲区来创建一个复合类型。</span><br><span class="line">ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer);</span><br><span class="line">// 由于复合类型仍是 ByteBuf，访问其内容很容易，</span><br><span class="line">//并且访问方法的行为就像是访问一个单独的缓冲区，</span><br><span class="line">//即使你想访问的区域是跨多个组件。</span><br><span class="line">//这里的无符号整数读取位于 body 和 footer</span><br><span class="line">messageWithFooter.getUnsignedInt(</span><br><span class="line">     messageWithFooter.readableBytes() - footer.readableBytes() - 1);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Automatic Capacity Extension 自动容量扩展<br>
许多协议定义可变长度的消息，这意味着没有办法确定消息的长度，直到你构建的消息。或者，在计算长度的精确值时，带来了困难和不便。这就像当你建立一个字符串。你经常估计得到的字符串的长度，让 StringBuffer 扩大了其本身的需求。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 一种新的动态缓冲区被创建。在内部，实际缓冲区是被“懒”创建，从而避免潜在的浪费内存空间。</span><br><span class="line">ByteBuf b = Unpooled.buffer(4);</span><br><span class="line">// 当第一个执行写尝试，内部指定初始容量 4 的缓冲区被创建</span><br><span class="line">b.writeByte(&apos;1&apos;);</span><br><span class="line">b.writeByte(&apos;2&apos;);</span><br><span class="line">b.writeByte(&apos;3&apos;);</span><br><span class="line">b.writeByte(&apos;4&apos;);</span><br><span class="line">// 当写入的字节数超过初始容量 4 时，</span><br><span class="line">//内部缓冲区自动分配具有较大的容量</span><br><span class="line">b.writeByte(&apos;5&apos;);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Better Performance 更好的性能<br>
最频繁使用的缓冲区 ByteBuf 的实现是一个非常薄的字节数组包装器（比如，一个字节）。与 ByteBuffer 不同，它没有复杂的边界和索引检查补偿，因此对于 JVM 优化缓冲区的访问更加简单。更多复杂的缓冲区实现是用于拆分或者组合缓存，并且比 ByteBuffer 拥有更好的性能。</p>
</li>
</ol>
<h2 id="粘包拆包和半包合并"><a class="header-anchor" href="#粘包拆包和半包合并">¶</a>粘包拆包和半包合并</h2>
<p>基于流的传输比如 TCP/IP, 接收到数据是存在 socket 接收的 buffer 中。不幸的是，基于流的传输并不是一个数据包队列，而是一个字节队列。造成粘包的原因，主要是由于缓冲区的介入，所以需要严格约定去所传输的包的格式——何时开始何时结束。意味着，即使你发送了 2 个独立的数据包，操作系统也不会作为 2 个消息处理而仅仅是作为一连串的字节而言。因此这是不能保证你远程写入的数据就会准确地读取。举个例子，让我们假设操作系统的 TCP/TP 协议栈已经接收了 3 个数据包，在应用程序中读取数据的时候可能被分成下面的片段：<br>
<img src="https://tallate.top/imgs/Netty/%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85%E9%97%AE%E9%A2%98.png" alt="粘包和半包问题" title="粘包和半包问题"><br>
因此，一个接收方不管他是客户端还是服务端，都应该把接收到的数据整理成一个或者多个更有意义并且能够让程序的业务逻辑更好理解的数据。<br>
在没有 Netty 的情况下，用户如果自己需要拆包，基本原理就是不断从 TCP 缓冲区中读取数据，每次读取完都需要判断是否是一个完整的数据包</p>
<ul>
<li>半包：如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。</li>
<li>粘包：如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。</li>
</ul>
<h2 id="解码器-bytetomessagedecoder"><a class="header-anchor" href="#解码器-bytetomessagedecoder">¶</a>解码器 - ByteToMessageDecoder</h2>
<p>入口：<code>io.netty.handler.codec.ByteToMessageDecoder#channelRead</code></p>
<ol>
<li>累加字节流<br>
累加器累加已读入的字节数，如果超过<code>ByteBuf</code>当前可读入的空间大小，则执行扩容。<br>
<code>io.netty.handler.codec.ByteToMessageDecoder.Cumulator#cumulate</code></li>
<li>调用子类的decode方法进行解析（模板方法）<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#callDecode</code></li>
<li>将子类解析出的ByteBuf向下传播<br>
<code>io.netty.handler.codec.ByteToMessageDecoder#fireChannelRead(io.netty.channel.ChannelHandlerContext, io.netty.handler.codec.CodecOutputList, int)</code></li>
</ol>
<h2 id="netty中的一些拆箱即用的解码器"><a class="header-anchor" href="#netty中的一些拆箱即用的解码器">¶</a>Netty中的一些拆箱即用的解码器</h2>
<p>如果要自己实现所有协议的拆包无疑是非常麻烦的，实际上 Netty 已经自带了一些开箱即用的拆包器：</p>
<ol>
<li>固定长度的拆包器 <code>FixedLengthFrameDecoder</code><br>
如果你的应用层协议非常简单，每个数据包的长度都是固定的，比如 100，那么只需要把这个拆包器加到 pipeline 中，Netty 会把一个个长度为 100 的数据包 (ByteBuf) 传递到下一个 channelHandler。</li>
<li>行拆包器 <code>LineBasedFrameDecoder</code><br>
从字面意思来看，发送端发送数据包的时候，每个数据包之间以<strong>换行符</strong>作为分隔，接收端通过 LineBasedFrameDecoder 将粘过的 ByteBuf 拆分成一个个完整的应用层数据包。</li>
<li>分隔符拆包器 <code>DelimiterBasedFrameDecoder</code><br>
DelimiterBasedFrameDecoder 是行拆包器的通用版本，只不过我们可以自定义分隔符。</li>
<li>基于长度域拆包器 <code>LengthFieldBasedFrameDecoder</code><br>
最后一种拆包器是最通用的一种拆包器，只要你的自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包。由于上面三种拆包器比较简单，读者可以自行写出 demo，接下来，我们就结合我们小册的自定义协议，来学习一下如何使用基于长度域的拆包器来拆解我们的数据包。</li>
</ol>
<h2 id="编码-messagetobyteencoder"><a class="header-anchor" href="#编码-messagetobyteencoder">¶</a>编码 - MessageToByteEncoder</h2>
<p>编码器是一个ChannelHandler，一般是第一个添加到Pipeline内，然后write的最后会将数据进行编码再输出。</p>
<ol>
<li>匹配对象<br>
<code>io.netty.handler.codec.MessageToByteEncoder#acceptOutboundMessage</code></li>
<li>内存分配<br>
<code>io.netty.handler.codec.MessageToByteEncoder#allocateBuffer</code></li>
<li>调用子类的编码实现<br>
<code>io.netty.handler.codec.MessageToByteEncoder#encode</code></li>
<li>释放内存<br>
<code>io.netty.util.ReferenceCountUtil#release(java.lang.Object)</code></li>
<li>放到Pipeline里传播<br>
默认情况下会一直传播到<code>head</code>节点<br>
<code>io.netty.channel.ChannelHandlerContext#write(java.lang.Object, io.netty.channel.ChannelPromise)</code><br>
<code>io.netty.channel.Channel.Unsafe#write</code></li>
<li>输出<br>
将数据暂存到ByteBuf，将堆内对象转换为堆外内存<br>
<code>io.netty.channel.nio.AbstractNioByteChannel#filterOutboundMessage</code><br>
插入写队列<br>
<code>io.netty.channel.ChannelOutboundBuffer#addMessage</code><br>
TODO: 什么时候刷新buffer队列？</li>
</ol>
<h1>自定义数据处理逻辑</h1>
<h2 id="基于拦截链模式的事件模型-pipeline"><a class="header-anchor" href="#基于拦截链模式的事件模型-pipeline">¶</a>基于拦截链模式的事件模型 - pipeline</h2>
<p>一个定义良好并具有扩展能力的事件模型是事件驱动开发的必要条件。Netty 具有定义良好的 I/O 事件模型。由于严格的层次结构区分了不同的事件类型，因此 Netty 也允许你在不破坏现有代码的情况下实现自己的事件类型。这是与其他框架相比另一个不同的地方。很多 NIO 框架没有或者仅有有限的事件模型概念；在你试图添加一个新的事件类型的时候常常需要修改已有的代码，或者根本就不允许你进行这种扩展。<br>
在 Netty 中一条连接对应一个 Channel，该 Channel 的所有处理逻辑都在一个 ChannelPipeline 对象内，ChannelPipeline 是一个双向链表结构，在一个 ChannelPipeline 内部一个 <a href="../%E6%8A%80%E6%9C%AF%E7%82%B9%E6%80%BB%E7%BB%93">ChannelEvent</a> 被一组 ChannelHandler 处理。这个管道是 Intercepting Filter (拦截过滤器)模式的一种高级形式的实现，因此对于一个事件如何被处理以及管道内部处理器间的交互过程，你都将拥有绝对的控制力。例如，你可以定义一个从 socket 读取到数据后的操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyReadHandler implements SimpleChannelHandler &#123;</span><br><span class="line">     public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">         Object message = evt.getMessage();</span><br><span class="line">         // Do something with the received message.</span><br><span class="line">            ...</span><br><span class="line">         // And forward the event to the next handler.</span><br><span class="line">         ctx.sendUpstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时你也可以定义一种操作响应其他处理器的写操作请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class MyWriteHandler implements SimpleChannelHandler &#123;</span><br><span class="line">    public void writeRequested(ChannelHandlerContext ctx, MessageEvent evt) &#123;</span><br><span class="line">        Object message = evt.getMessage();</span><br><span class="line">        // Do something with the message to be written.</span><br><span class="line">            ...</span><br><span class="line">        // And forward the event to the next handler.</span><br><span class="line">        ctx.sendDownstream(evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ChannelHandler 分为两种：</p>
<ul>
<li>ChannelInboundHandler<br>
处理读数据逻辑，核心方法是 channelRead。</li>
<li>ChannelOutBoundHandler<br>
处理些数据逻辑，核心方法是 write，在链式处理中总是位于 ChannelInboundHandler 之后。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">serverBootstrap</span><br><span class="line">        .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">            protected void initChannel(NioSocketChannel ch) &#123;</span><br><span class="line">                // inBound，处理读数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new InBoundHandlerC());</span><br><span class="line">                </span><br><span class="line">                // outBound，处理写数据的逻辑链</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerA());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerB());</span><br><span class="line">                ch.pipeline().addLast(new OutBoundHandlerC());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>
<p>其执行顺序如下图所示：<br>
<img src="https://tallate.top/imgs/Netty/pipeline%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.png" alt="pipeline执行顺序" title="pipeline执行顺序"></p>
<h2 id="异常处理"><a class="header-anchor" href="#异常处理">¶</a>异常处理</h2>
<p>netty 由于其异步化的开发方式，以及其事件机制，在异常处理方面就显得异常重要。为了保证连接的高可靠性，许多异常需要静悄悄的忽略，或者在用户态没有感知。<br>
netty 的异常会通过 pipeline 进行传播，所以在任何一层进行处理都是可行的，但编程习惯上，习惯性抛到最外层集中处理。<br>
为了最大限度的区别异常信息，通常会定义大量的异常类，不同的错误会抛出不同的异常。发生异常后，可以根据不同的类型选择断线重连（比如一些二进制协议的编解码紊乱问题)，或者调度到其他节点。</p>
<h2 id="codec-框架"><a class="header-anchor" href="#codec-框架">¶</a>Codec 框架</h2>
<p>我们可以使用 POJO 代替 ChannelBuffer，从业务逻辑代码中分离协议处理部分总是一个很不错的想法。然而如果一切从零开始便会遭遇到实现上的复杂性。你不得不处理分段的消息。一些协议是多层的（例如构建在其他低层协议之上的协议）。一些协议过于复杂以致难以在一台独立状态机上实现。<br>
因此，一个好的网络应用框架应该提供一种可扩展，可重用，可单元测试并且是多层的 codec 框架，为用户提供易维护的 codec 代码。<br>
Netty 提供了一组构建在其核心模块之上的 codec 实现，这些简单的或者高级的 codec 实现帮你解决了大部分在你进行协议处理开发过程会遇到的问题，无论这些协议是简单的还是复杂的，二进制的或是简单文本的。</p>
<h2 id="ssl-tls-支持"><a class="header-anchor" href="#ssl-tls-支持">¶</a>SSL / TLS 支持</h2>
<p>不同于传统阻塞式的 I/O 实现，在 NIO 模式下支持 SSL 功能是一个艰难的工作。你不能只是简单的包装一下流数据并进行加密或解密工作，你不得不借助于 javax.net.ssl.SSLEngine，SSLEngine 是一个有状态的实现，其复杂性不亚于 SSL 自身。你必须管理所有可能的状态，例如密码套件，密钥协商（或重新协商），证书交换以及认证等。此外，与通常期望情况相反的是 SSLEngine 甚至不是一个绝对的线程安全实现。<br>
在 Netty 内部，<a href="http://netty.io/4.0/api/io/netty/handler/ssl/SslHandler.html" target="_blank" rel="noopener">SslHandler</a> 封装了所有艰难的细节以及使用 SSLEngine 可 能带来的陷阱。你所做的仅是配置并将该 SslHandler 插入到你的 ChannelPipeline 中。同样 Netty 也允许你实现像 <a href="https://en.wikipedia.org/wiki/Opportunistic_TLS" target="_blank" rel="noopener">StartTlS</a> 那样所拥有的高级特性，这很容易。</p>
<h2 id="http-实现"><a class="header-anchor" href="#http-实现">¶</a>HTTP 实现</h2>
<p>HTTP 无 疑是互联网上最受欢迎的协议，并且已经有了一些例如 Servlet 容器这样的 HTTP 实现。因此，为什么 Netty 还要在其核心模块之上构建一套 HTTP 实现？<br>
与现有的 HTTP 实现相比 Netty 的 HTTP 实现是相当与众不同的。在 HTTP 消息的低层交互过程中你将拥有绝对的控制力。这是因为 Netty 的 HTTP 实现只是一些 HTTP codec 和 HTTP 消息类的简单组合，这里不存在任何限制——例如那种被迫选择的线程模型。你可以随心所欲的编写那种可以完全按照你期望的工作方式工作的客户端或服务器端代码。这包括线程模型，连接生命期，快编码，以及所有 HTTP 协议允许你做的，所有的一切，你都将拥有绝对的控制力。<br>
由于这种高度可定制化的特性，你可以开发一个非常高效的 HTTP 服务器，例如：</p>
<ul>
<li>要求持久化链接以及服务器端推送技术的聊天服务（如，<a href="http://en.wikipedia.org/wiki/Comet_%28programming%29" target="_blank" rel="noopener">Comet</a> )</li>
<li>需要保持链接直至整个文件下载完成的媒体流服务（如，2 小时长的电影）</li>
<li>需要上传大文件并且没有内存压力的文件服务（如，上传 1GB 文件的请求）</li>
<li>支持大规模混合客户端应用用于连接以万计的第三方异步 web 服务。</li>
</ul>
<h2 id="websockets-实现"><a class="header-anchor" href="#websockets-实现">¶</a>WebSockets 实现</h2>
<p><a href="http://en.wikipedia.org/wiki/WebSockets" target="_blank" rel="noopener">WebSockets</a> 允许双向，全双工通信信道，在 TCP socket 中。它被设计为允许一个 Web 浏览器和 Web 服务器之间通过数据流交互。<br>
WebSocket 协议已经被 IETF 列为 <a href="https://tools.ietf.org/html/rfc6455" target="_blank" rel="noopener">RFC 6455</a> 规范。<br>
Netty 已经实现了 WebSocket 和一些老版本的规范：<a href="http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html" target="_blank" rel="noopener">http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/package-frame.html</a></p>
<h2 id="google-protocol-buffer-整合"><a class="header-anchor" href="#google-protocol-buffer-整合">¶</a>Google Protocol Buffer 整合</h2>
<p><a href="http://code.google.com/apis/protocolbuffers/docs/overview.html" target="_blank" rel="noopener">Google Protocol Buffers</a> 是快速实现一个高效的二进制协议的理想方案。通过使用 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufEncoder.html" target="_blank" rel="noopener">ProtobufEncoder</a> 和 <a href="http://netty.io/4.0/api/io/netty/handler/codec/protobuf/ProtobufDecoder.html" target="_blank" rel="noopener">ProtobufDecoder</a>，你可以把 Google Protocol Buffers 编译器 (protoc) 生成的消息类放入到 Netty 的 codec 实现中。请参考“<a href="http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/localtime/package-summary.html" target="_blank" rel="noopener">LocalTime</a>”实例，这个例子也同时显示出开发一个由简单协议定义 的客户及服务端是多么的容易。</p>
<h1>性能优化</h1>
<h2 id="fastthreadlocal"><a class="header-anchor" href="#fastthreadlocal">¶</a>FastThreadLocal</h2>
<p>重写了JDK的ThreadLocal，但是速度更快</p>
<h2 id="recycle"><a class="header-anchor" href="#recycle">¶</a>Recycle</h2>
<p>对象池</p>
<h2 id="单机百万连接"><a class="header-anchor" href="#单机百万连接">¶</a>单机百万连接</h2>
<h2 id="netty应用级别性能优化"><a class="header-anchor" href="#netty应用级别性能优化">¶</a>Netty应用级别性能优化</h2>
<h1>QA</h1>
<h2 id="如何使用-netty"><a class="header-anchor" href="#如何使用-netty">¶</a>如何使用 Netty</h2>
<p>Netty 是 Java 中的一个 NIO 框架：</p>
<ol>
<li>易用的 API；</li>
<li>NIO 模型相对 BIO 更高效。</li>
<li>解决了 Java 原生 NIO 接口存在的一些问题。<br>
包括粘包半包问题、心跳检测等问题。</li>
</ol>
<h2 id="serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？"><a class="header-anchor" href="#serverbootstrap-默认情况下netty服务端会起多个线程？又是什么时候启动这些线程的？">¶</a>ServerBootstrap - 默认情况下Netty服务端会起多个线程？又是什么时候启动这些线程的？</h2>
<p>Netty中线程主要用于执行EventLoop的for循环任务，当ServerBootstrap<br>
默认情况下创建2倍CPU核心线程数的线程。<br>
<code>io.netty.channel.MultithreadEventLoopGroup#MultithreadEventLoopGroup(int, java.util.concurrent.Executor, java.lang.Object...)</code><br>
可以看到最终创建了个线程池<code>ThreadPerTaskExecutor</code><br>
<code>io.netty.util.concurrent.MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, java.util.concurrent.Executor, io.netty.util.concurrent.EventExecutorChooserFactory, java.lang.Object...)</code></p>
<h2 id="serverbootstrap-netty是如何解决jdk的空轮询bug的？"><a class="header-anchor" href="#serverbootstrap-netty是如何解决jdk的空轮询bug的？">¶</a>ServerBootstrap - Netty是如何解决JDK的空轮询Bug的？</h2>
<p>NioEventLoop</p>
<h2 id="serverbootstrap-netty是如何保证异步串行无锁化的？"><a class="header-anchor" href="#serverbootstrap-netty是如何保证异步串行无锁化的？">¶</a>ServerBootstrap - Netty是如何保证异步串行无锁化的？</h2>
<p>执行需要保证并发安全的操作时先判断是否是刚开始创建的线程，如果不是则放入一个单线程的线程池中执行。<br>
线程创建位置：<code>SingleThreadEventExecutor</code>的构造方法<br>
判断位置：<code>io.netty.util.concurrent.AbstractEventExecutor#inEventLoop</code></p>
<h2 id="nioeventloop-netty如何检测新连接的接入？"><a class="header-anchor" href="#nioeventloop-netty如何检测新连接的接入？">¶</a>NioEventLoop - Netty如何检测新连接的接入？</h2>
<p>初始化ServerBootstrap时</p>
<h2 id="nioeventloop-新连接怎样被注册nioeventloop线程？"><a class="header-anchor" href="#nioeventloop-新连接怎样被注册nioeventloop线程？">¶</a>NioEventLoop - 新连接怎样被注册NioEventLoop线程？</h2>
<p>调用bind时会启动一个NioEventLoop线程，用于监听连接请求。</p>
<h2 id="pipeline-netty如何判断channelhandler类型？"><a class="header-anchor" href="#pipeline-netty如何判断channelhandler类型？">¶</a>pipeline - Netty如何判断ChannelHandler类型？</h2>
<p>ChannelHandler分为Inbound类型和Outbound类型，在Netty中将ChannelHandler添加到Pipeline时会判断这个ChannelHandler的类型，然后设置到一个bool类型的成员变量里，在传播时使用。<br>
<code>io.netty.channel.DefaultChannelHandlerContext#isInbound</code><br>
<code>io.netty.channel.DefaultChannelHandlerContext#isOutbound</code></p>
<h2 id="pipeline-对channelhandler的添加会遵循什么样的顺序？"><a class="header-anchor" href="#pipeline-对channelhandler的添加会遵循什么样的顺序？">¶</a>pipeline - 对ChannelHandler的添加会遵循什么样的顺序？</h2>
<p>根据Pipeline的传播逻辑可以看出，Inbound类型的ChannelHandler按添加顺序传播，而Outbound类型的ChannelHandler是按逆顺序传播的。</p>
<h2 id="pipeline-用户手动触发事件传播-不同的触发方式有什么区别？"><a class="header-anchor" href="#pipeline-用户手动触发事件传播-不同的触发方式有什么区别？">¶</a>pipeline - 用户手动触发事件传播，不同的触发方式有什么区别？</h2>
<p>如果是在Pipeline中间的某个ChannelHandler中调用了read，则就是从这个节点开始往后传播，如果是write，就是从这个节点开始往前传播。</p>
<h2 id="bytebuf-内存的类别有哪些？"><a class="header-anchor" href="#bytebuf-内存的类别有哪些？">¶</a>ByteBuf - 内存的类别有哪些？</h2>
<h2 id="bytebuf-如何减少多线程之间内存分配的竞争？"><a class="header-anchor" href="#bytebuf-如何减少多线程之间内存分配的竞争？">¶</a>ByteBuf - 如何减少多线程之间内存分配的竞争？</h2>
<h2 id="bytebuf-不同大小的内存是如何进行分配的？"><a class="header-anchor" href="#bytebuf-不同大小的内存是如何进行分配的？">¶</a>ByteBuf - 不同大小的内存是如何进行分配的？</h2>
<h2 id="bytebuf-粘包半包问题是什么"><a class="header-anchor" href="#bytebuf-粘包半包问题是什么">¶</a>ByteBuf - 粘包半包问题是什么</h2>
<h2 id="解码器抽象的解码过程？"><a class="header-anchor" href="#解码器抽象的解码过程？">¶</a>解码器抽象的解码过程？</h2>
<h2 id="netty里面有哪些拆箱即用的解码器？"><a class="header-anchor" href="#netty里面有哪些拆箱即用的解码器？">¶</a>Netty里面有哪些拆箱即用的解码器？</h2>
<h2 id="如何把对象变成字节流-并最终写到socket底层？"><a class="header-anchor" href="#如何把对象变成字节流-并最终写到socket底层？">¶</a>如何把对象变成字节流，并最终写到socket底层？</h2>
<h2 id="如何使用netty实现长短连接？"><a class="header-anchor" href="#如何使用netty实现长短连接？">¶</a>如何使用Netty实现长短连接？</h2>
<p>长连接是为了复用连接资源，长连接下，多个请求可以使用同一个连接传输数据包。</p>
<h2 id="如何使用netty实现长短轮询？"><a class="header-anchor" href="#如何使用netty实现长短轮询？">¶</a>如何使用Netty实现长短轮询？</h2>
<p>长轮询的特点是请求发到服务器上时若没有资源（比如库存），请求会被挂起，直到资源充足后才返回。</p>
<h1>参考</h1>
<ol>
<li><a href="https://wiki.jikexueyuan.com/project/netty-4-user-guide/" target="_blank" rel="noopener">Netty 4.x 用户指南</a></li>
<li><a href="https://netty.io/wiki/user-guide-for-4.x.html" target="_blank" rel="noopener">User guide for 4.x（上面这个文档的英文原版）</a></li>
<li><a href="https://github.com/netty/netty" target="_blank" rel="noopener">github - netty / netty</a></li>
<li><a href="https://netty.io/4.0/xref/overview-summary.html" target="_blank" rel="noopener">Netty Source Xref (4.0.56.Final)（同上为源码）</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e13f9e03.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/e13f9e03.html" itemprop="url">MySQL 的集群</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-29T10:18:28+08:00">
                2020-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>主从同步</h1>
<p>MySQL的主从同步是基于bin log实现的。</p>
<h2 id="bin-log-同步流程"><a class="header-anchor" href="#bin-log-同步流程">¶</a>bin log 同步流程</h2>
<p>备库 B 和主库 A 之间维持了一个长连接，主库 A 内部有一个线程专门服务于与 B 的 bin log 同步，一个事务日志同步的过程如下：</p>
<ol>
<li>在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量；</li>
<li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 <code>io_thread</code> 和 <code>sql_thread</code>。其中 io_thread 负责与主库建立连接。</li>
<li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 bin log，发给 B。</li>
<li>备库 B 拿到 bin log 后，写到本地文件，称为中转日志（relay log）。</li>
<li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li>
</ol>
<h2 id="主备延迟"><a class="header-anchor" href="#主备延迟">¶</a>主备延迟</h2>
<p>产生主备延迟的可能情况：</p>
<ol>
<li>备库所在的机器性能较主库差；</li>
<li>备库的压力较大，比如因为备库不跑业务，所以很多人会随意执行一些特别耗时的操作，这些查询耗费大量的 CPU 资源，影响了同步速度，造成主备延迟。</li>
<li>出现了大事务，比如，一次性用 delete 语句删除大量数据，或者大表的 DDL。</li>
</ol>
<h2 id="并行复制策略"><a class="header-anchor" href="#并行复制策略">¶</a>并行复制策略</h2>
<p>为了避免备库追不上主库的情况，MySQL 利用并行复制策略提高复制的效率，从上面的<strong>主备同步流程图</strong>可知，并行化可以加到客户端连接和写入数据两个过程中。</p>
<ol>
<li>按表分发策略<br>
如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。<br>
当然，如果有跨表的事务，还是要把两张表放在一起考虑的。</li>
<li>按行分发策略<br>
按表复制存在热点表的并行复制问题，即热点表会被分配给一个 worker 执行复制，这样就会退化成单线程复制。<br>
按行复制的核心思路是：如果两个事务没有更新相同的行，则它们在备库上可以并行执行，为了知道具体修改了哪些行，这种模式需要设置 binlog 的格式为 row（因为 statement 格式直接记录更新语句，row 记录的是受影响的具体数据的 ID）。</li>
</ol>
<h2 id="半同步"><a class="header-anchor" href="#半同步">¶</a>半同步</h2>
<p>在 MySQL 5.5 版本之前一直采用的是上述的异步复制方案，主库的事务执行不会管备库的同步进度，如果备库落后，主库不幸 crash，那么就会导致数据丢失。<br>
于是在 MySQL 在 5.5 中就顺其自然地引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到 relay log 中。</p>
<h3 id="异步-半同步-全同步"><a class="header-anchor" href="#异步-半同步-全同步">¶</a>异步 &amp; 半同步 &amp; 全同步</h3>
<ul>
<li>对于异步复制，主库将事务 Binlog 事件写入到 bin log 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作，而此时不会保证这些 Binlog 传到任何一个从库节点上。</li>
<li>对于全同步复制，当主库提交事务之后，所有的从库节点必须收到，APPLY 并且提交这些事务，然后主库线程才能继续做后续操作。这里面有一个很明显的缺点就是，主库完成一个事务的时间被拉长，性能降低。</li>
<li>对于半同步复制，是介于全同步复制和异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全执行并且提交的反馈，这样就节省了很多时间。</li>
</ul>
<h1>主备切换</h1>
<p>主备功能主要是通过 bin log 实现的。</p>
<h2 id="主备切换流程"><a class="header-anchor" href="#主备切换流程">¶</a>主备切换流程</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" alt="MySQL-主备切换流程" title="MySQL-主备切换流程"><br>
如图示，客户端的读写都是直接访问的节点 A，而节点 B 是 A 的备库，通常是只读的，只是将 A 的更新同步过来到本地执行，节点 A 的 update 同步到节点 B 的流程图如下所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="MySQL-主备同步流程图" title="MySQL-主备同步流程图"></p>
<ol>
<li>主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog；</li>
<li>备库 B 跟主库 A 之间维持了一个长连接，专门用于服务备库 B 的事务日志同步；</li>
</ol>
<p>当需要切换时，切换到状态 2，这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库；</p>
<h2 id="双-m-架构"><a class="header-anchor" href="#双-m-架构">¶</a>双 M 架构</h2>
<p>实际生产中更多采用的是双 M 架构：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E5%8F%8CM%E6%9E%B6%E6%9E%84%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E6%B5%81%E7%A8%8B.png" alt="MySQL-双M架构主备切换流程" title="MySQL-双M架构主备切换流程"><br>
与原先的方案相比，只是节点 A 和 B 之间多了一条线，这样，节点 A 和 B 之间总是互为主备关系，在切换的时候就不用再修改主备关系。</p>
<h3 id="可靠性优先策略"><a class="header-anchor" href="#可靠性优先策略">¶</a>可靠性优先策略</h3>
<p>双 M 结构的可靠性优先主备切换流程如下：</p>
<ol>
<li>判断备库 B 现在的 <code>seconds_behind_master</code>，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li>
<li>把主库 A 改成只读状态，即把 readonly 设置为 true；</li>
<li>判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；</li>
<li>把备库 B 改成可读写状态，也就是把 readonly 设置为 false；</li>
<li>把业务请求切到备库 B。</li>
</ol>
<p>这个切换流程一般由专门的 HA 系统来完成，称为<strong>可靠性优先流程</strong>。<br>
注意：</p>
<ol>
<li>这个过程中，比较耗时的是第 3 步，可能会耗费好几秒的时间，因此一般会先在第 1 步中做判断，确保 seconds_behind_master 足够小后才执行。</li>
</ol>
<h3 id="可用性优先策略"><a class="header-anchor" href="#可用性优先策略">¶</a>可用性优先策略</h3>
<p>可靠性优先策略中，同步流程中存在一段系统不可用的时间，如果强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了，这个流程称为可用性优先策略。</p>
<h2 id="一主多从"><a class="header-anchor" href="#一主多从">¶</a>一主多从</h2>
<p>平时使用数据库一般都是读多写少，在发展过程中很可能会先遇到读性能问题，为了解决读性能问题，在架构上的解决方式是<strong>一主多从</strong>。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84.png" alt="MySQL-一主多从基本结构" title="MySQL-一主多从基本结构"><br>
其中：</p>
<ul>
<li>A 和 A’互为主备；</li>
<li>从库 B、C、D 指向主库 A，主库负责所有写入和一部分读，其他的读请求由从库分担。</li>
</ul>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E7%9A%84%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2.png" alt="MySQL-一主多从的主备切换" title="MySQL-一主多从的主备切换"></p>
<ul>
<li>主备切换后，A’将成为新的主库；</li>
<li>从库 B、C、D 改成连接到 A’。</li>
</ul>
<h1>读写分离</h1>
<p>上述的主从结构其实形成了一种读写分离的架构，连接信息一般保存到客户端，由客户端执行负载均衡。<br>
另一种读写分离架构在客户端和服务器之间架设了一个代理层 proxy，客户端全部连接到这个 proxy，由 proxy 根据请求类型和上下文执行请求的路由分发。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E5%B8%A6proxy%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84.png" alt="MySQL-带proxy的读写分离架构" title="MySQL-带proxy的读写分离架构"></p>
<ul>
<li>直连的架构，少了一层 proxy，因此性能稍微更好一点，排查问题也更方便，但是主备切换库迁移时客户端会感知到，所以客户端需要一个后端管理组件，比如 Zookeeper。</li>
<li>带 proxy 架构，对客户端友好，但是同时 proxy 架构也更加复杂。</li>
</ul>
<h2 id="过期读-问题"><a class="header-anchor" href="#过期读-问题">¶</a>“过期读”问题</h2>
<p>当客户端先写入再读取时可能会读到修改前的值，因为写入是对主库写入，读取是对从库读，而主从同步存在延迟，刚写入主库的数据可能还没有同步到所有的从库。<br>
解决过期读问题的方案：</p>
<ul>
<li>强制走主库方案；<br>
一些必须拿到最新结果的请求，可以强制将其发到主库上，比如用户支付后需要马上看到商品是否已经购买成功，这个请求需要马上拿到最新的结果，因此最好走主库；<br>
一些请求没有必要立刻拿到最新的结果，比如商户发布商品后，用户即使没有马上看到商品也是可以的，因此用户读取商品列表的请求完全可以路由到从库上去。</li>
<li>sleep 方案；<br>
不大靠谱，但是一定程度上还是可以解决问题的。</li>
<li>判断主备无延迟方案；<br>
判断 <code>show slave status</code> 结果里的 <code>seconds_behind_master</code> 参数的值，等于 0 才执行查询请求，这个参数可以表明从库是否已经完全同步。</li>
<li>配合 semi-sync 方案；</li>
<li>等主库位点方案；</li>
<li>等 GTID 方案。</li>
</ul>
<h1>探活</h1>
<p>在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。<br>
主备切换有两种场景：主动切换和被动切换，其中被动切换往往是因为主库出问题而由 HA 系统发起的。</p>
<h2 id="select-1"><a class="header-anchor" href="#select-1">¶</a>select 1</h2>
<p><code>select 1</code>只能用于判断该数据库进程仍能执行，但是<strong>不能说明主库没有问题</strong>，比如，数据库线程池（由参数 innodb_thread_concurrency 控制）被打满的情况下，虽然<code>select 1</code>能执行，但是线程池还是会被堵住。</p>
<blockquote>
<p>innodb_thread_concurrency 控制的是并发查询，而不是并发连接，因为并发连接多只是多占用一些内存空间，并不会占用 CPU 资源。</p>
</blockquote>
<h2 id="查表判断"><a class="header-anchor" href="#查表判断">¶</a>查表判断</h2>
<p>为了知道线程池是否被打满，我们可以创建一张<code>health_check</code>表，里面只放一条数据，然后定时执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from mysql.health_check;</span><br></pre></td></tr></table></figure>
<p>这种方法的缺点是，<strong>不能用于判断磁盘空间是否满了</strong>，因为如果磁盘空间满了，所有的更新语句和事务提交语句都会被堵塞，但是查询语句仍能执行。</p>
<h2 id="更新判断"><a class="header-anchor" href="#更新判断">¶</a>更新判断</h2>
<p>更新一行数据，一般会放一个 timestamp 字段，用来表示最后一次执行检测的时间。<br>
但是要注意如果主备都要检测，就不能只有一行数据了，因为会产生<strong>行冲突</strong>，导致主备同步的停止。一般会采用数据库实例的 server_id 作为主键，因为 MySQL 规定了主备服务器的 server_id 必须不同，这样就能保证主备的检测命令不会冲突了。<br>
这种方式仍然存在一种问题：这种更新语句占用的 IO 资源很少，即使当时 IO 已经 100%，检测语句仍可以获得 IO 资源来执行，但系统可能已经出问题了，也就是说，这种检测存在随机性。</p>
<h2 id="内部统计"><a class="header-anchor" href="#内部统计">¶</a>内部统计</h2>
<p>前面几种方法都是通过外部调用来发现问题的，更好的方式是利用 MySQL 本身的统计数据：<code>performance_schema</code>库的<code>file_summary_by_event_name</code>表。</p>
<h1>QA</h1>
<h2 id="主从同步的流程"><a class="header-anchor" href="#主从同步的流程">¶</a>主从同步的流程</h2>
<p>主备服务器之间维持了一个长连接，备库上回启动两个线程，一个 io_thread 负责与主库建立连接并读取 bin log，另一个 sql_thread 负责解析命令并执行。</p>
<h2 id="mysql-是怎么保证数据不丢失的"><a class="header-anchor" href="#mysql-是怎么保证数据不丢失的">¶</a>MySQL 是怎么保证数据不丢失的</h2>
<h2 id="mysql-是怎么保证高可用的"><a class="header-anchor" href="#mysql-是怎么保证高可用的">¶</a>MySQL 是怎么保证高可用的</h2>
<h2 id="mysql如何优化千万级的大表？"><a class="header-anchor" href="#mysql如何优化千万级的大表？">¶</a>MySQL如何优化千万级的大表？</h2>
<ol>
<li>优化SQL和索引；</li>
<li>加缓存，比如Memcached或Redis；</li>
<li>主从复制或主主复制，实现读写分离<br>
可以在应用层做，效率高<br>
也可以用三方工具，如360的atlas</li>
<li>使用MySQL自带的分区表<br>
优点是对应用透明，但是SQL需要针对分区表做一些优化，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区。</li>
<li>垂直拆分，根据模块耦合情况将一个大系统分为多个小系统</li>
<li>水平切分，选择合适的sharding key将大表数据拆分到多个小表上</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/zero-gg/p/9057092.html" target="_blank" rel="noopener">MySQL 5.7 半同步复制技术</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f312680c.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/f312680c.html" itemprop="url">MySQL 中的锁</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-28T10:18:28+08:00">
                2020-05-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  10.3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  37 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>解决并发冲突</h1>
<h2 id="mysql-中并发安全组件"><a class="header-anchor" href="#mysql-中并发安全组件">¶</a>MySQL 中并发安全组件</h2>
<h3 id="latch-和-lock"><a class="header-anchor" href="#latch-和-lock">¶</a>latch 和 lock</h3>
<p>MySQL 中的锁主要分为<strong>闩锁（latch）<strong>和</strong>锁（lock）</strong>。<br>
latch 主要用于保护临界资源的线程安全，lock。</p>
<table>
<thead>
<tr>
<th>-</th>
<th>lock</th>
<th>latch</th>
</tr>
</thead>
<tbody>
<tr>
<td>对象</td>
<td>事务</td>
<td>线程</td>
</tr>
<tr>
<td>保护</td>
<td>数据库内容</td>
<td>内存数据结构</td>
</tr>
<tr>
<td>持续时间</td>
<td>整个事务过程</td>
<td>临界资源</td>
</tr>
<tr>
<td>模式</td>
<td>行锁、表锁、意向锁</td>
<td>读写锁、互斥量</td>
</tr>
<tr>
<td>死锁</td>
<td>通过 waits-for graph、time out 等机制进行死锁检测与处理</td>
<td>无死锁检测与处理机制，仅通过控制应用程序加锁顺序（lock leveling）来保证无死锁发生</td>
</tr>
<tr>
<td>存在位置</td>
<td>Lock Manager 的哈希表中</td>
<td>每个数据结构的对象中</td>
</tr>
</tbody>
</table>
<p>latch 不能显式添加，而是线程在获取行锁时前，先对行所在的页面添加 latch，然后再对行添加 lock，添加完行 lock 后再释放页面的 latch。<br>
如果行被其他线程占有，则线程会先释放页面 latch，等待行锁，待获取行锁后会再次对页面添加 latch，查看页面数据是否有改动，再次获取改动后的行。<br>
这种机制主要是为了保证线程获取的行数据的一致性和完整性。</p>
<h3 id="多粒度锁-行锁和表锁"><a class="header-anchor" href="#多粒度锁-行锁和表锁">¶</a>多粒度锁 - 行锁和表锁</h3>
<p>除了使用行锁对记录进行加锁，事务还可以在表级别进行加锁，称为表锁，对一个表加锁会影响整个表中的记录，表锁也分共享锁（S 锁）和独占锁（X 锁）：<br>
1、如果一个事务给表加了 S 锁，那么：<br>
别的事务可以继续获得该表的 S 锁<br>
别的事务可以继续获得该表中的某些记录的 S 锁<br>
别的事务不可以继续获得该表的 X 锁<br>
别的事务不可以继续获得该表中的某些记录的 X 锁<br>
给表加 X 锁：<br>
2、如果一个事务给表加了 X 锁（意味着该事务要独占这个表），那么：<br>
别的事务不可以继续获得该表的 S 锁<br>
别的事务不可以继续获得该表中的某些记录的 S 锁<br>
别的事务不可以继续获得该表的 X 锁<br>
别的事务不可以继续获得该表中的某些记录的 X 锁</p>
<h3 id="封锁-blockade"><a class="header-anchor" href="#封锁-blockade">¶</a>封锁（Blockade）</h3>
<p>上面提到的 lock，在 MySQL 中正式地讲应该称为<strong>封锁（Blockade）</strong>，所谓封锁就是事务在对某个数据对象例如表、记录等操作之前，先向系统发出请求对其加锁，注意表锁和行锁其实都属于封锁。<br>
加锁后事务 T 就对该数据对象有了一定的控制，在事务 T 释放它的锁之前，其他事务不能更新此数据对象。例如，事务 T1 要修改 A，若在读出 A 之前先锁住 A，其他事务就不能再读取和修改 A 了，直到 T1 修改并写回 A 后解除了对 A 的封锁为止。这样，就不会丢失 T1 的修改。<br>
确切的控制由封锁的类型决定。基本的封锁类型有两种：排他锁(exclusive locks,简称 X 锁)和共享锁(share locks,简称 S 锁)</p>
<ul>
<li><strong>X 锁(排他写锁)</strong>：若事务 T1 对数据对象 A 加上 X 锁，则只允许 T 读取和修改 A，其他任何事物都不能再对 A 加任何类型的锁，直到 T 释放 A 上的锁为止。这就保证了其他事务在 T 释放 A 上的锁之前不能再读取和修改 A；</li>
<li><strong>S 锁(共享读锁)</strong>：若事务 T 对数据 A 加上 S 锁，则事务 T 可以读 A 但是不能修改 A，其他事务只能对 A 加 S 锁而不能加 X 锁，直到 T 释放 A 上的 S 锁为止。这就保证了其他食物可以读 A，但在 T 释放 A 上的 S 锁之前不能对 A 进行任何修改。</li>
</ul>
<p>封锁有 3 级的封锁协议：</p>
<ol>
<li>一级封锁协议<br>
事务 T 在对数据对象 A 进行修改之前，必须对其加 X 锁，直至事务结束才释放。事务结束包括正常结束(COMMIT)和非正常结束(ROLLBACK);<br>
在一级加锁协议中，如果仅仅是对数据进行读操作而不进行修改，是不需要进行加锁的。所以只能避免修改丢失而不能避免不可重复读和脏读。</li>
<li>二级封锁协议<br>
在一级加锁协议的基础上增加事务 T 在读取数据 R 之前必须先对其加 S 锁，读完后即可释放 S 锁；<br>
二级加锁协议除防止了丢失修改，还可进一步防止读脏数据。例如：事务 T1 正在对数据对象 R 进行修改，此前已经对 R 加上了 X 锁，此时事务 T2 想读取 R，就必须对 R 加上 S 锁，但是 T2 发现 R 已经被 T1 加上了 X 锁，于是 T2 只能等待 T1 释放了在 R 上加的锁之后才能对 R 加 S 锁并读取。这能防止 T2 读取到 T1 未提交的数据，从而避免了脏读。<br>
但是在二级封锁协议中，由于读完数据后即可释放 S 锁，所以它不能保证可重复读。</li>
<li>三级封锁协议<br>
三级封锁协议是指，在一级封锁协议的基础上增加事务 T 在读取数据 R 之前对其加 S 锁直至事务结束才释放。<br>
三级封锁协议除了防止丢失修改和读“脏”数据之外，还进一步防止了不可重复读。<br>
上述三级协议的主要区别在于什么操作需要申请加锁，以及何时释放锁(即锁的持有时间)。不同的封锁协议使事务达到的一致性是不同的，封锁协议越高，一致性程度越强。</li>
</ol>
<p>封锁与 MVCC 之间的关系：<br>
封锁与 MVCC 并不是互斥的，MySQL 实现隔离级别时结合了这二者，比如：</p>
<ul>
<li>读已提交：二级封锁协议+MVCC，二级封锁协议在读之前加 S 锁，读完之后就释放 S 锁，所以不能保证不可重复读与幻读；</li>
<li>可重复读：三级封锁协议+MVCC，读完之后不会立刻释放 S 锁，直到事务提交时才会释放，可以解决可重复读。</li>
</ul>
<p>封锁协议+MVCC 并不能解决幻读问题，在 MVCC 中是通过 Next-Key Lock 解决的。</p>
<h3 id="意向锁"><a class="header-anchor" href="#意向锁">¶</a>意向锁</h3>
<p>加表锁时怎么知道该表上有没有行锁？InnoDB 通过<strong>意向锁（Intention Locks）<strong>来解决这个问题：<br>
1、<strong>意向共享锁</strong>，英文名：Intention Shared Lock，简称</strong>IS 锁</strong>。当事务准备在某条记录上加 S 锁时，需要先在<strong>表级别</strong>加一个 IS 锁。<br>
2、<strong>意向独占锁</strong>，英文名：Intention Exclusive Lock，简称<strong>IX 锁</strong>。当事务准备在某条记录上加 X 锁时，需要先在<strong>表级别</strong>加一个 IX 锁。</p>
<p>IS、IX 锁是表级锁，它们的提出仅仅为了在之后加表级别的 S 锁和 X 锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实 IS 锁和 IX 锁是兼容的，IX 锁和 IX 锁是兼容的。</p>
<table>
<thead>
<tr>
<th>兼容性</th>
<th>X</th>
<th>IX</th>
<th>S</th>
<th>IS</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td>IX</td>
<td>不兼容</td>
<td>兼容</td>
<td>不兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>S</td>
<td>不兼容</td>
<td>不兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>IS</td>
<td>不兼容</td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<h3 id="mvcc"><a class="header-anchor" href="#mvcc">¶</a>MVCC</h3>
<p>MySQL 的特色之一是提供了 **MVCC（多版本并发控制）**机制，MVCC 给每行数据增加了版本号，事务在执行读操作时只能读到数据的历史版本，因此可以避免脏读等问题。<br>
MVCC 与事务紧密关联，因此我放到<a href="https://tallate.github.io//86b66af2.html">事务小节</a>中去论述了。</p>
<h2 id="innodb-的加锁规则"><a class="header-anchor" href="#innodb-的加锁规则">¶</a>InnoDB 的加锁规则</h2>
<ol>
<li>原则 1：加锁的基本单位是 next-key lock。</li>
</ol>
<blockquote>
<p>next-key lock 是前开后闭区间。</p>
</blockquote>
<ol>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>原则 3：只有明确指定主键时 InnoDB 才会使用行锁，否则会使用表锁</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ol>
<h3 id="例-1-等值查询间隙锁"><a class="header-anchor" href="#例-1-等值查询间隙锁">¶</a>例 1、等值查询间隙锁</h3>
<ol>
<li>根据原则 1，通过 next-key lock 加锁范围<code>(5, 10]</code>；</li>
<li>因为第一个查询是等值查询（id = 7），而 id = 10 不满足查询条件，因此 next-key lock 退化为间隙锁，因此最终加锁范围是<code>(5, 10)</code>。</li>
</ol>
<p>因此 Session B 要往这个间隙中插入 id = 8 会被锁住，但是 Session C 修改 id = 10 这行是可以的。</p>
<h3 id="例-2-主键不明确导致锁表"><a class="header-anchor" href="#例-2-主键不明确导致锁表">¶</a>例 2、主键不明确导致锁表</h3>
<p>下面的情况不会锁表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">明确指定主键，并且有此行数据，row lock</span><br><span class="line">SELECT * FROM products WHERE id = &apos;3&apos; FOR UPDATE;</span><br><span class="line">SELECT * FROM products WHERE id = &apos;3&apos; and type = 1 FOR UPDATE;</span><br><span class="line">明确指定主键，若查无此行数据，无lock</span><br><span class="line">SELECT * FROM products WHERE id = &apos;-1&apos; FOR UPDATE;</span><br></pre></td></tr></table></figure>
<p>下面的情况会锁表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">非索引字段，table lock</span><br><span class="line">SELECT * FROM products WHERE name = &apos;Mouse&apos; FOR UPDATE;</span><br><span class="line">主键不明确，table lock</span><br><span class="line">SELECT * FROM products WHERE id &lt;&gt; &apos;3&apos; FOR UPDATE;</span><br><span class="line">主键不明确，table lock</span><br><span class="line">SELECT * FROM products WHERE id LIKE &apos;3&apos; FOR UPDATE;</span><br></pre></td></tr></table></figure>
<h3 id="例-3-update未命中行触发间隙锁"><a class="header-anchor" href="#例-3-update未命中行触发间隙锁">¶</a>例 3、update未命中行触发间隙锁</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `hgc_test` (</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `b` int(11) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">insert into hgc_test values(1, 0), (5, 0), (10, 0);</span><br></pre></td></tr></table></figure>
<p>事务S1执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">update hgc_test set b = 10 where a = 7;</span><br></pre></td></tr></table></figure>
<p>事务S2执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">insert into hgc_test values(8, 1);</span><br></pre></td></tr></table></figure>
<p>由于事务S1已经锁住了<code>(5, 10]</code>这个区间，因此S2执行插入时会被阻塞。</p>
<h2 id="解决并发冲突的两种方式"><a class="header-anchor" href="#解决并发冲突的两种方式">¶</a>解决并发冲突的两种方式</h2>
<p>有以下两种方式：<br>
1、一致性读 - 读操作利用 MVCC（多版本并发控制），写操作进行加锁<br>
读操作只能读取记录的历史版本：读操作时生成一个 ReadView，记录当时正在执行的事务 ID，记录的每个版本都有事务 ID，查询数据时只能读到在生成 ReadView 之前已提交事务所做的修改，在生成 ReadView 之前未提交的事务或之前才开启的事务所做的修改都看不到。<br>
写操作只能针对最新版本的记录，因此写操作前需要加锁。<br>
2、锁定读 - 读写操作均采用加锁的方式<br>
利用 MVCC 的方式，读写操作彼此并不冲突，性能更高。而加锁的方式读写操作之间都是互斥的，需要排队执行，比较影响性能。</p>
<p>下面我们会分别描述这两种方案。</p>
<h2 id="一致性读-consistent-reads-一致性无锁读-快照读"><a class="header-anchor" href="#一致性读-consistent-reads-一致性无锁读-快照读">¶</a>一致性读（Consistent Reads、一致性无锁读、快照读）</h2>
<p>事务利用 MVCC 进行的读取操作称之为一致性读，所有普通的 SELECT 语句在 READ COMMITTED、REPEATABLE READ 隔离级别下都算是一致性读。<br>
也就是上面提到的“读操作利用 MVCC”。</p>
<h2 id="锁定读-locking-reads"><a class="header-anchor" href="#锁定读-locking-reads">¶</a>锁定读（Locking Reads）</h2>
<p>读-读的情况并不会引起并发冲突，我们不希望对这种情况造成影响，因此 MySQL 给锁分了几个类：<br>
1、共享锁（Shared Locks、S 锁）：在事务要读取一条记录时，需要先获取该记录的 S 锁。<br>
2、独占锁（排他锁、Exclusive Locks、X 锁）：在事务要改动一条记录时，需要先获取该记录的 X 锁。</p>
<table>
<thead>
<tr>
<th>兼容性</th>
<th>X</th>
<th>S</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td>S</td>
<td>不兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<p>一般读取一条记录时我们会获取这条记录的 S 锁，但是如果我们想在读取记录时就获取记录的 X 锁，来禁止别的事务读写该记录，则需要使用一些特殊的 SELECT 语句格式：<br>
1、对读取的记录加 S 锁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ... LOCK IN SHARE MODE;</span><br></pre></td></tr></table></figure>
<p>上面语句为记录加 S 锁，允许多个事务同时发起读请求，但是当别的事务尝试获取 X 锁（SELECT … FOR UPDATE 或修改这些记录）则会阻塞，直到当前事务提交之后将这些记录上的 S 锁释放掉。<br>
2、对读取的记录加 X 锁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ... FOR UPDATE;</span><br></pre></td></tr></table></figure>
<p>上面语句为记录加 X 锁，之后别的事务来获取该记录的 S 锁或 X 锁时都会被阻塞，直到当前事务提交之后将这些记录上的 X 锁释放掉。</p>
<h2 id="写操作-write-如何利用锁"><a class="header-anchor" href="#写操作-write-如何利用锁">¶</a>写操作（write）如何利用锁</h2>
<h3 id="delete"><a class="header-anchor" href="#delete">¶</a>DELETE</h3>
<p>DELETE 操作会先在 B+树中定位到这条记录，然后获取这条记录的 X 锁，并执行 delete mark 操作（逻辑删除）。</p>
<h3 id="update"><a class="header-anchor" href="#update">¶</a>UPDATE</h3>
<p>如果未修改该记录的键值并且被更新的列占用的存储空间在修改前后未发生变化，则先在 B+树种定位到这条记录然后获取该记录的 X 锁，最后在原记录的位置执行修改操作。<br>
如果未修改该记录的键值并且至少有一个被更新的列占用的存储空间在修改前后发生变化，则先在 B+树种定位到这条记录后获取 X 锁，将这条记录彻底删除（移入垃圾链表），最后插入一条记录。<br>
如果修改了该记录的键值，则相当于在原记录上 DELETE 后 INSERT。</p>
<h3 id="insert"><a class="header-anchor" href="#insert">¶</a>INSERT</h3>
<p>一般 INSERT 操作并不加锁，MySQL 引入了一种称为<strong>隐式锁</strong>的技术来保护这条新插入的记录在本事务提交之前不被其他事务访问。</p>
<blockquote>
<p>显式锁即 select … for update 语句，从语法上就能看出这个语句加了锁。</p>
</blockquote>
<p>让我们分几种情况来分析 insert 语句的锁。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  `d` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `c` (`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into t values(null, 1,1);</span><br><span class="line">insert into t values(null, 2,2);</span><br><span class="line">insert into t values(null, 3,3);</span><br><span class="line">insert into t values(null, 4,4);</span><br><span class="line"></span><br><span class="line">create table t2 like t</span><br></pre></td></tr></table></figure>
<h4 id="insert-select-语句"><a class="header-anchor" href="#insert-select-语句">¶</a>insert … select 语句</h4>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure>
<p>上面Session A语句需要对表 t 的所有行和间隙加锁。原因见下面的例子：</p>
<table>
<thead>
<tr>
<th>session A</th>
<th>session B</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>insert into t values(-1, -1, -1);</code></td>
<td><code>insert into t2(c, d) select c, d from t;</code></td>
</tr>
</tbody>
</table>
<p>上面的两个session，如果过session B先执行，由于对表t的主键索引加了<code>(-∞, 1]</code>这个next-key lock，会在语句执行完毕后，才允许session A的insert语句执行。<br>
但如果没有锁，就有可能出现session B的insert语句先执行，但是后写入binlog的情况，于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(-1,-1,-1);</span><br><span class="line">insert into t2(c,d) select c,d from t;</span><br></pre></td></tr></table></figure>
<p>这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。</p>
<h4 id="insert-唯一键冲突"><a class="header-anchor" href="#insert-唯一键冲突">¶</a>insert 唯一键冲突</h4>
<p>insert 发生唯一键冲突时可能引起死锁，例：</p>
<table>
<thead>
<tr>
<th>T</th>
<th>session A</th>
<th>session B</th>
<th>session C</th>
</tr>
</thead>
<tbody>
<tr>
<td>T1</td>
<td><code>begin; insert into t values(null, 5, 5)</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>T2</td>
<td></td>
<td><code>insert into t values(null, 5, 5)</code></td>
<td><code>insert into t values(null, 5, 5)</code></td>
</tr>
<tr>
<td>T3</td>
<td><code>rollback;</code></td>
<td></td>
<td>(Deadlock fount)</td>
</tr>
</tbody>
</table>
<ul>
<li>正如前面的《加锁规则》所述，session A执行insert语句时，会在所以c的c=5这行上加记录锁，由于这个索引是唯一索引，因此会退化为记录锁；</li>
<li>session B要执行相同的insert语句，发现了唯一键冲突，加上<strong>读锁</strong>，同时session C也会在同一个记录上加上读锁；</li>
</ul>
<blockquote>
<p>为什么加读锁？应该是为了保证不被删掉的同时，可以不影响读操作。</p>
</blockquote>
<ul>
<li>T3时刻，session A 回滚。这时候，session B 和 session C 都试图继续执行插入操作，都要加上写锁。两个 session 都要等待对方的行锁，所以就出现了死锁。</li>
</ul>
<h4 id="insert-into-on-duplicate-key-update"><a class="header-anchor" href="#insert-into-on-duplicate-key-update">¶</a>insert into … on duplicate key update</h4>
<p>上面的例子是主键冲突后直接报错，如果写成如下形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(11,10,10) on duplicate key update d=100;</span><br></pre></td></tr></table></figure>
<p>则会给索引c上<code>(5, 10]</code>加一个排他的next-key lock（写锁）。</p>
<h2 id="锁结构"><a class="header-anchor" href="#锁结构">¶</a>锁结构</h2>
<p>MySQL 中锁是通过共享内存实现的，当一个事务希望对一条记录做修改操作时，首先会看看内存中有没有与这条记录关联的锁结构，当没有的时候就会在内存中生成一个锁结构与之关联，这个锁结构中有两个主要属性：</p>
<ul>
<li>trx：代表生成该锁结构的事务；</li>
<li>is_waiting：代表当前事务是否在等待。</li>
</ul>
<p>获取锁成功（加锁成功）可以描述为：修改一条记录前生成了一个锁结构与之关联，因为之前没有别的记录为这条记录加锁，所以 is_waiting 为 false；<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105d9425c2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
获取锁失败可以描述为：在事务对一条记录进行修改前，已经有另一个事务创建了锁结构与之关联，那么当前事务需要生成一个锁结构且 is_waiting 为 true，表示当前事务需要等待。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105e955d9a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
释放锁时，就是把当前事务的锁结构释放掉，然后看有没有其他事务正在等待获取锁，并把正在等待的事务对应的锁结构的 is_waiting 置为 false，然后将该事务对应的线程唤醒。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a680105f387885?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<p>总结地说：</p>
<ul>
<li>不加锁<br>
意思就是不需要在内存中生成对应的锁结构，可以直接执行操作。</li>
<li>获取锁成功，或者加锁成功<br>
意思就是在内存中生成了对应的锁结构，而且锁结构的 is_waiting 属性为 false，也就是事务可以继续执行操作。</li>
<li>获取锁失败，或者加锁失败，或者没有获取到锁<br>
意思就是在内存中生成了对应的锁结构，不过锁结构的 is_waiting 属性为 true，也就是事务需要等待，不可以继续执行操作。</li>
</ul>
<h2 id="自增长与锁"><a class="header-anchor" href="#自增长与锁">¶</a>自增长与锁</h2>
<p>InnoDB 中，对每个含有自增长值的表都有一个自增长计数器。</p>
<ul>
<li>初始化：当对这样的表进行插入操作时，这个计数器会被初始化。</li>
<li>更新：插入操作根据这个自增长计数器值加 1 赋予自增长列，对该计数器的更新需要保证线程安全，这可以通过设置使用<strong>表锁</strong>还是<strong>互斥量</strong>来实现。</li>
</ul>
<h1>MySQL 全局锁</h1>
<p>全库逻辑备份</p>
<ol>
<li>Flush tables with read lock（FTWRL）<br>
这个命令不保证备份时数据库是否处于一个一致性视图，可能有的事务刚执行一半。</li>
<li>mysqldump<br>
在导数据前会启动事务，确保可以拿到一致性视图，前提是数据库中所有表都使用了支持事务的引擎，否则就只能使用<code>FTWRL</code>来备份了。</li>
</ol>
<h1>InnoDB 存储引擎中的表锁</h1>
<h2 id="表锁种类"><a class="header-anchor" href="#表锁种类">¶</a>表锁种类</h2>
<ol>
<li>lock tables …… read/write<br>
锁住整个表会对数据库效率产生比较大的影响。</li>
<li>MDL（metadata lock)<br>
MDL 不需要显式使用，在访问一个表的时候会被自动加上，表结构变更操作之间、表结构变更操作与读表操作之间都是互斥的，保证表结构变更的正确性。<br>
MDL 可能会导致表的锁死，比如一个 alter 语句正在等待一个长事务（该事务中有 select 语句）释放读 MDL，这时 alter 会加上写 MDL，因此之后的所有事务都需要等待该写 MDL 释放了，因此在变更表结构时最好先将长事务终止，或者给 alter 语句设置等待时间：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
<h2 id="不会加表锁的情况"><a class="header-anchor" href="#不会加表锁的情况">¶</a>不会加表锁的情况</h2>
<p>1、在对某个表执行 SELECT、INSERT、DELETE、UPDATE 语句时，InnoDB 存储引擎是不会为这个表添加表级别的 S 锁或者 X 锁的；<br>
2、执行 DDL 语句时（ALTER TABLE、DROP TABLE）时，使用的是 Server 层的<strong>元数据锁（Metadata Locks）</strong>。</p>
<p>手动获取表级 S 锁和 X 锁的方式：<br>
1、LOCK TABLES t READ：InnoDB 存储引擎会对表 t 加表级别的 S 锁。<br>
2、LOCK TABLES t WRITE：InnoDB 存储引擎会对表 t 加表级别的 X 锁。</p>
<p>不过一般表锁不会用到，只会在崩溃恢复之类的场景下会用到。</p>
<p>表级 IS 锁、IX 锁，和之前的描述一致。</p>
<p>如果实现自增列：<br>
1、表级别 AUTO-INC 锁：当表中某列设置了 auto_increment 属性，那么该列的值是会自动生成的，插入时会在表级加一个 AUTO-INC 锁，保证这个字段是严格递增的；当插入语句执行完毕后，该锁会自动释放，而不是在事务结束后再释放。<br>
2、一个轻量级锁：生成 auto_increment 列的值后马上释放。</p>
<blockquote>
<p>InnoDB 提供了一个称之为 innodb_autoinc_lock_mode 的系统变量来控制到底使用上述两种方式中的哪种来为 AUTO_INCREMENT 修饰的列进行赋值，当 innodb_autoinc_lock_mode 值为 0 时，一律采用 AUTO-INC 锁；当 innodb_autoinc_lock_mode 值为 2 时，一律采用轻量级锁；当 innodb_autoinc_lock_mode 值为 1 时，两种方式混着来（也就是在插入记录数量确定时采用轻量级锁，不确定时使用 AUTO-INC 锁）。不过当 innodb_autoinc_lock_mode 值为 2 时，可能会造成不同事务中的插入语句为 AUTO_INCREMENT 修饰的列生成的值是交叉的，在有主从复制的场景中是不安全的。</p>
</blockquote>
<h1>InnoDB 存储引擎中的行锁</h1>
<h2 id="两阶段锁协议"><a class="header-anchor" href="#两阶段锁协议">¶</a>两阶段锁协议</h2>
<p>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束（commit）时才释放。这个就是两阶段锁协议。<br>
由于两阶段锁协议的存在，如果我们的事务中需要锁住多个行，最好把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<h2 id="锁的种类"><a class="header-anchor" href="#锁的种类">¶</a>锁的种类</h2>
<p>1、Record Locks（行锁）<br>
该锁的官方类型名为 LOCK_REC_NOT_GAP。<br>
和前面提到的表锁一样，分 S 锁和 X 锁，只是作用粒度精确到行了。<br>
2、Gap Locks（间隙锁）<br>
该锁的官方类型名为 LOCK_GAP。<br>
MySQL 解决幻读问题有两种方案：<br>
第一种是 MVCC，因为新插入的数据事务 ID 必然不在 ReadView 内，因此读取这些记录后会被直接忽略，但是快照读只在普通读操作中生效，如果发生了当前读仍然会有幻读问题；<br>
第二种是加锁，但是加锁有一个问题，就是事务没法给尚不存在的记录加锁。<br>
如果我们希望为 number 值为 8 的记录加 gap 锁，则该记录的前后间隙都不允许别的事务立即插入记录：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-gap%E9%94%81.png" alt="MySQL-gap锁" title="MySQL-gap锁"><br>
如图中为 number 值为 8 的记录加了 gap 锁，意味着不允许别的事务在 number 值为 8 的记录前边的间隙插入新记录，其实就是 number 列的值(3, 8)这个区间的新记录是不允许立即插入的。比方说有另外一个事务再想插入一条 number 值为 4 的新记录，它定位到该条新记录的下一条记录的 number 值为 8，而这条记录上又有一个 gap 锁，所以就会阻塞插入操作，直到拥有这个 gap 锁的事务提交了之后，number 列的值在区间(3, 8)中的新记录才可以被插入。<br>
另外，如何为(20, +∞)这个区间加 gap 锁？其实是为数据页中的 Infimum 和 Supremum 记录加上了 gap 锁。<br>
比如假设此时表里有 5、25 这两条数据，则<code>SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE</code>查询 10 到 20 范围内的记录，并加上范围<code>(5, 10)</code>、<code>[10, 20]</code>、<code>(20, 25]</code>以内的 gap 锁。<br>
比如假设此时表里有 102、105、107 三个值，则<code>select * from test where n = 105 for update;</code>这个语句会对<code>(102, 105)</code>、<code>(105, 107]</code>这两个区间加 gap 锁。<br>
3、Next-Key Locks<br>
该锁的官方类型名为 LOCK_ORDINARY。<br>
Next-Key Lock 其实是<strong>Record Lock 和 Gap Lock 的组合</strong>，它既会保护该条记录，又能阻止别的事务将新记录插入被保护记录的前后间隙。<br>
4、Insert Intention Locks（插入意向锁）<br>
该锁的官方类型名为 LOCK_INSERT_INTENTION。<br>
InnoDB 中事务在等待<strong>gap 锁</strong>的释放时，还需要在内存里生成一个锁结构，表示事务现在正想往某个间隙中插入记录，但是现在正在等待。<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a72bf8133eb1dc?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
如上图所示，有 3 个事务，其中 T1 持有 gap 锁，所以 T2 和 T3 需要生成一个插入意向锁的锁结构，等待 T1 释放后才能获取到插入意向锁（本质上是将 is_waiting 属性改成了 false），然后再继续执行插入操作。<br>
5、隐式锁<br>
一般来说间隙锁可以避免 gap 锁锁住的区间被其他事务修改（当要插入的记录所在的区间有 gap 锁，事务会先再该间隙上加一个插入意向锁），但是还有一种情况正好是反过来的：如果一个事务首先插入了一条记录，别的记录如果直接读（SELECT … LOCK IN SHARE MODE 或 SELECT … FOR UPDATE）则会产生脏读问题，如果直接修改则又会产生脏写问题。<br>
这个问题在 InnoDB 中是通过事务 ID 解决的：</p>
<ul>
<li>聚簇索引中有一个隐藏列 trx_id，存储的是最后改动该记录的事务 ID，新插入记录的 trx_id 当然就是当前事务的事务 ID，如果别的事务想对该记录添加 S 锁或 X 锁，<strong>会首先看一下该记录 trx_id 是否是当前正活跃的事务</strong>，如果是的话就会创建一个 X 锁然后进入等待状态；</li>
<li>二级索引本身没有 trx_id 列，但是在二级索引页面的 Page Header 部分有一个 PAGE_MAX_TRX_ID 属性，该属性代表对该页面做改动的最大的事务 id，如果 PAGE_MAX_TRX_ID 属性值小于当前最小的活跃事务 id，那么说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记录，然后再重复聚簇索引的做法。</li>
</ul>
<h2 id="活锁-死锁与死锁检测"><a class="header-anchor" href="#活锁-死锁与死锁检测">¶</a>活锁、死锁与死锁检测</h2>
<h3 id="活锁"><a class="header-anchor" href="#活锁">¶</a>活锁</h3>
<p>活锁：如果事务 T1 封锁了数据 R，事务 T2 又请求封锁 R，于是 T2 等待。T3 也请求封锁 R，当 T1 释放了 R 上的锁之后系统首先批准了 T3 的请求，T2 继续等待；然后 T4 又请求封锁 R，T3 在释放 R 上的锁之后系统又批准了 T4 的请求，T2 有可能永远等待，这就是活锁的情形。<br>
避免活锁的简单方法就是采用先来先服务的策略。当多个事务请求封锁同一数据对象时，封锁子系统按请求锁的先后次序对事务进行排队，数据对象上的锁一旦释放就批准批准申请队列中第一个事务获得锁。</p>
<h3 id="死锁"><a class="header-anchor" href="#死锁">¶</a>死锁</h3>
<p>死锁在许多操作系统书中都有描述，简而言之，就是多个线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，都会导致这些线程都进入无限等待的状态，称为死锁。<br>
在 InnoDB 中，也会出现两个事务互相等待对方释放某条记录的行锁的情况，从而导致进入死锁状态。死锁可以预防，也可以等发生死锁后再作处理。</p>
<h3 id="死锁预防"><a class="header-anchor" href="#死锁预防">¶</a>死锁预防</h3>
<p>在数据库中，产生死锁的原因是两个或多个事务都已经封锁了一些数据对象，然后又都请求对已被事务封锁的对象加锁，从而出现死锁。防止死锁的发生其实就是要破坏产生死锁的条件。预防死锁发生通常有以下两种方法。</p>
<ul>
<li><strong>一次封锁法</strong>：一次封锁法要求每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行下去。一次封锁法虽然可以有效防止死锁的发生，但是<strong>增加了锁的粒度，从而降低了系统的并发性</strong>。并且数据库是不断变化的，所以事先很难精确地确定每个事务所需进行加锁的对象，为此只能扩大封锁范围，将事务在执行过程中可能需要封锁的数据对象全部加锁，这就进一步降低了并发度；</li>
<li><strong>顺序封锁法</strong>：顺序封锁法是预先对数据对象规定一个封锁顺序，所有事务都按这个顺序实施封锁。例如在 B 树结构的索引中，可规定封锁的顺序必须是从根节点开始，然后是下一级的子节点，逐级封锁。顺序封锁法可以有效地避免死锁，但是要实现顺序封锁法十分的困难，因为<strong>很难事先确定每一个事务要封锁哪些对象，因此也就很难按规定的顺序去实施加锁</strong>。</li>
</ul>
<p>由此可见数据库中不适合预防死锁，只适合进行死锁的诊断与解除。</p>
<h3 id="死锁检测与解除"><a class="header-anchor" href="#死锁检测与解除">¶</a>死锁检测与解除</h3>
<ul>
<li>设置最大等待时间，等待超过目标时间后自动释放之前获取到的锁，让别的事务先执行；<br>
可以通过参数<code>innodb_lock_wait_timeout</code>来设置<br>
超时法实现简单，但其不足也十分明显，一是有可能误判了死锁，如事务因为其他原因而使等待时间超过时限，系统就会误认为发生了死锁；二是若时限设置得太长，则不能及时发现死锁。</li>
<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行<br>
将参数 <code>innodb_deadlock_detect</code> 设置为 on 即表示开启死锁检测。<br>
死锁检测是一个耗时操作，因为每当一个事务被锁的时候，都要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。<br>
死锁检测的基础是<strong>事务等待图</strong>，事务等待图是一个有向图 G=(T,U),T 为结点的集合，每个结点表示正在运行的事务；U 为边的集合，每条边表示事务等待的情况。若 T1 等待 T2，则在 T1,T2 之间画一条有向边，从 T1 指向 T2。事务等待图动态地反应了所有事务的等待情况。并发控制子系统周期性(比如每隔数秒)生成事务等待图，并进行检测。如果发现图中存在回路，则表示系统中出现了死锁。</li>
</ul>
<p>数据库管理系统的并发控制系统一旦检测到系统中存在死锁，就要设法<strong>解除死锁</strong>。通常采用的方法是选择一个处理死锁代价最小的事务，将其撤销，释放此事务持有的所有的锁，使其他事务得以继续运行下去。当然，对撤销的事务所进行的数据修改必须加以恢复。</p>
<p>死锁的检测会产生一定的性能损耗，因此解决热点行更新导致的性能问题需要结合业务来进行权衡：</p>
<ol>
<li>如果能确保业务一定不会出现死锁，可以临时把死锁检测关掉。<br>
但是需要注意的是，死锁检测可以保证出现死锁后可以通过业务回滚然后重试来解决，这是业务无损的，而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</li>
<li>控制并发度<br>
保证对于相同行的更新，在进入引擎之前排队，这样就可以避免大量的死锁检测工作了。</li>
<li>将对同一行的操作改成多行<br>
比如，将库存分成多份，减库存时随机取出一份来操作，这样冲突的概率就会变成原本的 1/10 了，既减少了锁等待个数，又减少了死锁检测的 CPU 消耗。</li>
</ol>
<h3 id="可能发生死锁的情况"><a class="header-anchor" href="#可能发生死锁的情况">¶</a>可能发生死锁的情况</h3>
<ol>
<li>注意加锁顺序<br>
比如下面语句查3行数据，而且由于<code>desc</code>，该查询语句是<strong>倒序</strong>在索引树上遍历的，遍历过程中会给查到的记录和区间加行锁和间隙锁。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from t where c in(5,20,10) order by c desc for update;</span><br></pre></td></tr></table></figure>
<p>在上面这条语句执行期间，如果有另外一条语句是正序遍历并加锁的，就很有可能会导致死锁，比如如下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from t where c in(5,20,10) lock in share mode;</span><br></pre></td></tr></table></figure>
<p>因此对同一组咨询，要<strong>尽量按照相同的顺序访问</strong>。</p>
<h3 id="如何查看死锁"><a class="header-anchor" href="#如何查看死锁">¶</a>如何查看死锁</h3>
<p>出现死锁后，执行 <code>show engine innodb status</code> 命令，这个命令会输出很多信息，有一节 <code>LATESTDETECTED DEADLOCK</code>。</p>
<h2 id="锁的内存结构"><a class="header-anchor" href="#锁的内存结构">¶</a>锁的内存结构</h2>
<p>InnoDB 中，不是获取多少记录就给多少记录加锁，如果符合下边这些条件则这些记录的锁就会被放到一个锁结构中：<br>
1、在同一个事务中进行加锁操作<br>
2、被加锁的记录在同一个页面中<br>
3、加锁的类型是一样的<br>
4、等待状态是一样的</p>
<p>具体的，InnoDB 中的锁结构如下所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a68cda54348429?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<ul>
<li>锁所在的事务信息：<br>
不论是表锁还是行锁，都是在事务执行过程中生成的，哪个事务生成了这个锁结构，这里就记载着这个事务的信息。</li>
<li>索引信息：<br>
对于行锁来说，需要记录一下加锁的记录是属于哪个索引的。</li>
<li>表锁／行锁信息：<br>
表锁结构和行锁结构在这个位置的内容是不同的：<br>
表锁：记载着这是对哪个表加的锁，还有其他的一些信息。<br>
行锁记载了三个重要的信息：<br>
Space ID：记录所在表空间。<br>
Page Number：记录所在页号。<br>
n_bits：对于行锁来说，一条记录就对应着一个比特位，一个页面中包含很多记录，用不同的比特位来区分到底是哪一条记录加了锁。为此在行锁结构的末尾放置了一堆比特位，这个 n_bits 属性代表使用了多少比特位，n_bits 一般会比实际数据量大一些，避免每次插入记录都需要重新分配内存。</li>
<li>type_mode：<br>
这是一个 32 位的数，被分成了 lock_mode、lock_type 和 rec_lock_type 三个部分，如图所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/5/16a864f3298df751?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="">
<ul>
<li>锁的模式（lock_mode），占用低 4 位，可选的值如下：<br>
LOCK_IS（十进制的 0）：表示共享意向锁，也就是 IS 锁，属于表级锁。<br>
LOCK_IX（十进制的 1）：表示独占意向锁，也就是 IX 锁，属于表级锁。<br>
LOCK_S（十进制的 2）：表示共享锁，也就是 S 锁，既可以属于表级锁也可以属于行级锁。<br>
LOCK_X（十进制的 3）：表示独占锁，也就是 X 锁，既可以属于表级锁也可以属于行级锁。<br>
LOCK_AUTO_INC（十进制的 4）：表示 AUTO-INC 锁，属于表级锁。</li>
<li>锁的类型（lock_type），占用第 5～8 位，不过现阶段只有第 5 位和第 6 位被使用：<br>
LOCK_TABLE（十进制的 16），也就是当第 5 个比特位置为 1 时，表示表级锁。<br>
LOCK_REC（十进制的 32），也就是当第 6 个比特位置为 1 时，表示行级锁。</li>
<li>行锁的具体类型（rec_lock_type），使用其余的位来表示。只有在 lock_type 的值为 LOCK_REC 时，也就是只有在该锁为行级锁时，才会被细分为更多的类型：<br>
LOCK_ORDINARY（十进制的 0）：表示 next-key 锁。<br>
LOCK_GAP（十进制的 512）：也就是当第 10 个比特位置为 1 时，表示 gap 锁。<br>
LOCK_REC_NOT_GAP（十进制的 1024）：也就是当第 11 个比特位置为 1 时，表示正经记录锁。<br>
LOCK_INSERT_INTENTION（十进制的 2048）：也就是当第 12 个比特位置为 1 时，表示插入意向锁。<br>
其他的类型：还有一些不常用的类型我们就不多说了。<br>
怎么还没看见 is_waiting 属性呢？这主要还是设计 InnoDB 的大叔太抠门了，一个比特位也不想浪费，所以他们把 is_waiting 属性也放到了 type_mode 这个 32 位的数字中：<br>
LOCK_WAIT（十进制的 256） ：也就是当第 9 个比特位置为 1 时，表示 is_waiting 为 true，也就是当前事务尚未获取到锁，处在等待状态；当这个比特位为 0 时，表示 is_waiting 为 false，也就是当前事务获取锁成功。</li>
</ul>
</li>
<li>其他信息</li>
<li>一堆比特位<br>
如果是行锁结构的话，在该结构末尾还放置了一堆比特位，比特位的数量是由上边提到的 n_bits 属性表示的。我们前边唠叨 InnoDB 记录结构的时候说过，页面中的每条记录在记录头信息中都包含一个 heap_no 属性，伪记录 Infimum 的 heap_no 值为 0，Supremum 的 heap_no 值为 1，之后每插入一条记录，heap_no 值就增 1。锁结构最后的一堆比特位就对应着一个页面中的记录，一个比特位映射一个 heap_no，不过为了编码方便，映射方式有点怪。<br>
<img src="https://user-gold-cdn.xitu.io/2019/4/29/16a69c2f7b413698?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></li>
</ul>
<h2 id="锁优化"><a class="header-anchor" href="#锁优化">¶</a>锁优化</h2>
<ol>
<li>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。<br>
比如用户买电影票的场景中，扣减用户账户余额和给影院账户余额加钱，显然后者的竞争更加频繁，因此对其的加锁应该放在事务更靠后的位置。</li>
</ol>
<h1>其他存储引擎中的锁</h1>
<p>MyISAM、MEMORY、MERGE 这些引擎不支持事务，因此加锁一般都是针对当前会话来说的，比如 Session1 先对表加 S 锁，之后 Session2 再对该表执行 UPDATE 操作时，获取 X 锁的过程就会被阻塞了。<br>
相当于这些存储引擎同一时刻只允许一个会话对表执行写操作，因此这些存储引擎最好用于读多写少的场景下。</p>
<h1>QA</h1>
<h2 id="如何安全地给表加字段"><a class="header-anchor" href="#如何安全地给表加字段">¶</a>如何安全地给表加字段</h2>
<p>首先需要处理掉长事务，因为长事务不提交的话会一直占用 MDL 锁。</p>
<blockquote>
<p>information_schema 库的 innodb_trx 表中可以看到当前执行中的长事务。<br>
但是如果这样的事务比较多，kill 掉并不一定管用，因为新的请求总是会源源不断地到来，所以最好的方法是在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ...</span><br></pre></td></tr></table></figure>
<h2 id="mysql-如何处理死锁"><a class="header-anchor" href="#mysql-如何处理死锁">¶</a>MySQL 如何处理死锁</h2>
<p>MySQL 有两种死锁处理方式：</p>
<ol>
<li>等待直到超时（<code>show variables like 'innodb_lock_wait_timeout'</code>）</li>
<li>发起死锁检测，主动回滚一条事务，让其他事务继续执行（<code>show variables like 'innodb_deadlock_detect'</code>）</li>
</ol>
<h2 id="mysql-如何检测死锁"><a class="header-anchor" href="#mysql-如何检测死锁">¶</a>MySQL 如何检测死锁</h2>
<p>死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。</p>
<h2 id="mysql-连接池被打满怎么办"><a class="header-anchor" href="#mysql-连接池被打满怎么办">¶</a>MySQL 连接池被打满怎么办</h2>
<p>这里的连接池指的是应用服务器里访问 MySQL 服务的连接池，比如 Druid，</p>
<h2 id="以下哪些场景会导致语句q1-select-from-t1-limit-1被堵住？"><a class="header-anchor" href="#以下哪些场景会导致语句q1-select-from-t1-limit-1被堵住？">¶</a>以下哪些场景会导致语句<code>Q1: select * from t1 limit 1</code>被堵住？</h2>
<ol>
<li>另一个线程在Q1执行前，执行了<code>alter table t1 add index(f1)</code>，当前正处于拷贝数据到临时表阶段。</li>
</ol>
<h2 id="以下什么情况会发生-等待行锁-的状态？"><a class="header-anchor" href="#以下什么情况会发生-等待行锁-的状态？">¶</a>以下什么情况会发生&quot;等待行锁&quot;的状态？</h2>
<p>RR隔离级别下，表t的建表结构和初始化数据如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table t (id int primary key, c int) engine = innoDB;</span><br><span class="line">insert into t values (1, 1), (11, 11), (21, 21);</span><br></pre></td></tr></table></figure>
<p>在会话1中执行如下语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">select * from t lock in share mode;</span><br></pre></td></tr></table></figure>
<p>可见这条语句希望对表t加一个表级的读锁。</p>
<ol>
<li>会进入&quot;等待行锁&quot;的情况1<br>
<code>insert into t values (15, 15);</code><br>
插入时会先给表加IX意向锁，IX意向锁是和会话1中对表t加上的读锁互斥的，因此会导致阻塞。</li>
<li>不会进入&quot;等待行锁&quot;的情况1<br>
<code>update t set c = c + 1 where id = 15;</code><br>
因为id = 15这条数据不存在，因此这条语句实际上不会加锁。</li>
<li>不会进入&quot;等待行锁&quot;的情况2<br>
<code>delete from t where id = 15;</code><br>
因为找不到id = 15这条数据，因此也不会加锁。</li>
<li>不会进入&quot;等待行锁&quot;的情况3<br>
<code>alter table t add d int;</code><br>
alter table 会加MDL，这并不是行锁。</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://www.cnblogs.com/jay-huaxiao/p/11456921.html" target="_blank" rel="noopener">Mysql 死锁如何排查：insert on duplicate 死锁一次排查分析过程</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b7a6e835.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b7a6e835.html" itemprop="url">MySQL 中的查询</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-27T10:18:28+08:00">
                2020-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  10.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  38 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>查询缓存</h1>
<p>缓存失效的情况：</p>
<ol>
<li>如果两个查询请求<strong>在任何字符上的不同</strong>（例如：空格、注释、大小写），都会导致缓存不会命中</li>
<li>如果查询请求中<strong>包含某些系统函数、用户自定义变量和函数、一些系统表</strong>，如 mysql 、information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存</li>
<li>MySQL 的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了 INSERT、 UPDATE、DELETE、TRUNCATE TABLE、ALTER TABLE、DROP TABLE 或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除。</li>
</ol>
<p>查询缓存的维护开销大、且容易引起数据一致性问题，因此在 MySQL8.0 中已经被删除。</p>
<h1>查询 - 单表查询方法</h1>
<p>MySQL 查询优化器会解析 SQL 得到执行计划，然后按照执行计划中的顺序调用 InnoDB 的接口来执行查询。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `single_table` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `key1` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key2` int(11) DEFAULT NULL,</span><br><span class="line">  `key3` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part1` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part2` varchar(100) DEFAULT NULL,</span><br><span class="line">  `key_part3` varchar(100) DEFAULT NULL,</span><br><span class="line">  `common_field` varchar(100) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `idx_key2` (`key2`),</span><br><span class="line">  KEY `idx_key1` (`key1`),</span><br><span class="line">  KEY `idx_key3` (`key3`),</span><br><span class="line">  KEY `idx_key_part` (`key_part1`,`key_part2`,`key_part3`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=73 DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure>
<h2 id="索引查询方法"><a class="header-anchor" href="#索引查询方法">¶</a>索引查询方法</h2>
<p>根据优化器的结果不同，可能会生成多种查询方法，可以使用 explain 来查看一个 SQL 使用了哪种查询方法。</p>
<h3 id="const"><a class="header-anchor" href="#const">¶</a>const</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e05c8e33?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE id = 1438;</span><br></pre></td></tr></table></figure>
<p>这种查询因为命中了聚簇索引，所以会直接用主键到聚簇索引中去查找。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 = 3841;</span><br></pre></td></tr></table></figure>
<p>这种通过**唯一(unique)**二级索引直接定位某几条数据的查询语句同样是非常快的，因此被称为 const。<br>
但是等值的查询还有一个例外，如果查询的是 NULL 值的记录，则可能访问到多条记录而导致无法使用 const 查询方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 IS NULL;</span><br></pre></td></tr></table></figure>
<h3 id="ref"><a class="header-anchor" href="#ref">¶</a>ref</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e5e227f1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
普通二级索引不限制索引列的唯一性，因此可能会检索到多条记录，然后再回表得到具体数据，这种情况相对 const 来说会稍微耗时一些，因此被称为 ref。<br>
注意：<br>
1、就算是唯一索引，NULL 值的匹配仍可能会匹配到多条，因此 key is null 这种形式的搜索会采用 ref 的访问方式。<br>
2、如果查询中包含范围查询则不是 ref：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key_part1 = &apos;god like&apos; AND key_part2 &gt; &apos;legendary&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="ref-or-null"><a class="header-anchor" href="#ref-or-null">¶</a>ref_or_null</h3>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/3/16a7b843e8927bee?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
当使用二级索引而且既查某个常数又查 NULL 值记录时，会采用 ref_or_null 查询方式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;abc&apos; OR key1 IS NULL;</span><br></pre></td></tr></table></figure>
<h3 id="range"><a class="header-anchor" href="#range">¶</a>range</h3>
<p>对索引进行范围查询：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79);</span><br></pre></td></tr></table></figure>
<h3 id="index"><a class="header-anchor" href="#index">¶</a>index</h3>
<p>要查询的列在二级索引内，但是又不是最左索引列，因此就算不能高效使用索引，InnoDB 也会优先从索引中遍历获取数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="all"><a class="header-anchor" href="#all">¶</a>all</h3>
<p>扫描聚簇索引，即全表扫描。</p>
<h2 id="确定范围区间"><a class="header-anchor" href="#确定范围区间">¶</a>确定范围区间</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 AND common_field = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<p>如上 SQL，因为 common_field 字段没有索引，因此确定范围时没有作用，优化器会先使用 idx_key2 索引确定范围，然后回表查到数据后再用<code>common_field = 'abc'</code>过滤。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 OR common_field = &apos;abc&apos;;</span><br></pre></td></tr></table></figure>
<p>其中关联条件被我们改成了 OR，这会导致全表扫描。<br>
为了直观地确定范围区间，我们可以把用不到索引的搜索条件直接替换成 TRUE：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key2 &gt; 100 OR TRUE;</span><br></pre></td></tr></table></figure>
<p>显然，这条语句会触发全表扫描。<br>
这种方法也可以应用到一些比较复杂的查询语句中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE </span><br><span class="line">        (key1 &gt; &apos;xyz&apos; AND key2 = 748 ) OR</span><br><span class="line">        (key1 &lt; &apos;abc&apos; AND key1 &gt; &apos;lmn&apos;) OR</span><br><span class="line">        (key1 LIKE &apos;%suf&apos; AND key1 &gt; &apos;zzz&apos; AND (key2 &lt; 8000 OR common_field = &apos;abc&apos;)) ;</span><br></pre></td></tr></table></figure>
<p>1、因为 where 语句中 key1、key2 都可以命中索引，因此候选的索引包括 idx_key1 和 idx_key2<br>
2、假设使用 idx_key1 执行查询，将不涉及该索引的条件都化简：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &gt; &apos;xyz&apos;;</span><br></pre></td></tr></table></figure>
<p>3、假设使用 idx_key2 执行查询，同理可化简：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE TRUE;</span><br></pre></td></tr></table></figure>
<p>因此优化器最终会采用 idx_key1。</p>
<h2 id="索引合并"><a class="header-anchor" href="#索引合并">¶</a>索引合并</h2>
<p>使用到多个索引来完成一次查询的执行方法被称为<strong>index merge</strong>，分 3 种情况：</p>
<h3 id="intersection-合并"><a class="header-anchor" href="#intersection-合并">¶</a>Intersection 合并</h3>
<p>某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;a&apos; AND key3 = &apos;b&apos;;</span><br></pre></td></tr></table></figure>
<p>为什么使用 2 个索引查询 merge 而不是一个查完后再过滤其他条件？主要是因为二级索引的操作是<strong>顺序 I/O</strong>，而回表操作是<strong>随机 I/O</strong>，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数相对更少，因此当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读取一个二级索引的成本更低。<br>
发生 Intersection 合并的条件：<br>
1、针对主键的范围查询；<br>
2、针对二级索引的等值匹配；<br>
为什么范围查询不行？因为二级索引中是按索引列排序的，只有等值匹配时结果才会按 id 列排序，而求并集时<br>
3、单独使用某个二级索引获取到的记录数太多，导致回表开销太大。</p>
<h3 id="union-合并"><a class="header-anchor" href="#union-合并">¶</a>Union 合并</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 = &apos;a&apos; OR key3 = &apos;b&apos;</span><br></pre></td></tr></table></figure>
<p>OR 相连的不同查询条件可能会使用到不同的索引，这种情况可能会使用到 Union 索引合并，具体的还分以下几种情况：<br>
1、二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。<br>
比如范围查询就无法使用 Union 合并。<br>
2、主键列可以是范围匹配；<br>
3、使用 Intersection 索引合并的搜索条件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key_part1 = &apos;a&apos; AND key_part2 = &apos;b&apos; AND key_part3 = &apos;c&apos; OR (key1 = &apos;a&apos; AND key3 = &apos;b&apos;);</span><br></pre></td></tr></table></figure>
<p>Intersection 索引合并得到的是一个主键的集合，Union 合并可以将多个这样的主键集合取交集。</p>
<h3 id="sort-union"><a class="header-anchor" href="#sort-union">¶</a>Sort-Union</h3>
<p>Union 合并的条件比较苛刻，要求全部查询条件都是等值查询，比如下面的查询语句就无法使用 Union 索引合并：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 &lt; &apos;a&apos; OR key3 &gt; &apos;z&apos;;</span><br></pre></td></tr></table></figure>
<p>因为按照两种查询条件得到的主键值并不是有序的，如果这两批主键值数量并不大，InnoDB 会再对这两批主键值进行排序，最后按照 Union 合并的方式进行合并。</p>
<h3 id="联合索引"><a class="header-anchor" href="#联合索引">¶</a>联合索引</h3>
<p>上面这个例子中，key1 和 key3 分别属于两个索引，如果把这两个列合一块搞一个联合索引，效率会更高。</p>
<h1>count</h1>
<h2 id="count-的实现方式"><a class="header-anchor" href="#count-的实现方式">¶</a>count(*) 的实现方式</h2>
<p>不同引擎对<code>count(*)</code>有不同的实现方式：</p>
<ul>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</li>
<li>而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>
</ul>
<h3 id="为什么-innodb-不把数字存起来？"><a class="header-anchor" href="#为什么-innodb-不把数字存起来？">¶</a>为什么 InnoDB 不把数字存起来？</h3>
<p>因为<strong>MVCC</strong>的存在，对每个事务来说返回多少行都是不确定的。</p>
<h3 id="innodb对count-的优化"><a class="header-anchor" href="#innodb对count-的优化">¶</a>InnoDB对count(*)的优化</h3>
<p>普通索引树比主键索引树小很多，因此对于<code>count(*)</code>这样的操作，MySQL更倾向于找到最小的那棵树来遍历。</p>
<h3 id="table-rows能替代count-吗？"><a class="header-anchor" href="#table-rows能替代count-吗？">¶</a>table_rows能替代count(*)吗？</h3>
<p><code>show table status</code>命令结果里也有一个table_rows用于显示这个表当前有多少行，但是这个值其实只是一个估计值，并不准。</p>
<h3 id="有什么办法能替代count-？"><a class="header-anchor" href="#有什么办法能替代count-？">¶</a>有什么办法能替代count(*)？</h3>
<p>为了替代<code>count(*)</code>，我们只能自己计数，也就是找一个地方存储表的行数。</p>
<ol>
<li>用缓存计数<br>
优点是速度快，但是缺点是缓存系统可能会丢失更新，比如两个事务都读了一遍Redis的值，然后在操作后将最新的值覆盖上，但是先写入的事务所做的更新会被后来的事务覆盖，也就是说发生了丢失更新。<br>
而且，Redis的重启、宕机都是不可避免的，发生这种情况后，怎么保证计数不丢失呢？<br>
一般来说需要将数据再持久化到DB上，但是如果写DB成功、同步Redis失败了，又会导致二者的不一致。这种情况当然是有解决的办法，比如Redis异常重启后就到数据库里面单独执行一次<code>count(*)</code>获取真实的行数，再把这个值写回到Redis里就可以了。<br>
总而言之，因为与数据库并不在一个事务内，不能保证Redis与数据库的绝对一致，因此Redis并不能提供精确的计数，只能供粗略的计数。</li>
<li>用数据库计数<br>
不同于Redis，只要保证计数和插入/删除数据命令处于同一条SQL内，基于数据库的计数就是精确的。</li>
</ol>
<h2 id="不同count的区别"><a class="header-anchor" href="#不同count的区别">¶</a>不同count的区别</h2>
<ol>
<li><code>count(*)</code><br>
<code>count(*)</code>并不会把全部字段取出来，而是专门做了优化，不取值，因为<code>count(*)</code>肯定不是null，直接按行累加即可。</li>
<li><code>count(主键ID)</code><br>
InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</li>
<li><code>count(1)</code><br>
InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</li>
<li><code>count(字段)</code><br>
表示返回满足条件的数据行里面，参数<code>字段</code>不为NULL的总个数。<br>
如果<code>字段</code>被定义成了<code>null</code>，则这个操作相对<code>count(主键ID)</code>会更慢一些，因为server层还需要一行一行判断值是否为null，只有不是null的才累加。</li>
</ol>
<p>所以结论是：按照效率排序的话，<code>count(字段)</code> &lt; <code>count(主键 id)</code> &lt; <code>count(1)</code> ≈ <code>count(*)</code>，所以建议尽量使用 <code>count(*)</code>。</p>
<h1>连接（Join）</h1>
<h2 id="连接查询的大致执行过程"><a class="header-anchor" href="#连接查询的大致执行过程">¶</a>连接查询的大致执行过程</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &apos;d&apos;;</span><br></pre></td></tr></table></figure>
<p>这个查询语句包含 3 个过滤条件，大致执行过程如下：<br>
1、确定第一个需要查询的表，称之为<strong>驱动表</strong>，InnoDB 会选取代价最小的方法去执行查询（从 const、ref、ref_or_null、range、index、all 这些执行方法中选取代价最小的去执行查询）；<br>
2、针对从驱动表中查询出的每一条记录，<strong>分别</strong>到其他表中查询匹配的记录，这些表称为<strong>被驱动表</strong>。<br>
因此，驱动表只会被查询一次，而被驱动表则会被查询多次。</p>
<h2 id="内连接和外连接"><a class="header-anchor" href="#内连接和外连接">¶</a>内连接和外连接</h2>
<p>内连接<br>
左连接（左外连接）：左侧的表为驱动表。<br>
右连接（右外连接）：右侧的表为驱动表。</p>
<p>对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合 ON 子句条件的记录时也会被加入到结果集，所以左连接和右连接的驱动表和被驱动表的位置不能轻易互换。</p>
<h2 id="连接的原理"><a class="header-anchor" href="#连接的原理">¶</a>连接的原理</h2>
<h3 id="嵌套循环连接-nested-loop-join"><a class="header-anchor" href="#嵌套循环连接-nested-loop-join">¶</a>嵌套循环连接（Nested-Loop Join）</h3>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-NestedLoopJoin%E7%AE%97%E6%B3%95.png" alt="MySQL-NestedLoopJoin算法" title="MySQL-NestedLoopJoin算法"><br>
驱动表中查询到的每条记录都需要分别到被驱动表中查找匹配的记录，当有 3 张表进行连接时，上一步得到的结果集就会成为新的驱动表，第 3 张表则成为了新的被驱动表，重复这个过程。<br>
这个过程就像是一个嵌套的循环，所以这种驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为<strong>嵌套循环连接（Nested-Loop Join）</strong>。</p>
<h3 id="simple-nested-loop-join"><a class="header-anchor" href="#simple-nested-loop-join">¶</a>Simple Nested-Loop Join</h3>
<p>到被驱动表上查询的时候没有命中索引，导致每次查询都是全表扫描，时间复杂度退化为<code>N * M</code>。<br>
实际上，MySQL 并没有使用这么简单粗暴的算法，而是<code>Block Nested-Loop Join</code>。</p>
<h3 id="基于块的嵌套循环连接-block-nested-loop-join"><a class="header-anchor" href="#基于块的嵌套循环连接-block-nested-loop-join">¶</a>基于块的嵌套循环连接（Block Nested-Loop Join）</h3>
<p>因为嵌套循环连接中，被驱动表可能被访问非常多次（现实中单表的数据量是非常大的），这个过程中涉及到随机磁盘扫描，因此效率并不高，为了减少这个 IO 代价，所以我们应该尽量减少访问被驱动表的次数。<br>
当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。<br>
优化方法是在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价了。<strong>join buffer</strong>就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个 join buffer 中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和 join buffer 中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的 I/O 代价。<br>
<img src="https://user-gold-cdn.xitu.io/2018/12/25/167e43ab3e5fa2f6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
这种加入了 join buffer 的嵌套循环连接算法被称为<strong>基于块的嵌套循环连接（Block Nested-Loop Join）</strong>。</p>
<ul>
<li>另外需要注意的是，驱动表的记录并不是所有列都会被放到 join buffer 中，只有查询列表中的列和过滤条件中的列才会被放到 join buffer 中，所以最好不要把*作为查询列表。</li>
<li>相对<code>Simple Nested-Loop Join</code>来说，<code>Block Nested-Loop Join</code>在时间复杂度上并没有提高，但是由于所有匹配操作都是内存操作，速度会快很多，性能也更好。</li>
<li>join buffer 的空间是有限的，如果放不下所有数据，则每次只放入一批，匹配完后清空 join buffer，再放另一批。</li>
</ul>
<h3 id="连接优化"><a class="header-anchor" href="#连接优化">¶</a>连接优化</h3>
<ol>
<li>索引<br>
对每一步得到的结果集（第一步时，这个结果集就是第一张驱动表），到被驱动表中匹配记录时，相当于执行等值查询，因此我们可以在被驱动表上的这个被关联字段上加索引来提高效率。这种在连接查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：<strong>eq_ref</strong>。</li>
<li>用小表作驱动表（能命中索引的情况下）<br>
假设驱动表的行数是 N，则遍历驱动表时间复杂度为<code>N</code>，假设被驱动表的行数是 M，则在被驱动表上查一行数据的时间复杂度是<code>2 * log2(M)</code>（这里假设索引树的基为 2，<code>2 *</code>是因为要先从二级索引找到记录的主键，然后再用主键从聚簇索引找到记录的其他字段），因此，join 查询的近似复杂度为<code>N + N*2*log2M</code>。<br>
显然，N 对扫描行数的影响更大，因此最好使用小表作为驱动表。</li>
<li>用小表作驱动表（不能命中索引，即 Block Nested-Loop Join 的情况）<br>
驱动表会被放入 join_buffer 中和被驱动表匹配，总的时间复杂度仍为<code>N * M</code>，N 被分成 K 段，K 与 N 成正比，可以表示为<code>K = λ * N</code>，因此，这个算法的扫描行数是<code>N + λ * N * M</code>，由于<code>N * M</code>的值不变，因此 N 越小这个算式的结果也会越小，所以，应该用小表作为驱动表。</li>
</ol>
<blockquote>
<p>小表的定义：各表按查询条件过滤，最终得到的总数据量中较小的那个。</p>
</blockquote>
<ol>
<li>调大<code>join_buffer_size</code><br>
上式中，除了 N 外，<code>λ</code>也是关键，这里<code>λ</code>其实主要与<code>join_buffer_size</code>有关，<code>join_buffer_size</code>越大，一次性放入 join_buffer 的行数越大，分成的段数也越少，对被驱动表的全表扫描次数也越少。</li>
</ol>
<h3 id="什么情况下可以使用-join"><a class="header-anchor" href="#什么情况下可以使用-join">¶</a>什么情况下可以使用 join</h3>
<p>查看 explain 结果里 Extra 字段里有没有出现<code>Block Nested Loop</code>：</p>
<ul>
<li>如果出现，则该 join 查询属于<code>Block Nested-Loop Join</code>，扫描行数过多，会占用大量资源，因此这种 join 尽量不要使用；</li>
<li>如果没有出现，说明该 join 查询属于<code>Index Nested-Loop Join</code>，这种 join 查询是没有问题的。</li>
</ul>
<h3 id="join-的进一步优化"><a class="header-anchor" href="#join-的进一步优化">¶</a>join 的进一步优化</h3>
<ol>
<li>
<p>MRR（Multi-Range Read）<br>
普通回表过程是一行一行地查数据——普通索引上定位到主键 id、然后从主键索引上查到整行数据，一般来说这个过程是随机读磁盘的，性能比较差。<br>
MRR 的核心思路是将 id 先保存到<code>read_rnd_buffer</code>，批量、按顺序地回表，这样排序后能达到接近顺序读磁盘的效果。</p>
</li>
<li>
<p>BKA（Batched Key Access）<br>
BKA 是对 NLJ 的优化。<br>
类似 MRR，从驱动表取值到被驱动表上执行 join 时，BKA 会先将驱动表上的记录先放到<code>join_buffer</code>，然后批量到执行 join 操作。<br>
如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set optimizer_switch=&apos;mrr=on,mrr_cost_based=off,batched_key_access=on&apos;;</span><br></pre></td></tr></table></figure>
<p>其中前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于 MRR。</p>
</li>
</ol>
<h1>基于成本的优化</h1>
<p>MySQL 的查询优化器会比较多种查询方案，得到成本最低的方案，即所谓<strong>执行计划</strong>，之后才会调用存储引擎提供的接口来执行查询，这个过程大致如下：<br>
1、根据搜索条件，找出所有可能使用的索引（<strong>possible keys</strong>）；<br>
2、计算全表扫描的代价；<br>
3、计算使用不同索引执行查询的代价；<br>
4、对比各种执行方案的代价，找出成本最低的那一个。</p>
<h2 id="计算代价"><a class="header-anchor" href="#计算代价">¶</a>计算代价</h2>
<p>1、全表扫描的代价<br>
全表扫描需要将聚簇索引所有页面加载到内存然后一一匹配，对全表扫描的性能统计涉及到聚簇索引占用的页面数和该表中的记录数，可以使用<code>SHOW TABLE STATUS</code>来统计这个信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW TABLE STATUS LIKE &apos;ad_content&apos;;</span><br></pre></td></tr></table></figure>
<p>结果中的<strong>Rows</strong>表示记录条数，在 MyISAM 中是准确的，而在 InnoDB 中则是一个估计值。因为全表扫描时需要判断每条记录是否满足条件，因此该值能粗略代表对该表执行全表扫描所需的<strong>CPU 成本</strong>。<br>
<strong>Data_length</strong>表示表占用的存储空间字节数，对于 MyISAM 来说就是数据文件的大小，对于 InnoDB 来说就是聚簇索引占用的存储空间大小。因为默认页面大小为 16KB，因此可以推导出聚簇索引的页面数量是<code>Data_length / 16 / 1024</code>，实际上可以粗略代表对该表执行全表扫描所需的<strong>IO 成本</strong>。<br>
2、二级索引的代价<br>
从二级索引中定位数据的 ID，<strong>回表</strong>（到聚簇索引）根据上一步的 ID 值找到完整的记录。<br>
另外，统计记录数量时，还会用到一个<strong>index dive</strong>的方法（MySQL 自创的一个方法），比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM single_table WHERE key1 IN (&apos;aa1&apos;, &apos;aa2&apos;, &apos;aa3&apos;, ... , &apos;zzz&apos;);</span><br></pre></td></tr></table></figure>
<p>由于 idx_key1 并不是唯一（unique）索引，因此<code>key1='aa1'</code>这些条件并不一定能唯一确定一条记录，查询优化器会先获取索引对应的 B+树的<strong>区间最左记录</strong>和<strong>区间最右记录</strong>，然后估算这两条记录之间有多少条记录，这种方式被称为<strong>index dive</strong>。<br>
当然<strong>index dive</strong>并不是一定会生效，如果 in 条件中的参数超过了<strong>阈值</strong>就不能生效，这个阈值可以通过<code>SHOW VARIABLES LIKE '%dive%';</code>查到。<br>
如果因为超过阈值（默认 200）而无法生效，则需要改用所谓的索引统计数据来进行估算，MySQL 也会为表中的每一个索引维护一份统计数据，可以使用<code>show index from 表名</code>来查看，其中有一个比较关键的字段<code>Cardinality</code>表示基数，即索引列中不重复值的个数，计算平均一个值重复次数即<code>Rows / Cardinality</code>，比如表里现在有 100 行数据，表基数为 2，则最终计算出的每个值会有的记录条数就是 50，对于上面那条 sql，如果<code>IN</code>条件中有 10000 个参数，则统计结果约需要回表的记录数就是<code>50 * 10000 = 500000</code>，不过这种方式相对<code>index dive</code>来说虽然简单，但是并不精确。<br>
3、多个二级索引的代价（索引合并 Index Merge）<br>
将多个搜索条件用 AND 连接之后，查询优化器还需要判断一下是否满足 Intersection 索引合并的条件，简而言之，如果查询出的记录都是按主键排序的，则可以采用 Intersection 索引合并。<br>
4、对比多种执行方案，找出成本最低的一种<br>
查询优化器在统计每种查询方式的代价时都会给一个<strong>代价常量</strong>，用于计算每一种方式的代价值，最后比较选取代价最小的那个。</p>
<h2 id="连接查询的成本"><a class="header-anchor" href="#连接查询的成本">¶</a>连接查询的成本</h2>
<h3 id="单表连接"><a class="header-anchor" href="#单表连接">¶</a>单表连接</h3>
<p>对两表的连接查询来说，查询成本主要包括：<br>
1、单次查询驱动表的成本；<br>
2、根据第一步查出的结果（称为<strong>扇出</strong>）多次查询被驱动表的成本。</p>
<p>所以，判断连接查询成本的方法是计算扇出值的大小：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本</span><br></pre></td></tr></table></figure>
<p>当连接方式为外连接，则驱动表是固定的，因此查询时只要为驱动表和被驱动表选择最优访问方式即可，但是如果是内连接，驱动表和被驱动表的位置是可以互换的，那么优化器会使用索引统计数据来进行比较选择。</p>
<h3 id="多表连接"><a class="header-anchor" href="#多表连接">¶</a>多表连接</h3>
<p>如果是 n 张表的内连接，计算的时间复杂度将是单表连接的 n!倍，当然优化器并不是老老实实地这么做：<br>
1、预先设定最小连接成本，只要少于这个值就采用这种连接方式；<br>
2、只对<code>optimizer_search_depth</code>张表执行连接顺序成本的分析，这个值是一个系统变量，显然越大则成本分析越精确；<br>
3、启发式规则：如果满足一些规则则直接不分析，这些规则被称为启发式规则。</p>
<h1>Explain</h1>
<h2 id="explain-各列的含义"><a class="header-anchor" href="#explain-各列的含义">¶</a>Explain 各列的含义</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select * from auth_user;</span><br><span class="line"></span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |</span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">| 1 | SIMPLE | auth_user | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL |</span><br><span class="line">+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>列名	描述<br>
id	在一个大的查询语句中每个 SELECT 关键字都对应一个唯一的 id<br>
select_type	SELECT 关键字对应的那个查询的类型<br>
table	表名<br>
partitions	匹配的分区信息<br>
type	针对单表的访问方法<br>
possible_keys	可能用到的索引<br>
key	实际上使用的索引<br>
key_len	实际使用到的索引长度<br>
ref	当使用索引列等值查询时，与索引列进行等值匹配的对象信息<br>
rows	预估的需要读取的记录条数<br>
filtered	某个表经过搜索条件过滤后剩余记录条数的百分比<br>
Extra	一些额外的信息</p>
<h2 id="explain-各列描述"><a class="header-anchor" href="#explain-各列描述">¶</a>Explain 各列描述</h2>
<h3 id="table"><a class="header-anchor" href="#table">¶</a>table</h3>
<p>表示该查询的目标表，当涉及到连接时会有多行分别表示对各张表的访问方式。</p>
<h3 id="id"><a class="header-anchor" href="#id">¶</a>id</h3>
<p>查询语句中每有一个 select 关键字，MySQL 就会为其分配一个唯一的 id 值，如果 select 中包含多张表的连接，则每张表都会有一条记录、且这些记录中的 id 值都是相同的。</p>
<h3 id="select-type"><a class="header-anchor" href="#select-type">¶</a>select_type</h3>
<ul>
<li>SIMPLE<br>
查询语句中不包含 UNION 或者子查询的查询都算作是 SIMPLE 类型。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1;</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2;</span><br></pre></td></tr></table></figure>
<ul>
<li>PRIMARY<br>
对于包含 UNION、UNION ALL 或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的 select_type 值就是 PRIMARY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2;</span><br></pre></td></tr></table></figure>
<ul>
<li>UNION<br>
对于包含 UNION 或者 UNION ALL 的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的 select_type 值就是 UNION。</li>
<li>UNION RESULT<br>
MySQL 选择使用临时表来完成 UNION 查询的去重工作，针对该临时表的查询的 select_type 就是 UNION RESULT。</li>
<li>SUBQUERY<br>
如果包含子查询的查询语句不能够转为对应的 semi-join 的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个 SELECT 关键字代表的那个查询的 select_type 就是 SUBQUERY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>DEPENDENT SUBQUERY<br>
如果包含子查询的查询语句不能够转为对应的 semi-join 的形式，并且该子查询是相关子查询，则该子查询的第一个 SELECT 关键字代表的那个查询的 select_type 就是 DEPENDENT SUBQUERY。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE s1.key2 = s2.key2) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>DEPENDENT UNION<br>
在包含 UNION 或者 UNION ALL 的大查询中，如果各个小查询都依赖于外层查询的话，那除了最左边的那个小查询之外，其余的小查询的 select_type 的值就是 DEPENDENT UNION。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE key1 = &apos;a&apos; UNION SELECT key1 FROM s1 WHERE key1 = &apos;b&apos;);</span><br></pre></td></tr></table></figure>
<p>其中<code>SELECT key1 FROM s2 WHERE key1 = 'a'</code>这个查询是 DEPENDENT SUBQUERY，而<code>UNION</code>后面的那个查询就是 DEPENDENT UNION。</p>
<ul>
<li>DERIVED<br>
对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的 select_type 就是 DERIVED。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM (SELECT key1, count(*) as c FROM s1 GROUP BY key1) AS derived_s1 where c &gt; 1;</span><br></pre></td></tr></table></figure>
<ul>
<li>MATERIALIZED<br>
当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的 select_type 属性就是 MATERIALIZED。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2);</span><br></pre></td></tr></table></figure>
<ul>
<li>UNCACHEABLE SUBQUERY<br>
不常用</li>
<li>UNCACHEABLE UNION<br>
不常用</li>
</ul>
<h3 id="partitions"><a class="header-anchor" href="#partitions">¶</a>partitions</h3>
<p>分区，一般查询计划中的该字段都是 NULL。</p>
<h3 id="type"><a class="header-anchor" href="#type">¶</a>type</h3>
<p>对某张表执行查询时的访问方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>由于 idx_key1 二级索引的存在，因此这个等值查询的 type 列的值为 ref。具体的访问方法如下所示：</p>
<ul>
<li>system<br>
当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如<strong>MyISAM</strong>、<strong>Memory</strong>，那么对该表的访问方法就是 system。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM t;</span><br></pre></td></tr></table></figure>
<ul>
<li>const<br>
当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是 const。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE id = 5;</span><br></pre></td></tr></table></figure>
<ul>
<li>eq_ref<br>
在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是 eq_ref。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;</span><br></pre></td></tr></table></figure>
<ul>
<li>ref<br>
当通过普通的二级索引列与常量进行等值匹配时来查询某个表，那么对该表的访问方法就可能是 ref。</li>
<li>fulltext<br>
全文索引。</li>
<li>ref_or_null<br>
当对普通二级索引进行等值匹配查询，该索引列的值也可以是 NULL 值时，那么对该表的访问方法就可能是 ref_or_null。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; OR key1 IS NULL;</span><br></pre></td></tr></table></figure>
<ul>
<li>index_merge<br>
包括 Intersection、Union、Sort-Union 这三种索引合并方式</li>
<li>unique_subquery<br>
类似于两表连接中被驱动表的 eq_ref 访问方法，unique_subquery 是针对在一些包含 IN 子查询的查询语句中，如果查询优化器决定将 IN 子查询转换为 EXISTS 子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的 type 列的值就是 unique_subquery，比如下边的这个查询语句：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>index_subquery<br>
index_subquery 与 unique_subquery 类似，只不过访问子查询中的表时使用的是普通的索引</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key3 FROM s2 where s1.key1 = s2.key1) OR key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>range<br>
如果使用索引获取某些范围区间的记录，那么就可能使用到 range 访问方法。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;);</span><br><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 &gt; &apos;a&apos; AND key1 &lt; &apos;b&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>index<br>
当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是 index。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT key_part2 FROM s1 WHERE key_part3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>ALL<br>
全表扫描。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1;</span><br></pre></td></tr></table></figure>
<h3 id="possible-keys-和-key"><a class="header-anchor" href="#possible-keys-和-key">¶</a>possible_keys 和 key</h3>
<p>possible_keys 列表示在某个查询语句中，对某个表执行单表查询时可能用到的索引有哪些，key 列表示实际用到的索引有哪些。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这条 sql，因为 key1 和 key3 分别可以命中 idx_key1 和 idx_key3 这两个索引，因此 possible_keys 列的值包含这二者。</p>
<h3 id="key-len"><a class="header-anchor" href="#key-len">¶</a>key_len</h3>
<p>key_len 列表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度。</p>
<h3 id="ref-v2"><a class="header-anchor" href="#ref-v2">¶</a>ref</h3>
<p>当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是 const、eq_ref、ref、ref_or_null、unique_subquery、index_subquery 其中之一时，ref 列表示与索引列进行匹配的目标类型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 因为与key1进行匹配的&apos;a&apos;是常量，因此ref列的值为const</span><br><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos;;</span><br><span class="line">-- 与id列比较，ref值为对应库.对应表.id</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;</span><br><span class="line">-- 与函数进行比较，ref值为func</span><br><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s2.key1 = UPPER(s1.key1);</span><br></pre></td></tr></table></figure>
<h3 id="rows"><a class="header-anchor" href="#rows">¶</a>rows</h3>
<p>如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的 rows 列就代表预计需要扫描的行数，如果使用索引来执行查询时，执行计划的 rows 列就代表预计扫描的索引记录行数。</p>
<h3 id="filtered"><a class="header-anchor" href="#filtered">¶</a>filtered</h3>
<p>优化器估算 rows 中满足搜索条件的记录的百分比。</p>
<h3 id="extra"><a class="header-anchor" href="#extra">¶</a>Extra</h3>
<p>额外信息的种类比较多：</p>
<ul>
<li>No tables used<br>
当查询语句的没有 FROM 子句时将会提示该额外信息</li>
<li>Impossible WHERE<br>
查询语句的 WHERE 子句永远为 FALSE 时将会提示该额外信息：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE 1 != 1;</span><br></pre></td></tr></table></figure>
<ul>
<li>No matching min/max row<br>
当查询列表处有 MIN 或者 MAX 聚集函数，但是并没有符合 WHERE 子句中的搜索条件的记录时，将会提示该额外信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT MIN(key1) FROM s1 WHERE key1 = &apos;abcdefg&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using index<br>
当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用<strong>索引覆盖</strong>的情况下，在 Extra 列将会提示该额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT key1 FROM s1 WHERE key1 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using index condition<br>
有些搜索条件中虽然出现了索引列，但却不能使用到索引</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key1 LIKE &apos;%a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这个条件中，优化器会先根据<code>key1 &gt; 'z'</code>从二级索引<code>idx_key1</code>中定位到符合的二级索引记录，但是不会直接回表，而是先根据<code>key1 LIKE '%a'</code>找到匹配的记录再回表，这被称为<strong>索引条件下推</strong>。<br>
索引下推应用于多条件查询上，5.6之前，查了一个条件后就会尝试回表得到结果，然后再对结果过滤其他字段，比如上面查完<code>key1 &gt; 'z'</code>后就会回表；而5.6之后，如果有多个条件会先尝试在联合索引上进行过滤再回表，比如上面先根据<code>key1 &gt; 'z'</code>查询，再使用<code>key1 LIKE '%a'</code>过滤，最后才回表。</p>
<ul>
<li>Using Where<br>
当我们使用全表扫描来执行对某个表的查询，并且该语句的 WHERE 子句中有针对该表的搜索条件时，在 Extra 列中会提示上述额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<p>当使用索引访问来执行对某个表的查询，并且该语句的 WHERE 子句中有除了该索引包含的列之外的其他搜索条件时，在 Extra 列中也会提示上述额外信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; AND common_field = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using join buffer (Block Nested Loop)<br>
在连接查询执行过程中，当被驱动表不能有效的利用索引加快访问速度，MySQL 一般会为其分配一块名叫<strong>join buffer</strong>的内存块来加快查询速度，也就是我们所讲的<strong>基于块的嵌套循环算法</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.common_field = s2.common_field;</span><br></pre></td></tr></table></figure>
<ul>
<li>Not exists<br>
当我们使用左（外）连接时，如果 WHERE 子句中包含要求被驱动表的某个列等于 NULL 值的搜索条件，而且那个列又是不允许存储 NULL 值的，那么在该表的执行计划的 Extra 列就会提示 Not exists 额外信息。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 LEFT JOIN s2 ON s1.key1 = s2.key1 WHERE s2.id IS NULL;</span><br></pre></td></tr></table></figure>
<p>左外连接时如果被驱动表中匹配不到驱动表的某条记录，则该条记录对应的 <a href="http://s2.id" target="_blank" rel="noopener">s2.id</a> 就为 NULL。</p>
<ul>
<li>Using intersect(…)、Using union(…)和 Using sort_union(…)<br>
如果执行计划的 Extra 列出现了 Using intersect(…)提示，说明准备使用 Intersect 索引合并的方式执行查询，括号中的…表示需要进行索引合并的索引名称；如果出现了 Using union(…)提示，说明准备使用 Union 索引合并的方式执行查询；出现了 Using sort_union(…)提示，说明准备使用 Sort-Union 索引合并的方式执行查询。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 = &apos;a&apos; AND key3 = &apos;a&apos;;</span><br></pre></td></tr></table></figure>
<ul>
<li>Zero limit<br>
当我们的 LIMIT 子句的参数为 0 时，表示压根儿不打算从表中读出任何记录，将会提示该额外信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 LIMIT 0;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using filesort<br>
有一些情况下对结果集中的记录进行排序是可以使用到索引的。但是很多情况下排序操作无法使用到索引，只能在内存中（记录较少的时候）或者磁盘中（记录较多的时候）进行排序，这种在内存中或者磁盘上进行排序的方式统称为文件排序（filesort）。如果某个查询需要使用<strong>文件排序</strong>的方式执行查询，就会在执行计划的 Extra 列中显示 Using filesort 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 ORDER BY key1 LIMIT 10;</span><br></pre></td></tr></table></figure>
<ul>
<li>Using temporary<br>
在许多查询的执行过程中，MySQL 可能会借助临时表来完成一些功能，比如去重、排序之类的，比如我们在执行许多包含 DISTINCT、GROUP BY、UNION 等子句的查询过程中，如果不能有效利用索引来完成查询，MySQL 很有可能寻求通过建立内部的<strong>临时表</strong>来执行查询。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT DISTINCT common_field FROM s1;</span><br></pre></td></tr></table></figure>
<ul>
<li>Start temporary, End temporary<br>
我们前边唠叨子查询的时候说过，查询优化器会优先尝试将 IN 子查询转换成 semi-join，而 semi-join 又有好多种执行策略，当执行策略为 DuplicateWeedout 时，也就是通过建立临时表来实现为外层查询中的记录进行去重操作时，驱动表查询执行计划的 Extra 列将显示 Start temporary 提示，被驱动表查询执行计划的 Extra 列将显示 End temporary 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 WHERE common_field = &apos;a&apos;);</span><br></pre></td></tr></table></figure>
<ul>
<li>LooseScan<br>
在将 In 子查询转为 semi-join 时，如果采用的是 LooseScan 执行策略，则在驱动表执行计划的 Extra 列就是显示 LooseScan 提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE key3 IN (SELECT key1 FROM s2 WHERE key1 &gt; &apos;z&apos;);</span><br></pre></td></tr></table></figure>
<ul>
<li>FirstMatch(tbl_name)<br>
在将 In 子查询转为 semi-join 时，如果采用的是 FirstMatch 执行策略，则在被驱动表执行计划的 Extra 列就是显示 FirstMatch(tbl_name)提示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key1 FROM s2 where s1.key3 = s2.key3);</span><br></pre></td></tr></table></figure>
<h2 id="optimizer-trace"><a class="header-anchor" href="#optimizer-trace">¶</a>optimizer trace</h2>
<p>查看优化器生成执行计划的整个过程，这个功能的开启与关闭由系统变量 optimizer_trace 决定：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &apos;optimizer_trace&apos;;</span><br></pre></td></tr></table></figure>
<p>这个 optimizer_trace 表中有 4 个列：</p>
<ul>
<li>QUERY：表示我们的查询语句。</li>
<li>TRACE：表示优化过程的 JSON 格式文本。</li>
<li>MISSING_BYTES_BEYOND_MAX_MEM_SIZE：由于优化过程可能会输出很多，如果超过某个限制时，多余的文本将不会被显示，这个字段展示了被忽略的文本字节数。</li>
<li>INSUFFICIENT_PRIVILEGES：表示是否没有权限查看优化过程，默认值是 0，只有某些特殊情况下才会是 1，我们暂时不关心这个字段的值。</li>
</ul>
<p>optimizer trace 使用步骤如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 1. 打开optimizer trace功能 (默认情况下它是关闭的):</span><br><span class="line">SET optimizer_trace=&quot;enabled=on&quot;;</span><br><span class="line"></span><br><span class="line"># 2. 这里输入你自己的查询语句</span><br><span class="line">SELECT ...; </span><br><span class="line"></span><br><span class="line"># 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程</span><br><span class="line">SELECT * FROM information_schema.OPTIMIZER_TRACE;</span><br><span class="line"></span><br><span class="line"># 4. 可能你还要观察其他语句执行的优化过程，重复上边的第2、3步</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># 5. 当你停止查看语句的优化过程时，把optimizer trace功能关闭</span><br><span class="line">SET optimizer_trace=&quot;enabled=off&quot;;</span><br></pre></td></tr></table></figure>
<p>优化过程大致分为了三个阶段：<br>
1、prepare 阶段<br>
2、optimize 阶段<br>
单表查询需要重点关注 rows_estimation 这个过程，因为分析了对单表查询的各种执行方案的成本；<br>
对于夺标连接查询，更多的需要关注 considered_execution_plans 这个过程，因为这个过程里会写明各种不同的连接方式所对应的成本。<br>
3、execute 阶段</p>
<h1>QA</h1>
<h2 id="什么时候会发生文件排序？如何优化"><a class="header-anchor" href="#什么时候会发生文件排序？如何优化">¶</a>什么时候会发生文件排序？如何优化</h2>
<p>如果没有用到索引，InnoDB 排序前一般会先将数据加载到内存的<strong>sort_buffer</strong>中，或者由于数据量太大需要借助磁盘空间来存放中间结果，排序完后再将结果集返回给客户端，在 MySQL 中，这种在内存或磁盘上进行排序的方式被称为<strong>文件排序（filesort）</strong>。<br>
order by 语句最好能使用到覆盖索引，因为索引本身就对记录进行了排序，并且需要注意索引字段的顺序。</p>
<h2 id="什么是索引下推"><a class="header-anchor" href="#什么是索引下推">¶</a>什么是索引下推</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM s1 WHERE key1 &gt; &apos;z&apos; AND key1 LIKE &apos;%a&apos;;</span><br></pre></td></tr></table></figure>
<p>上面这个条件中，优化器会先根据<code>key1 &gt; 'z'</code>从二级索引<code>idx_key1</code>中定位到符合的二级索引记录，但是不会直接回表，而是先根据<code>key1 LIKE '%a'</code>找到匹配的记录再回表，这被称为<strong>索引条件下推</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/937fe6d5.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/937fe6d5.html" itemprop="url">MySQL 中的日志</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-26T10:18:28+08:00">
                2020-05-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>redo log</h1>
<p>实现持久性的方式：<br>
1、在事务提交完成之前把该事务所修改的所有页面都刷新到磁盘；<br>
但是只修改了一点数据也刷新整个页比较浪费，且一次写入可能涉及到很多不连续的页，这样随机 IO 效率比较低。<br>
2、把修改了哪些东西记录一下就好，即使系统崩溃也能恢复<br>
即 redo log，优点是占用空间小、顺序写入。</p>
<h2 id="wal-write-ahead-logging"><a class="header-anchor" href="#wal-write-ahead-logging">¶</a>WAL（Write-Ahead Logging）</h2>
<p>先写日志，再写磁盘，同时，InnoDB 引擎会在系统相对空闲的时候将操作记录同步到磁盘上。<br>
WAL 保证了 InnoDB 是<strong>crash-safe</strong>的，因为即使数据库发生异常重启，之前提交的记录都不会丢失。</p>
<h2 id="redo-log-的结构"><a class="header-anchor" href="#redo-log-的结构">¶</a>redo log 的结构</h2>
<p>每条 redo log 会记录以下属性：</p>
<ul>
<li>type：该条 redo 日志的类型。</li>
<li>space ID：表空间 ID。</li>
<li>page number：页号。</li>
<li>data：该条 redo 日志的具体内容。</li>
</ul>
<p>对不同类型字段作修改时会记录不同类型的 redo log，比如：</p>
<ul>
<li>表中没有主键时，会生成一个<code>row_id</code>隐藏列保存到 data 字段里；</li>
<li>涉及变长字符串类型的 redo log 因为不确定具体占用多少字段空间，因此 data 字段中还有一个<code>len</code>字段。</li>
</ul>
<h2 id="mini-transaction"><a class="header-anchor" href="#mini-transaction">¶</a>Mini-Transaction</h2>
<p>在 MySQL 中对底层页面中的一次原子访问的过程称之为一个<code>Mini-Transaction</code>，简称<code>mtr</code>，一个 mtr 可以包含一组 redo log，在进行崩溃恢复时这一组 redo log 是一个不可分割的整体。<br>
比如插入一条记录的时候，如果数据页的空闲空间不足，需要进行页分裂操作：新建一个叶子节点，然后把原先数据页中的一部分记录复制到这个新的数据页中，然后再把记录插入进去，把这个叶子节点插入到叶子节点链表中，最后还要在内节点中添加一条目录项记录指向这个新创建的页面。这个过程中需要对多个页面进行改改，因此会产生多条 redo log，这个过程必须是原子的，InnoDB 会以组的形式来记录 redo log，崩溃恢复时要么整组恢复、要么一条也不恢复，因此被称为<strong>悲观插入</strong>。</p>
<blockquote>
<p>如果数据页的空闲空间充足则可以直接插入，这种方式被称为<strong>乐观插入</strong>。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-MiniTransaction.png" alt="MySQL-MiniTransaction" title="MySQL-MiniTransaction"></p>
</blockquote>
<h2 id="redo-日志的存储结构"><a class="header-anchor" href="#redo-日志的存储结构">¶</a>redo 日志的存储结构</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-redolog.png" alt="MySQL-redolog" title="MySQL-redolog"><br>
MySQL 会向操作系统申请一块<strong>redo log buffer</strong>连续内存空间，这块内存空间之后被划分为若干连续 redo log block。<br>
InnoDB 会维护一个全局变量<code>buf_free</code>，指示后续 redo 日志应该写入到 log buffer 中的哪个位置。<br>
最终 redo log 会被刷新到磁盘中被称为<strong>block</strong>的页中，其中关键字段包括：</p>
<ul>
<li>该 block 的唯一标识；</li>
<li>第一条 redo 日志偏移量：一个 mtr 会生成多条 redo 日志记录（redo log record），这些日志被统称为一个 redo 日志记录组（redo log record group），block 会记录这个 redo 日志记录组第一条记录的偏移量。</li>
<li>checkpoint 的序号。</li>
<li>lsn：每条日志都有一个序列号<strong>Log Sequence Number</strong>，简称为<strong>lsn</strong>，它的值是不断增长的，初始值为 8704，lsn 值越小，则说明该 redo log 生成的时间越早。</li>
</ul>
<h2 id="redo-log-刷盘时机"><a class="header-anchor" href="#redo-log-刷盘时机">¶</a>redo log 刷盘时机</h2>
<p>当内存数据页和磁盘数据页内容不一致时，我们称这个内存页为&quot;脏页&quot;，内存数据写入到磁盘后，内存和磁盘上的数据页内容就一致了称为&quot;干净页&quot;，，redo log 就是内存数据页，而 B+树结构的聚簇索引就是磁盘数据页。<br>
redo log 会被复制到 log buffer 中，但是 log buffer 的空间是有限的，当满足一定条件时需要被刷新到磁盘里：</p>
<ul>
<li>log buffer 空间不足时<br>
log buffer 的大小是有限的（通过系统变量<code>innodb_log_buffer_size</code>指定），当要读入的数据页没有在内存中的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页就必须将脏页先刷到磁盘，变成干净页后才能复用。</li>
<li>事务提交时<br>
我们前边说过之所以使用 redo 日志主要是因为它占用的空间少，还是顺序写，在事务提交时可以不把修改过的 Buffer Pool 页面刷新到磁盘，但是为了保证持久性，必须要把修改这些页面对应的 redo 日志刷新到磁盘。</li>
<li>后台线程的执行<br>
后台有一个线程，大约每秒都会刷新一次 log buffer 中的 redo 日志到磁盘。</li>
<li>正常关闭服务器时</li>
<li>做<strong>checkpoint</strong>时</li>
</ul>
<h3 id="批量从-flush-链表中刷出脏页"><a class="header-anchor" href="#批量从-flush-链表中刷出脏页">¶</a>批量从 flush 链表中刷出脏页</h3>
<p>我们在介绍 Buffer Pool 的时候说过，一般情况下都是后台的线程在对 LRU 链表和 flush 链表进行刷脏操作，这主要因为刷脏操作比较慢，不想影响用户线程处理请求。但是如果当前系统修改页面的操作十分频繁，这样就导致写日志操作十分频繁，系统 lsn 值增长过快。如果后台的刷脏操作不能将脏页刷出，那么系统无法及时做 checkpoint，可能就需要用户线程同步的从 flush 链表中把那些最早修改的脏页（oldest_modification 最小的脏页）刷新到磁盘，这样这些脏页对应的 redo 日志就没用了，然后就可以去做 checkpoint 了。</p>
<h3 id="查看各种-lsn-值"><a class="header-anchor" href="#查看各种-lsn-值">¶</a>查看各种 LSN 值</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINE INNODB STATUS</span><br></pre></td></tr></table></figure>
<ul>
<li>Log sequence number：代表系统中的 lsn 值，也就是当前系统已经写入的 redo 日志量，包括写入 log buffer 中的日志。</li>
<li>Log flushed up to：代表 flushed_to_disk_lsn 的值，也就是当前系统已经写入磁盘的 redo 日志量。</li>
<li>Pages flushed up to：代表 flush 链表中被最早修改的那个页面对应的 oldest_modification 属性值。</li>
<li>Last checkpoint at：当前系统的 checkpoint_lsn 值。</li>
</ul>
<h3 id="innodb-flush-log-at-trx-commit"><a class="header-anchor" href="#innodb-flush-log-at-trx-commit">¶</a>innodb_flush_log_at_trx_commit</h3>
<p>为了保证事务的持久性，一般来说用户线程在事务提交时需要将该事务执行过程中产生的所有 redo 日志都刷新到磁盘上。<br>
但是出于效率上的考虑，可以修改<code>innodb_flush_log_at_trx_commit</code>的取值来调整这个过程：</p>
<ul>
<li>0：当该系统变量值为 0 时，表示在事务提交时不立即向磁盘中同步 redo 日志，这个任务是交给后台线程做的。<br>
这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将 redo 日志刷新到磁盘，那么该事务对页面的修改会丢失。</li>
<li>1：当该系统变量值为 1 时，表示在事务提交时需要将 redo 日志同步到磁盘，可以保证事务的持久性。1 也是<code>innodb_flush_log_at_trx_commit</code>的默认值。</li>
<li>2：当该系统变量值为 2 时，表示在事务提交时需要将 redo 日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。<br>
这种情况下如果数据库挂了，操作系统没挂的话，事务的持久性还是可以保证的，但是操作系统也挂了的话，那就不能保证持久性了。</li>
</ul>
<h2 id="崩溃恢复"><a class="header-anchor" href="#崩溃恢复">¶</a>崩溃恢复</h2>
<p>1、确定恢复的起点<br>
<code>checkpoint_lsn</code>之前的 redo 日志都可以被覆盖，也就是说这些 redo 日志对应的脏页都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。对于<code>checkpoint_lsn</code>之后的 redo 日志，它们对应的脏页可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从<code>checkpoint_lsn</code>开始读取 redo 日志来恢复页面。<br>
redo 日志文件组的第一个文件的管理信息中有两个 block 都存储了 checkpoint_lsn 的信息，我们当然是要选取最近发生的那次 checkpoint 的信息。衡量 checkpoint 发生时间早晚的信息就是所谓的 checkpoint_no，我们只要把 checkpoint1 和 checkpoint2 这两个 block 中的 checkpoint_no 值读出来比一下大小，哪个的 checkpoint_no 值更大，说明哪个 block 存储的就是最近的一次 checkpoint 信息。这样我们就能拿到最近发生的 checkpoint 对应的 checkpoint_lsn 值以及它在 redo 日志文件组中的偏移量 checkpoint_offset。<br>
2、确定恢复的终点<br>
普通 block 的 log block header 部分有一个称之为 LOG_BLOCK_HDR_DATA_LEN 的属性，该属性值记录了当前 block 里使用了多少字节的空间。<br>
<img src="https://user-gold-cdn.xitu.io/2019/3/26/169b8990b6d085cd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
对于已经填满的 block 来说，该值就是 512，也就是说如果该值不是 512，那么它就是这次崩溃恢复中需要扫描的最后一个 block 了。<br>
3、恢复<br>
确定起点和终点后，我们就可以按照 redo log 的顺序依次扫描<code>checkpoint_lsn</code>之后的各条 redo 日志来执行恢复了。</p>
<h2 id="redo-log-flush"><a class="header-anchor" href="#redo-log-flush">¶</a>redo log flush</h2>
<p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“<strong>脏页</strong>”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“<strong>干净页</strong>”。<br>
MySQL 偶尔的<strong>抖动</strong>，很有可能就是在<strong>刷脏页（flush）</strong>。<br>
有以下几种情况都会引起 flush：</p>
<ul>
<li>redo log 写满了，需要释放一些空间，将 checkpoint 往前推进，并将之间的日志对应的脏页都 flush 到磁盘上。</li>
<li>系统内存不足，需要新的内存页时内存不够用了，需要淘汰一些数据页，空出内存来给其他数据页使用，如果淘汰的是脏页，则需要先将脏页写入到磁盘。</li>
<li>空闲期间，MySQL 会自动用过剩的计算能力执行 flush 任务。</li>
<li>正常关闭时，MySQL 会将内存的脏页都 flush 到磁盘。</li>
</ul>
<h1>bin log</h1>
<p>WAL 机制保证了 MySQL 数据不会丢失，WAL 的核心是 <strong>bin log</strong> 和 <strong>redo log</strong>。</p>
<h2 id="bin-log-与-redo-log-区别"><a class="header-anchor" href="#bin-log-与-redo-log-区别">¶</a>bin log 与 redo log 区别</h2>
<p>1、redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。<br>
2、redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。<br>
3、redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>
<ol>
<li>bin log 只能用于归档，没有 crash-safe 能力，而 redo log 是 InnoDB 的，可以提供 crash-safe 能力。</li>
</ol>
<h2 id="binlog-写入机制"><a class="header-anchor" href="#binlog-写入机制">¶</a>binlog 写入机制</h2>
<ol>
<li>事务执行过程中，先把日志写到 binlog cache；</li>
<li>事务提交的时候，再把 binlog cache 写入到 binlog 文件中。</li>
</ol>
<p>binlog 写入的关键是要保证原子性：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-binlog%E5%86%99%E7%9B%98.png" alt="MySQL-binlog写盘" title="MySQL-binlog写盘"></p>
<ol>
<li>每个线程有自己的 binlog cache，但是共用同一份 binlog 文件；</li>
<li>上图的<code>write</code>指的是把日志写入文件系统的<code>page cache</code>，并没有把数据持久化到磁盘，所以速度较快；</li>
<li>上图的<code>fsync</code>才是将数据持久化到磁盘的操作。</li>
</ol>
<p>redo log 会被先写入到 <strong>redo log buffer</strong> 内，分以下几种情况：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-redolog%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81.png" alt="MySQL-redolog存储状态" title="MySQL-redolog存储状态"></p>
<ol>
<li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；</li>
<li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；</li>
<li>持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。</li>
</ol>
<p>redo log buffer 写入磁盘的时机：</p>
<ol>
<li>后台线程每秒轮询，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘；</li>
<li>redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。</li>
<li>并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。</li>
</ol>
<h2 id="bin-log-格式"><a class="header-anchor" href="#bin-log-格式">¶</a>bin log 格式</h2>
<p>bin log 有 3 种格式：</p>
<ul>
<li>statement: 存的是语句原文，可能会导致主备不一致，比如在主库和之后在备库上执行时选取的索引不一样；</li>
<li>row: 会记录具体作用的目标数据，比较占用空间、且会消耗大量 IO 资源；<br>
比如一条 delete 语句，statement 格式的 bin log 会直接记录该语句，而 row 格式会记录具体删除的记录的 ID。</li>
<li>mixed: 自动判断 SQL 语句是否可能导致主备不一致，若有可能则采用 row，否则 statement。</li>
</ul>
<h2 id="查看-bin-log"><a class="header-anchor" href="#查看-bin-log">¶</a>查看 bin log</h2>
<p>本地创建配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line">[mysqld]</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">expire-logs-days=14</span><br><span class="line">server-id=1</span><br><span class="line">binlog_format=statement</span><br></pre></td></tr></table></figure>
<p>使用 Docker 启动 MySQL 进程，注意-v 前面是宿主机的配置文件所在目录，后面是容器内的配置文件目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -v /Users/huanggaochi/Downloads/mysql:/etc/mysql/conf.d -d mysql:5.7</span><br></pre></td></tr></table></figure>
<p>连接时如果遇到文件，可以使用<code>docker logs [CONTAINER ID]</code>查看容器启动日志。</p>
<p>连接 MySQL 后查看 bin log 是否有被开启：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;log_bin&apos;;</span><br></pre></td></tr></table></figure>
<p>下面是测试用 SQL 语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `a` (`a`),</span><br><span class="line">  KEY `t_modified`(`t_modified`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into t values(1,1,&apos;2018-11-13&apos;);</span><br><span class="line">insert into t values(2,2,&apos;2018-11-12&apos;);</span><br><span class="line">insert into t values(3,3,&apos;2018-11-11&apos;);</span><br><span class="line">insert into t values(4,4,&apos;2018-11-10&apos;);</span><br><span class="line">insert into t values(5,5,&apos;2018-11-09&apos;);</span><br><span class="line"></span><br><span class="line">delete from t /*comment*/  where a&gt;=4 and t_modified&lt;=&apos;2018-11-10&apos; limit 1;</span><br></pre></td></tr></table></figure>
<p>运行后，查看 bin log：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show binlog events in &apos;mysql-bin.000001&apos;;</span><br></pre></td></tr></table></figure>
<h1>undo log</h1>
<p>需要回滚的情况：<br>
1、事务执行过程中可能遇到各种错误，比如服务器本身的错误，操作系统错误，甚至是突然断电导致的错误。<br>
2、程序员可以在事务执行过程中手动输入 ROLLBACK 语句结束当前的事务的执行。<br>
为了有需要时能够回滚，每当我们要对一条记录做改动时都需要将回滚时所需的东西都记录一下，包括：<br>
1、插入记录时，记录主键，这样回滚时直接删除这条记录即可；<br>
2、删除记录时，将这条记录的内容记录下来，回滚时重新插入即可；<br>
3、修改记录时，将旧值记录下来，回滚时重新更新回旧值。</p>
<h2 id="事务-id-trx-id"><a class="header-anchor" href="#事务-id-trx-id">¶</a>事务 ID（trx_id）</h2>
<h3 id="分配时机"><a class="header-anchor" href="#分配时机">¶</a>分配时机</h3>
<p>如果某个事务执行过程中对某个表执行了增、删、改操作，那么 InnoDB 存储引擎就会给它分配一个独一无二的事务 id。<br>
1、只读事务（START TRANSACTION READ ONLY）<br>
只读事务中不可以对普通的表进行增删改操作，但可以对临时表做增、删、改操作。<br>
对于只读事务来说，只有在它第一次对某个用户创建的临时表执行增、删、改操作时才会为这个事务分配一个事务 id，否则的话是不分配事务 id 的。<br>
2、读写事务（START TRANSACTION READ WRITE、BEGIN、START TRANSACTION）<br>
在读写事务中可以对表执行增删改查操作。<br>
对于读写事务来说，只有在它第一次对某个表（包括用户创建的临时表）执行增、删、改操作时才会为这个事务分配一个事务 id，否则的话也不会分配事务 id</p>
<p>总而言之，<strong>只有在事务对表中的记录做改动时才会为这个事务分配一个唯一的事务 id</strong>。</p>
<h3 id="生成方式"><a class="header-anchor" href="#生成方式">¶</a>生成方式</h3>
<p>和 row_id 的生成方式类似：</p>
<ul>
<li>服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个事务 id 时，就会把该变量的值当作事务 id 分配给该事务，并且把该变量自增 1。</li>
<li>每当这个变量的值为 256 的倍数时，就会将该变量的值刷新到系统表空间的页号为 5 的页面中一个称之为 Max Trx ID 的属性处，这个属性占用 8 个字节的存储空间。</li>
<li>当系统下一次重新启动时，会将上边提到的 Max Trx ID 属性加载到内存中，将该值加上 256 之后赋值给我们前边提到的全局变量（因为在上次关机时该全局变量的值可能大于 Max Trx ID 属性值）。</li>
</ul>
<h2 id="undo-log-格式"><a class="header-anchor" href="#undo-log-格式">¶</a>undo log 格式</h2>
<p>1、查看 table id<br>
记录 undo log 时会使用到表的 table id，这个值可以通过<code>SELECT * FROM information_schema.innodb_sys_tables WHERE name = 'database_name/undo_demo';</code>这条命令来查看<br>
2、INSERT 操作的 undo log<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afa8857a9e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
undo no 在一个事务中是从 0 开始递增的，也就是说只要事务没提交，每生成一条 undo 日志，那么该条日志的 undo no 就增 1。<br>
主键可能是有多个列组成的，如果有多个列，则每个列占用的存储空间大小和对应的真实值都需要记录下来。<br>
比如对下面这条插入了两条记录的 SQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BEGIN;  # 显式开启一个事务，假设该事务的id为100</span><br><span class="line"></span><br><span class="line"># 插入两条记录</span><br><span class="line">INSERT INTO undo_demo(id, key1, col) </span><br><span class="line">    VALUES (1, &apos;AWM&apos;, &apos;狙击枪&apos;), (2, &apos;M416&apos;, &apos;步枪&apos;);</span><br></pre></td></tr></table></figure>
<p>针对这两条数据生成的 undo log 如下所示：<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af96301bdd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af943ce197?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
3、DELETE 操作对应的 undo log<br>
插入到页面中的记录会通过头信息中的<code>next_record</code>属性组成一个单向链表，而被删除的记录则会组成另一个链表，<code>Page Header</code>中的<code>PAGE_FREE</code>属性指向了这个链表的头节点。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af99f1eb4e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
删除时会先将记录的<code>delete_mask</code>标识位设置为 1，表示已经被逻辑删除了。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afc12f5533?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
当该删除语句所在的事务提交之后，会有专门线程将记录真正地清除掉：将该记录从链表中移除并移入自由链表中。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875afc377e08f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
由上可知，在事务执行完毕之前，记录并不会被真正地清除，所以回滚时也只需要将这个删除标识清除即可。<br>
3、UPDATE 操作的 undo log<br>
不更新主键的情况下，如果更新后的列和更新前的列值占用的存储空间一样大，那么就可以执行<code>就地更新</code>，直接在原记录上修改对应列的值；但是如果有任何一个列更新后占用的存储空间大小有变化，那么就需要将旧的记录从聚簇索引页面中删除（这是真正的删除，不是逻辑删除），然后创建一条新的记录插入到页面中。<br>
更新主键的情况下，旧记录会执行<code>delete mark</code>操作，由一个后台线程做 purge 操作，将其加入到垃圾链表中。</p>
<h2 id="roll-pointer-隐藏列"><a class="header-anchor" href="#roll-pointer-隐藏列">¶</a>roll_pointer 隐藏列</h2>
<p>每条记录的结构中都包含了一个 roll_pointer 隐藏列，其实这个字段是指向该记录对应 undo log 的指针。<br>
<img src="https://user-gold-cdn.xitu.io/2019/6/24/16b875af986df5c6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<h2 id="undo-log-写入过程"><a class="header-anchor" href="#undo-log-写入过程">¶</a>undo log 写入过程</h2>
<p><a href="https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c923cf3f265da60fb3bea67" target="_blank" rel="noopener">https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c923cf3f265da60fb3bea67</a></p>
<h1>slow log</h1>
<h2 id="查看慢查询日志"><a class="header-anchor" href="#查看慢查询日志">¶</a>查看慢查询日志</h2>
<p>查看是否开启慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &quot;%slow%&quot;;</span><br></pre></td></tr></table></figure>
<p>使用 sql 命令开启慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set global slow_query_log=1</span><br></pre></td></tr></table></figure>
<p>设置慢查询阈值，执行超过该时间的 sql 将被视作慢查询：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set global long_query_time=4</span><br></pre></td></tr></table></figure>
<p>注意修改这个阈值后需要重新连接或新开一个会话才能看到修改值。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/86b66af2.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/86b66af2.html" itemprop="url">MySQL 中的事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-25T10:18:28+08:00">
                2020-05-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  29 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="事务语法"><a class="header-anchor" href="#事务语法">¶</a>事务语法</h2>
<p>1、开启事务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 注意后面的WORK可有可无</span><br><span class="line">BEGIN [WORK];</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- START TRANSACTION和BEGIN的区别主要是前者还能指定事务的访问模式，如果不设置访问模式，</span><br><span class="line">则默认是READ WRITE模式</span><br><span class="line">START TRANSACTION [READ ONLY | READ WRITE | WITH CONSISTENT SNAPSHOT];</span><br></pre></td></tr></table></figure>
<p>需要注意的是，<code>begin/start transaction</code>并不是事务的起点，当执行到第一个操作 InnoDB 表的语句时事务才真正启动。或者可以使用<code>start transaction with consistent snapshot</code>来立刻启动。<br>
2、提交事务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">COMMIT [WORK];</span><br></pre></td></tr></table></figure>
<p>3、手动中止事务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ROLLBACK [WORK];</span><br></pre></td></tr></table></figure>
<p>注意，ROLLBACK 语句是我们程序员手动的去回滚事务时才去使用的，如果事务在执行过程中遇到了某些错误而无法继续执行的话，事务自身会自动的回滚。<br>
4、事务中涉及到的所有表都支持事务<br>
目前只有 InnoDB 和 NDB 存储引擎是支持事务的，如果某个事务中操作的表使用的是不支持事务的表，则对这些表所做的修改将无法被回滚。<br>
5、自动提交</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &apos;autocommit&apos;;</span><br></pre></td></tr></table></figure>
<p>如果这个自动提交开关是打开的，则只要我们不显式使用 START TRANSACTION 或者 BEGIN 语句开启一个事务，那么每一条语句都算是一个独立的事务，这种特性称之为事务的自动提交。<br>
6、隐式提交<br>
就算 autocommit 开关是关闭的，如果我们输入了某些语句还是会触发隐式的提交，包括：<br>
DDL：CREATE、ALTER、DROP<br>
对系统表执行的操作：ALTER USER、CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD<br>
事务控制或关于锁定的语句：当我们在一个事务还没提交或者回滚时就又使用 START TRANSACTION 或者 BEGIN 语句开启了另一个事务时，会隐式的提交上一个事务；或原来 autocommit 为 OFF 的情况下将其修改为 ON，也会触发隐式提交；或者使用 LOCK TABLES、UNLOCK TABLES 等关于锁定的语句也会隐式的提交前边语句所属的事务。<br>
加载数据的语句：比如我们使用 LOAD DATA 语句来批量往数据库中导入数据时，也会隐式的提交前边语句所属的事务。<br>
关于 MySQL 复制的一些语句：使用 START SLAVE、STOP SLAVE、RESET SLAVE、CHANGE MASTER TO 等语句时也会隐式的提交前边语句所属的事务。<br>
其它的一些语句：使用 ANALYZE TABLE、CACHE INDEX、CHECK TABLE、FLUSH、 LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE、RESET 等语句也会隐式的提交前边语句所属的事务。<br>
7、保存点<br>
在事务执行的某个阶段设置检查点，下次回滚时可以回滚至此处，而不是从头开始：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SAVEPOINT 保存点名称;</span><br><span class="line">ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称;</span><br><span class="line">RELEASE SAVEPOINT 保存点名称;</span><br></pre></td></tr></table></figure>
<h2 id="事务的属性"><a class="header-anchor" href="#事务的属性">¶</a>事务的属性</h2>
<p>事务具有以下 4 个基本特征：</p>
<h3 id="原子性-atomic"><a class="header-anchor" href="#原子性-atomic">¶</a>原子性(Atomic)</h3>
<p>事务中包含的每个操作都被看做一个逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。（记录之前的版本，允许回滚）。</p>
<h3 id="一致性-consistency"><a class="header-anchor" href="#一致性-consistency">¶</a>一致性(Consistency)</h3>
<p>事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。换句话说，事务执行前和事务执行后数据内在的逻辑始终是成立的。比如转帐前后两人的存款总和始终不变。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这时数据库就处于一种不正确的状态，或者说是不一致的状态。例如在一在进行转账的操作中，需要从账户 A 取出 100 元转入账户 B。那么就可以定义一个事务，该事物包括两个操作：第一个操作是从账户 A 中减去 100 元，第二个操作是向账户 B 中转入 100 元。这两个操作要么全做，要么全不做。全做或者全不做，数据库就会处于一致性状态。如果只做一个操作，则逻辑上就会发生错误，减少或增加 100 元，数据库就 处于不一致的状态了。所以说一致性和原子性是密不可分的。</p>
<p>但是现在问题来了——<strong>原子性就一定能够保证一致性吗？</strong><br>
答案是否定的：原子性不能完全保证一致性。因为在多个事务并行进行的情况下，即使保证了每个事务的原子性，仍然可能导致数据不一致的结果。例如事务 1 需要将 100 元转入账户 A：先读取 A 的账户余额的值，然后在这个值上加上 100.但是，在这两个操作之间，事务 2 修改了账户 A 的值，为它增加了 100 元，那么最后结果应该是 A 增加了 200 元。但事实上，当事务 1 最终完成时，账户 A 只增加了 100 元，因为事务 2 的执行结果被事务 1 覆盖掉了。所以为了保证并发事务的一致性，就引入了事务的隔离性。(事务开始和结束之间的中间状态不会被其他事务看到)</p>
<h3 id="隔离性-isolation"><a class="header-anchor" href="#隔离性-isolation">¶</a>隔离性(Isolation)</h3>
<p>一个事务的执行不能被其他事务干扰。即一个事务的内部操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能互相干扰。要达到这么一种效果：对于任意两个并发的事务 T1 和 T2，T2 要么在 T1 开始之前就已经结束，要么在 T1 结束之后才开始，这样每个事务都感觉不到有其他事务在并发的执行。关于事务的隔离性数据库提供了多种隔离级别，后面会提到。(适当地破坏一致性来提升性能与并行度 例如：最终一致 ~= 读未提交)</p>
<h3 id="持久性-durability"><a class="header-anchor" href="#持久性-durability">¶</a>持久性(Durability)</h3>
<p>持久性是指一个事务一旦提交，它对数据库中数据的改变就是永久性的。接下来的操作或故障不应该对其执行结果有影响。(每一次的事务提交之后就会保证不丢失)</p>
<h2 id="事务的状态"><a class="header-anchor" href="#事务的状态">¶</a>事务的状态</h2>
<p>事务是一个抽象的概念，它对应一个或多个数据库操作。根据这些操作所执行的不同阶段，我们可以把事务大致划分为以下几个状态：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%BA%8B%E5%8A%A1%E7%8A%B6%E6%80%81.png" alt="MySQL-事务状态" title="MySQL-事务状态"><br>
如上图可知，事务从活动的开始，直到提交或中止状态时生命周期才算结束，当事务是已提交的，它做的修改会持久生效（事务的<strong>持久性</strong>），当事务中止，该事务所做的一切修改都会被回滚（<strong>原子性</strong>）。<br>
1、活动的（active）<br>
事务对应的数据库操作正在执行过程中时，我们就说该事务处在活动的状态。<br>
2、部分提交的（partially committed）<br>
当事务中的最后一个操作执行完成，但由于操作都在内存中执行，所造成的影响并没有刷新到磁盘时，我们就说该事务处在部分提交的状态。<br>
3、失败的（failed）<br>
当事务处在活动的或者部分提交的状态时，可能遇到了某些错误（数据库自身的错误、操作系统错误或者直接断电等）而无法继续执行，或者人为的停止当前事务的执行，我们就说该事务处在失败的状态。<br>
4、中止的（aborted）<br>
事务执行到一半出错会变为失败状态，此时，需要进行回滚，即撤销失败事务对当前数据库造成的影响，回滚完毕后，事务就处在了中止的状态。<br>
比如 A 向 B 转账，A 账户扣除后遇到错误，导致 B 账户余额没变，此时需要将 A 账户的扣减操作回滚，恢复到原来的金额。<br>
5、提交的（committed）<br>
当一个处在部分提交的状态的事务将修改过的数据都同步到磁盘上之后，我们就可以说该事务处在了提交的状态。</p>
<h2 id="事务隔离级别"><a class="header-anchor" href="#事务隔离级别">¶</a>事务隔离级别</h2>
<h3 id="事务并发执行可能遇到的问题"><a class="header-anchor" href="#事务并发执行可能遇到的问题">¶</a>事务并发执行可能遇到的问题</h3>
<p>在不保证串行执行的情况下，多个事务的并行执行可能会导致一些问题，按由重到轻分别为：<br>
1、脏写（Dirty Write）：一个事务修改了另一个未提交事务修改过的数据；<br>
2、脏读（Dirty Read）：一个事务读到了另一个未提交事务修改过的数据；<br>
3、不可重复读（Non-Repeatable Read）：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值；<br>
4、幻读（Phantom）：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。</p>
<p>隔离级别越低，越严重的问题就越可能发生，按隔离级别的严格程度由轻到严分别为：<br>
1、READ UNCOMMITTED：未提交读。<br>
2、READ COMMITTED：已提交读。<br>
3、REPEATABLE READ：可重复读。<br>
4、SERIALIZABLE：可串行化。</p>
<p>隔离级别	脏读	不可重复读	幻读<br>
READ UNCOMMITTED	Possible	Possible	Possible<br>
READ COMMITTED	Not Possible	Possible	Possible<br>
REPEATABLE READ	Not Possible	Not Possible	Possible<br>
SERIALIZABLE	Not Possible	Not Possible	Not Possible</p>
<h3 id="设置隔离级别"><a class="header-anchor" href="#设置隔离级别">¶</a>设置隔离级别</h3>
<p>以可重复读为例，设置某次连接的事务隔离级别：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br></pre></td></tr></table></figure>
<h3 id="隔离级别与-mvcc-锁之间的关系"><a class="header-anchor" href="#隔离级别与-mvcc-锁之间的关系">¶</a>隔离级别与 MVCC、锁之间的关系</h3>
<p>接下来我们会讨论如何实现各种隔离级别，原理是利用 MVCC 机制和各种锁，因此这里提前说明一下实现各种隔离级别所需的技术：</p>
<p>隔离级别 | 是否使用 MVCC | 是否使用行锁 | 是否使用间隙锁</p>
<ul>
<li>| - | -<br>
读未提交 | 否 | 否，忽略其他事务放置的锁 | 否<br>
读已提交 | 是 | 是 | 否<br>
可重复读 | 是，与读已提交的区别是创建 ReadView 的时机不同 | 是 | 是<br>
序列化 | 否，所有事务序列化执行，没有使用 MVCC 的必要了 | 是 | 是</li>
</ul>
<h3 id="幻读与间隙锁"><a class="header-anchor" href="#幻读与间隙锁">¶</a>幻读与间隙锁</h3>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E5%BD%93%E5%89%8D%E8%AF%BB%E4%BE%8B%E5%AD%902.png" alt="MySQL-当前读例子2" title="MySQL-当前读例子2"><br>
注意上图中的 Q1、Q2、Q3 语句末尾带了<code>for update</code>，说明均为当前读，并会加上写锁，可以看到，Q3 语句看到了 Session B 和 Session C 插入的记录，说明发生了<strong>幻读</strong>的现象。</p>
<ol>
<li>在<strong>可重复读隔离级别</strong>下，普通的查询是<strong>快照读</strong>，是不会看到别的事务插入的数据的。因此，幻读在<strong>当前读</strong>下才会出现。<br>
当前读包括写操作和加锁的查询语句（<code>for update</code>）。</li>
<li>Q2 读到了 Session B 更新的数据，这个修改结果是可以被<strong>当前读</strong>看到的，但不能称为幻读，幻读特指新插入的行被其他事务读到了。</li>
</ol>
<blockquote>
<p>当前读的规则是要读到所有已经提交的记录的最新值。</p>
</blockquote>
<h4 id="幻读可能导致的问题及解决办法-间隙锁"><a class="header-anchor" href="#幻读可能导致的问题及解决办法-间隙锁">¶</a>幻读可能导致的问题及解决办法 - 间隙锁</h4>
<p>由于当前读只会对<strong>当前可见</strong>的那些记录进行加锁，因此上述两种情况引入的<strong>新记录</strong>都是锁不上的，锁不上一方面导致可重复读的语义被破坏，因为我要把所有满足条件的记录都锁住，但是事务执行期间却有其他事务引入的满足条件的记录没有被锁住；另一方面是数据一致性问题，如下图所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E5%B9%BB%E8%AF%BB%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98.png" alt="MySQL-幻读导致的数据不一致问题" title="MySQL-幻读导致的数据不一致问题"><br>
执行期间：</p>
<ol>
<li>经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的；</li>
<li>经过 T2 时刻，id=0 这一行变成 (0,5,5)；</li>
<li>经过 T4 时刻，表里面多了一行 (1,5,5)；</li>
<li>其他行跟这个执行序列无关，保持不变。</li>
</ol>
<p>但是 binlog 中的内容：</p>
<ol>
<li>T2 时刻，session B 事务提交，写入了两条语句；</li>
<li>T4 时刻，session C 事务提交，写入了两条语句；</li>
<li>T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。</li>
</ol>
<p>注意 binlog 中 T1 的语句位置变到了最后提交的时候执行。</p>
<p>那么 update 和 insert 引入“新记录”有什么区别呢？为什么只有 insert 这种情况被称为幻读而要单独拿出来讲？其实是因为，就算我们在当前读的时候就算把所有记录都加上锁（极端情况），新插入的记录因为其还未被分配存储空间，所以我们是无法为其加锁的。<br>
MySQL 中解决幻读的方式是<strong>间隙锁</strong>，在给对应记录加行锁的同时，MySQL 还会给行两边的间隙加间隙锁，行锁和间隙锁又合称<strong>Next-Key Lock</strong>。<br>
不同于行锁，间隙锁之间是不存在冲突关系的，跟间隙锁存在冲突关系的，是“往这个间隙中插入一条记录”这个操作。</p>
<h4 id="间隙锁的生效条件"><a class="header-anchor" href="#间隙锁的生效条件">¶</a>间隙锁的生效条件</h4>
<ol>
<li>事务的隔离级别是可重复读</li>
<li>查找过程中访问到的对象才会加锁<br>
查找并非特指<code>select</code>，不管是<code>delete</code>还是<code>update</code>，语句执行的第一步都是先找到对象，因此这些语句都会用到锁。</li>
</ol>
<h4 id="间隙锁存在的问题-死锁"><a class="header-anchor" href="#间隙锁存在的问题-死锁">¶</a>间隙锁存在的问题 - 死锁</h4>
<p>间隙锁可能会引起<strong>死锁</strong>，如下图所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E9%97%B4%E9%9A%99%E9%94%81%E5%BC%95%E8%B5%B7%E7%9A%84%E6%AD%BB%E9%94%81.png" alt="MySQL-间隙锁引起的死锁" title="MySQL-间隙锁引起的死锁">……</p>
<ol>
<li>session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10)；</li>
<li>session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>
<li>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；</li>
<li>session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</li>
</ol>
<p>可见，两个 session 进入了互相等待的状态，形成了死锁，可见，死锁会导致同样的语句锁住更大的范围，这其实是影响了并发度的。<br>
如果需要避免这种死锁，可以：</p>
<ul>
<li>将隔离级别设置为读提交，但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。</li>
</ul>
<h2 id="mvcc-原理"><a class="header-anchor" href="#mvcc-原理">¶</a>MVCC 原理</h2>
<p>MVCC 利用 Read View（一致性读视图）来表示数据一个可见的状态，当数据当前的 Read View 是不可见时，能够通过 undo log 串联起来的版本链回溯找到数据可见的版本。</p>
<h3 id="undo-log"><a class="header-anchor" href="#undo-log">¶</a>undo log</h3>
<p>在 InnoDB 引擎中，聚簇索引都会有 2 个隐藏列：</p>
<blockquote>
<p>row_id 并不是必要的，我们创建的表中有主键或者非 NULL 的 UNIQUE 键时都不会包含 row_id 列</p>
</blockquote>
<ul>
<li>trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务 id 赋值给 trx_id 隐藏列。</li>
<li>roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到 undo 日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-undolog.png" alt="MySQL-undolog" title="MySQL-undolog"></li>
</ul>
<p>这个<strong>undo log</strong>就是 MVCC 的核心，undo log 的类型包括：<br>
1、insert undo：在事务正式提交之后就可以被释放掉了，因为要回滚插入操作直接将记录删掉即可；<br>
2、update undo：因为 update undo 还需要支持 MVCC，不能直接释放。</p>
<p>每次修改记录时，都会记录一条 undo log，每条 undo log 都有一个 roll_pointer 属性，因此所有 undo log 实际山可以组成一个链表，称为<strong>版本链</strong>：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E7%89%88%E6%9C%AC%E9%93%BE.png" alt="MySQL-版本链" title="MySQL-版本链"><br>
版本链的头节点就是当前记录最新的值，注意每条 undo log 都含有一个事务 id（trx_id）。</p>
<h3 id="read-view-一致性读视图"><a class="header-anchor" href="#read-view-一致性读视图">¶</a>Read View (一致性读视图)</h3>
<p>Read View 只有在 READ COMMITTED、REPEATABLE READ 两种隔离级别下才能生效。<br>
READ UNCOMMITTED：由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本；<br>
SERIALIZABLE：加锁；<br>
READ COMMITTED、REPEATABLE READ：只能读到已提交的事务修改过的记录，因此需要判断一下版本链中的<strong>哪个版本是当前事务可见的</strong>。</p>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E6%95%B0%E6%8D%AE%E7%89%88%E6%9C%AC%E5%8F%AF%E8%A7%81%E6%80%A7%E8%A7%84%E5%88%99.png" alt="MySQL-数据版本可见性规则" title="MySQL-数据版本可见性规则"><br>
对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：</p>
<ul>
<li>落在中间部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>
<li>落在右边，表示这个版本是由将来启动的事务生成的，不可见；</li>
<li>如果落在左边，若 row trx_id 在数组中，表示这个版本是由还未提交的事务生成的，不可见；若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li>
</ul>
<p>总而言之，除了自己的更新总是可见以外，有三种情况：</p>
<ul>
<li>版本未提交，不可见；</li>
<li>版本已提交，但是是在视图创建后提交的，不可见；</li>
<li>版本已提交，而且是在视图创建前提交的，可见。</li>
</ul>
<p>如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。<br>
虽然期间这行数据可能被修改过，但是事务不论在什么时候查询，看到这行数据的结构都是一致的，所以我们称之为<strong>一致性读</strong>。</p>
<p>前面提过 READ COMMITTED、REPEATABLE READ 都需要维护版本，它们之间的区别主要是<strong>生成 ReadView 的时机</strong>不同。</p>
<h3 id="read-committed-每次读取数据前生成一个-readview"><a class="header-anchor" href="#read-committed-每次读取数据前生成一个-readview">¶</a>READ COMMITTED - <strong>每次</strong>读取数据前生成一个 ReadView</h3>
<p>1、首先有两个事务在执行：<br>
ID 为 100 的事务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Transaction 100</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;关羽&apos; WHERE number = 1;</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;张飞&apos; WHERE number = 1;</span><br></pre></td></tr></table></figure>
<p>ID 为 200 的事务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Transaction 200</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line"># 更新了一些别的表的记录</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>此时，表 hero 中 number 为 1 的记录得到的版本链表如下所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-ReadView%E7%89%88%E6%9C%AC%E9%93%BE.png" alt="MySQL-ReadView版本链" title="MySQL-ReadView版本链"></p>
<p>2、上面两个事务正在执行的过程中，如果有一个使用 READ COMMITTED 隔离级别的事务开始执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用READ COMMITTED隔离级别的事务</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line"># SELECT1：Transaction 100、200未提交</span><br><span class="line">SELECT * FROM hero WHERE number = 1; # 得到的列name的值为&apos;刘备&apos;</span><br></pre></td></tr></table></figure>
<p>这个 SELECT1 的执行过程如下：</p>
<ul>
<li>在执行 SELECT 语句时会先生成一个 ReadView，ReadView 中的 trx_id 列表为<code>[100, 200]</code>；</li>
<li>trx_id=100 的事务写入了两个版本，这些版本处在未提交事务集合内，因此不符合可见性要求，跳到下面的版本；</li>
<li>跳到刘备这个版本后，因为 trx_id=80，处于已提交事务集合内，是可见的，因此最终返回的版本就是这条数据。</li>
</ul>
<p>3、提交其中一个事务<br>
我们把事务 id 为 100 的事务提交一下，就像这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Transaction 100</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;关羽&apos; WHERE number = 1;</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;张飞&apos; WHERE number = 1;</span><br><span class="line"></span><br><span class="line">COMMIT;</span><br></pre></td></tr></table></figure>
<p>然后再到事务 id 为 200 的事务中更新一下表 hero 中 number 为 1 的记录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Transaction 200</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line"># 更新了一些别的表的记录</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;赵云&apos; WHERE number = 1;</span><br><span class="line"></span><br><span class="line">UPDATE hero SET name = &apos;诸葛亮&apos; WHERE number = 1;</span><br></pre></td></tr></table></figure>
<p>此刻，表 hero 中 number 为 1 的记录的版本链如下所示：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-ReadView%E7%89%88%E6%9C%AC%E9%93%BE1.png" alt="MySQL-ReadView版本链1" title="MySQL-ReadView版本链1"></p>
<p>4、然后再到刚才使用 READ COMMITTED 隔离级别的事务中继续查找这个 number 为 1 的记录，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 使用READ COMMITTED隔离级别的事务</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line"># SELECT1：Transaction 100、200均未提交</span><br><span class="line">SELECT * FROM hero WHERE number = 1; # 得到的列name的值为&apos;刘备&apos;</span><br><span class="line"></span><br><span class="line"># SELECT2：Transaction 100提交，Transaction 200未提交</span><br><span class="line">SELECT * FROM hero WHERE number = 1; # 得到的列name的值为&apos;张飞&apos;</span><br></pre></td></tr></table></figure>
<p>这个 SELECT2 的执行过程如下：</p>
<ul>
<li>在执行 SELECT 语句时会<strong>又单独生成一个 ReadView</strong>，该 ReadView 的 trx_id 列表为<code>[200]</code>，此时 trx_id 为 100 的事务已经提交了；</li>
<li>头两个版本诸葛亮、赵云因为版本 trx_id=200 处于未提交事务集合内，因此不可见；</li>
<li>下一个版本张飞可见，因此被返回。</li>
</ul>
<h3 id="repeatable-read-在第一次读取数据时生成一个-readview"><a class="header-anchor" href="#repeatable-read-在第一次读取数据时生成一个-readview">¶</a>REPEATABLE READ - 在<strong>第一次</strong>读取数据时生成一个 ReadView</h3>
<p>READ COMMITTED 会在<strong>每次</strong>读取数据时生成 ReadView，而 REPEATABLE READ 则只在<strong>第一次</strong>读取数据时生成一个 ReadView，之后的查询就不会重复生成了。<br>
同上一节中的例子，在 REPEATABLE READ 隔离级别的事务中多次查找这个 number 为 1 的记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 使用REPEATABLE READ隔离级别的事务</span><br><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line"># SELECT1：Transaction 100、200均未提交</span><br><span class="line">SELECT * FROM hero WHERE number = 1; # 得到的列name的值为&apos;刘备&apos;</span><br><span class="line"></span><br><span class="line"># SELECT2：Transaction 100提交，Transaction 200未提交</span><br><span class="line">SELECT * FROM hero WHERE number = 1; # 得到的列name的值仍为&apos;刘备&apos;</span><br></pre></td></tr></table></figure>
<p>这个 SELECT2 的执行过程如下：</p>
<ul>
<li>因为当前事务的隔离级别为 REPEATABLE READ，而之前在执行 SELECT1 时已经生成过 ReadView 了，所以此时直接复用之前的 ReadView，快照中的 trx_id 列表为<code>[100, 200]</code>。</li>
<li>头几个版本诸葛亮、赵云、张飞、关羽均不符合可见性原则；</li>
<li>下一个版本刘备 trx_id 为 80，符合可见性原则，因此返回。</li>
</ul>
<p>之后该事务不论何时查找，结果都会是这样。</p>
<h3 id="更新"><a class="header-anchor" href="#更新">¶</a>更新</h3>
<p>更新数据都是先读后写的，如果按照之前读取的规则，当前事务应该是读取不到其他更新的事务所做的修改的，但是这样可能会导致其他事务的更新丢失，因此更新操作的读取都是读当前的值，即<strong>当前读（current read）</strong>。</p>
<blockquote>
<p>除了 update 语句外，如果 select 语句加锁也是当前读，可以用 lock in share mock（读锁）或 for update（写锁）语句来加锁。</p>
</blockquote>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E5%BD%93%E5%89%8D%E8%AF%BB.png" alt="MySQL-当前读" title="MySQL-当前读"><br>
如上图所示，事务 A、B 刚开始时就创建了视图，事务 C 没有显式使用 begin/commit，表示该 update 语句本身就是一个事务。</p>
<ol>
<li>刚开始，id 为 1 的记录的字段 k 值为 1；</li>
<li>事务 C 更新 k 为 2；</li>
<li>由于当前读的规则，事务 B 在 update 时能看到 k 为 2，并更新为 3，注意因为更新后最新版本是当前事务写入的，因此当前事务之后的读操作总是可以读到最新的数据。</li>
<li>事务 A 在继续查询时，依据版本链找到可见的 k 为 1。</li>
</ol>
<p>可见，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，我们称之为<strong>一致性读</strong>。</p>
<p>注意，上面的事务 C 更新完后直接提交了，如果不提交，由于二段锁协议，事务 B 将一直等待 C 提交事务。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%AD%BB%E9%94%81.png" alt="MySQL-死锁" title="MySQL-死锁"></p>
<h3 id="删除"><a class="header-anchor" href="#删除">¶</a>删除</h3>
<p>DELETE 语句并不会立即将记录从页面中清除，而是执行一个所谓的<strong>delete mark</strong>操作，为此，表的每一行记录都会额外增加一个删除版本号（delete_version）。<br>
1、新增<br>
| - | - | - |</p>
<table>
<thead>
<tr>
<th>id</th>
<th>create_version</th>
<th>delete_version</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td></td>
</tr>
</tbody>
</table>
<p>2、更新<br>
采用 delete+add 的方式实现，将老数据行标志为删除，然后新增一行新的数据：</p>
<p>| - | - | - |</p>
<table>
<thead>
<tr>
<th>id</th>
<th>create_version</th>
<th>delete_version</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td></td>
</tr>
</tbody>
</table>
<p>3、删除<br>
删除会直接将数据的删除版本号更新为当前事务的版本号：</p>
<p>| - | - | - |</p>
<table>
<thead>
<tr>
<th>id</th>
<th>create_version</th>
<th>delete_version</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>4、查询<br>
为了避免查到旧数据或已经被其他事务更改过的数据，需要满足：</p>
<ul>
<li>当前事务的版本号需要大于等于创建版本号；</li>
<li>当前事务的版本号需要小于删除的版本号。</li>
</ul>
<h3 id="count"><a class="header-anchor" href="#count">¶</a>count(*)</h3>
<p><code>count(*)</code>用于统计表中的数据量，不同的存储引擎的实现方式有所不同：</p>
<ul>
<li>MyISAM：总行数会被存到磁盘，执行 count(*)时直接返回这个值；</li>
<li>InnoDB：把数据一行一行读出然后累积计数。</li>
</ul>
<blockquote>
<p>上述讨论的 count(*)都是不带查询条件的，不然肯定还要用到索引来过滤数据，MyISAM 也不能这么快返回。</p>
</blockquote>
<p>InnoDB 不把数据总数存起来的原因是，由于 MVCC，即使多个查询是在同一时刻发生的，它们该返回多少行数据也是不确定的，如下图所示：<br>
<img src="https://tallate.top/imgs/MySQL/MVCC%E4%B8%8Ecount%E6%98%9F%E6%9F%A5%E8%AF%A2.png" alt="MVCC与count星查询" title="MVCC与count星查询"><br>
三个会话，最后查出的数据总量是不同的。<br>
<code>show table status</code>命令输出结果中也有一个<code>TABLE_ROWS</code>字段用于显示该表当前有多少行，但是由于误差比较大，不能直接拿来用。</p>
<p>由于上述方法存在的缺陷，当需要获取数据库表记录总数时，我们一般会自己计数：</p>
<ol>
<li>用缓存系统计数<br>
由于更新数据库和更新缓存并不是一个原子操作，可能会导致其他线程读到缓存中的计数但是读不到新数据的情况。</li>
<li>在数据库保存计数<br>
由于会话 A 的事务还未提交，对表 C 的技术值的修改对会话 B 就是不可见的，因此可以保证逻辑上是一致的。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%A1%E6%95%B0%E8%A7%A3%E5%86%B3%E7%BB%9F%E8%AE%A1%E9%97%AE%E9%A2%98.png" alt="MySQL-使用数据库计数解决统计问题" title="MySQL-使用数据库计数解决统计问题"><br>
注意，最好先插入操作记录再更新计数表，因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。</li>
</ol>
<p><code>count(主键ID)</code>、<code>count(*)</code>、<code>count(1)</code>、<code>count(字段)</code>之间的比较：</p>
<ul>
<li><code>count(主键ID)</code>：InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</li>
<li><code>count(1)</code>：InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。<br>
因为不取值、不涉及解析数据行及拷贝字段值的操作，所以<code>count(1)</code>会比<code>count(主键ID)</code>要快。</li>
<li><code>count(字段)</code>：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；<br>
如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。</li>
<li><code>count(*)</code>：并不会把全部字段取出来，而是专门做了优化，不取值。<code>count(*)</code> 肯定不是 null，按行累加。<br>
因此<code>count(*)</code>会比其他方式更快。</li>
</ul>
<h3 id="mvcc-小结"><a class="header-anchor" href="#mvcc-小结">¶</a>MVCC 小结</h3>
<p>从上边的描述中我们可以看出来，所谓的 MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD、REPEATABLE READ 这两种隔离级别的事务在执行普通的 SELECT 操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ 这两个隔离级别的一个很大不同就是生成 ReadView 的时机不同：</p>
<ul>
<li>READ COMMITTD 在每一次进行普通 SELECT 操作前都会生成一个 ReadView；</li>
<li>而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个 ReadView，之后的查询操作都重复使用这个 ReadView 就好了。</li>
</ul>
<p>可重复读的核心是一致性读（consistent read），而事务更新数据时，只能用当前读。如果当前的记录的行锁被其他事务占用，则需要进入锁等待。</p>
<h2 id="qa"><a class="header-anchor" href="#qa">¶</a>QA</h2>
<h3 id="如何正确地删除表中的大量数据"><a class="header-anchor" href="#如何正确地删除表中的大量数据">¶</a>如何正确地删除表中的大量数据</h3>
<p>比如，现在想要删除表中的前 10000 条数据，有以下三种方法：<br>
* 直接执行 delete from T limit 10000;<br>
一个大的删除语句，单个语句占用时间长，锁的时间也比较长，且大事务还会导致主从延迟。<br>
* 在一个连接中循环执行 20 次 delete from T limit 500;<br>
相对第 1、3 两种方式较好。<br>
* 在 20 个连接中同时执行 delete from T limit 500。<br>
这 20 个连接互相之间可能会产生锁冲突。</p>
<h3 id="下面的更新为什么没有成功"><a class="header-anchor" href="#下面的更新为什么没有成功">¶</a>下面的更新为什么没有成功</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);</span><br></pre></td></tr></table></figure>
<p>以下事务可能并不能将所有 c 都置为 0。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">select * from t;</span><br><span class="line">update t set c = 0 where id = c;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure>
<p>比如：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%9B%B4%E6%96%B0%E4%B8%A2%E5%A4%B1.png" alt="MySQL-更新丢失" title="MySQL-更新丢失"><br>
其中，事务 A 开始后，在还未对数据进行加锁的情况下，被事务 B 修改了数据，这时，读操作由于<strong>快照读规则</strong>，只能读取到老版本数据，而写操作由于<strong>当前读规则</strong>可以读取到事务 B 写入的数据。<br>
现实中，给数据加乐观锁时也有可能会出现这种情况。</p>
<h3 id="mysql-实现各隔离级别的方式"><a class="header-anchor" href="#mysql-实现各隔离级别的方式">¶</a>MySQL 实现各隔离级别的方式</h3>
<p>读未提交和串行化比较简单，读未提交完全没有做任何事务控制，串行化一个个事务轮流执行。<br>
读已提交隔离级别下，事务会在每次执行读操作前创建一个 ReadView，记录当前正在执行中的所有事务的 trx_id 集合——当然包括当前事务，读取数据时有一个回溯版本的过程：若判断数据当前版本在 ReadView 内，则说明该事务正在执行中，不可读，因此回溯到上一个版本，直到找到一个版本不在 ReadView 内。<br>
可重复读和读已提交原理类似，只是可重复读是在第一次执行读操作的时候生成 ReadView 的。</p>
<h3 id="mysql-怎么实现事务的-acid"><a class="header-anchor" href="#mysql-怎么实现事务的-acid">¶</a>MySQL 怎么实现事务的 ACID</h3>
<ol>
<li>一致性<br>
数据库通过原子性、隔离性、持久性来保证一致性，也就是说 ACID 四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。</li>
<li>原子性<br>
利用 undo log，如果事务需要回滚则使用 undo log 撤销所有已经成功执行的 sql 语句。</li>
</ol>
<blockquote>
<p>对 delete 语句回滚即重新 insert 原语句；<br>
对 update 回滚即 update 成旧值；<br>
对 insert 语句回滚即 delete 该记录。</p>
</blockquote>
<ol>
<li>持久性<br>
利用 redo log，事务提交前先将记录写入 redo log，提交时将 redo log 刷盘，宕机时会将 redo log 中的内容恢复到数据库，再根据 undo log 和 bin log 的内容决定应该回滚数据还是提交数据。<br>
相对数据页来说，redo log 有以下好处：
<ul>
<li>redo log 体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。</li>
<li>redo log 是一直往末尾进行追加，属于顺序 IO。效率显然比随机 IO 来的快。</li>
</ul>
</li>
<li>隔离性<br>
利用锁和 MVCC 机制保证隔离性。</li>
</ol>
<h3 id="为什么最好不要有长事务"><a class="header-anchor" href="#为什么最好不要有长事务">¶</a>为什么最好不要有长事务</h3>
<p>一般当系统判断当没有事务再使用到某些回滚日志时，这些回滚日志会被删除。那么系统怎么判断一个回滚日志不会再被使用到呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。<br>
长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/86b66af2.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/86b66af2.html" itemprop="url">MySQL 中的索引</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-24T10:18:28+08:00">
                2020-05-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index">
                    <span itemprop="name">MySQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  19.6k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  70 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>InnoDB 记录存储结构</h1>
<p>InnoDB 将数据划分为若干个页，以<strong>页作为磁盘和内存之间交互的基本单位</strong>，InnoDB 中页的大小一般为 16 KB</p>
<h2 id="行格式"><a class="header-anchor" href="#行格式">¶</a>行格式</h2>
<p>指定行格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称、ALTER TABLE 表名 ROW_FORMAT=行格式名称</span><br></pre></td></tr></table></figure>
<p>InnoDB 中提供四种可用的格式：Compact、Redundant、Dynamic 和 Compressed<br>
行格式细节比较多，但我们只需要关注其中的部分关键字段：</p>
<ul>
<li>row_id: InnoDB 引擎中一个表只能有一个主键，用于聚簇索引，如果表没有定义主键会选择第一个非 Null 的唯一索引作为主键，如果还没有，生成一个隐藏的 row_id 作为主键构造聚簇索引。</li>
<li>trx_id: 最近更改该行数据的事务 ID；</li>
<li>roll_ptr: undo log 的指针，用于记录之前历史数据在 undo log 中的位置；</li>
<li>delete bit: 索引删除标志，如果 DB 删除了一条数据，是优先通知索引将该标志位设置为 1，然后通过 purge 清除线程异步删除真实的数据。</li>
</ul>
<h1>InnoDB 数据页结构</h1>
<p>1、数据页被组织为一个双向链表；<br>
2、每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表；<br>
3、每个数据页都会为存储在它里面的记录生成一个页目录，页目录又按 ID 分段形成一个个槽，遍历该槽对应分组中的记录即可快速找到指定的记录；<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E9%A1%B5%E7%BB%93%E6%9E%84.png" alt="MySQL-页结构" title="MySQL-页结构"></p>
<h1>数据目录</h1>
<h2 id="查看-mysql-数据目录"><a class="header-anchor" href="#查看-mysql-数据目录">¶</a>查看 MySQL 数据目录</h2>
<p>数据目录不同于安装目录，可以使用以下命令来查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &apos;datadir&apos;;</span><br></pre></td></tr></table></figure>
<h2 id="数据目录的结构"><a class="header-anchor" href="#数据目录的结构">¶</a>数据目录的结构</h2>
<h3 id="create-database-db-name"><a class="header-anchor" href="#create-database-db-name">¶</a>CREATE DATABASE &lt;db_name&gt;</h3>
<p>在数据目录下创建一个子目录 db_name，在该子目录下再创建一个名为 db.opt 的文件，该文件中包含了该数据库的各种属性，比如该数据库的字符集（charset）、比较规则（collation）等。<br>
可以使用 SHOW DATABASES 命令来查看有哪些数据库。</p>
<h3 id="create-table-tb-name"><a class="header-anchor" href="#create-table-tb-name">¶</a>CREATE TABLE &lt;tb_name&gt;</h3>
<p>在数据库目录（db_name）下会创建一个名为 tb_name.frm 的用于描述表结构的文件。注意这个.frm 文件是二进制文件。</p>
<h3 id="表中数据的存储-innodb"><a class="header-anchor" href="#表中数据的存储-innodb">¶</a>表中数据的存储 - InnoDB</h3>
<p>1、InnoDB 其实是使用页为基本单位来管理存储空间的，默认的页大小为 16KB。<br>
2、对于 InnoDB 存储引擎来说，每个索引都对应着一棵 B+树，该 B+树的每个节点都是一个数据页，数据页之间<strong>不必要是物理连续的</strong>，因为数据页之间有双向链表来维护着这些页的顺序。<br>
3、InnoDB 的聚簇索引的叶子节点存储了完整的用户记录，也就是所谓的<strong>索引即数据，数据即索引</strong>。</p>
<p>为了更好地管理这些页（目录页、数据页），InnoDB 引入了一个更高级的结构<strong>表空间（文件空间、table space、file space）</strong>，这个表空间是一个抽象的概念，它可以对应文件系统上一个或多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多很多很多个页，我们的表数据就存放在某个表空间下的某些页里。表空间有许多类：<br>
1、系统表空间（system tablespace）<br>
默认情况下 InnoDB 会在<strong>数据目录</strong>下创建一个名为<strong>ibdata1</strong>文件，这个文件是<strong>自扩展文件</strong>，当不够用时会自动增加大小，因此不会有不够用的情况。<br>
在一个 MySQL 服务器中，系统表空间只有一份。从 MySQL5.5.7 到 MySQL5.6.6 之间的各个版本中，我们表中的数据都会被默认存储到这个 系统表空间。<br>
2、独立表空间（file-per-table tablespace）<br>
在 MySQL5.6.6 以及之后的版本中，InnoDB 并不会默认的把各个表的数据存储到系统表空间中，而是为每一个表建立一个独立表空间，也就是说我们创建了多少个表，就有多少个独立表空间。<br>
使用独立表空间时同样会在<strong>数据目录</strong>下创建一个文件，文件名为&lt;tb_name.ibd&gt;，用于存储该表中的数据和索引。<br>
3、通用表空间（general tablespace）、undo 表空间（undo tablespace）、临时表空间（temporary tablespace）等。</p>
<h3 id="表中数据的存储-myisam"><a class="header-anchor" href="#表中数据的存储-myisam">¶</a>表中数据的存储 - MyISAM</h3>
<p>和 InnoDB 不同的是：<br>
1、MyISAM 中的索引全部都是二级索引，该存储引擎的数据和索引是分开存放的；<br>
2、MyISAM 并没有什么所谓的表空间一说，表数据都存放到对应的数据库子目录下。<br>
建表后，在数据目录下会新增 3 个文件 tb_name.frm、tb_name.MYD 和 tb_name.MYI。</p>
<h3 id="视图的存储"><a class="header-anchor" href="#视图的存储">¶</a>视图的存储</h3>
<p>我们知道 MySQL 中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储视图的时候是不需要存储真实的数据的，只需要把它的结构存储起来就行了。和表一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下边，只会存储一个视图名.frm 的文件。</p>
<h3 id="其他文件"><a class="header-anchor" href="#其他文件">¶</a>其他文件</h3>
<p>数据目录下除了存储表数据外，还有服务器进程文件、服务器日志文件、默认/自动生成的 SSL 和 RSA 证书和密钥文件等。</p>
<h2 id="mysql-的一些系统数据库"><a class="header-anchor" href="#mysql-的一些系统数据库">¶</a>MySQL 的一些系统数据库</h2>
<p>MySQL 额外创建了几个数据库来保存一些系统信息：<br>
1、mysql<br>
这个数据库贼核心，它存储了 MySQL 的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。<br>
2、information_schema<br>
这个数据库保存着 MySQL 服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。<br>
3、performance_schema<br>
这个数据库里主要保存 MySQL 服务器运行过程中的一些状态信息，算是对 MySQL 服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。<br>
4、sys<br>
这个数据库主要是通过视图的形式把 information_schema 和 performance_schema 结合起来，让程序员可以更方便的了解 MySQL 服务器的一些性能信息。</p>
<h1>表空间</h1>
<h2 id="表空间是什么"><a class="header-anchor" href="#表空间是什么">¶</a>表空间是什么</h2>
<p>表空间可以理解为一个页池，当 B+树需要增加页时会从表空间中获取空闲页分配。<br>
每个页的 File Header 由以下字段组成：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">名称	占用空间大小	描述</span><br><span class="line">FIL_PAGE_SPACE_OR_CHKSUM	4字节	页的校验和（checksum值）</span><br><span class="line">FIL_PAGE_OFFSET	4字节	页号</span><br><span class="line">FIL_PAGE_PREV	4字节	上一个页的页号</span><br><span class="line">FIL_PAGE_NEXT	4字节	下一个页的页号</span><br><span class="line">FIL_PAGE_LSN	8字节	页面被最后修改时对应的日志序列位置（英文名是：Log Sequence Number）</span><br><span class="line">FIL_PAGE_TYPE	2字节	该页的类型</span><br><span class="line">FIL_PAGE_FILE_FLUSH_LSN	8字节	仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值</span><br><span class="line">FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID	4字节	页属于哪个表空间</span><br></pre></td></tr></table></figure>
<p>1、表空间中的每一个页都对应着一个页号，也就是 FIL_PAGE_OFFSET，这个页号由 4 个字节组成，也就是 32 个比特位，所以一个表空间最多可以拥有 2³²个页，如果按照页的默认大小 16KB 来算，一个表空间最多支持 64TB 的数据。表空间的第一个页的页号为 0，之后的页号分别是 1，2，3…依此类推。<br>
2、表空间中的每一个页都对应着一个页号，也就是 FIL_PAGE_OFFSET，这个页号由 4 个字节组成，也就是 32 个比特位，所以一个表空间最多可以拥有 2³²个页，如果按照页的默认大小 16KB 来算，一个表空间最多支持 64TB 的数据。表空间的第一个页的页号为 0，之后的页号分别是 1，2，3…依此类推<br>
3、每个页的类型由 FIL_PAGE_TYPE 表示，比如像数据页的该字段的值就是 0x45BF，我们后边会介绍各种不同类型的页，不同类型的页在该字段上的值是不同的。</p>
<h2 id="独立表空间结构"><a class="header-anchor" href="#独立表空间结构">¶</a>独立表空间结构</h2>
<h3 id="区-extent"><a class="header-anchor" href="#区-extent">¶</a>区（extent）</h3>
<p>在表空间和页之间还有一个中间结构，称为区（extent）。对于 16KB 的页来说，连续的 64 个页就是一个区，也就是说一个区默认占用 1MB 空间大小。<br>
不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，每 256 个区被划分成一组。<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f33c4a1c3a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""></p>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f33df9307a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
如上图可知，第一个组最开始的 3 个页面的类型是固定的，也就是说 extent 0 这个区最开始的 3 个页面的类型是固定的，分别是：</p>
<ul>
<li>FSP_HDR 类型：这个类型的页面是用来登记整个表空间的一些整体属性以及本组所有的区，也就是 extent 0 ~ extent 255 这 256 个区的属性，稍后详细唠叨。需要注意的一点是，整个表空间只有一个 FSP_HDR 类型的页面。</li>
<li>IBUF_BITMAP 类型：这个类型的页面是存储本组所有的区的所有页面关于 INSERT BUFFER 的信息。当然，你现在不用知道啥是个 INSERT BUFFER，后边会详细说到你吐。</li>
<li>INODE 类型：这个类型的页面存储了许多称为 INODE 的数据结构，还是那句话，现在你不需要知道啥是个 INODE，后边儿会说到你吐。</li>
</ul>
<p>其余各组最开始的 2 个页面的类型是固定的，也就是说 extent 256、extent 512 这些区最开始的 2 个页面的类型是固定的，分别是：</p>
<ul>
<li>XDES 类型：全称是 extent descriptor，用来登记本组 256 个区的属性，也就是说对于在 extent 256 区中的该类型页面存储的就是 extent 256 ~ extent 511 这些区的属性，对于在 extent 512 区中的该类型页面存储的就是 extent 512 ~ extent 767 这些区的属性。上边介绍的 FSP_HDR 类型的页面其实和 XDES 类型的页面的作用类似，只不过 FSP_HDR 类型的页面还会额外存储一些表空间的属性。</li>
<li>IBUF_BITMAP 类型：上边介绍过了。</li>
</ul>
<p>为什么要引入区的概念？实际上按之前讨论过的 B+树的结构已经能应付正常的页分配、回收操作了，引入区是为了更好地利用空间局部性，如果对页的位置不作限制，页之间可能离得特别远，导致频繁的随机 IO，而一个区是由连续的 64 个页组成的，能减少这种随机 IO 的情况。</p>
<h3 id="段-segment"><a class="header-anchor" href="#段-segment">¶</a>段（segment）</h3>
<p>如果将所有页都放到同一个区内，因为页分叶子节点（数据页）和非叶子节点（目录页），我们执行范围查询的时候是对叶子节点进行的，如果分配到一块，会导致范围查询时从各种区跳来跳去。<br>
因此，InnoDB 又引入了段的概念，存放叶子节点的区的集合就算是一个段（segment），存放非叶子节点的区的集合也算是一个段。也就是说，一个索引是由一个叶子节点段和一个非叶子节点段组成的。</p>
<h3 id="碎片-fragment"><a class="header-anchor" href="#碎片-fragment">¶</a>碎片（fragment）</h3>
<p>前面提到的段有浪费空间的问题，因为不管多大的表，都会给分配至少两块相同大小的区，即使这张表中的数据量非常小。<br>
因此，InnoDB 又引入了碎片（fragment）区的概念，在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段 A，有些页用于段 B，有些页甚至哪个段都不属于。因此，为某个段分配存储空间时：<br>
1、在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。<br>
2、当某个段已经占用了 32 个碎片区页面之后，就会以完整的区为单位来分配存储空间。<br>
因此，段实际上是由一些零散的页面和一些完整区的集合。</p>
<h3 id="区的分类"><a class="header-anchor" href="#区的分类">¶</a>区的分类</h3>
<p>1、空闲的区：现在还没有用到这个区中的任何页面。<br>
2、有剩余空间的碎片区：表示碎片区中还有可用的页面。<br>
3、没有剩余空间的碎片区：表示碎片区中的所有页面都被使用，没有空闲页面。<br>
4、附属于某个段的区。每一个索引都可以分为叶子节点段和非叶子节点段，除此之外 InnoDB 还会另外定义一些特殊作用的段，在这些段中的数据量很大时将使用区来作为基本的分配单位。<br>
这四种区对应 4 种状态（State）：<br>
状态名	含义<br>
FREE	空闲的区<br>
FREE_FRAG	有剩余空间的碎片区<br>
FULL_FRAG	没有剩余空间的碎片区<br>
FSEG	附属于某个段的区</p>
<p>需要再次强调一遍的是，处于 FREE、FREE_FRAG 以及 FULL_FRAG 这三种状态的区都是独立的，算是直属于表空间；而处于 FSEG 状态的区是附属于某个段的。</p>
<h3 id="xdes-entry"><a class="header-anchor" href="#xdes-entry">¶</a>XDES Entry</h3>
<p>InnoDB 使用一种称为 XDES Entry（Extent Descriptor Entry）的结构来管理这些区，每个区都对应着一个 XDES Entry 结构，这个结构记录了对应的区的一些属性。<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f343654829?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
从图中我们可以看出，XDES Entry 是一个 40 个字节的结构，大致分为 4 个部分，各个部分的释义如下：</p>
<ul>
<li>Segment ID（8 字节）<br>
每一个段都有一个唯一的编号，用 ID 表示，此处的 Segment ID 字段表示就是该区所在的段。当然前提是该区已经被分配给某个段了，不然的话该字段的值没啥意义。</li>
<li>List Node（12 字节）<br>
这个部分可以将若干个 XDES Entry 结构串联成一个链表<br>
如果我们想定位表空间内的某一个位置的话，只需指定页号以及该位置在指定页号中的页内偏移量即可。所以：<br>
Pre Node Page Number 和 Pre Node Offset 的组合就是指向前一个 XDES Entry 的指针<br>
Next Node Page Number 和 Next Node Offset 的组合就是指向后一个 XDES Entry 的指针。</li>
<li>State（4 字节）<br>
这个字段表明区的状态。可选的值就是我们前边说过的那 4 个，分别是：FREE、FREE_FRAG、FULL_FRAG 和 FSEG。具体释义就不多唠叨了，前边说的够仔细了。</li>
<li>Page State Bitmap（16 字节）<br>
这个部分共占用 16 个字节，也就是 128 个比特位。我们说一个区默认有 64 个页，这 128 个比特位被划分为 64 个部分，每个部分 2 个比特位，对应区中的一个页。比如 Page State Bitmap 部分的第 1 和第 2 个比特位对应着区中的第 1 个页面，第 3 和第 4 个比特位对应着区中的第 2 个页面，依此类推，Page State Bitmap 部分的第 127 和 128 个比特位对应着区中的第 64 个页面。这两个比特位的第一个位表示对应的页是否是空闲的，第二个比特位还没有用。</li>
</ul>
<h3 id="利用-xdes-entry-链表向段中插入数据的过程"><a class="header-anchor" href="#利用-xdes-entry-链表向段中插入数据的过程">¶</a>利用 XDES Entry 链表向段中插入数据的过程</h3>
<p>当段中数据量比较少时，首先会查看表空间中是否有状态为 FREE_FLAG 的区，也就是有空闲空间的碎片区，如果找到了则从中取一些零散的页将数据插入，否则，从表空间申请一个状态为 FREE 的区，并把该区的状态变为 FREE_FLAG，并从中取一些页将数据插入，直到这个区没有空闲空间，则状态变成 FULL_FLAG。<br>
当表空间的大小增大到一定的程度，这个查询操作无疑会成为瓶颈，在 InnoDB 中这个问题是通过 XDES Entry 的 List Node 来解决的：</p>
<ul>
<li>把状态为 FREE 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FREE 链表。</li>
<li>把状态为 FREE_FRAG 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FREE_FRAG 链表。</li>
<li>把状态为 FULL_FRAG 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FULL_FRAG 链表。</li>
</ul>
<p>将记录插入段中的基本过程：<br>
1、这样每当我们需要 FREE_FLAG 状态的区时，可以直接从 FREE_FLAG 链表中取；<br>
2、当节点对应的区已经没有剩余的空间时，则修改这个节点的 State，并将其从 FREE_FLAG 链表移动到 FULL_FRAG 链表；<br>
3、如果 FREE_FLAG 链表中一个节点都没有，则从 FREE 链表中取一个节点移动到 FREE_FLAG 链表，并修改该节点的 State 值为 FREE_FLAG。</p>
<p>段中所有区的空间都已用完，需要申请更多的空闲区，但是怎么知道段中的区都已经满了呢？我们之前只提到表空间是有 FREE、FREE_FLAG、FULL_FLAG 这三种链表的，实际上段空间也需要：</p>
<ul>
<li>FREE 链表：同一个段中，所有页面都是空闲的区对应的 XDES Entry 结构会被加入到这个链表。注意和直属于表空间的 FREE 链表区别开了，此处的 FREE 链表是附属于某个段的。</li>
<li>NOT_FULL 链表：同一个段中，仍有空闲空间的区对应的 XDES Entry 结构会被加入到这个链表。</li>
<li>FULL 链表：同一个段中，已经没有空闲空间的区对应的 XDES Entry 结构会被加入到这个链表。</li>
</ul>
<h3 id="链表基节点-list-base-node"><a class="header-anchor" href="#链表基节点-list-base-node">¶</a>链表基节点（List Base Node）</h3>
<p>上述的每个链表都有一个 List Base Node，该结构中包含了链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息：<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f388927e1c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
其中：</p>
<ul>
<li>List Length 表明该链表一共有多少节点，</li>
<li>First Node Page Number 和 First Node Offset 表明该链表的头节点在表空间中的位置。</li>
<li>Last Node Page Number 和 Last Node Offset 表明该链表的尾节点在表空间中的位置。</li>
</ul>
<p>List Base Node 总是被放在表空间的固定位置，因此主要用于定位链表位置。</p>
<h3 id="段的结构"><a class="header-anchor" href="#段的结构">¶</a>段的结构</h3>
<p>段是一个逻辑上的概念，它由若干个零散的页面及一些完整的区组成。像每个区都有对应的 XDES Entry 来记录该区中的属性，段也定义了一个 INODE Entry 来记录段中的属性：<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f4087c4a56?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
其中：</p>
<ul>
<li>Segment ID<br>
就是指这个 INODE Entry 结构对应的段的编号（ID）。</li>
<li>NOT_FULL_N_USED<br>
这个字段指的是在 NOT_FULL 链表中已经使用了多少个页面。</li>
<li>3 个 List Base Node<br>
分别为段的 FREE 链表、NOT_FULL 链表、FULL 链表定义了 List Base Node，这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的 List Base Node。</li>
<li>Magic Number：<br>
这个值是用来标记这个 INODE Entry 是否已经被初始化了（初始化的意思就是把各个字段的值都填进去了）。如果这个数字是值的 97937874，表明该 INODE Entry 已经初始化，否则没有被初始化。（不用纠结这个值有啥特殊含义，人家规定的）。</li>
<li>Fragment Array Entry<br>
我们前边强调过无数次段是一些零散页面和一些完整的区的集合，每个 Fragment Array Entry 结构都对应着一个零散的页面，这个结构一共 4 个字节，表示一个零散页面的页号。</li>
</ul>
<h3 id="各种类型的页面"><a class="header-anchor" href="#各种类型的页面">¶</a>各种类型的页面</h3>
<h4 id="fsp-hdr-类型"><a class="header-anchor" href="#fsp-hdr-类型">¶</a>FSP_HDR 类型</h4>
<p><img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f4733af475?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
名称	中文名	占用空间大小	简单描述<br>
File Header	文件头部	38 字节	页的一些通用信息<br>
File Space Header	表空间头部	112 字节	表空间的一些整体属性信息<br>
XDES Entry	区描述信息	10240 字节	存储本组 256 个区对应的属性信息<br>
Empty Space	尚未使用空间	5986 字节	用于页结构的填充，没啥实际意义<br>
File Trailer	文件尾部	8 字节	校验页是否完整</p>
<p>File Space Header 部分<br>
<img src="https://user-gold-cdn.xitu.io/2019/5/1/16a739f47508ede5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
名称	占用空间大小	描述<br>
Space ID	4 字节	表空间的 ID<br>
Not Used	4 字节	这 4 个字节未被使用，可以忽略<br>
Size	4 字节	当前表空间占有的页面数<br>
FREE Limit	4 字节	尚未被初始化的最小页号，大于或等于这个页号的区对应的 XDES Entry 结构都没有被加入 FREE 链表<br>
Space Flags	4 字节	表空间的一些占用存储空间比较小的属性<br>
FRAG_N_USED	4 字节	FREE_FRAG 链表中已使用的页面数量<br>
List Base Node for FREE List	16 字节	FREE 链表的基节点<br>
List Base Node for FREE_FRAG List	16 字节	FREE_FRAG 链表的基节点<br>
List Base Node for FULL_FRAG List	16 字节	FULL_FRAG 链表的基节点<br>
Next Unused Segment ID	8 字节	当前表空间中下一个未使用的 Segment ID<br>
List Base Node for SEG_INODES_FULL List	16 字节	SEG_INODES_FULL 链表的基节点<br>
List Base Node for SEG_INODES_FREE List	16 字节	SEG_INODES_FREE 链表的基节点</p>
<p>TODO</p>
<h2 id="表空间配置和优化"><a class="header-anchor" href="#表空间配置和优化">¶</a>表空间配置和优化</h2>
<h3 id="表数据存储位置：innodb-file-per-table"><a class="header-anchor" href="#表数据存储位置：innodb-file-per-table">¶</a>表数据存储位置：innodb_file_per_table</h3>
<p>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；<br>
这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。<br>
建议将这个值设置为 ON，因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</p>
<h3 id="收缩表空间-重建表"><a class="header-anchor" href="#收缩表空间-重建表">¶</a>收缩表空间（重建表）</h3>
<p>表数据是存储在 B+树的叶子节点（数据页）上的，将一行数据删除置灰将这条记录标记为删除，空间并不会被释放，<strong>只有当该页的所有记录都被删除后，该页才会被标记为可复用</strong>。<br>
当我们将整个表的数据删除，所有的数据页都会被标记为可复用，但是磁盘上的文件并不会变小，造成<strong>空洞</strong>。<br>
可以使用<code>alter table A engine=InnoDB</code>命令来重建表，MySQL 会自动完成建立临时表、转存数据、交换表名、删除旧表的操作。<br>
在往临时表写入数据的过程中如果有新数据写入到表 A 的话，就会造成数据丢失，因此在整个 DDL 过程中表 A 不能有更新，这将阻塞正常的数据库语句执行，因此说这个 DDL 不是 Online 的，但是在 MySQL5.6 之后开始引入<strong>Online DDL</strong>，对这个操作流程做了优化：</p>
<ol>
<li>建立一个临时文件，扫描表 A 主键的所有数据页；</li>
<li>用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；</li>
<li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；</li>
<li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；</li>
<li>用临时文件替换表 A 的数据文件。</li>
</ol>
<p>重建表的过程中，允许对表 A 进行增删改操作，虽然刚开始 DDL 需要拿到 MDL 写锁，但是在真正拷贝数据之前就退化成了读锁，因此并不会阻塞增删改操作。</p>
<h1>B+树索引的结构</h1>
<p>InnoDB 和 MyISAM 会自动为主键或者声明为 UNIQUE 的列去自动建立 B+树索引，但是如果我们想为其他的列建立索引就需要我们显式的去指明。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CREATE TALBE 表名 (</span><br><span class="line">    各种列的信息 ··· ,</span><br><span class="line">    [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)</span><br><span class="line">)</span><br><span class="line">ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列);</span><br><span class="line">ALTER TABLE 表名 DROP [INDEX|KEY] 索引名;</span><br><span class="line">-- 例子</span><br><span class="line">CREATE TABLE index_demo(</span><br><span class="line">    c1 INT,</span><br><span class="line">    c2 INT,</span><br><span class="line">    c3 CHAR(1),</span><br><span class="line">    PRIMARY KEY(c1),</span><br><span class="line">    INDEX idx_c2_c3 (c2, c3)</span><br><span class="line">);</span><br><span class="line">ALTER TABLE index_demo DROP INDEX idx_c2_c3;</span><br></pre></td></tr></table></figure>
<h2 id="使用索引的优点"><a class="header-anchor" href="#使用索引的优点">¶</a>使用索引的优点</h2>
<ol>
<li>通过创建唯一索引，可以保证数据库表中每一行数据的唯一性；</li>
<li>大大加快数据查询速度；</li>
<li>加速表和表之间的连接；</li>
<li>减少查询中分组和排序的时间。</li>
</ol>
<h2 id="没有索引时的查找规则"><a class="header-anchor" href="#没有索引时的查找规则">¶</a>没有索引时的查找规则</h2>
<p>根据搜索条件不同分两种情况：<br>
1、以主键为搜索条件<br>
在页目录中使用二分查找法快速定位到对应的槽，然后遍历该槽对应分组中的记录即可定位目标记录；<br>
2、以其他列作为搜索条件<br>
只能从最小记录开始遍历单链表中的每条记录，效率非常低。</p>
<h2 id="使用索引的缺点"><a class="header-anchor" href="#使用索引的缺点">¶</a>使用索引的缺点</h2>
<ol>
<li>创建索引和维护索引要耗费时间，并且随着数据量的增加耗费的时间也会增加；</li>
<li>索引需要占用磁盘空间，除了数据表占数据空间（一个数据文件）外，每一个索引还需要占用一定的磁盘空间（一个索引文件），如果有大量的索引，索引文件的大小可能超过文件数据本身；</li>
<li>当对表中的数据进行增、删、改时，索引也要动态地维护，会导致操作本身效率降低。</li>
</ol>
<h2 id="一个简单的索引方案"><a class="header-anchor" href="#一个简单的索引方案">¶</a>一个简单的索引方案</h2>
<p>1、插入数据时需要保证主键值是递增的<br>
每页的记录数必须不超过 3 条，因此当要插入更多数据时，必须执行一个页分裂的操作，并且这个过程中如果不满足主键的递增要求，记录则必须要执行移动操作，这个过程称为页分裂：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%95%B0%E6%8D%AE%E9%A1%B5%E5%88%86%E8%A3%82.png" alt="MySQL-数据页分裂" title="MySQL-数据页分裂"><br>
2、给所有页建立目录项<br>
页的用户记录中最小的主键值用 key 来表示；页号用 page_no 表示<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E7%9B%AE%E5%BD%95%E9%A1%B5.png" alt="MySQL-目录页" title="MySQL-目录页"><br>
如上所示，每个目录项实际上记录了对应页中最小的主键值（已经有点像 B+树的结构了）。<br>
当要查找一个 key 时，会先在目录中根据二分法找到其所处的页，然后再到对应页中搜索。</p>
<h2 id="innodb-索引方案"><a class="header-anchor" href="#innodb-索引方案">¶</a>InnoDB 索引方案</h2>
<h3 id="简化方案存在的一些问题"><a class="header-anchor" href="#简化方案存在的一些问题">¶</a>简化方案存在的一些问题</h3>
<ol>
<li>InnoDB 中使用页来管理存储空间，最多只能保证 16KB 的连续存储空间，而随着表中的数据量增多，一页是无法存储下所有的目录项的；</li>
<li>我们如果一页中的记录都已经被删除光了，该页也就没必要存在了，但是删除该页后却需要将其所处目录项之后的目录项都向前移动一下，这显然是非常低效的。<br>
因此，InnoDB 中使用目录项来管理多级的页：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-InnoDB%E4%B8%AD%E7%9A%84B%E5%8A%A0%E6%A0%91.png" alt="MySQL-InnoDB中的B加树" title="MySQL-InnoDB中的B加树"><br>
当我们要查找一条记录时，先根据主键值在目录项记录的页中查找，查找方式其实和之前说的一样，定位到后再去下一级的页中查找，直到查到底层数据页中的记录或根本没找到。<br>
实际上上面描述的是一种称为 B+树的结构，不论是存放用户记录的数据页，还是存放目录项记录的数据页，我们都把它们存放到 B+树这个数据结构中了，所以我们也称这些数据页为节点。从图中可以看出来，我们的实际用户记录其实都存放在 B+树的最底层的节点上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项的节点称为非叶子节点或者内节点，其中 B+树最上边的那个节点也称为根节点。<br>
在真实情况中 B+树存放的记录数是非常多的，层数也不会太高，如果每个数据页能存放 100 条记录，目录页能存放 1000 条记录，那么3层就能存1000x1000x100=1亿条数据，4 层就是 1000×1000×1000×100=1*10^11 条记录，所以我们用到的 B+树都不会超过 4 层，通过主键值去查找某条记录最多只需要做 4 个页面内的查找（查找 3 个目录项页和一个数据页），又因为在每个页面内有所谓的 Page Directory（页目录），所以在页面内也可以通过二分法实现快速定位记录。</li>
</ol>
<h3 id="b-树的形成过程大致如下"><a class="header-anchor" href="#b-树的形成过程大致如下">¶</a>B+树的形成过程大致如下</h3>
<ol>
<li>每当为某个表创建一个 B+树索引（聚簇索引不是人为创建的，默认就有）的时候，都会为这个索引创建一个根节点页面。最开始表中没有数据的时候，每个 B+树索引对应的根节点中既没有数据记录，也没有目录项记录。</li>
<li>随后向表中插入数据记录时，先把用户记录存储到这个根节点中。</li>
<li>当根节点中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的页，比如页 a 中，然后对这个新页进行页分裂的操作，得到另一个新页，比如页 b。这时新插入的记录根据键值（也就是聚簇索引中的主键值，二级索引中对应的索引列的值）的大小就会被分配到页 a 或者页 b 中，而根节点便升级为存储目录项记录的页。</li>
</ol>
<h3 id="唯一索引"><a class="header-anchor" href="#唯一索引">¶</a>唯一索引</h3>
<p>唯一索引和普通索引没有本质区别，主要是在插入时会检查是否违反了唯一约束。</p>
<h3 id="聚簇索引"><a class="header-anchor" href="#聚簇索引">¶</a>聚簇索引</h3>
<p>前面已经对 InnoDB 中的 B+树结构做了一个阐述，但是至今为止我们的讨论还没有涉及索引，我们称满足以下条件的 B+树是一个聚簇索引：<br>
1、使用记录主键值的大小进行记录和页的排序<br>
包括页内记录按主键大小排成单链表，各个页按页中记录的主键大小顺序排成双向链表，存放目录项记录的页在不同层次（B+树的每层）也是根据页中目录项记录的主键大小排序排成一个双向链表。<br>
2、B+树的叶子节点存储的是完整数据<br>
这种聚簇索引不需要手动用 INDEX 语句创建，InnoDB 引擎会为我们自动创建聚簇索引，实际上在 InnoDB 中聚簇索引就是数据的存储方式。</p>
<h3 id="二级索引"><a class="header-anchor" href="#二级索引">¶</a>二级索引</h3>
<p>聚簇索引只能根据主键的查询，如果我们需要根据别的列来查询数据，则必须另外建几棵对应字段的 B+树。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.png" alt="MySQL-二级索引" title="MySQL-二级索引"><br>
这棵 B+树为字段 a 增加了索引，和之前的聚簇索引的区别包括：<br>
1、页内的记录是按字段 a 排列成一个单向链表；<br>
2、各个存放数据的页也是根据页中记录的 a 列大小顺序排成一个双向链表；<br>
3、存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的 a 列大小顺序排成一个双向链表。<br>
4、叶子节点存储的并不是完成的数据，而是 a 列+主键这两列的值；<br>
5、目录项记录中不再是主键+页号的搭配，而是 a 列+页号的搭配。<br>
由于叶子节点只存储了字段 a 和主键，如果要获取完整数据，还得根据主键到聚簇索引中再查一遍，这个过程被称为回表。这种按照非主键列建立的 B+树需要一次回表操作才可以定位到完整的记录，所以这种 B+树也被称为二级索引（英文名 secondary index），或者辅助索引。</p>
<h3 id="联合索引"><a class="header-anchor" href="#联合索引">¶</a>联合索引</h3>
<p>我们也可以同时对多个列建立索引，实际上就是先按字段 a 排序然后再按另一个字段 b 排序，原理与之前的类似。</p>
<h3 id="myisam-中的索引"><a class="header-anchor" href="#myisam-中的索引">¶</a>MyISAM 中的索引</h3>
<p>InnoDB 中索引即数据，也就是聚簇索引的那棵 B+树的叶子节点中已经把所有完整的用户记录都包含了，而 MyISAM 的索引方案虽然也使用树形结构，但是却将索引和数据分开存储</p>
<ol>
<li>将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据页，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。<br>
当然 MyISAM 同样需要记录头信息来存储一些额外数据：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-MyISAM%E7%B4%A2%E5%BC%95.png" alt="MySQL-MyISAM索引" title="MySQL-MyISAM索引"><br>
注意插入记录的时候并没有可以按照主键大小排序，因此无法直接使用二分查找。</li>
<li>使用 MyISAM 存储引擎的表会把索引信息另外存储到一个称为索引文件的另一个文件中。MyISAM 会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是主键值 + 行号的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录<br>
这一点和 InnoDB 是完全不相同的，在 InnoDB 存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录，而在 MyISAM 中却需要进行一次回表操作，意味着 MyISAM 中建立的索引相当于全部都是二级索引！</li>
<li>如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和 InnoDB 中的索引差不多，不过在叶子节点处存储的是相应的列 + 行号。这些索引也全部都是二级索引。</li>
</ol>
<h1>B+树索引的使用</h1>
<h2 id="索引的代价"><a class="header-anchor" href="#索引的代价">¶</a>索引的代价</h2>
<p>1、空间代价<br>
一个页所占的空间默认为 16KB，现实中这样的 B+树可能由许多页组成，非常占空间；<br>
2、时间代价<br>
每次对数据增删改操作时都需要修改各个 B+树索引，因为所有节点、页面、记录都是按照主键大小顺序排序的，增删改操作会破坏这个顺序，因此 InnoDB 需要一些额外的记录移位、页面分裂、页面回收等操作来维护节点和记录的顺序。</p>
<h2 id="什么时候使用-b-树索引"><a class="header-anchor" href="#什么时候使用-b-树索引">¶</a>什么时候使用 B+树索引</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE person_info(</span><br><span class="line">    id INT NOT NULL auto_increment,</span><br><span class="line">    name VARCHAR(100) NOT NULL,</span><br><span class="line">    birthday DATE NOT NULL,</span><br><span class="line">    phone_number CHAR(11) NOT NULL,</span><br><span class="line">    country varchar(100) NOT NULL,</span><br><span class="line">    PRIMARY KEY (id),</span><br><span class="line">    KEY idx_name_birthday_phone_number (name, birthday, phone_number)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>该表有两个索引<br>
1、表中的主键是 id 列，它存储一个自动递增的整数。所以 InnoDB 存储引擎会自动为 id 列建立聚簇索引。<br>
2、显式定义了一个联合索引 idx_name_birthday_phone_number，它由 name、birthday、phone_number 三个字段组成。<br>
画成图其结构大致如下：<br>
<img src="https://user-gold-cdn.xitu.io/2019/10/9/16db02bc665cf0b1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt=""><br>
下面我们分析不同的查询语句是如何使用这张表里的索引的。</p>
<h3 id="全值匹配"><a class="header-anchor" href="#全值匹配">¶</a>全值匹配</h3>
<p>搜索条件中的列和索引的定义一致。<br>
这种情况要求搜索字段一致，但是顺序并没有太严格的要求，因为<strong>查询优化器</strong>会分析搜索条件并且按照可以使用的索引中列的顺序来决定使用搜索条件的先后顺序。</p>
<h3 id="匹配左边的列"><a class="header-anchor" href="#匹配左边的列">¶</a>匹配左边的列</h3>
<p>上面的索引中有 3 个字段，但是我们查询时并不一定会用到所有字段，如果只用到索引中左边的字段，索引页能生效，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info WHERE name = &apos;Ashburn&apos; AND birthday = &apos;1990-09-27&apos;;</span><br></pre></td></tr></table></figure>
<p>但是如果查询条件中没有最左边的列，则索引是无法生效的，因为索引结构是先按索引字段定义顺序依次排序的。</p>
<h3 id="最左前缀匹配"><a class="header-anchor" href="#最左前缀匹配">¶</a>最左前缀匹配</h3>
<p>建立索引的本质就是对字段进行排序，很多时候字段都是字符串类型的，字符串类型字段在排序时会从前缀开始一个一个字符排序，所以我们只匹配前缀也是能够快速定位记录的，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info WHERE name LIKE &apos;As%&apos;;</span><br></pre></td></tr></table></figure>
<p>但是如果只给出了后缀或中间的某个字符串就无法利用索引了，只能执行全表扫描，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info WHERE name LIKE &apos;%As%&apos;;</span><br></pre></td></tr></table></figure>
<p>如果需要按后缀查询，则可以考虑在存储时逆序存储，查询时就可以实现最左前缀匹配了。</p>
<h3 id="匹配范围值"><a class="header-anchor" href="#匹配范围值">¶</a>匹配范围值</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info WHERE name &gt; &apos;Asa&apos; AND name &lt; &apos;Barlow&apos;;</span><br></pre></td></tr></table></figure>
<p>因为 B+树索引是按该列值顺序从小到大排序的，因此匹配范围值时，只要分别找到’Asa’和’Barlow’记录，然后通过链表（同一页内是单链表，如果是跨多个数据页则会利用到页之间的双链表）取出它们之间的所有记录，如果是覆盖索引会直接返回，如果是涉及到其他字段则会再<strong>回表</strong>到聚簇索引中获取完整记录。<br>
需要注意的是，对多个列执行范围查找时，只有对索引最左边那个列进行范围查找时才能用到 B+树索引，因为按 name 列范围查询出的记录并不是按照 birthday 列进行排序的，只有 name 值相同的情况下才会按 birthday 列进行排序，如下所示：<br>
±---------------±----------+<br>
| name           | birthday  |<br>
±---------------±----------+<br>
| a              | x         |<br>
| a              | y         |<br>
| b              | x         |<br>
| b              | y         |<br>
| c              | z         |<br>
| …            | …       |<br>
±---------------±----------+</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info WHERE name &gt;= &apos;a&apos; AND name &lt;= &apos;b&apos; and birthday &lt; &apos;y&apos;;</span><br></pre></td></tr></table></figure>
<p>按上面条件进行查询时，先按 name 字段过滤，得到的 4 条记录中 birthday 并没有顺序，因此继续查询 birthday 列时是用不到这个 B+树索引的。<br>
但是如果前面的列是精确查找，那么对后面的列就可以进行范围查找了，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from person_info where name = &apos;a&apos; and birthday &lt; &apos;y&apos;;</span><br></pre></td></tr></table></figure>
<h2 id="排序"><a class="header-anchor" href="#排序">¶</a>排序</h2>
<p>如果没有用到索引，InnoDB 排序前一般会先将数据加载到内存的<strong>sort_buffer</strong>中，或者由于数据量太大需要借助磁盘空间来存放中间结果，排序完后再将结果集返回给客户端，在 MySQL 中，这种在内存或磁盘上进行排序的方式被称为<strong>文件排序（filesort）</strong>。</p>
<blockquote>
<p>explain 命令查看语句的执行情况，Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。</p>
</blockquote>
<p>但是如果 ORDER BY 子句使用到了我们的索引列，就可能省去 filesort 这个步骤了，因为索引本身就对记录进行了排序。<br>
同理，使用联合索引进行排序时，要注意 ORDER BY 后字段的顺序，比如 birthday, name 就用不了上面建立的索引了。</p>
<h3 id="全字段排序执行流程"><a class="header-anchor" href="#全字段排序执行流程">¶</a>全字段排序执行流程</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `city` varchar(16) NOT NULL,</span><br><span class="line">  `name` varchar(16) NOT NULL,</span><br><span class="line">  `age` int(11) NOT NULL,</span><br><span class="line">  `addr` varchar(128) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `city` (`city`)) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select city,name,age from t where city=&apos;杭州&apos; order by name limit 1000;</span><br></pre></td></tr></table></figure>
<p>因为 city 字段加上了索引，因此我们的查询语句会走<code>city</code>这个索引，具体的执行流程如下：</p>
<ol>
<li>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</li>
<li>从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；</li>
<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>
<li>从索引 city 取下一个记录的主键 id；</li>
<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>
<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>
<li>按照排序结果取前 1000 行返回给客户端。</li>
</ol>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F%E4%BE%8B%E5%AD%90.png" alt="MySQL-全字段排序例子" title="MySQL-全字段排序例子"></p>
<h3 id="不可以使用索引进行排序的几种情况"><a class="header-anchor" href="#不可以使用索引进行排序的几种情况">¶</a>不可以使用索引进行排序的几种情况</h3>
<p>1、ASC、DESC 混用<br>
在使用联合索引进行排序时，要求各个排序的列的顺序是一致的，要么都是 ASC，要么都是 DESC，举个例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from person_info order by name, birthday desc limit 10;</span><br></pre></td></tr></table></figure>
<p>这样，InnoDB 会先从索引的最左边确定 name 列最小的值，然后找到 name 列等于该值的所有记录，然后从这些记录最右边那条开始往左找 10 条记录；如果不足 10 条，则会继续往右找 name 第二小的记录，以此类推。<br>
这个过程并不能高效利用索引，甚至不如直接利用文件排序。<br>
2、where 子句中出现非排序使用到的索引列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from person_info where country = &apos;China&apos; ORDER BY name LIMIT 10;</span><br></pre></td></tr></table></figure>
<p>如上所示，name 字段是有索引的，但是 country 字段没有，因此查询时必须先把符合搜索条件 country='China’的记录查出再执行排序，这样无法使用索引。<br>
3、排序列包含非同一索引的列<br>
用来排序的多个列不是同一个索引里的，则也不能使用索引来进行排序，原因和上一点其实差不多。<br>
4、排序子句使用了复杂表达式<br>
比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;</span><br></pre></td></tr></table></figure>
<p>原 name 排序可能是 Bbc、Cbc、abc，但是用 UPPER 计算后可能会变成 abc、bbc、cbc（默认情况下 MySQL 是会忽略大小写的区别的，这里只是作个例子）。<br>
同理，下面这样的表达式也无法利用索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from person_info where grade / 100.0 &gt; 0.8;</span><br></pre></td></tr></table></figure>
<h3 id="文件排序的例子"><a class="header-anchor" href="#文件排序的例子">¶</a>文件排序的例子</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `city` varchar(16) NOT NULL,</span><br><span class="line">  `name` varchar(16) NOT NULL,</span><br><span class="line">  `age` int(11) NOT NULL,</span><br><span class="line">  `addr` varchar(128) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `city` (`city`)</span><br><span class="line">) default charset = utf8mb4 ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>
<p>对下面 select 语句执行 explain，可以发现 Extra 中包含 filesort 选项，表示该查询语句将会使用到临时文件来执行文件排序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain select city, name,age from t where city=&apos;杭州&apos; order by name limit 1000;</span><br></pre></td></tr></table></figure>
<p>可以用下面方法来确定一个排序语句是否使用了临时文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/* 打开optimizer_trace，只对本线程有效 */</span><br><span class="line">SET optimizer_trace=&apos;enabled=on&apos;; </span><br><span class="line"></span><br><span class="line">/* @a保存Innodb_rows_read的初始值 */</span><br><span class="line">select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = &apos;Innodb_rows_read&apos;;</span><br><span class="line"></span><br><span class="line">/* 执行语句 */</span><br><span class="line">select city, name,age from t where city=&apos;杭州&apos; order by name limit 1000; </span><br><span class="line"></span><br><span class="line">/* 查看 OPTIMIZER_TRACE 输出 */</span><br><span class="line">SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G</span><br><span class="line"></span><br><span class="line">/* @b保存Innodb_rows_read的当前值 */</span><br><span class="line">select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &apos;Innodb_rows_read&apos;;</span><br><span class="line"></span><br><span class="line">/* 计算Innodb_rows_read差值 */</span><br><span class="line">select @b-@a;</span><br></pre></td></tr></table></figure>
<p>这个方法是通过查看 <code>OPTIMIZER_TRACE</code> 的结果来确认的，可以从输出中的 <code>number_of_tmp_files</code> 中看到是否使用了临时文件，如果这个值是 0，表示 sort_buffer_size 足够进行内存排序了，就没必要再执行文件排序了。</p>
<blockquote>
<p>number_of_tmp_files 结果永远是 2 的倍数，因为 MySQL 使用归并排序算法，将数据分成多份分别排序后存在这些临时文件中，然后把这些有序文件合并成一个有序的大文件。</p>
</blockquote>
<h3 id="rowid-排序"><a class="header-anchor" href="#rowid-排序">¶</a>rowid 排序</h3>
<p>如果表中每一行的字段很多、数据量较大，很容易超出<code>sort_buffer</code>的容量、并切换到文件排序，要对多个临时文件进行归并排序，效率很低。<br>
字段数量过多的情况下，MySQL 会采用另一种方式来执行排序，这种方式只用将**要排序的列和主键加载到<code>sort_buffer</code>，但是这样排完序后还需要回到原表去带出需要返回的字段，需要更多次的读磁盘，所以不会被优先选择。</p>
<blockquote>
<p>这个字段数量的阈值可以通过<code>SET max_length_for_sort_data = 16;</code>来设置。</p>
</blockquote>
<h3 id="使用索引排序"><a class="header-anchor" href="#使用索引排序">¶</a>使用索引排序</h3>
<p>如果排序字段正好与索引字段一致，则 MySQL 会直接使用索引来进行排序，因为 B+树叶子节点的记录就是按索引定义的顺序来组织的，如果要查询的字段都在索引里面，则我们称该索引为覆盖索引，使用索引排序后可以直接使用索引中的字段返回、不需要再回表了。</p>
<h2 id="分组"><a class="header-anchor" href="#分组">¶</a>分组</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number</span><br></pre></td></tr></table></figure>
<p>上面这个语句会先按 name 值进行分组，所有 name 值相同的划分为一组，对 name 值相同的分组内再按 birthday 的值进行分组，以此类推。<br>
如果没有索引，这个分组统计过程全部都需要在内存里实现，而因为 name,birthday,phone_number 这些字段已经有了索引，InnoDB 会直接使用索引列的顺序来进行分组。</p>
<h2 id="回表的代价"><a class="header-anchor" href="#回表的代价">¶</a>回表的代价</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from person_info where name &gt; &apos;abc&apos; and name &lt; &apos;def&apos;;</span><br></pre></td></tr></table></figure>
<p>上述 SQL 会先按二级索引查到位于’abc’和’def’之间的记录，因为这些记录在磁盘上是连续的、集中分布在几个相邻的页中，因此我们可以很快地读出这些记录，这种读取方式被称为<strong>顺序 IO</strong>。但是这些记录的 id 并不一定是连续的，在聚簇索引中它们可能被分布在不同的数据页中，读取它们时需要访问更多的页，这种读取方式被称为<strong>随机 IO</strong>。<br>
随机 IO 的性能比顺序 IO 的性能低得多，一般需要回表的记录越多，使用二级索引的性能就越低，如果查询的全部记录数占总体比重过大，InnoDB 甚至会放弃聚簇索引而采用全表扫描。<br>
那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方式去执行查询呢？这个就是传说中的查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。当然优化器做的分析工作不仅仅是这么简单，但是大致上是个这个过程。<strong>一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用二级索引 + 回表的方式进行查询，因为回表的记录越少，性能提升就越高</strong>。<br>
为了减少这种需要全表扫描的情况，我们需要遵循一些规范，比如：<br>
1、写查询语句后使用 explain 评估效率；<br>
2、如果查询列表是*，优化器会更倾向于使用全表扫描；<br>
3、如果加了 LIMIT 条件，因为记录变少，优化器会更倾向于使用<strong>二级索引+回表</strong>的方式查询。<br>
4、<strong>覆盖索引</strong>，即要查询的目标列都处在索引中，那么优化器就会直接使用索引而不是回表操作了。</p>
<h2 id="挑选索引"><a class="header-anchor" href="#挑选索引">¶</a>挑选索引</h2>
<p>1、只为用于搜索、排序或分组的列创建索引<br>
为 WHERE、ORDER BY、GROUP BY 子句中的列建立索引，一般来说业务字段变更频繁，没有必要强行建立覆盖索引。<br>
2、考虑列的基数<br>
在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。<br>
最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好，因为基数小的话，更有可能一次性查出很多记录，还需要执行回表操作，这样对性能损耗会比较大，索引就起不到作用了。<br>
3、索引列的类型尽量小<br>
在表示的整数范围允许的情况下，尽量让索引列使用较小的类型，比如 TINYINT、MEDIUMINT、INT、BIGINT 中，相对 BIGINT 来说我们更优先使用 INT，因为：<br>
数据类型越小，在查询时进行的比较操作越快（这是 CPU 层次的东东）<br>
数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘 I/O 带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率。<br>
4、索引字符串值的前缀<br>
一些字符串类型的字段，如果要完整索引会占用较大的存储空间，所以我们一般只对字符串的前几个字符进行索引，就算遇到某几条记录中索引字段的前缀相同，也能通过它们的主键回表查询再进行比对，可以大大节省存储空间。<br>
但是如果只索引了字段的前缀，那么 ORDER BY 排序时就无法使用到索引了，因为如果前几个处于索引中的字符相同，后面的字符不同无法比较。<br>
通过比较选取不同长度前缀的区分度，可以作为创建前缀索引的参考：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select </span><br><span class="line">  count(distinct left(email,4)）as L4,</span><br><span class="line">  count(distinct left(email,5)）as L5,</span><br><span class="line">  count(distinct left(email,6)）as L6,</span><br><span class="line">  count(distinct left(email,7)）as L7,</span><br><span class="line">from SUser;</span><br></pre></td></tr></table></figure>
<p>如果发现前缀区分度太低，也可以考虑使用后缀或原字段的 hash 字段作为索引。<br>
5、主键插入顺序<br>
InnoDB 中数据是存储在聚簇索引的叶子节点的，数据页和记录都是按照记录的主键从小到大排序的，如果插入数据的主键是依次增大的，那么每填满一个数据页就可以再创建一个继续插入。但是如果主键值位于某个页面的中间，那么将不得不另外执行页分裂操作，造成额外的性能损耗。<br>
因此，我们写建表语句时一般都会给主键设置<strong>AUTO_INCREMENT</strong>属性，让存储引擎自己为表生成主键，而不是我们手动插入。<br>
6、冗余索引<br>
不要给一个字段重复定义索引。</p>
<h2 id="为什么-innodb-会选错索引"><a class="header-anchor" href="#为什么-innodb-会选错索引">¶</a>为什么 InnoDB 会选错索引</h2>
<h3 id="可能选择错误的情况"><a class="header-anchor" href="#可能选择错误的情况">¶</a>可能选择错误的情况</h3>
<ol>
<li>使用组合索引时没有遵守最左前缀原则；</li>
<li>使用范围查询时（&gt;,&lt;,&lt;&gt;，!=,between and ,like），该条件查询右边的列都会失效。</li>
<li>如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引；</li>
<li>表中数据量比较小的时候，MySQL 优化引擎，会决定不实用索引；</li>
<li>使用 or 进行查询，联合索引会失效；</li>
<li>在索引列上做任何操作（计算，函数，（自动或者手动）类型装换），会导致索引失效而导致全表扫描。</li>
</ol>
<p>即使我们正确使用了索引，还是有可能会出现没有命中索引的情况，这和 MySQL 中的所索引选择机制有关：</p>
<ol>
<li>采样统计扫描行数<br>
InnoDB 通过<strong>采样统计</strong>查询需要扫描的行数，然后在不同查询方式（使用哪些索引、要不要排序等）中选择需要扫描行数最少的那个。<br>
采样统计时，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</li>
<li>判断执行语句本身要扫描的行数<br>
explain 结果中的 rows 是预计扫描的行数，是结合所使用的索引得出的粗略结果，但是这个结果仅供参考，因为：
<ul>
<li>索引统计不准确，可以使用 analyze 来修正。</li>
<li>实际如何选择索引还会考虑其他因素，比如非主键索引因为要回表所以性能损耗更大，因此 InnoDB 会更倾向于选择主键索引——即使主键索引的扫描行数要多得多。</li>
</ul>
</li>
</ol>
<h3 id="索引选择异常和处理"><a class="header-anchor" href="#索引选择异常和处理">¶</a>索引选择异常和处理</h3>
<p>如果发现 MySQL 选择索引错误，可以通过下面的方法来优化：</p>
<ol>
<li>使用<code>force index</code>强行选择一个索引；</li>
<li>修改语句，引导 MySQL 使用我们期望的索引。</li>
<li>建一个更合适的索引，或删掉不合适的索引；</li>
</ol>
<h2 id="索引优化策略"><a class="header-anchor" href="#索引优化策略">¶</a>索引优化策略</h2>
<p>从前面对索引的讨论可以得出一些针对索引的优化策略：</p>
<ol>
<li>覆盖索引<br>
如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为 <strong>覆盖索引</strong>。<br>
如果可以从索引中获取到所有数据，那么就不需要再去回表了。<br>
覆盖索引必须要存储索引列的值，哈希索引、空间索引和全文索引都不存储列值，MySQL 只能使用 Btree 索引作为覆盖索引。<br>
排序 MySQL 支持两种方式生成排序结果：通过排序操作；通过索引顺序扫描，MySQL 可以使用同一个索引既满足查找又满足排序，只有当索引的列顺序和 Order By 子句的顺序完全一致，并且所有列的排序方向也一样时，才能使用索引进行排序，其中 Order By 子句和查询限制一样，需要满足索引的最左前缀匹配，当前导列为常量时，可以不满足最左前缀的要求。</li>
<li>冗余和重复索引<br>
重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引，一旦发现重复索引，应该立即移除。<br>
冗余索引与重复索引有些不同，如果创建了索引（A, B），再创建索引(A)就是冗余索引，因为这只是前一个索引的前缀索引；索引（A, ID）对于 InnodDB 来说主键列已经包含在二级索引中，所以也是冗余。<br>
应尽量扩展已有索引而不是创建新的索引，但也有时候出于性能考虑需要冗余索引，因为扩展已有的索引会导致其变得太大，从而影响其他使用该索引的查询性能，特别是 count，group by 等统计查询。<br>
未使用的索引，就是永远都用不到的索引，这种索引就是累赘，直接删除。</li>
<li>前缀索引和索引选择性<br>
MySQL 无法使用前缀索引做 Group By 和 Order By，也无法使用前缀索引做覆盖扫描。<br>
MySQL 本身不支持反向索引，但可以将字符串反转后存储，并基于此建立前缀索引。</li>
</ol>
<p>索引设计不合理或者缺少索引都会对数据库和应用程序的性能造成障碍。高效的索引对于获得良好的性能非常重要。设计索引时，应该考虑以下准则：</p>
<ol>
<li>索引<strong>并非越多越好</strong><br>
一个表中如有大量的索引，不仅占用磁盘空间，而且会影响 INSERT、DELETE、UPDATE 等语句的性能，因为当表中的数据更改的同时，索引也会进行调整和更新。也可以在维护期间根据需要删除不再使用或者很少使用的索引。</li>
<li>避免对经常<strong>更新</strong>的表进行过多的索引，并且索引中的列尽可能的少。而对经常用于查询的字段应该创建索引，但要避免添加不必要的字段。</li>
<li>尽量使用<strong>字段短</strong>的索引，这样可以提高索引的检索效率。如果是长度比较长的字段，应尽量使用<strong>前缀索引</strong>。</li>
<li><strong>数据量</strong>小的表最好不要使用索引，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。</li>
<li>在<strong>条件表达式</strong>中经常用到的不同值较多的列上建立索引，在不同值少的列上不要建立索引。比如在学生表的“性别”字段上只有“男”与“女”两个不同值，因此就无需建立索引了，如果建立索引反而会严重降低更新速度。</li>
<li>当<strong>唯一</strong>性是某种数据本身的特征时，制定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度。</li>
<li>在频繁进行<strong>排序、分组、联合</strong>（即进行 group by、order by、join on 操作）的列上建立索引。如果待排序的列有多个，可以在这些列上建立组合索引。</li>
</ol>
<h1>update 语句的执行流程</h1>
<p>一条 SQL 语句的整体执行流程如下：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-SQL%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="MySQL-SQL语句执行流程" title="MySQL-SQL语句执行流程"></p>
<ol>
<li>执行语句前要先通过连接器连接数据库；</li>
<li>分析器通过词法和语法解析得知该语句为更新语句；</li>
<li>优化器确定需要使用哪些索引；</li>
<li>执行更新语句前，将跟这个表有关的查询缓存全部失效；</li>
<li>执行器负责具体执行，找到该行数据并执行更新。</li>
</ol>
<h2 id="两阶段提交协议"><a class="header-anchor" href="#两阶段提交协议">¶</a>两阶段提交协议</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%8D%8F%E8%AE%AE.jpg" alt="MySQL-两阶段提交协议" title="MySQL-两阶段提交协议"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update T set c=c+1 where ID=2;</span><br></pre></td></tr></table></figure>
<p>对于上面这行简单的 update 语句，执行器和 InnoDB 引擎在执行时的内部流程如下：</p>
<ol>
<li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
</ol>
<blockquote>
<p>这里的&quot;内存&quot;指的是 Buffer Pool。另外，如果不影响数据一致性，MySQL 会直接写入到 change buffer，而不是从磁盘加载页面到 Buffer Pool 中，当然这是有条件的，在 CacheBuffer 的相关内容中我们还需要再讨论。</p>
</blockquote>
<ol>
<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</li>
</ol>
<blockquote>
<p>两阶段提交的 prepare 阶段。</p>
</blockquote>
<ol>
<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
<blockquote>
<p>两阶段提交的 commit 阶段。</p>
</blockquote>
<h3 id="两阶段提交的异常情况"><a class="header-anchor" href="#两阶段提交的异常情况">¶</a>两阶段提交的异常情况</h3>
<p>两阶段提交异常主要体现在：如果各阶段发生重启，数据库的一致性是否会受到影响。<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%8D%8F%E8%AE%AE.jpg" alt="MySQL-两阶段提交协议" title="MySQL-两阶段提交协议"></p>
<ol>
<li>图中A处，写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash）<br>
由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。</li>
<li>图中B处，即bin log写完，redo log还没commit前发生crash<br>
这时，如果redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；<br>
如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。<br>
这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。</li>
</ol>
<h3 id="两阶段提交的问题"><a class="header-anchor" href="#两阶段提交的问题">¶</a>两阶段提交的问题</h3>
<ol>
<li>MySQL怎么知道bin log是完整的？<br>
一个事务的bin log是有完整格式的。</li>
<li>为什么MySQL不设计成先redo log写完、再写bin log？<br>
主要是为了解决事务的持久性问题：<br>
对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。</li>
<li>只留bin log支持崩溃恢复和归档，不要redo log了可以吗？<br>
这个主要是历史问题，MySQL的原生引擎MyISAM设计之初就没有支持崩溃恢复，后来接入InnoDB、利用InnoDB的redo log才有了崩溃恢复能力。<br>
为什么bin log不能实现崩溃恢复呢？因为bin log记录的是写操作，它不能恢复数据页。<br>
InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。<br>
如果两个事务相邻执行，第二个事务还没提交前系统崩溃了，此时，事务1的数据可能还没有刷盘，事务2由于bin log可以恢复，但是事务1因为已经提交了，就不能再应用bin log来恢复了。</li>
<li>能不能反过来只用redo log 不要 bin log？<br>
如果只从崩溃恢复的角度来讲是可以的。你可以把 bin log 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。<br>
但是redo log因为是循环写的，历史日志没法保留、也就起不到归档的作用。</li>
<li>正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？<br>
这个问题涉及到redo log和buffer pool的本质区别，我们知道写入数据实际上是写入buffer pool然后异步刷盘，那么redo log里面到底存了什么呢？<br>
实际上redo log并没有记录数据页的完整数据，最终数据的落盘实际上和redo log毫无关系。<strong>在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让redo log更新内存内容，更新完成后，内存页变成脏页，就回到了第一种情况的状态。</strong></li>
<li>redo log buffer是什么？<br>
InnoDB并不会立刻将redo log数据写入磁盘，而是先写入到内存中的redo log buffer，只有在事务最后执行commit时才会真正地写入到redo log文件内。</li>
</ol>
<h1>其他索引类型</h1>
<h2 id="hash-索引"><a class="header-anchor" href="#hash-索引">¶</a>hash 索引</h2>
<ol>
<li>hash 索引基于哈希表实现，只有精确匹配索引的所有列的查询才会生效。</li>
<li>Hash 索引将所有哈希值存储在索引中，同时保持指向每个数据行的指针。</li>
<li>Hash 索引结构非常紧凑，查找速度非常快。</li>
<li>Memory 引擎支持非唯一的哈希索引。</li>
<li>InnoDB 有一个功能叫 “ 自适应哈希索引 ”，当它注意到某些列索引值被使用的非常频繁时，会在内存中基于 Btree 索引之上再建一个 hash 索引，以提高访问速度</li>
</ol>
<h2 id="空间数据索引"><a class="header-anchor" href="#空间数据索引">¶</a>空间数据索引</h2>
<p>MyISAM 表支持空间索引，可以作为地理数据存储。但 MySQL 对 GIS 支持不够全面。</p>
<h2 id="全文索引"><a class="header-anchor" href="#全文索引">¶</a>全文索引</h2>
<ol>
<li>全文索引是一种特殊类型的索引，他查找的是文中的关键词，而不是直接比较索引中的值。</li>
<li>全文索引有很多的细节需要调整，比如分词、停用词、词干、复数、布尔查询等。</li>
<li>MySQL 对空间数据索引和全文索引支持都不是很好，如果有此功能需求，建议使用其他存储引擎，如 monogDB 或基于 lucene 的 solr、es。</li>
</ol>
<h1>QA</h1>
<h2 id="mysql-为什么使用-b-树作为索引的底层实现数据结构？而不是希表-数组-红黑树"><a class="header-anchor" href="#mysql-为什么使用-b-树作为索引的底层实现数据结构？而不是希表-数组-红黑树">¶</a>MySQL 为什么使用 B+树作为索引的底层实现数据结构？而不是希表、数组、红黑树</h2>
<ol>
<li>vs 哈希表<br>
哈希表支持 O(1)的读写，但是无序，无法满足排序需求。</li>
<li>vs （有序）数组<br>
数组虽然通过二分查找可以保证 O(log2n)的查找效率，且有序，但是写操作需要对整个数组“挪位置”，非常耗时。</li>
<li>vs 红黑树<br>
红黑树的每个节点都非常小，自顶向下搜索的过程中又会遍历多个节点，遍历的节点数量和树的高度有关，如果这些节点被分散到了多个页面上，相当于要将这些页面全部加载到内存中，并在内存不足时淘汰掉一些页面，导致 IO 压力增大。</li>
</ol>
<h2 id="一页可以保存多少个-b-树节点？一棵-b-树能存储多少条记录？"><a class="header-anchor" href="#一页可以保存多少个-b-树节点？一棵-b-树能存储多少条记录？">¶</a>一页可以保存多少个 B+树节点？一棵 B+树能存储多少条记录？</h2>
<p>一页对应一个 B+树节点。<br>
一页的大小是 16KB，假设一行数据占用空间为 1KB，那么数据页（叶子节点）一页最多能存储 16 行数据。<br>
非叶子节点存储的是数据的主键和对其他页的指针，假设主键的类型为 bigint，则占用的空间为 8 字节，指针大小在 InnoDB 源码中设置为 6 字节，因此总共为 14 字节，非叶子节点总共能存储的记录数=16384(16KB) / 14 = 1170。<br>
InnoDB 中 B+树的高度一般为 1-3 层，因此能存储的记录数=1170 * 1170 * 16 = 21902400(2 千万)。</p>
<h2 id="为什么主键要使用自增主键"><a class="header-anchor" href="#为什么主键要使用自增主键">¶</a>为什么主键要使用自增主键</h2>
<p>目标是占用尽可能少的空间、且保证较高的效率，自增可以保证递增的插入，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。<br>
如果是业务字段，就不容易保证有序插入了，会导致数据的写成本相对较高，而且业务字段往往较长，会更加占用存储空间。</p>
<h2 id="重建索引"><a class="header-anchor" href="#重建索引">¶</a>重建索引</h2>
<p>索引可能会因为删除、页分裂等原因而导致数据页产生空洞，为了消除这些空洞、压缩磁盘空间，就需要重建索引，将原数据按顺序插入。<br>
重建索引时没有必要 drop 后再 add，比如：<br>
alter table T drop index k;<br>
alter table T add index(k);<br>
因为这两个语句都会将整个索引重建。重建索引可以用以下语句代替：<br>
alter table T engine=InnoDB</p>
<h2 id="下面的建表语句中-既然已经有了-a-b-作为主键索引-那么在-c-上加了索引后-就已经包含了-a-b-c-三个字段-为什么还需要创建-c-a-c-b-这两个索引"><a class="header-anchor" href="#下面的建表语句中-既然已经有了-a-b-作为主键索引-那么在-c-上加了索引后-就已经包含了-a-b-c-三个字段-为什么还需要创建-c-a-c-b-这两个索引">¶</a>下面的建表语句中，既然已经有了(a, b)作为主键索引，那么在 c 上加了索引后，就已经包含了 a、b、c 三个字段，为什么还需要创建(c, a)、(c, b)这两个索引</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `geek` (</span><br><span class="line">  `a` int(11) NOT NULL,</span><br><span class="line">  `b` int(11) NOT NULL,</span><br><span class="line">  `c` int(11) NOT NULL,</span><br><span class="line">  `d` int(11) NOT NULL,</span><br><span class="line">  PRIMARY KEY (`a`,`b`),</span><br><span class="line">  KEY `c` (`c`),</span><br><span class="line">  KEY `ca` (`c`,`a`),</span><br><span class="line">  KEY `cb` (`c`,`b`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>
<p>为了解答这个问题，首先需要理解索引的字段顺序是有意义的，(a, b)表示先按 a 排序，a 值相同的情况下再按 b 进行排序，索引(c, a)是先按 c 排序，再按 a 排序，这实际上和索引©是一样的，所以(c, a)是多余的。</p>
<h2 id="收缩表空间"><a class="header-anchor" href="#收缩表空间">¶</a>收缩表空间</h2>
<p>对一个大小为 1TB 的表文件执行<code>alter table t engine=InnoDB</code>重建，为什么会出现占用空间没变小反而变大的情况。<br>
这是因为，在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的，反而引入了一些空洞。</p>
<h2 id="如何使用慢查询日志-slow-log"><a class="header-anchor" href="#如何使用慢查询日志-slow-log">¶</a>如何使用慢查询日志（slow log）</h2>
<h2 id="自增主键是连续的吗"><a class="header-anchor" href="#自增主键是连续的吗">¶</a>自增主键是连续的吗</h2>
<ol>
<li>由于 AUTO_INCREMENT 存在内存中，重启时导致不连续
<ul>
<li>MyISAM 引擎的自增值保存在数据文件中。</li>
<li>InnoDB 引擎的自增值，其实是保存在了内存里，重启后会从表中查当前最大的值+1 作为下一次主键取值；到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。<br>
也就是说，MySQL8.0 之前自增主键是有可能丢失的，比如：当前最大主键是 10，AUTO_INCREMENT=11，这时我们删除了 id=10 的行，AUTO_INCREMENT 不变，但是如果马上重启实例，则重启后的这个表的 AUTO_INCREMENT 会变成 10。</li>
</ul>
</li>
<li>主键冲突<br>
出现空洞还有一种情况：插入行未指定主键的时候，MySQL 会用当前的 AUTO_INCREMENT 作为主键值，并且设置 AUTO_INCREMENT+1，但是仍有可能出现跟其他唯一键冲突的情况，导致插入失败，这时 AUTO_INCREMENT 是不会回滚的，也就导致了自增主键的不连续。</li>
<li>回滚</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">insert into t values(null,1,1);</span><br><span class="line">begin;</span><br><span class="line">insert into t values(null,2,2);</span><br><span class="line">rollback;</span><br><span class="line">insert into t values(null,2,2);</span><br><span class="line">//插入的行是(3,2,2)</span><br></pre></td></tr></table></figure>
<p>为什么事务回滚不允许把自增值也回滚了？主要是存在多个事务并发执行的情况：<br>
* 假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。<br>
* 事务 B 正确提交了，但事务 A 出现了唯一键冲突。<br>
* 如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。<br>
* 接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。</p>
<ol>
<li>事务乱序执行<br>
多个事务并发执行时，这些事务内部各个语句执行顺序不确定，比如：
<ul>
<li>session B 先插入了两个记录，(1,1,1)、(2,2,2)；</li>
<li>然后，session A 来申请自增 id 得到 id=3，插入了（3,5,5)；</li>
<li>之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。<br>
如果现在<code>binlog_format=statement</code>，则 binlog 里对表的更新日志，要么先记 session A 的，要么先记 session B 的，那么在备库中各 session 执行的结果 id 都是连续的，这时这个库就发生了数据不一致。<br>
这个问题的一种解决办法是让原库的批量插入数据语句固定生成连续的 id 值；或者在 binlog 里把插入数据的操作都如实记录进来，即<strong>innodb_autoinc_lock_mode 设置为 2，同时 binlog_format 设置为 row</strong>。</li>
</ul>
</li>
</ol>
<h2 id="对-a-b-字段分别加索引-现有一个查询条件同时对这两个字段进行过滤-怎么知道最终使用的是哪个索引？"><a class="header-anchor" href="#对-a-b-字段分别加索引-现有一个查询条件同时对这两个字段进行过滤-怎么知道最终使用的是哪个索引？">¶</a>对 a, b 字段分别加索引，现有一个查询条件同时对这两个字段进行过滤，怎么知道最终使用的是哪个索引？</h2>
<p>采样统计查询需要扫描的行数，在不同查询方式中选择需要扫描行数最少的那个。<br>
采样统计时，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</p>
<h2 id="下面的语句为什么不走索引"><a class="header-anchor" href="#下面的语句为什么不走索引">¶</a>下面的语句为什么不走索引</h2>
<p>建表语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `x` (</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `b` tinyint(4) DEFAULT NULL,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  `str` varchar(20) DEFAULT NULL,</span><br><span class="line">  KEY `idx_test` (`a`,`b`,`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>
<p>查询语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">explain select * from x</span><br><span class="line">where a = 5</span><br><span class="line">order by b, c;</span><br></pre></td></tr></table></figure>
<p>其中，如下图所示，key_len 字段为 5，这是 a 字段的数据长度，因此 b、c 字段实际上并没有走索引：<br>
<img src="https://tallate.top/imgs/MySQL/MySQL-%E6%9F%90%E4%BA%9B%E6%9D%A1%E4%BB%B6%E4%B8%8B%E4%B8%8D%E8%B5%B0%E7%B4%A2%E5%BC%951.png" alt="MySQL-某些条件下不走索引1" title="MySQL-某些条件下不走索引1"></p>
<p>没有走索引的原因是：SQL 查询的执行流程是先根据<code>where</code>子句条件查二级索引，将数据回表带出<code>select</code>所需的所有字段，加载到<code>sort_buffer</code>内，然后排序。所以无法利用索引结构的有序性来实现排序。</p>
<h2 id="为什么要加主键"><a class="header-anchor" href="#为什么要加主键">¶</a>为什么要加主键</h2>
<p>主键唯一确定一行，没有主键我们无法 CRUD 特定的某行。</p>
<h2 id="innodb的辅助索引叶子节点为什么不直接保存记录地址而要存主键键值？"><a class="header-anchor" href="#innodb的辅助索引叶子节点为什么不直接保存记录地址而要存主键键值？">¶</a>InnoDB的辅助索引叶子节点为什么不直接保存记录地址而要存主键键值？</h2>
<p>试想将记录地址直接保存到叶子节点，那每次直接可以从记录地址取到数据，就不用再回表了，这样不是更快吗？<br>
其实主要原因是InnoDB的数据是按主键组织的，数据被保存到主键的叶子节点上：</p>
<ul>
<li>如果辅助索引保存的是记录地址，那么每次页分裂时记录的地址发生变化，还得同步到辅助索引上，这就非常麻烦了；</li>
<li>如果辅助索引保存的是主键，除了不受主键索引树页分裂影响外，其实还要提一句的是，回表并没有那么慢，因为InnoDB中B+树的高度是非常低的，查一条记录并不需要读多少页。</li>
</ul>
<h2 id="为什么不要创建过多的索引"><a class="header-anchor" href="#为什么不要创建过多的索引">¶</a>为什么不要创建过多的索引</h2>
<p>因为维护索引开销大，当我们修改一个字段时，需要同步修改到使用了这个字段的所有索引上，也就是说会对 insert/update/delete 语句会有负面影响。<br>
原则上应该只有查询的字段才建立索引、这些字段重复度不高且基本不变，或者通过读写分离等分库分表技术来提高数据库整体效率。</p>
<h2 id="b-树和-b-树之间的区别"><a class="header-anchor" href="#b-树和-b-树之间的区别">¶</a>B 树和 B+树之间的区别</h2>
<p><img src="https://tallate.top/imgs/MySQL/MySQL-B%E6%A0%91%E7%A4%BA%E4%BE%8B.png" alt="MySQL-B树示例" title="MySQL-B树示例"><br>
<img src="https://tallate.top/imgs/MySQL/MySQL-B%E5%8A%A0%E6%A0%91%E7%A4%BA%E4%BE%8B.png" alt="MySQL-B加树示例" title="MySQL-B加树示例"></p>
<ol>
<li>B 树内部节点也会存储数据，而 B+树只有叶子节点会存储数据<br>
对于数据库的场景来说，因为 B+树只有叶子节点存储数据，内部节点只存储每个叶子节点中最大的键值，相当于一个页面的“指针”，因为这个“指针”占用的空间很小，因此内部节点就可以存储很多叶子节点的指针，即使这个 B+树的高度只有 3 也可以存储千万级别的页面。</li>
<li>B+树叶子节点之间前后串联形成链表<br>
如果需要范围查找，B 树需要中序遍历，而 B+树只需遍历叶子节点组成的链表。</li>
</ol>
<h2 id="innodb-与-myisam-之间的区别"><a class="header-anchor" href="#innodb-与-myisam-之间的区别">¶</a>InnoDB 与 MyISAM 之间的区别</h2>
<ol>
<li>索引角度<br>
InnoDB 支持外键，而 MyISAM 不支持。<br>
InnoDB 是聚集索引，而 MyISAM 是非聚集索引。</li>
<li>表行数<br>
InnoDB 不保存具体表行数，<code>select count(*) from table</code>需要全表扫描，而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时可以直接读出该变量。</li>
<li>锁角度<br>
InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。</li>
<li>事务角度<br>
InnoDB 支持事务，而 MyISAM 不支持。</li>
</ol>
<h2 id="mysql-为什么会发生抖动"><a class="header-anchor" href="#mysql-为什么会发生抖动">¶</a>MySQL 为什么会发生抖动</h2>
<p>InnoDB 写入磁盘前需要先记<strong>redo log</strong>，redo log 是一个有限大小的环形数组，剩余空间不足以继续写入时会执行刷脏页操作，当出现以下两种情况时，都会明显地影响性能：</p>
<ol>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li>
<li>日志被写满，更新全部堵住，写性能跌为 0，这种情况对于敏感业务来说是不能接受的。</li>
</ol>
<p>redo log 能帮助 MySQL 实现 ACID 中的持久化能力，非常重要，因此刷脏页本身是无法避免的，解决办法是优化刷脏页的控制策略：</p>
<ol>
<li>刷脏页速度<br>
<code>innodb_io_capacity</code>：告诉 InnoDB 磁盘能力，最好设置成磁盘的 IOPS。</li>
<li>控制刷邻居行为<br>
<code>innodb_flush_neighbors</code>：如果要刷的页面旁边也是脏页，也会一块刷了，如果这个页面旁边还是脏页则这个过程会不断扩散，这个行为可以通过<code>innodb_flush_neighbors</code>这个参数控制，即最多刷新多少个邻居。</li>
</ol>
<h2 id="为什么写-bin-log-和-redo-log-时需要两阶段提交"><a class="header-anchor" href="#为什么写-bin-log-和-redo-log-时需要两阶段提交">¶</a>为什么写 bin log 和 redo log 时需要两阶段提交</h2>
<p>由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。<br>
在写这两个 log 的时候中间如果发生了 crash，可能会出现无法恢复的情况：</p>
<ol>
<li>先写 redo log 后写 bin log。<br>
redo log 写完后即使系统崩溃仍然能把数据恢复过来。但是由于 bin log 没写完就 crash 了，所以 bin log 中就没有这条语句了，之后使用这个 bin log 来恢复临时库时就会丢了这次更新，导致主从不一致。</li>
<li>先写 bin log 后写 redo log<br>
bin log 写完后 crash，由于 redo log 还没写，崩溃恢复后这个事务无效（update 语句相当于没执行）。但是 bin log 里已经记录了修改操作，因此之后用 bin log 恢复的时候就多了一个事务，与原库中的值不同。</li>
</ol>
<h2 id="哪些命令可以立刻释放磁盘空间？"><a class="header-anchor" href="#哪些命令可以立刻释放磁盘空间？">¶</a>哪些命令可以立刻释放磁盘空间？</h2>
<p>一般情况下删除数据只是惰性删除，不会立刻释放磁盘空间：</p>
<ul>
<li><code>delete * from t where ...</code></li>
<li><code>delete * from t</code></li>
</ul>
<p>但是有些命令会立刻释放磁盘空间：</p>
<ul>
<li><code>truncate table t</code>删除表中全部数据</li>
<li><code>alter table t engine = innodb</code>重做数据</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/6ce879b3.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/6ce879b3.html" itemprop="url">规则引擎</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-20T18:53:22+08:00">
                2019-11-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9.7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  43 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1>规则引擎介绍</h1>
<h2 id="什么是规则引擎"><a class="header-anchor" href="#什么是规则引擎">¶</a>什么是规则引擎</h2>
<p><strong>规则引擎</strong>是<strong>专家系统</strong>的变种，它通过一组规则的集合、通过作用于事实，从而推理得到结果。当一个事实满足某条规则的条件时，就可以认为这个事实与这条规则匹配。比如，如果我的成绩达到 90 分以上就出去旅游，其中的事实是<code>我</code>，规则是<code>if(x的成绩达到90分以上){x出去玩}</code></p>
<ul>
<li>规则<br>
可以理解为类似 if-else、switch 这样的代码；</li>
<li>事实<br>
在 Java 中可以认为就是类的实例；</li>
</ul>
<h2 id="为什么使用规则引擎"><a class="header-anchor" href="#为什么使用规则引擎">¶</a>为什么使用规则引擎</h2>
<ol>
<li>规则引擎实现了数据同逻辑的完全解耦。</li>
<li>有助于规则的集中管理，但是也要注意可能发生的冲突。</li>
<li>每个开发的习惯、水平都不一样，有些人可能会生硬地套用一些设计模式，导致业务逻辑被强行设计得很复杂，而且随着版本、人员迭代越发严重；<br>
而规则引擎相当于一套实现业务逻辑的规范，它会逼迫需求和研发人员梳理业务，并建立统一的 BOM（业务对象模型）。</li>
<li>可以使用<strong>决策表</strong>等形式来展示规则，方便业务人员浏览，减少与技术人员沟通成本。</li>
<li>方便业务人员修改业务逻辑，甚至可以做到动态修改、实时生效，减少规则变动带来的额外开发工作。</li>
</ol>
<blockquote>
<p>在复杂的大型业务场景下，规则引擎常和<strong>流程引擎</strong>搭配使用来强化对业务逻辑的管理。</p>
</blockquote>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/6ce879b3.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">135</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">70</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
