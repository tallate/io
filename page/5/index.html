<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/page/5/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/page/5/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/3b3d260d.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/3b3d260d.html" itemprop="url">并发和中间件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-22T21:07:49+08:00">
                2019-09-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计/" itemprop="url" rel="index">
                    <span itemprop="name">设计</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  24 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="rpc"><a class="header-anchor" href="#rpc">¶</a>RPC</h2>
<h3 id="客户端-or-服务端-异步"><a class="header-anchor" href="#客户端-or-服务端-异步">¶</a>客户端 OR 服务端 异步</h3>
<p>客户端异步比较常见，因为任何网络调用基本都可以方便地包装成异步调用，朴实无华且枯燥，下载这段代码是一个简单的 demo：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class ClientAsync &#123;</span><br><span class="line"></span><br><span class="line">    private static class ClientAsyncExecutor &#123;</span><br><span class="line"></span><br><span class="line">        private ExecutorService threadPool;</span><br><span class="line">        private Supplier&lt;String&gt; dataSupplier;</span><br><span class="line">        private Consumer&lt;String&gt; callback;</span><br><span class="line"></span><br><span class="line">        public ClientAsyncExecutor(ExecutorService threadPool,</span><br><span class="line">                Supplier&lt;String&gt; dataSupplier,</span><br><span class="line">                Consumer&lt;String&gt; callback) &#123;</span><br><span class="line">            this.threadPool = threadPool;</span><br><span class="line">            this.dataSupplier = dataSupplier;</span><br><span class="line">            this.callback = callback;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void call() &#123;</span><br><span class="line">            threadPool.submit(() -&gt; &#123;</span><br><span class="line">                String data = dataSupplier.get();</span><br><span class="line">                callback.accept(data);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        ExecutorService threadPool = Executors.newCachedThreadPool();</span><br><span class="line">        ClientAsyncExecutor executor = new ClientAsyncExecutor(</span><br><span class="line">                threadPool,</span><br><span class="line">                () -&gt; &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        Thread.sleep(3000);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                    return &quot;done&quot;;</span><br><span class="line">                &#125;,</span><br><span class="line">                res -&gt; System.out.println(&quot;结果：&quot; + res));</span><br><span class="line">        executor.call();</span><br><span class="line">        System.out.println(&quot;call returned&quot;);</span><br><span class="line">        threadPool.shutdown();</span><br><span class="line">        threadPool.awaitTermination(10000, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端异步是一种伪异步，本质上仍是同步调用，只不过等待是放到另外一个线程中去做的，如果这样等待的线程比较多，对客户端的线程池容易造成压力，。<br>
服务端的异步实现起来就比较费劲了，因为客户端需要额外提供一个入口来接收服务端执行完毕的结果：<br>
<img src="http://47.88.24.11/imgs/%E5%B9%B6%E5%8F%91/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%BC%82%E6%AD%A5.png" alt="服务端异步" title="服务端异步"></p>
<h3 id="良好习惯"><a class="header-anchor" href="#良好习惯">¶</a>良好习惯</h3>
<p>不论是桌面应用还是 Web 应用，多线程代码都是比较难玩得转的，玩不明白的结果就是一大堆令人毛骨悚然且难以捉摸、难以调试的问题——实际上，一旦你意识到正在处理一个并发问题，你可能就不得不完全放弃调试了，并转而手动检查代码。<br>
鉴于此，我们当然是希望尽量避免并发问题的，理想情况下希望完全避免多线程错误，同样，不存在那种一刀切的方法，但这有一些调试和防止多线程错误的实际考虑因素：</p>
<ol>
<li>避免全局状态<br>
首先，牢记 “全局状态” 问题。如果你正创建一个多线程应用，那么应该密切关注任何可能全局修改的内容，如果可能的话，将他们全部删掉，如果部分全局变量确实有理由保留，那么应该仔细保证其并发安全，并对程序性能进行跟踪，以确定不会因为引入新的等待时间而导致系统性能降低（并发修改时需要同步多个线程）。</li>
<li>避免可变性<br>
这点直接来自于 函数式编程，并且适用于 OOP，声明应该避免类和对象状态的改变。简而言之，这意味着放弃 setter 方法，并在需要避免可变性的类或字段上拥有私有的 final 字段，它们的值唯一发生变化的时间是在构造期间。这样，你可以确定不会出现争用问题，且访问对象属性将始终提供正确的值。</li>
<li>日志及报警<br>
评估你的程序可能会在何处发生异常，并预先记录所有关键数据。如果发生错误，你将很高兴可以得到信息说明收到了哪些请求，并可更好地了解你的应用程序为什么会出现错误。需要再次注意的是，日志记录引入了额外的文件 I/O，可能会严重影响应用的性能，因此请不要滥用日志。<br>
在记日志的基础上，有必要根据 SLA 记录一些指标的报警阈值，比如订单中心下单失败，考虑可能是网络出现抖动引起超时（如果用到三方服务这个问题会更明显），因此报警阈值可以稍微调高一些，比如 1 分钟 3 次失败就打电话报警。</li>
<li>复用现存实现<br>
每当你需要创建自己的线程时（例如：向不同的服务发出异步请求），复用现有的安全实现来代替创建自己的解决方案。这在很大程度上意味着要使用 ExecutorService 和 Java 8 简洁的函数式 CompletableFuture 来创建线程。Spring 还允许通过 DeferredResult 类来进行异步请求处理。</li>
</ol>
<h3 id="反模式-异步狂热"><a class="header-anchor" href="#反模式-异步狂热">¶</a>反模式-异步狂热</h3>
<p>上边我们已经讨论过异步存在的优势和劣势，实际上在我读过的项目代码中，确实存在不少那种不异步不开心的“炫技代码”，给维护带来很大困难。<br>
下面是一个非常直观的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public String punch(People t) &#123;</span><br><span class="line">    return &quot;Oh, No&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过一个莫名其妙的异步包装，原来的可扩展性、性能均没有提升，甚至性能成功降低了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public Function doPunch(People t) &#123;</span><br><span class="line">    return t -&gt; &#123;</span><br><span class="line">        return &quot;Oh, No&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public String punch(People t) &#123;</span><br><span class="line">    Function f = doPunch(t);</span><br><span class="line">    return f.apply(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际情况可能会复杂得多，这样的代码不够简单直观、容易暗藏 Bug、不符合 KISS 原则，但是即便如此，还是有很多人会觉得特别绕的代码能体现一个人的水平、对代码的驾驭能力、能灵活运用设计模式的能力，我觉得大部分情况下事实并非如此。</p>
<h2 id="spring-deferredresult"><a class="header-anchor" href="#spring-deferredresult">¶</a>Spring - DeferredResult</h2>
<p>TODO</p>
<h2 id="hystrix-command"><a class="header-anchor" href="#hystrix-command">¶</a>Hystrix - Command</h2>
<p>Hystrix 的 Command 框架在 CompletableFuture 的基础上提供了合并请求的特性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">public class BatchGetDataCommand extends HystrixCommand&lt;List&lt;Double&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; requests;</span><br><span class="line"></span><br><span class="line">    public BatchGetDataCommand(Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; requests) &#123;</span><br><span class="line">        super(Setter.withGroupKey(</span><br><span class="line">                HystrixCommandGroupKey.Factory.asKey(&quot;batchGetData&quot;)));</span><br><span class="line">        this.requests = requests;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected List&lt;Double&gt; run() throws Exception &#123;</span><br><span class="line">        // TODO: 做些批量查询操作，这里作为示范直接返回</span><br><span class="line">        return requests.stream()</span><br><span class="line">                .map(CollapsedRequest::getArgument)</span><br><span class="line">                .map(arg -&gt; (double) arg)</span><br><span class="line">                .collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class SimpleGetDataCommand extends HystrixCollapser&lt;List&lt;Double&gt;, Double, Long&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private Long id;</span><br><span class="line"></span><br><span class="line">    public SimpleGetDataCommand(Long id) &#123;</span><br><span class="line">        super(HystrixCollapser.Setter</span><br><span class="line">                .withCollapserKey(HystrixCollapserKey.Factory.asKey(&quot;getData&quot;))</span><br><span class="line">                .andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter()</span><br><span class="line">                        .withMaxRequestsInBatch(2)</span><br><span class="line">                        .withTimerDelayInMilliseconds(5)</span><br><span class="line">                        // 允许缓存request的结果</span><br><span class="line">                        .withRequestCacheEnabled(true))</span><br><span class="line">                .andScope(Scope.REQUEST));</span><br><span class="line">        this.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Long getRequestArgument() &#123;</span><br><span class="line">        return id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected HystrixCommand&lt;List&lt;Double&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; collapsedRequests) &#123;</span><br><span class="line">        return new BatchGetDataCommand(collapsedRequests);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void mapResponseToRequests(final List&lt;Double&gt; batchResponse, Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; collapsedRequests) &#123;</span><br><span class="line">        final AtomicInteger count = new AtomicInteger();</span><br><span class="line">        collapsedRequests.forEach(request -&gt; &#123;</span><br><span class="line">            request.setResponse(</span><br><span class="line">                    batchResponse.get(count.getAndIncrement()));</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        HystrixRequestContext context = HystrixRequestContext.initializeContext();</span><br><span class="line">        try &#123;</span><br><span class="line">            // Hystrix内部将多个查询合并成一个</span><br><span class="line">            SimpleGetDataCommand command1 = new SimpleGetDataCommand(1L);</span><br><span class="line">            SimpleGetDataCommand command2 = new SimpleGetDataCommand(2L);</span><br><span class="line">            // 这里需要先使用queue而不是execute</span><br><span class="line">            Future&lt;Double&gt; f1 = command1.queue();</span><br><span class="line">            Future&lt;Double&gt; f2 = command2.queue();</span><br><span class="line">            System.out.println(f1.get());</span><br><span class="line">            System.out.println(f2.get());</span><br><span class="line">        &#125; catch (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            context.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="任务调度"><a class="header-anchor" href="#任务调度">¶</a>任务调度</h2>
<h3 id="补偿执行"><a class="header-anchor" href="#补偿执行">¶</a>补偿执行</h3>
<p>异常订单表，定时任务</p>
<h3 id="定时任务的实现"><a class="header-anchor" href="#定时任务的实现">¶</a>定时任务的实现</h3>
<p>无分布式的，HashTimeWheelTimer<br>
分布式情况下，可以先用 Redis，当复杂时再用 RabbitMQ 等消息队列中间件。</p>
<h3 id="消息-or-定时任务"><a class="header-anchor" href="#消息-or-定时任务">¶</a>消息 OR 定时任务</h3>
<p>很多异步实现的功能既可以通过消息实现又可以通过定时任务来实现，我经历过很多需要抉择的情况，甚至也碰到过对此都不大清楚的架构师，我认为对此没有唯一的答案，只能根据具体业务场景来分析，一些要点可供参考。</p>
<ul>
<li>
<p>分布式</p>
</li>
<li>
<p>并发安全</p>
</li>
<li>
<p>运维便利性<br>
消息本质上是把任务暂存在队列服务里，统计某段时间内发生了什么、会发生什么就比较困难了，因为往往消息队列都会有自定义的数据格式，判断一条消息是否被消费往往得通过日志来判断。<br>
定时任务一般都会有执行记录，什么时间会执行任务也可以直接用 cron 表达式计算出来，缺点是使用定时任务意味着需要自己维护很多东西，比如在数据库里维护一个队列保存消息，保存有创建时间、重试次数、重试时间等，失败 N 次后还需要存一份失败记录。</p>
</li>
</ul>
<p>以一个“通知拉取”的场景举例，A 系统需要从 B 系统拉取数据，但并不是定时地直接调 B 的接口，而是先由 B 通知 A 哪些数据发生了变更，然后由 A 去拉取这些数据的变更部分：</p>
<ul>
<li>如果使用消息队列来实现：</li>
<li>如果使用定时任务实现：</li>
</ul>
<h3 id="使用-thread-实现任务调度"><a class="header-anchor" href="#使用-thread-实现任务调度">¶</a>使用 Thread 实现任务调度</h3>
<p>实现任务调度最简单的方式可以直接利用 Thread：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(10);</span><br><span class="line">Thread thread = new Thread(() -&gt; &#123;</span><br><span class="line">    while (true) &#123;</span><br><span class="line">        String task = &quot;&quot;;</span><br><span class="line">        try &#123;</span><br><span class="line">            task = queue.take();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(task);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">thread.start();</span><br><span class="line">queue.put(&quot;hello&quot;);</span><br></pre></td></tr></table></figure>
<h3 id="timer"><a class="header-anchor" href="#timer">¶</a>Timer</h3>
<p>Timer 内部通过一个 TimerThread 来循环执行提交给 Timer 的任务，因此任务是<strong>串行的</strong>，前一个任务的延迟会影响后续的所有任务。<br>
Timer 可以看做一种简化版的 ScheduledExecutor，下面是一种 Demo 实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class DemoTimer &#123;</span><br><span class="line">    private static ScheduledExecutorService timer = Executors.newScheduledThreadPool(1);</span><br><span class="line"></span><br><span class="line">    public static void setTimeout(final Runnable function, long time,</span><br><span class="line">                                  TimeUnit timeUnit, final Executor executor) &#123;</span><br><span class="line">        Preconditions.checkArgument(time &gt;= 0);</span><br><span class="line">        Preconditions.checkNotNull(function);</span><br><span class="line">        Preconditions.checkNotNull(timeUnit);</span><br><span class="line">        Preconditions.checkNotNull(executor);</span><br><span class="line">        timer.schedule(() -&gt; executor.execute(function), time, timeUnit);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="scheduledexecutor"><a class="header-anchor" href="#scheduledexecutor">¶</a>ScheduledExecutor</h3>
<p>ScheduledExecutor 能提供一种更灵活的周期性任务处理功能，</p>
<h3 id="quartz"><a class="header-anchor" href="#quartz">¶</a>Quartz</h3>
<h3 id="spring-task"><a class="header-anchor" href="#spring-task">¶</a>Spring Task</h3>
<h3 id="quartz-集群版"><a class="header-anchor" href="#quartz-集群版">¶</a>Quartz 集群版</h3>
<h3 id="tbschedule"><a class="header-anchor" href="#tbschedule">¶</a>tbschedule</h3>
<h3 id="xxl-job"><a class="header-anchor" href="#xxl-job">¶</a>xxl-job</h3>
<h3 id="elastic-job"><a class="header-anchor" href="#elastic-job">¶</a>Elastic-Job</h3>
<p><img src="http://47.88.24.11/imgs/%E5%B9%B6%E5%8F%91/Elastic-Job%E6%9E%B6%E6%9E%84.png" alt="Elastic-Job架构" title="Elastic-Job架构"><br>
Elastic-Job 分为 Elastic-Job-Lite 和 Elastic-Job-Console 两个模块。Elastic-Job-Lite 实现了分布式任务调度、动态扩容缩容、任务分片、失效转移等功能。<br>
如上图所示，Elastic-Job-Lite 采用去中心化的调度方式，由 Elastic-Job-Lite 的客户端定时自动触发任务调度，通过任务分片的概念实现服务器负载的动态扩容和缩容，并且使用 ZooKeeper 作为分布式任务调度的注册中心；当某任务实例崩溃后，自动失效转移，实现高可用。</p>
<h2 id="消息队列-mq-原理"><a class="header-anchor" href="#消息队列-mq-原理">¶</a>消息队列（MQ）原理</h2>
<p>MQ 有很多优势，当我们选择 MQ 时，主要是为了：</p>
<ul>
<li>解耦……<br>
比如 A 系统要将用户提交的数据推送到 B、C 两个系统的时候，最初的想法很有可能是直接用 http 或 rpc 调用实现。像这样的下游系统后来又会多出 D、E、F…，对 A 系统的压力就会越来越大，更复杂的场景中，数据通过接口传给其他系统有时候还要考虑重试、超时等一些异常情况。<br>
这时，对 A 来说更好的方案是将消息发送给 mq，不管有哪个下游系统需要这个数据都可以直接订阅这个 subject。</li>
<li>异步<br>
当请求比较复杂，而其中有部分数据没必要实时更新时，可以用 mq 实现异步化。比如取消订单后需要做订单状态的更新、对账、退款等操作，而其中只有状态的变更是有必要实时反馈给用户的，那么后续的所有操作就完全可以做成异步的。</li>
<li>削峰填谷<br>
消息队列作为缓冲队列应对突发流量时，并不能使处理速度变快，而是使处理速度变平滑，从而不会因瞬时压力过大而压垮应用。<br>
举个例子，比如我们的订单系统，在下单的时候就会往数据库写数据。但是数据库只能支撑每秒 1000 左右的并发写入，并发量再高就容易宕机。<br>
低峰期的时候并发也就 100 多个，但是在高峰期时候，并发量会突然激增到 5000 以上，这个时候数据库肯定死了。<br>
但是使用了 MQ 之后，情况就变了，消息被 MQ 保存起来了，然后系统就可以按照自己的消费能力来消费，比如每秒 1000 个数据，这样慢慢写入数据库，这样就不会打死数据库了。<br>
如果没有用 MQ 的情况下，并发量高峰期的时候是有一个“顶峰”的，然后高峰期过后又是一个低并发的“谷”。<br>
但是使用了 MQ 之后，限制消费消息的速度为 1000，但是这样一来，高峰期产生的数据势必会被积压在 MQ 中，高峰就被“削”掉了。<br>
但是因为消息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在 1000QPS，直到消费完积压的消息,这就叫做“填谷”。</li>
</ul>
<h3 id="高可用"><a class="header-anchor" href="#高可用">¶</a>高可用</h3>
<p>使用了 MQ 之后，我们肯定是希望 MQ 有高可用特性，因为不可能接受机器宕机了，就无法收发消息的情况。<br>
这一块我们也是基于 RabbitMQ 这种经典的 MQ 来说明一下：<br>
RabbitMQ 是比较有代表性的，因为是基于主从做高可用性的，我们就以他为例子讲解第一种 MQ 的高可用性怎么实现。<br>
rabbitmq 有三种模式：单机模式，普通集群模式，镜像集群模式<br>
单机模式<br>
单机模式就是 demo 级别的，就是说只有一台机器部署了一个 RabbitMQ 程序。<br>
这个会存在单点问题，宕机就玩完了，没什么高可用性可言。一般就是你本地启动了玩玩儿的，没人生产用单机模式。<br>
普通集群模式<br>
这个模式的意思就是在多台机器上启动多个 rabbitmq 实例。类似的 master-slave 模式一样。<br>
但是创建的 queue，只会放在一个 master rabbtimq 实例上，其他实例都同步那个接收消息的 RabbitMQ 元数据。<br>
在消费消息的时候，如果你连接到的 RabbitMQ 实例不是存放 Queue 数据的实例，这个时候 RabbitMQ 就会从存放 Queue 数据的实例上拉去数据，然后返回给客户端。<br>
总的来说，这种方式有点麻烦，没有做到真正的分布式，每次消费者连接一个实例后拉取数据，如果连接到不是存放 queue 数据的实例，这个时候会造成额外的性能开销。如果从放 Queue 的实例拉取，会导致单实例性能瓶颈。<br>
如果放 queue 的实例宕机了，会导致其他实例无法拉取数据，这个集群都无法消费消息了，没有做到真正的高可用。<br>
所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。<br>
镜像集群模式<br>
镜像集群模式才是真正的 rabbitmq 的高可用模式，跟普通集群模式不一样的是：创建的 queue 无论元数据还是 queue 里的消息都会存在于多个实例上，<br>
每次写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。<br>
这样的话任何一个机器宕机了别的实例都可以用提供服务，这样就做到了真正的高可用了。<br>
但是也存在着不好之处：</p>
<ul>
<li>性能开销过高，消息需要同步所有机器，会导致网络带宽压力和消耗很重</li>
<li>扩展性低：无法解决某个 queue 数据量特别大的情况，导致 queue 无法线性拓展。<br>
就算加了机器，那个机器也会包含 queue 的所有数据，queue 的数据没有做到分布式存储。<br>
对于 RabbitMQ 的高可用一般的做法都是开启镜像集群模式，这样起码来说做到了高可用，一个节点宕机了，其他节点可以继续提供服务。</li>
</ul>
<h3 id="高性能"><a class="header-anchor" href="#高性能">¶</a>高性能</h3>
<ul>
<li>对于内存操作的线程分离，大部分中间件做法是将数据文件缓存与内存中，通过异步线程 flush 至硬盘</li>
<li>合理的存储引擎对应不同的服务场景 B+树，hash，LSM</li>
<li>对于消息队列，选取顺序读写磁盘的方式，可以高效的提升磁盘 IO 速度</li>
<li>顺序写磁盘可以带来足够的写入速度，其读取方式为二分查找</li>
<li>对于 LSM 存储引擎，同样采用顺序写磁盘方式，牺牲一部分读性能从而获得更优越的写性能</li>
</ul>
<h3 id="消息队列如何选型"><a class="header-anchor" href="#消息队列如何选型">¶</a>消息队列如何选型</h3>
<h3 id="异步处理"><a class="header-anchor" href="#异步处理">¶</a>异步处理</h3>
<h3 id="延时消费"><a class="header-anchor" href="#延时消费">¶</a>延时消费</h3>
<h3 id="应用隔离-系统解耦"><a class="header-anchor" href="#应用隔离-系统解耦">¶</a>应用隔离（系统解耦）</h3>
<p>比如有两个主题的消息，其中 A 主题的消息特别多，别的消息就会来不及处理。<br>
这种情况有点类似于服务治理中的隔离策略：一个服务出错不能影响别的服务不可用。一般会采用线程池、信号量来实现。<br>
MQ 消息中的主题隔离</p>
<h3 id="数据同步"><a class="header-anchor" href="#数据同步">¶</a>数据同步</h3>
<blockquote>
<p>Canel 订阅数据库 binlog 可以实现数据库数据变更捕获，然后业务端订阅 Canel 进行业务处理，这种方式可以保证一致性，且不会有乱序问题。</p>
</blockquote>
<h3 id="数据异构"><a class="header-anchor" href="#数据异构">¶</a>数据异构</h3>
<h3 id="反模式-为了撇清关系所以使用-mq-消息"><a class="header-anchor" href="#反模式-为了撇清关系所以使用-mq-消息">¶</a>反模式-为了撇清关系所以使用 MQ 消息</h3>
<h3 id="反模式-为了解耦过度使用-mq-消息"><a class="header-anchor" href="#反模式-为了解耦过度使用-mq-消息">¶</a>反模式-为了解耦过度使用 MQ 消息</h3>
<h3 id="反模式-利用数据差异化来触发事件"><a class="header-anchor" href="#反模式-利用数据差异化来触发事件">¶</a>反模式-利用数据差异化来触发事件</h3>
<p>公司里有几位老员工基于 MQ 监听器组件开发了一套 MQ 客户端，这套 MQ 客户端的核心就是能通过修改数据来触发监听对应字段修改事件的监听器，这样可以避免定义一大堆主题，看起来似乎变简单了对吗？但是经过一段时间的维护发现情况并非如此，大量监听器不再根据主题来相互关联，而是数据中的一大堆字段，最开始的一批开发爽了，因为需要定义的主题少了，少了很多手动发消息的代码，但是后续维护的人就糟了，试想，每次希望修改某个字段的时候都需要把监听该字段修改事件的监听器都找一遍。<br>
两条业务同时修改</p>
<h3 id="mq-存在的缺陷"><a class="header-anchor" href="#mq-存在的缺陷">¶</a>MQ 存在的缺陷</h3>
<p>上边已经说过了优点，那么 mq 又有哪些缺点呢？</p>
<ul>
<li>系统可用性降低<br>
上面的说解耦的场景，本来 A 系统的哥们要把系统关键数据发送给 B、C 系统的，现在突然加入一个 MQ，现在 BC 系统接收数据要通过 MQ 来接收。<br>
万一 MQ 挂了怎么办？这就引出一个问题，加入了 MQ 之后，系统的可用性是不是就降低了？<br>
因为多了一个风险因素：MQ 可能会挂掉。只要 MQ 挂了，数据没了，系统运行就不对了。</li>
<li>系统复杂度提高<br>
本来我的系统通过接口调用一下就能完事的，但是加入一个 MQ 之后，需要考虑消息重复消费、消息丢失、甚至消息顺序性的问题<br>
为了解决这些问题，又需要引入很多复杂的机制，这样一来是不是系统的复杂度提高了。</li>
<li>数据一致性问题<br>
本来好好的，A 系统调用 BC 系统接口，如果 BC 系统出错了，会抛出异常，返回给 A 系统让 A 系统知道，这样的话就可以做回滚操作了<br>
但是使用了 MQ 之后，A 系统发送完消息就完事了，认为成功了。而刚好 C 系统写数据库的时候失败了，但是 A 认为 C 已经成功了？这样一来数据就不一致了。</li>
</ul>
<h3 id="并发修改"><a class="header-anchor" href="#并发修改">¶</a>并发修改</h3>
<p>消息从发出到被消费会有一小段时间，这一段时间内数据可能会经过其他线程的多次修改，所以在消息消费方的编程中尤其需要注意并发修改的问题。<br>
如果是同步操作——比如用户购买商品扣款的场景——需要在比较高并发的情况下才会出现并发问题，但是如果功能是基于消息实现的，由于消息消费具有不确定性，这种风险会被放大。<br>
<img src="http://47.88.24.11/imgs/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E6%89%A3%E6%AC%BE.png" alt="并发扣款" title="并发扣款"></p>
<ul>
<li>这些并发查询是在不同的站点实例 / 服务实例上完成的，进程内互斥锁无法解决问题。</li>
<li>不确定性来自于很多方面，比如同一主题的消息可能被多个业务线的触发、被重试、被手动重发。</li>
</ul>
<p>解决这种不一致问题的解决办法一般是加锁，因为异步处理并没有直接被用户感知，因此对效率并没有特别高的要求，悲观锁或乐观锁都是可行的。</p>
<blockquote>
<p>悲观锁会牺牲一定的吞吐量，乐观锁实现起来比较有技巧性、且可能会和业务数据耦合。</p>
</blockquote>
<p>以乐观锁为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 查询订单，Order中包含了版本信息</span><br><span class="line">Order order = queryOrder();</span><br><span class="line">// 这里使用状态机校验订单状态</span><br><span class="line">if (isStatusInvalid(order)) &#123;</span><br><span class="line">    记一下日志</span><br><span class="line">    return ;</span><br><span class="line">&#125;</span><br><span class="line">// 扭转状态的同时也做了版本的校验，相当于一个原子操作，如果校验失败则抛出异常、交给外层MQ组件重试</span><br><span class="line">changeOrderStatus(order, targetStatus);</span><br></pre></td></tr></table></figure>
<h3 id="at-least-once-消息丢失"><a class="header-anchor" href="#at-least-once-消息丢失">¶</a>At-Least-Once（消息丢失）</h3>
<p>有很多情况可能发生 MQ 消息的丢失：</p>
<ul>
<li>生产者向 MQ 发送消息时，网络传输出现问题；</li>
<li>消息在 MQ 中存储时，发生磁盘故障等不可控问题；</li>
<li>消费者从 MQ 接收消息时，网络传输出现问题；</li>
</ul>
<p>一般 MQ 中间件都会保证<strong>At-Least-Once</strong>的消费，就需要避免消息丢失的情况，有两种方式可以解决这种情况：</p>
<p>事务方式：<br>
在生产者发送消息之前，通过<code>channel.txSelect</code>开启一个事务，接着发送消息<br>
如果消息没有成功被 RabbitMQ 接收到，生产者会收到异常，此时就可以进行事务回滚<code>channel.txRollback</code>然后重新发送。假如 RabbitMQ 收到了这个消息，就可以提交事务<code>channel.txCommit</code>。<br>
但是这样一来，生产者的吞吐量和性能都会降低很多，现在一般不这么干。</p>
<p>另外一种方式就是通过 confirm 机制：<br>
这个 confirm 模式是在生产者哪里设置的，就是每次写消息的时候会分配一个唯一的 id，然后 RabbitMQ 收到之后会回传一个 ack，告诉生产者这个消息 ok 了。<br>
如果 rabbitmq 没有处理到这个消息，那么就回调一个 nack 的接口，这个时候生产者就可以重发。<br>
事务机制和 cnofirm 机制最大的不同在于事务机制是同步的，提交一个事务之后会阻塞在那儿<br>
但是 confirm 机制是异步的，发送一个消息之后就可以发送下一个消息，然后那个消息 rabbitmq 接收了之后会异步回调你一个接口通知你这个消息接收到了。<br>
所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。</p>
<p>Rabbitmq 弄丢了数据<br>
RabbitMQ 集群也会弄丢消息，这个问题在官方文档的教程中也提到过，就是说在消息发送到 RabbitMQ 之后，默认是没有落地磁盘的，万一 RabbitMQ 宕机了，这个时候消息就丢失了。<br>
所以为了解决这个问题，RabbitMQ 提供了一个持久化的机制，消息写入之后会持久化到磁盘<br>
这样哪怕是宕机了，恢复之后也会自动恢复之前存储的数据，这样的机制可以确保消息不会丢失。<br>
设置持久化有两个步骤：</p>
<ul>
<li>第一个是创建 queue 的时候将其设置为持久化的，这样就可以保证 rabbitmq 持久化 queue 的元数据，但是不会持久化 queue 里的数据</li>
<li>第二个是发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 rabbitmq 就会将消息持久化到磁盘上去。<br>
但是这样一来可能会有人说：万一消息发送到 RabbitMQ 之后，还没来得及持久化到磁盘就挂掉了，数据也丢失了，怎么办？<br>
对于这个问题，其实是配合上面的 confirm 机制一起来保证的，就是在消息持久化到磁盘之后才会给生产者发送 ack 消息。<br>
万一真的遇到了那种极端的情况，生产者是可以感知到的，此时生产者可以通过重试发送消息给别的 RabbitMQ 节点<br>
消费端弄丢了数据<br>
RabbitMQ 消费端弄丢了数据的情况是这样的：在消费消息的时候，刚拿到消息，结果进程挂了，这个时候 RabbitMQ 就会认为你已经消费成功了，这条数据就丢了。<br>
对于这个问题，要先说明一下 RabbitMQ 消费消息的机制：在消费者收到消息的时候，会发送一个 ack 给 RabbitMQ，告诉 RabbitMQ 这条消息被消费到了，这样 RabbitMQ 就会把消息删除。<br>
但是默认情况下这个发送 ack 的操作是自动提交的，也就是说消费者一收到这个消息就会自动返回 ack 给 RabbitMQ，所以会出现丢消息的问题。<br>
所以针对这个问题的解决方案就是：关闭 RabbitMQ 消费者的自动提交 ack,在消费者处理完这条消息之后再手动提交 ack。<br>
这样即使遇到了上面的情况，RabbitMQ 也不会把这条消息删除，会在你程序重启之后，重新下发这条消息过来。</li>
</ul>
<h3 id="消息重复"><a class="header-anchor" href="#消息重复">¶</a>消息重复</h3>
<p>一般情况下 MQ 除了不保证消息的有序性外、还不保证消息不重复。<br>
因为在「网络不可达」的情况下，MQ 不能确认消息接收方收到了消息必然会重试。重试除了本文讲的幂等处理外，还可以采用每个消息有唯一的 ID+去重表实现。</p>
<h3 id="消息的有序性"><a class="header-anchor" href="#消息的有序性">¶</a>消息的有序性</h3>
<p>因为 MQ 消息在服务器上是分区存储的，每个分区自己是有序的。分区被接收端消费的时候。一般也是多个接收端一起消费。中间的每个环节都是只能保证局部有序。如果想全局有序。就需要分区只有一个，并且接收端服务器是单点，而且一次只处理一个请求。<br>
TODO: TCP 是怎么做的。</p>
<h3 id="消息积压"><a class="header-anchor" href="#消息积压">¶</a>消息积压</h3>
<h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2>
<h3 id="任务调度-v2"><a class="header-anchor" href="#任务调度-v2">¶</a>任务调度</h3>
<ol>
<li>cron<br>
<a href="https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html" target="_blank" rel="noopener">crontab 定时任务</a></li>
<li><a href="https://www.jianshu.com/p/989298cf5314" target="_blank" rel="noopener">中心化-去中心化调度设计</a><br>
xxl-job 和 elastic-job 在设计上的本质区别是中心化还是去中心化。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a894e74e.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/a894e74e.html" itemprop="url">Disruptor 原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-22T15:26:49+08:00">
                2019-09-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  491 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>Disruptor 相对于传统方式（普通）的优点</h1>
<ol>
<li>无锁<br>
相对 Lock 来说效率更高（线程不需要挂起，只涉及到一次内存交换速度快），但是同时会带来 ABA 问题，且多线程下竞争容易产生空转。</li>
<li>所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。</li>
<li>在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的 cache line padding，就意味着没有为伪共享和非预期的竞争。</li>
</ol>
<h1>如何使用 Disruptor</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class LongEvent &#123;</span><br><span class="line"></span><br><span class="line">    private long value;</span><br><span class="line"></span><br><span class="line">    public void set(long value) &#123;</span><br><span class="line">        this.value = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long getValue() &#123;</span><br><span class="line">        return this.value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public LongEvent newInstance() &#123;</span><br><span class="line">        return new LongEvent();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123;</span><br><span class="line">        System.out.println(&quot;Event:  &quot; + event.getValue() + &quot; sequence:+&quot; + sequence + &quot; endOfBatch:&quot; + endOfBatch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123;</span><br><span class="line">        System.out.println(&quot;Event:  &quot; + event.getValue() + &quot; sequence:+&quot; + sequence + &quot; endOfBatch:&quot; + endOfBatch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventProducer &#123;</span><br><span class="line"></span><br><span class="line">    private final RingBuffer&lt;LongEvent&gt; ringBuffer;</span><br><span class="line"></span><br><span class="line">    public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer) &#123;</span><br><span class="line">        this.ringBuffer = ringBuffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void onData(ByteBuffer bb) &#123;</span><br><span class="line">        // Grab the next sequence</span><br><span class="line">        long sequence = ringBuffer.next();</span><br><span class="line">        try &#123;</span><br><span class="line">            // Get the entry in the Disruptor</span><br><span class="line">            LongEvent event = ringBuffer.get(sequence);</span><br><span class="line">            // for the sequence Fill with data</span><br><span class="line">            event.set(bb.getLong(0));</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            ringBuffer.publish(sequence);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventMain &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // Executor that will be used to construct new threads for consumers</span><br><span class="line">        Executor executor = Executors.newCachedThreadPool();</span><br><span class="line"></span><br><span class="line">        // The factory for the event</span><br><span class="line">        LongEventFactory factory = new LongEventFactory();</span><br><span class="line"></span><br><span class="line">        // Specify the size of the ring buffer, must be power of 2.</span><br><span class="line">        int bufferSize = 1024;</span><br><span class="line"></span><br><span class="line">        // Construct the Disruptor</span><br><span class="line">        Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, executor);</span><br><span class="line"></span><br><span class="line">        // Connect the handler</span><br><span class="line">        disruptor.handleEventsWith(new LongEventHandler());</span><br><span class="line"></span><br><span class="line">        // Start the Disruptor, starts all threads running</span><br><span class="line">        disruptor.start();</span><br><span class="line"></span><br><span class="line">        // Get the ring buffer from the Disruptor to be used for publishing.</span><br><span class="line">        RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();</span><br><span class="line"></span><br><span class="line">        LongEventProducer producer = new LongEventProducer(ringBuffer);</span><br><span class="line"></span><br><span class="line">        ByteBuffer bb = ByteBuffer.allocate(8);</span><br><span class="line">        for (long l = 0; true; l++) &#123;</span><br><span class="line">            bb.putLong(0, l);</span><br><span class="line">            producer.onData(bb);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1>QA</h1>
<ol>
<li><a href="http://ifeve.com/disruptor/" target="_blank" rel="noopener">并发框架 Disruptor 译文</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/df2941e1.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/df2941e1.html" itemprop="url">Redis 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">
                2019-09-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  29.3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  108 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="为什么使用-redis"><a class="header-anchor" href="#为什么使用-redis">¶</a>为什么使用 Redis</h2>
<h3 id="redis-的缺点-优点"><a class="header-anchor" href="#redis-的缺点-优点">¶</a>Redis 的缺点 &amp; 优点</h3>
<p>特性及优势：</p>
<ol>
<li>内存数据库，吞吐率不受磁盘影响；</li>
<li>每秒可以处理超过 10 万次读写操作；</li>
<li>多数据结构支持，包括 string、hash、list、set、zset、Bitmaps、Hyperloglog、Geo、Pub/Sub、Redis Module、BloomFilter、RedisSearch、Redis-ML 等，支持绝大多数应用场景；</li>
<li>Replication（复制）；</li>
<li>lua（支持服务端执行复杂的业务逻辑）；</li>
<li>LRU eviction（缓存淘汰）；</li>
<li>Transactions；</li>
<li>Persistence（持久化），包括 rdb（快照）和 AOF 两种；</li>
<li>Sentinel（哨兵）；</li>
<li>Cluster（分区）。</li>
</ol>
<p>但是也不能忽略 Redis 本身的一些缺点：</p>
<ol>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上；</li>
<li>缓存和数据库双写一致性问题；</li>
<li>缓存雪崩问题；</li>
<li>缓存击穿问题；</li>
<li>缓存的并发竞争问题。</li>
</ol>
<h3 id="redis-memcached"><a class="header-anchor" href="#redis-memcached">¶</a>Redis &amp; Memcached</h3>
<p>Redis 相对 Memcached 来说有以下优点：</p>
<ol>
<li>memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型</li>
<li>redis 的速度比 memcached 快很多</li>
<li>redis 可以持久化其数据</li>
</ol>
<p>Redis 和 Memcached 之间存在以下区别：</p>
<ol>
<li>存储方式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis 有部份存在硬盘上，这样能保证数据的持久性。</li>
<li>数据支持类型 Memcache 对数据类型支持相对简单。 Redis 有复杂的数据类型。</li>
<li>使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</li>
</ol>
<h3 id="应用场景"><a class="header-anchor" href="#应用场景">¶</a>应用场景</h3>
<ol>
<li>会话缓存（Session Cache）<br>
最常用的一种使用 Redis 的情景是会话缓存（session cache）。用 Redis 缓存会话比其他存储（如 Memcached）的优势在于：Redis 提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？<br>
幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文档。甚至广为人知的商业平台 Magento 也提供 Redis 的插件。</li>
<li>全页缓存（FPC）<br>
除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。<br>
再次以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。<br>
此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</li>
<li>队列<br>
Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如 Python）对 list 的 push/pop 操作。<br>
当然要将 Redis 作为消息队列投入生产环境还有很多设计要点，比如采用 sleep 一段时间重试还是 blpop 阻塞、主题订阅、如何应对消费者下线导致的消息丢失问题（如何保证消息一定能被消费）等。<br>
Redis 作为消息队列坑比较多，如果希望少点麻烦且对服务质量有一定要求，最好还是采用 RocketMQ 这些比较成熟的方案。</li>
<li>延时队列<br>
使用 zset，时间戳作为 score，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理，这种思路和 JDK 中的 ScheduledThreadPoolExecutor 有点像。</li>
<li>排行榜/计数器<br>
Redis 在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们<br>
称之为“user_scores”，我们只需要像下面一样执行即可：<br>
当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：<br>
ZRANGE user_scores 0 10 WITHSCORES<br>
Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可以在这里看到。</li>
<li>发布/订阅<br>
最后（但肯定不是最不重要的）是 Redis 的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用 Redis 的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。<br>
Redis 提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。</li>
<li>分布式锁<br>
不要用 setnx+expire，因为如果进程 crash 或重启这个锁就直接失效了。实际上 set 命令本身就包含超时和 cas 的设置。</li>
<li>扫描<br>
如果 Redis 中有 1 亿多个 key，其中有 10W+个 key 有固定的前缀（这种场景非常常见），如何将它们全部找出来？<br>
由于 Redis 的单线程特性，使用 keys 可能会阻塞 Redis 进程，最好换成 scan 命令，不过可能提取出的部分 key 是重复的，需要客户端做去重。</li>
</ol>
<h2 id="redis环境搭建及基本用法"><a class="header-anchor" href="#redis环境搭建及基本用法">¶</a>Redis环境搭建及基本用法</h2>
<h3 id="搭建环境"><a class="header-anchor" href="#搭建环境">¶</a>搭建环境</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name myredis -d -p6379:6379 redis</span><br><span class="line">docker exec -it myredis redis-cli</span><br></pre></td></tr></table></figure>
<h3 id="使用"><a class="header-anchor" href="#使用">¶</a>使用</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># exists 查看某个key是否存在</span><br><span class="line">exists aa</span><br><span class="line">SET 创建一个key；</span><br><span class="line">GET 获取一个key的值；</span><br><span class="line">DEL ***一个key；</span><br><span class="line">TYPE 获取一个key的类型；</span><br><span class="line">EXISTS 判断一个key是否存在，0：存在，1，不存在；</span><br><span class="line"># KEYS 获取给定模糊匹配的key，但要谨慎使用，因为线上的key一般非常多</span><br><span class="line">keys *</span><br><span class="line">keys a?</span><br><span class="line">EXPIRE 设置一个key过期的秒数；</span><br><span class="line">PERSTST ***一个key过期的秒数；</span><br><span class="line">PEXPIRE 设置一个key过期的毫秒数；</span><br><span class="line">RENAME 将一个key重命名；</span><br><span class="line">RENAMENX 将一个key重命名，且新的key必须是不存在的可以；</span><br><span class="line">TTL 获取key的有效时间，以秒为单位，-1表示永不过期，-2表示已过期、已转移</span><br><span class="line"># dbsize 查看当前库中key数量</span><br><span class="line">dbsize</span><br><span class="line"># flushdb 清除数据库（内存）</span><br><span class="line">flushdb</span><br><span class="line"># move 移动key到另一个库</span><br><span class="line">move aa 2</span><br></pre></td></tr></table></figure>
<h3 id="容量预估"><a class="header-anchor" href="#容量预估">¶</a>容量预估</h3>
<p>在实际部署前一般都会先对所需容量进行一个评估，这样可以尽量避免在上线后容量不够还要扩容、或者容量过大造成浪费。<br>
官方提供了一个<a href="http://www.redis.cn/redis_memory/" target="_blank" rel="noopener">容量预估工具</a>，一些博客比如<a href="https://gameinstitute.qq.com/community/detail/114987" target="_blank" rel="noopener">Redis 容量评估模型</a>贴近 Redis 底层数据结构给出了容量的评估分析，可以作为一个参考，但是业务架构一直在变，实际的容量监控还是必须的，我们下面还会谈到这方面的工具。</p>
<h2 id="基本数据结构"><a class="header-anchor" href="#基本数据结构">¶</a>基本数据结构</h2>
<h3 id="string"><a class="header-anchor" href="#string">¶</a>String</h3>
<h4 id="特点"><a class="header-anchor" href="#特点">¶</a>特点</h4>
<ol>
<li>最大能存储 512MB == 536870912 B(byte) ；</li>
<li>二进制安全，在传输数据的时候，能保证二进制数据的信息安全，也就是不会被篡改、破译；如果被攻击，能够及时检测出来</li>
<li>能存储各种类型的数据，字符串、数字，以至对象（通过json序列化）、位图等。</li>
</ol>
<h4 id="基本使用"><a class="header-anchor" href="#基本使用">¶</a>基本使用</h4>
<p>容量：512M</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set aa &apos;str&apos;</span><br><span class="line">get aa</span><br></pre></td></tr></table></figure>
<p>操作总结</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set/get/del/append/strlen key</span><br><span class="line">incr/decr/incrby/decrby key</span><br><span class="line">getrange key start end/setrange key offset value（从offset处开始读取/覆盖）</span><br><span class="line">setex key seconds value(set with expire插入key的同时设置过期时间)/setnx key value(set if not exists如果已存在则直接返回0)</span><br><span class="line">mset/mget/msetnx key value &#123;key value&#125;（设置/读取多个key的值，msetnx比较特殊，要么都成功，要么一个都不执行，可以用来设置一个对象的多个不同字段）</span><br><span class="line">getset key(设置并返回key对应的旧值，可以用于计数器的重置)</span><br></pre></td></tr></table></figure>
<h4 id="常见应用"><a class="header-anchor" href="#常见应用">¶</a>常见应用</h4>
<p>字符串、jpg图片、序列化对象、一些复杂的计数功能的缓存</p>
<h3 id="hash"><a class="header-anchor" href="#hash">¶</a>Hash</h3>
<p>存储 String 类型键值对的映射表、对象</p>
<h4 id="基本使用方法"><a class="header-anchor" href="#基本使用方法">¶</a>基本使用方法</h4>
<p>容量：每个 Hash 可存 2^32 - 1（约 40 亿）个键值对</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hmset user username &apos;name&apos; password &apos;123456&apos; # 定义一个有两个元素的Hash表</span><br><span class="line">hgetall user # 获取user中所有key和value</span><br><span class="line">hget user username # 获取user中key为username的value</span><br></pre></td></tr></table></figure>
<h4 id="常见应用-v2"><a class="header-anchor" href="#常见应用-v2">¶</a>常见应用</h4>
<p>单点登录（存&lt;CookieId, 用户信息&gt;，设置 30 分钟为缓存过期时间，能很好地模拟出类似 Session 的效果）。</p>
<h3 id="list"><a class="header-anchor" href="#list">¶</a>List</h3>
<p>String列表</p>
<h4 id="基本使用方法-v2"><a class="header-anchor" href="#基本使用方法-v2">¶</a>基本使用方法</h4>
<p>容量：每个 List 可存 2^32 - 1 个元素</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lpush ball basketball soccer # 按顺序从左侧压入，如果ball列表不存在则创建</span><br><span class="line">rpush ball volleyball</span><br><span class="line">lrange 0 1 # 获取索引从0到1的值</span><br></pre></td></tr></table></figure>
<p>操作总结</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lpush/rpush/lrange</span><br><span class="line">lpop/rpop</span><br><span class="line">lindex</span><br><span class="line">llen</span><br><span class="line">lrem key</span><br><span class="line">ltrim key</span><br><span class="line">rpoplpush</span><br><span class="line">lset key index value</span><br><span class="line">linsert key before/after val1 val2</span><br></pre></td></tr></table></figure>
<h4 id="常见应用-v3"><a class="header-anchor" href="#常见应用-v3">¶</a>常见应用</h4>
<p>简单的消息队列<br>
基于 Redis 的分页功能（利用 lrang 命令，性能极佳，用户体验好）</p>
<h3 id="set"><a class="header-anchor" href="#set">¶</a>Set</h3>
<p>字符串的无序集合，使用 Hash 实现（key 和 value 相同的 Hash）</p>
<h4 id="基本使用方法-v3"><a class="header-anchor" href="#基本使用方法-v3">¶</a>基本使用方法</h4>
<p>容量：2^32 - 1 个成员</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sadd myset li1 # 向集合myset中添加一个元素li1，若不存在则创建</span><br><span class="line">smembers myset</span><br></pre></td></tr></table></figure>
<h4 id="常见应用-v4"><a class="header-anchor" href="#常见应用-v4">¶</a>常见应用</h4>
<p>全局去重（为什么不用 JDK 自带的 Set 去重？因为我们的系统一般都是集群部署）<br>
计算共同喜好、全部喜好、自己独有的喜好等功能（交集、并集、差集）</p>
<h3 id="zset"><a class="header-anchor" href="#zset">¶</a>ZSet</h3>
<p>字符串的有序集合，每个元素都关联一个 double 类型的权重参数 score，集合中的元素能够按 score 进行排列。</p>
<h4 id="基本使用方法-v4"><a class="header-anchor" href="#基本使用方法-v4">¶</a>基本使用方法</h4>
<p>容量：2^32 - 1 个成员</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zadd myzset 0 abc</span><br><span class="line">zrangebyscore myzset 0 10</span><br></pre></td></tr></table></figure>
<h4 id="常见应用-v5"><a class="header-anchor" href="#常见应用-v5">¶</a>常见应用</h4>
<p>排行榜<br>
取 Top N 操作<br>
延时任务（<a href="https://www.cnblogs.com/rjzheng/p/8972725.html%EF%BC%89" target="_blank" rel="noopener">https://www.cnblogs.com/rjzheng/p/8972725.html）</a><br>
范围查找</p>
<h4 id="原理"><a class="header-anchor" href="#原理">¶</a>原理</h4>
<p>实现上类似于 Java 的 SortedSet 和 HashMap 的结合体，value 唯一（Set 结构的特点），每个 value 一个 score 代表该 value 的排序权重。<br>
zset 内部是使用一种叫做跳跃列表的结构实现的。</p>
<h2 id="redis-数据结构的实现"><a class="header-anchor" href="#redis-数据结构的实现">¶</a>Redis 数据结构的实现</h2>
<p><img src="http://47.88.24.11/imgs/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0.png" alt="Redis数据结构及其实现" title="Redis数据结构及其实现"><br>
Redis 中的 set、zset 等结构在 Redis 中并不是由一个单独的数据结构实现的，而是会根据情况有所变化。</p>
<h3 id="sds-simple-dynamic-string"><a class="header-anchor" href="#sds-simple-dynamic-string">¶</a>SDS(Simple Dynamic String)</h3>
<p>Redis 中的动态数组有以下特点：</p>
<ul>
<li>可动态扩展内存。sds 表示的字符串其内容可以修改，也可以追加。在很多语言中字符串会分为 mutable 和 immutable 两种，显然 sds 属于 mutable 类型的。</li>
<li>减少修改字符串的内存重新分配次数<br>
C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。<br>
而对于SDS，由于<code>len</code>属性和<code>free</code>属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：<br>
1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。<br>
2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</li>
<li>二进制安全（Binary Safe）。sds 能存储任意二进制数据，而不仅仅是可打印字符。</li>
<li>与传统的 C 语言字符串类型兼容。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct SDS&lt;T&gt; &#123;</span><br><span class="line">  T capacity; // 数组容量</span><br><span class="line">  T len; // 数组当前长度</span><br><span class="line">  byte flags; // 特殊标识位，不理睬它</span><br><span class="line">  byte[] content; // 数组内容</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面的函数将 t 数组拷贝到 s 中，如果长度不够则需要进行扩容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/* Append the specified binary-safe string pointed by &apos;t&apos; of &apos;len&apos; bytes to the</span><br><span class="line"> * end of the specified sds string &apos;s&apos;.</span><br><span class="line"> *</span><br><span class="line"> * After the call, the passed sds string is no longer valid and all the</span><br><span class="line"> * references must be substituted with the new pointer returned by the call. */</span><br><span class="line">sds sdscatlen(sds s, const void *t, size_t len) &#123;</span><br><span class="line">    size_t curlen = sdslen(s);  // 原字符串长度</span><br><span class="line"></span><br><span class="line">    // 按需调整空间，如果 capacity 不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中</span><br><span class="line">    s = sdsMakeRoomFor(s,len);</span><br><span class="line">    if (s == NULL) return NULL; // 内存不足</span><br><span class="line">    memcpy(s+curlen, t, len);  // 追加目标字符串的内容到字节数组中</span><br><span class="line">    sdssetlen(s, curlen+len); // 设置追加后的长度值</span><br><span class="line">    s[curlen+len] = &apos;\0&apos;; // 让字符串以\0 结尾，便于调试打印，还可以直接使用 glibc 的字符串函数进行操作</span><br><span class="line">    return s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>SDS 有 embstr 和 raw 两种存储结构，它们的区别是：</p>
<ol>
<li>内存分配上：<br>
embstr 调用 1 次 malloc, 因此 redisObject 和 SDS 内存是连续分配的；<br>
raw 需要调用 2 次 malloc, 因此 redisObject 和 SDS 内存不连续分配</li>
<li>使用上:<br>
embstr 整体 64 byte, 正好和<strong>cpu cache line</strong> 64byte 一样, 可以更好的使用缓存, 效率更高</li>
</ol>
<h3 id="dict-字典"><a class="header-anchor" href="#dict-字典">¶</a>dict（字典）</h3>
<p>dict 是 Redis 中使用最广泛的数据结构：</p>
<ol>
<li>hash 结构的数据会用到字典；</li>
<li>整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典；</li>
<li>带过期时间的 key 集合也是一个字典；</li>
<li>set 结构的底层实现也是字典，只是所有 value 都是 NULL；</li>
<li>zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct RedisDb &#123;</span><br><span class="line">    dict* dict; // all keys  key=&gt;value</span><br><span class="line">    dict* expires; // all expired keys key=&gt;long(timestamp)</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct dict &#123;</span><br><span class="line">    ...</span><br><span class="line">    dictht ht[2];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct zset &#123;</span><br><span class="line">    dict *dict; // all values  value=&gt;score</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="hashtable"><a class="header-anchor" href="#hashtable">¶</a>hashtable</h4>
<p>dict 中的 hashtable 结构和 Java 中的 HashMap 类似，使用一个数组来保存所有的哈希桶，通过<strong>siphash</strong>函数来将 key 散列到数组中的某个桶上，每个哈希桶都是一个链表，也就是说如果发生哈希冲突，则将新元素直接插入到桶的头部。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct dictEntry &#123;</span><br><span class="line">    void* key;</span><br><span class="line">    void* val;</span><br><span class="line">    dictEntry* next; // 链接下一个 entry</span><br><span class="line">&#125;</span><br><span class="line">struct dictht &#123;</span><br><span class="line">    dictEntry** table; // 二维</span><br><span class="line">    long size; // 第一维数组的长度</span><br><span class="line">    long used; // hash 表中的元素个数</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="扩容：渐进式-rehash"><a class="header-anchor" href="#扩容：渐进式-rehash">¶</a>扩容：渐进式 rehash</h4>
<p>正常情况下，当 hashtable 中元素的个数等于第一维数组的长度时、来了一个新增/修改/删除操作，就会触发扩容，扩容的新数组是原数组大小的 2 倍。</p>
<blockquote>
<p>存在一个特殊情况：如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (<code>dict_can_resize</code>)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (<code>dict_force_resize_ratio</code>)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。</p>
</blockquote>
<p><img src="http://47.88.24.11/imgs/Redis/Redis-dict%E6%89%A9%E5%AE%B9rehash.png" alt="Redis-dict扩容rehash" title="Redis-dict扩容rehash"><br>
一般情况下 dict 中只有一个 hashtable 有值，但是在扩容时会分配另一个新的 hashtable，然后执行<strong>渐进式</strong>的数据迁移，避免一次性对所有 key 执行 rehash，而是将 rehash 操作分散到了对 dict 的各个增删改查操作中去了。</p>
<ol>
<li>在扩容过程中，如果有新增元素，则该元素会被同时添加到新 hashtable 中；</li>
<li>查询、删除、修改操作中，会先查询旧 hashtable，若存在则迁移这个 key 所在的桶并返回元素，若不存在则到新 hashtable 中查找元素。</li>
<li>有一个异步线程执行定时任务对字典主动迁移。</li>
</ol>
<p>dict 之所以这样设计，是为了避免 rehash 期间单个请求的响应时间剧烈增加。<br>
当旧 hashtable 中无元素时，即代表迁移完毕，这时会将新旧 hashtable 的指针交换，旧的会被删除，而新的则取而代之。</p>
<h4 id="缩容"><a class="header-anchor" href="#缩容">¶</a>缩容</h4>
<p>当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。<br>
缩容不会考虑 Redis 是否正在做 bgsave，因为 COW 的特性是当内存页上的数据被修改时会复制一页做修改，如果删除操作并不会触发删除内存页的数据，操作系统回收内存机制导致的。</p>
<h3 id="ziplist"><a class="header-anchor" href="#ziplist">¶</a>ziplist</h3>
<p>ziplist 是一种压缩存储的数组结构，当 Redis 中的集合数据结构很小，则它会使用这种紧凑的存储形式存储，元素之间紧挨着存储，查找就是对数组进行遍历找到目标对象。</p>
<ul>
<li>zset 和 hash 容器在元素个数较少时会采用 ziplist 存储。当存储的对象数量小于 512 且所有 entry 的 value 值长度小于 64，采用 ziplist 存储，否则转为采用 hashtable 存储。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import redis</span><br><span class="line">client = redis.StrictRedis()</span><br><span class="line">client.delete(&quot;hello&quot;)</span><br><span class="line">for i in range(512):</span><br><span class="line">    client.hset(&quot;hello&quot;, str(i), str(i))</span><br><span class="line">print client.object(&quot;encoding&quot;, &quot;hello&quot;)</span><br><span class="line">client.hset(&quot;hello&quot;, &quot;512&quot;, &quot;512&quot;)</span><br><span class="line"># 或者插入一个长度为65的值也能起到转化的作用</span><br><span class="line">print client.object(&quot;encoding&quot;, &quot;hello&quot;)</span><br></pre></td></tr></table></figure>
<p>可以上服务器上使用<code>debug object</code>命令验证数据结构的类型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; zadd hgc_test 1.0 go 2.0 python 2.0 java</span><br><span class="line">...</span><br><span class="line">&gt; debug object hgc_test</span><br><span class="line">Value at:0x7f73c6d673a0 refcount:1 encoding:ziplist serializedlength:36 lru:1381596 lru_seconds_idle:77</span><br></pre></td></tr></table></figure>
<h4 id="结构"><a class="header-anchor" href="#结构">¶</a>结构</h4>
<p><img src="http://47.88.24.11/imgs/Redis/Redis-ziplist%E7%BB%93%E6%9E%84.png" alt="Redis-ziplist结构" title="Redis-ziplist结构"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">struct ziplist&lt;T&gt; &#123;</span><br><span class="line">    int32 zlbytes; // 整个压缩列表占用字节数</span><br><span class="line">    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点</span><br><span class="line">    int16 zllength; // 元素个数</span><br><span class="line">    T[] entries; // 元素内容列表，挨个挨个紧凑存储</span><br><span class="line">    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF</span><br><span class="line">&#125;</span><br><span class="line">struct entry &#123;</span><br><span class="line">    int&lt;var&gt; prevlen; // 前一个 entry 的字节长度</span><br><span class="line">    int&lt;var&gt; encoding; // 元素类型编码</span><br><span class="line">    optional byte[] content; // 元素内容</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>zltail_offset 字段可以快速定位到 ziplist 中的最后一个节点，可以用于倒序遍历，entry 中的 prevlen 表示前一个 entry 的字节长度，可以用于倒序遍历时找到下一个元素的位置；</li>
<li>encoding 记录编码类型，ziplist 利用该字段决定后面的 content 内容的形式，比如用<code>00xxxxxx</code>表示最大长度为 63 的短字符串，<code>01xxxxxx xxxxxxxx</code>表示中等长度的字符串；</li>
</ul>
<h4 id="插入"><a class="header-anchor" href="#插入">¶</a>插入</h4>
<p>ziplist 是紧凑存储的，没有冗余空间，因此插入一个新元素就需要调用 realloc 重新分配内存空间，并将之前的内容一次性拷贝到新的内存空间中。<br>
重新分配空间是比较耗时的，因此 ziplist 不适合存储大量数据。</p>
<h4 id="更新-删除"><a class="header-anchor" href="#更新-删除">¶</a>更新/删除</h4>
<p>修改或删除一个元素后其后一个位置的元素中的 prevlen 也需要级联更新，prevlen 字段又是变长的，所以可能会导致连锁反应。</p>
<h4 id="ziplist-vs-dict"><a class="header-anchor" href="#ziplist-vs-dict">¶</a>ziplist vs dict</h4>
<p>为什么 hash 结构中会采用 ziplist 而不是 dict，主要原因如下：</p>
<ol>
<li>数据量小时，ziplist 的速度也很快；</li>
<li>数据量大时，ziplist 在每次插入或修改时引发的 realloc 操作会有更大的概率造成内存拷贝，从而降低性能，而且数据项过多的时候，在 ziplist 上查找指定数据项的性能会变得很低，因为在 ziplist 上的查找需要进行遍历。</li>
</ol>
<h3 id="quicklist"><a class="header-anchor" href="#quicklist">¶</a>quicklist</h3>
<p>Redis 早期版本存储 list 数据结构采用元素少时 ziplist+多时 linkedlist 的方案，但是：</p>
<ol>
<li>链表的附加空间太高，prev 和 next 指针就要占去 16 个字节（64 位系统）；</li>
<li>链表每个节点都是单独分配，会加剧内存的碎片化。</li>
</ol>
<p>因此在之后的版本中转换为了 quicklist 存储。<br>
quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。<br>
<img src="http://47.88.24.11/imgs/Redis/Redis-quicklist%E7%BB%93%E6%9E%84.png" alt="Redis-quicklist结构" title="Redis-quicklist结构"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">struct ziplist &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">struct ziplist_compressed &#123;</span><br><span class="line">    int32 size;</span><br><span class="line">    byte[] compressed_data;</span><br><span class="line">&#125;</span><br><span class="line">struct quicklistNode &#123;</span><br><span class="line">    quicklistNode* prev;</span><br><span class="line">    quicklistNode* next;</span><br><span class="line">    ziplist* zl; // 指向压缩列表</span><br><span class="line">    int32 size; // ziplist 的字节总数</span><br><span class="line">    int16 count; // ziplist 中的元素数量</span><br><span class="line">    int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">struct quicklist &#123;</span><br><span class="line">    quicklistNode* head;</span><br><span class="line">    quicklistNode* tail;</span><br><span class="line">    long count; // 元素总数</span><br><span class="line">    int nodes; // ziplist 节点的个数</span><br><span class="line">    int compressDepth; // LZF 算法压缩深度</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="skiplist"><a class="header-anchor" href="#skiplist">¶</a>skiplist</h3>
<p>zset 中除了 dict（字典）外，还会用一个 skiplist 来提供按 score 排序的要求，以实现指定 score 的范围来获取 value 列表的功能。</p>
<p><img src="http://47.88.24.11/imgs/Redis/Redis-skiplist%E7%BB%93%E6%9E%84.png" alt="Redis-skiplist结构" title="Redis-skiplist结构"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">struct zslnode &#123;</span><br><span class="line">  string value;</span><br><span class="line">  double score;</span><br><span class="line">  zslnode*[] forwards;  // 多层连接指针</span><br><span class="line">  zslnode* backward;  // 回溯指针</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct zsl &#123;</span><br><span class="line">  zslnode* header; // 跳跃列表头指针</span><br><span class="line">  int maxLevel; // 跳跃列表当前的最高层</span><br><span class="line">  map&lt;string, zslnode*&gt; ht; // hash 结构的所有键值对</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>各层均为一个有序的链表结构；</li>
<li>层数越大，节点越少；</li>
<li>有一个 header 节点作为哨兵，value=null，score=Double.MIN_VALUE。</li>
</ul>
<h4 id="插入-v2"><a class="header-anchor" href="#插入-v2">¶</a>插入</h4>
<p>插入时会先自顶向下找到新节点在跳表中底层的插入位置，插入每一层时都有概率晋升到更高一层，在 Redis 中是 25%。</p>
<h4 id="删除"><a class="header-anchor" href="#删除">¶</a>删除</h4>
<p>删除每一层上的对应节点。</p>
<h4 id="更新"><a class="header-anchor" href="#更新">¶</a>更新</h4>
<p>如果不影响排序则直接更新，否则会先删除再重新插入。</p>
<h3 id="布隆过滤器"><a class="header-anchor" href="#布隆过滤器">¶</a>布隆过滤器</h3>
<h3 id="hyperloglog"><a class="header-anchor" href="#hyperloglog">¶</a>HyperLogLog</h3>
<p>布隆过滤器用于实现<code>contains</code>的需求，而 HyperLogLog 主要用于实现<code>count</code>。<br>
同样是一个特别大的位数组，HyperLogLog 将位数组拆分为桶，每个桶是连续的 6 个位，计数时并非单独对某个桶计数，而是：</p>
<ul>
<li>set 操作：计算 key 的散列值，为一个 64 位的数字，前 14 位是捅的位置，桶记录后 50 位中第一个 1 的位置 count，并且<code>count = max(count, oldCount)</code>，即每次记录最大的计数。</li>
<li>count 操作：因为是概率算法，每个桶的计数值并不精确，但是所有桶的调和均值非常接近真实的计数值。</li>
</ul>
<h3 id="pubsub"><a class="header-anchor" href="#pubsub">¶</a>pubsub</h3>
<p>用于实现轻量级的发布订阅功能。</p>
<h2 id="redis-的进程和-io-模型"><a class="header-anchor" href="#redis-的进程和-io-模型">¶</a>Redis 的进程和 IO 模型</h2>
<h3 id="为什么-redis-这么快"><a class="header-anchor" href="#为什么-redis-这么快">¶</a>为什么 Redis 这么快</h3>
<p>Redis 采用的是一种<strong>单线程工作模型</strong>，它能这么快主要归功于下面几个策略：</p>
<ol>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)；</li>
<li>数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
<li>使用<strong>多路 I/O 复用</strong>模型，非阻塞 IO；<br>
多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。<br>
Redis-Client 在操作的时候，会产生具有不同事件类型的 socket，在服务端，有一段 I/O 多路复用程序，将其置入队列之中，然后，文件事件分派器依次去队列中取，转发到不同的事件处理器中（对这个 I/O 多路复用机制，Redis 还提供了 select、epoll、evport、kqueue 等多路复用函数库）。<br>
这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。<br>
<img src="http://47.88.24.11/imgs/Redis/%E5%A4%9A%E8%B7%AFIO%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.jpg" alt="多路IO复用模型" title="多路IO复用模型"></li>
</ol>
<h3 id="一些常见的进程模型"><a class="header-anchor" href="#一些常见的进程模型">¶</a>一些常见的进程模型</h3>
<ol>
<li>单进程多线程模型：MySQL、Memcached、Oracle（Windows 版本）；</li>
<li>多进程模型：Oracle（Linux 版本）；</li>
<li>Nginx 有两类进程，一类称为 Master 进程(相当于管理进程)，另一类称为 Worker 进程（实际工作进程）。启动方式有两种：
<ol>
<li>单进程启动：此时系统中仅有一个进程，该进程既充当 Master 进程的角色，也充当 Worker 进程的角色。</li>
<li>多进程启动：此时系统有且仅有一个 Master 进程，至少有一个 Worker 进程工作。</li>
<li>Master 进程主要进行一些全局性的初始化工作和管理 Worker 的工作；事件处理是在 Worker 中进行的。</li>
</ol>
</li>
</ol>
<h3 id="为什么是-nio"><a class="header-anchor" href="#为什么是-nio">¶</a>为什么是 NIO</h3>
<p>对于优化单个 server 节点的网络层，多使用 NIO 方式，server 端与 client 端在多次通讯的情况下使用 TCP 长连接维持会话，比如 Redis epoll 模型，RocketMq 的 netty 模型<br>
对于高性能 Server 节点，在处理好网络请求同时，还要保证 server 端逻辑可以快速执行完成，这就涉及到合理的数据结构与线程模型。<br>
在 Redis 中，采用的是 Reactor 模式实现文件事件处理器：<br>
<img src="http://47.88.24.11/imgs/Redis/Redis-%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B.png" alt="Redis-事件处理模型" title="Redis-事件处理模型"></p>
<ol>
<li>IO 多路复用<br>
根据平台不同选择不同的 IO 复用模型，比如 Linux 就是选择 epoll，select 是备选方案，不过正常情况下根本不会采用，因为 select 效率低，且有文件描述符监听上限。</li>
<li>封装不同 IO 模型，为事件处理器提供统一接口</li>
</ol>
<h3 id="大-key-问题"><a class="header-anchor" href="#大-key-问题">¶</a>大 Key 问题</h3>
<blockquote>
<p>也可以叫大 Value 问题。</p>
</blockquote>
<p>大 Key 有两种状况：</p>
<ol>
<li>Redis 中单个简单的 Key 存储的 value 很大</li>
<li>hash、set、zset、list 中存储的元素过多（以万为单位）。</li>
</ol>
<p>由于 Redis 的单线程模型，读写大 Key 时服务器的耗时可能会比较长、甚至阻塞。</p>
<p>解决方案一般是能拆则拆，对于单个大 Key 的情况：<br>
1.1 将大 Key 进行分割，拆成几个小的 key-value，使用 multiGet 获取值。<br>
这样分拆的意义是将单次操作的压力分摊到多个 Redis 实例上，降低对单个 Redis 的 IO 影响，而且大 Key 拆分之后每次只查询一部分，减小了 IO 阻塞的风险。<br>
为了均匀分割，可以对 field 进行 hash 并通过质数 N 取余，将余数加到 key 上面。<br>
1.2 将大 Key 拆分成多个 key-value，并将这些存储在一个 hash 中，每个 field 代表一个具体的属性，使用 hget、hmget 来获取部分的 value，使用 hset、hmset 来更新部分属性</p>
<p>对于 hash、set、zset、list 中存储的元素过多的情况，可以控制将 field 分散到多个集合内。<br>
比如以下代码将属于一个大 hash 内的 field 分散到 10000 个拆分后的小 hash 内：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">newHashKey = hashKey + (hash(field) % 10000)</span><br><span class="line">hset(newHashKey, field, value)</span><br><span class="line">hget(newHashKey, field)</span><br></pre></td></tr></table></figure>
<p>对于一些需要考虑顺序的场景，比如 lpop、zrange，需要在 hash 函数上做些文章，比如按照时间来拆分。</p>
<h3 id="pipeline"><a class="header-anchor" href="#pipeline">¶</a>pipeline</h3>
<p>将多次 IO 往返的网络请求时间缩减为 1 次。</p>
<h2 id="事务"><a class="header-anchor" href="#事务">¶</a>事务</h2>
<h3 id="redis-事务的特征"><a class="header-anchor" href="#redis-事务的特征">¶</a>Redis 事务的特征</h3>
<p>和众多其它数据库一样，Redis 作为 NoSQL 数据库也同样提供了事务机制。在 Redis 中，MULTI/EXEC/DISCARD/WATCH 这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出<br>
Redis 中事务的实现特征：</p>
<ol>
<li>在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。</li>
<li>和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。</li>
<li>我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为&quot;BEGIN TRANSACTION&quot;语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行 EXEC/DISCARD 命令来提交/回滚该事务内的所有操作。这两个 Redis 命令可被视为等同于关系型数据库中的 COMMIT/ROLLBACK 语句。</li>
<li>在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。</li>
<li>当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。</li>
</ol>
<p>Redis 服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用 Redis 工具包中提供的 redis-check-aof 工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动 Redis 服务器了。</p>
<h3 id="watch-命令和基于-cas-check-and-set-的乐观锁"><a class="header-anchor" href="#watch-命令和基于-cas-check-and-set-的乐观锁">¶</a>WATCH 命令和基于 CAS（Check-And-Set）的乐观锁</h3>
<p>在 Redis 的事务中，WATCH 命令可用于提供 CAS(check-and-set)功能。假设我们通过 WATCH 命令在事务执行之前监控了多个 Keys，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 Null multi-bulk 应答以通知调用者事务执行失败。例如，我们再次假设 Redis 中并未提供 incr 命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val = GET mykey</span><br><span class="line">val = val + 1</span><br><span class="line">SET mykey $val</span><br></pre></td></tr></table></figure>
<p>以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景–竞态争用(race condition)。比如，客户端 A 和 B 都在同一时刻读取了 mykey 的原有值，假设该值为 10，此后两个客户端又均将该值加一后 set 回 Redis 服务器，这样就会导致 mykey 的结果为 11，而不是我们认为的 12。为了解决类似的问题，我们需要借助 WATCH 命令的帮助，见如下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">WATCH mykey</span><br><span class="line">val = GET mykey</span><br><span class="line">val = val + 1</span><br><span class="line">MULTI</span><br><span class="line">SET mykey $val</span><br><span class="line">EXEC</span><br></pre></td></tr></table></figure>
<p>和此前代码不同的是，新代码在获取 mykey 的值之前先通过 WATCH 命令监控了该键，此后又将 set 命令包围在事务中，这样就可以有效的保证每个连接在执行 EXEC 之前，如果当前连接获取的 mykey 的值被其它连接的客户端修改，那么当前连接的 EXEC 命令将执行失败。这样调用者在判断返回值后就可以获悉 val 是否被重新设置成功。</p>
<h2 id="持久化"><a class="header-anchor" href="#持久化">¶</a>持久化</h2>
<p>Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，redis 将会越来越受欢迎。<br>
如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。<br>
不过 Redis 也提供了持久化的选项。</p>
<h3 id="file-snap-shotting-半持久化模式-rdb"><a class="header-anchor" href="#file-snap-shotting-半持久化模式-rdb">¶</a>file snap shotting（半持久化模式 / rdb）</h3>
<h4 id="特点-v2"><a class="header-anchor" href="#特点-v2">¶</a>特点</h4>
<p>以快照的方式将内存数据写入到一个二进制文件中（默认为 dump.rdb），异步保存到磁盘上。</p>
<h4 id="开启"><a class="header-anchor" href="#开启">¶</a>开启</h4>
<p>快照是 redis 的默认持久化方式。修改配置文件的 save 属性可以配置自动快照方式。</p>
<h4 id="命令"><a class="header-anchor" href="#命令">¶</a>命令</h4>
<p>可以使用 save 或 bgsave 命令直接通知 redis 做一个快照，save 操作是在主线程中保存快照的，由于 redis 是用一个主线程来处理所有 client 的请求，这种方式会阻塞所有 client 请求。但是<strong>bgsave</strong>就没有这个问题。</p>
<h4 id="bgsave-过程"><a class="header-anchor" href="#bgsave-过程">¶</a>bgsave 过程</h4>
<ol>
<li>当 redis 需要做持久化时，redis 会 <strong>fork</strong> 一个子进程；</li>
<li>父进程继续处理客户端请求，子进程根据配置文件中的 save 策略将内存数据写到磁盘上一个临时 RDB 文件中；</li>
<li>当子进程完成写临时文件后，将原来的 RDB 文件替换掉，然后子进程退出。这样的好处就是可以 <strong>COW</strong>。<br>
Redis并不是在同步时就直接将内存都拷贝一份，而是<strong>写时复制（COW）</strong>，也就是说当没有发生写入操作时，子进程和父进程共享内存空间，父进程对内存的某页有写入时，子进程会复制一份该页，之后都是基于该复制出的页面进行写盘。</li>
</ol>
<h4 id="问题"><a class="header-anchor" href="#问题">¶</a>问题</h4>
<p>filesnapshotting 在 redis 异常死掉时，最近的数据会丢失（因为最近没有持久化的数据还在内存中）。每次做快照都是将内存数据完整写入到磁盘，如果程序 io 频繁可能会严重影响性能。</p>
<h3 id="virtual-memory-虚拟内存-vm"><a class="header-anchor" href="#virtual-memory-虚拟内存-vm">¶</a>Virtual-Memory（虚拟内存 / VM）</h3>
<p>当 key 很小而 value 很大时，使用 VM 更能节约内存。<br>
当 key 并不小时，可以通过将 key 和 value 拼接作为新的 value 来减小 key 的大小。<br>
vm-max-threads 这个参数可以设置访问 swap 文件的线程数,设置最好不要超过机器的核数,如果设置为 0，那么所有对 swap 文件的操作都是串行的。可能会造成比较长时间的延迟，但是对数据完整性有很好的保证。</p>
<h3 id="append-only-file-全持久化模式-aof"><a class="header-anchor" href="#append-only-file-全持久化模式-aof">¶</a>Append-only file（全持久化模式 / AOF）</h3>
<h4 id="特点-v3"><a class="header-anchor" href="#特点-v3">¶</a>特点</h4>
<p>把每一次数据变化都写入到一个 append only file(默认是 appendonly.aof)里，所以可以做到全部数据都不丢失，但性能要劣于 filesnapshotting 模式。当 redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。</p>
<h4 id="开启-v2"><a class="header-anchor" href="#开启-v2">¶</a>开启</h4>
<p>在配置文件中设置 appendonly 为 yes 可开启 AOF 模式。AOF 文件的刷新方式有三种，可以根据需要修改 appendfsync。</p>
<h4 id="过程"><a class="header-anchor" href="#过程">¶</a>过程</h4>
<p>同样用到了 COW，首先 redis 会 fork 一个子进程；<br>
子进程将最新的 AOF 写入一个临时文件；<br>
父进程<strong>增量</strong>的把内存中的最新执行的修改写入（这时仍写入旧的 AOF，rewrite 如果失败也是安全的）；<br>
当子进程完成 rewrite 临时文件后，父进程会收到一个信号，并把之前内存中增量的修改写入临时文件末尾；<br>
这时 redis 将旧 AOF 文件重命名，临时文件重命名，开始向新的 AOF 中写入。</p>
<h4 id="问题-v2"><a class="header-anchor" href="#问题-v2">¶</a>问题</h4>
<ol>
<li>AOF 文件损坏，redis 无法加载的情况，照下面步骤解决，(1) 备份当前 AOF 文件；(2) 修复执行 redis-check-aof -fix；(3) 重启 redis 服务。</li>
<li>Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。<strong>Master 最好不要做任何持久化工作</strong>，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。</li>
<li>Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。</li>
</ol>
<h4 id="命令-v2"><a class="header-anchor" href="#命令-v2">¶</a>命令</h4>
<p>调用 bgrewriteaof 可以使用与快照类似的方式将内存中的数据以<strong>命令的形式</strong>保存到临时文件，最后替换原来的文件，具体的</p>
<ol>
<li>Redis 调用 fork ，现在有父子两个进程；</li>
<li>子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令（<strong>是命令而不是内存数据</strong>）；</li>
<li>父进程继续处理 client 请求，除了把写命令写入到原来的 aof 文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题；</li>
<li>当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件；</li>
<li>现在父进程可以使用临时文件替换老的 aof 文件，并重命名，后面收到的写命令也开始往新的 aof 文件中追加。</li>
</ol>
<h3 id="宕机恢复"><a class="header-anchor" href="#宕机恢复">¶</a>宕机恢复</h3>
<p>如果突然机器掉电会怎样？取决于 aof 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync，比如 1s1 次，这个时候最多就会丢失 1s 的数据。<br>
最后，为以防万一（机器坏掉或磁盘坏掉），记得定期把使用 filesnapshotting 或 Append-only 生成的*rdb *.aof 文件备份到远程机器上。比如用 crontab 每半小时 scp 一次。<br>
或者一种常见替代方案是主从，虽然会浪费一些机器资源。</p>
<h3 id="文件压缩"><a class="header-anchor" href="#文件压缩">¶</a>文件压缩</h3>
<p>如果 aof 文件过大可能会导致恢复时间过长，Redis 提供了两个特性来减小这个影响：</p>
<ol>
<li>Redis 会定期做 aof 重写，压缩 aof 文件日志大小。</li>
<li>Redis4.0 之后有了混合持久化的功能，将 bgsave 的全量和 aof 的增量做了融合处理，AOF 只记录最后一次 bgsave 之后的增量 AOF 日志，这样既保证了恢复的效率又兼顾了数据的安全性。</li>
</ol>
<h3 id="生产中如何设计持久化方案"><a class="header-anchor" href="#生产中如何设计持久化方案">¶</a>生产中如何设计持久化方案</h3>
<p>bgsave 做镜像全量持久化，aof 做增量持久化。<br>
因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 aof 来配合使用。在 redis 实例重启时，优先使用 aof 来恢复内存的状态，如果没有 aof 日志，就会使用 rdb 文件来恢复。</p>
<h2 id="优化"><a class="header-anchor" href="#优化">¶</a>优化</h2>
<ul>
<li>单进程单线程，无法充分发挥服务器多核 cpu 的性能；大流量下造成 IO 阻塞，同样是由于单进程单线程, cpu 在处理业务逻辑的时候,网络 IO 被阻塞住, 造成无法处理更多的请求.<br>
多线程 master + N<em>work 工作模式.master 线程负责监听网络事件, 在接收到一个新的连接后, master 会把新的 fd 注册到 worker 的 epoll 事件中, 交由 worker 处理这个 fd 的所有读写事件, 这样 master 线程就可以完全被释放出来接收更多的连接, 同时又不妨碍 worker 处理业务逻辑和 IO 读写.<br>
采用这种 master + N</em>worker 的网络层事件模型,可以实现 redis 性能的平行扩展. 真正的让 redis 在面临高并发请求时可以丛容面对.</li>
<li>维护成本高, 如果想要充分发挥服务器的所有资源包括 cpu, 网络 io 等, 就必须建立多个 instance, 但此时不可避免会增加维护成本. 拿 24 核服务器举例来讲, 如果部署 24 个单机版的 instance,理论上可以实现 10w*24core= 240wQPS 的总体性能.但是每个 instance 有各自独立的数据,占用资源如内存也会同比上升,反过来制约一台服务器又未必能支持这么多的 instance. 如果部署 24 个 Instance 来构成单机集群, 虽然可以共享数据，但是因为节点增加, redis 的状态通讯更加频繁和费时,性能也下会降很多. 并且两种方式都意味着要维护 24 个 Instance，运维成本都会成倍增加.</li>
<li>持久化：redis 提供了两种 save 方式 1)save 触发. 2)bgsave. 当然也可以使用 3)aof 来实现持久化, 但是这 3 点都有弊端.
<ul>
<li>save: 由于是单进程单线程, redis 会阻塞住所有请求, 来遍历所有 redisDB, 把 key-val 写入 dump.rdb. 如果内存数据量过大, 会造成短时间几秒到几十秒甚至更长的时间停止服务, 这种方案对于 twitter, taobao 等大流量的网站, 显然是不可取的.</li>
<li>bgsave: 在触发 bgsave 时, redis 会 fork 自身, child 进程会进入 1)的处理方式,这意味着服务器内存要有一半的冗余才可以, 如今内存已变得越来越廉价, 但是对于存储海量数据的情况,内存以及服务器的成本还是不容忽视的.</li>
<li>aof: 说到持久化, redis 提供的 aof 算是最完美的方案了, 但是有得必有失, 严重影响性能! 因为 redis 每接收到一条请求, 就要把命令内容完整的写到磁盘文件, 且不说频繁读写会影响磁盘寿命,写磁盘的时间足以拖垮 redis 整体性能 . 当然熟悉 redis 的开发者会想到用 appendfsync 等参数来调整, 但都不是完美.即使使用 SSD，性能也只是略有提升，并且性价比不高。</li>
</ul>
</li>
<li>优化 jemalloc, 采用大内存页. Redis 在使用内存方面可谓苛刻至极, 压缩, string 转 number 等, 能省就省, 但是在实际生产环境中, 为了追求性能, 对于内存的使用可以适度（不至于如 bgsave 般浪费）通融处理, 因此 AliRedis 对 jemalloc 做了微调, 通过调整 pagesize 来让一次 je_malloc 分配更多 run 空间来储备更多的用户态可用内存, 同时可以减轻换页表的负载, 降低 user sys 的切换频率, 来提高申请内存的性能, 对 jemalloc 有兴趣的开发者可以参考 jemalloc 源码中的 bin, run, chunk 数据结构进行分析.</li>
</ul>
<h3 id="内存"><a class="header-anchor" href="#内存">¶</a>内存</h3>
<p>因为系统的内存大小有限，所以我们在使用 Redis 的时候可以配置 Redis 能使用的最大的内存大小。<br>
redis.conf：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Redis最大占用内存大小</span><br><span class="line">maxmemory 100mb</span><br></pre></td></tr></table></figure>
<p>通过命令修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set maxmemory 100mb</span><br><span class="line">127.0.0.1:6379&gt; config get maxmemory</span><br></pre></td></tr></table></figure>
<p>如果不设置最大内存大小或设置最大内存大小为 0，在 64 位操作系统下不限制内存大小，在 32 位操作系统下最大使用 3GB 内存。</p>
<h3 id="修改数据库配置"><a class="header-anchor" href="#修改数据库配置">¶</a>修改数据库配置</h3>
<p>redis 默认创建 16 个数据库（类似一个数组），默认值对应在 redis.conf 配置文件中 database 的值。<br>
默认使用 0 号库，可以使用 select 命令来选择其他库。</p>
<h3 id="过期时间的设置"><a class="header-anchor" href="#过期时间的设置">¶</a>过期时间的设置</h3>
<p>如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。</p>
<h3 id="缓存穿透-击穿"><a class="header-anchor" href="#缓存穿透-击穿">¶</a>缓存穿透（击穿）</h3>
<p>缓存穿透即即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。这也是经常提的缓存命中率问题。<br>
应付大规模缓存穿透的方案如下：</p>
<ol>
<li>
<p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试</p>
</li>
<li>
<p>采用异步更新策略，无论 key 是否取到值，都直接返回。value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做<strong>缓存预热</strong>(项目启动前，先加载缓存)操作。</p>
</li>
<li>
<p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用<strong>布隆过滤器</strong>，内部维护一系列合法有效的 key，将这些数据 hash 到一个足够大的 bitmap 中。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p>
</li>
<li>
<p>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过 5 分钟，通过这个直接设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 击穿到db</span><br><span class="line">        cacheValue = getFromDB();</span><br><span class="line">        if (cacheValue == null) &#123;</span><br><span class="line">            // 如果发现为空，则缓存个默认值</span><br><span class="line">            cacheValue = &quot;&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把空结果也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。同时也可以单独设置一个缓存区域存储空值，对要查询的key进行进行预先校验，然后再放行给后面的正常缓存处理逻辑。</p>
</li>
</ol>
<h3 id="缓存雪崩"><a class="header-anchor" href="#缓存雪崩">¶</a>缓存雪崩</h3>
<p>缓存雪崩即缓存同一时间大面积的失效（例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期），这个时候又来了一波请求，结果请求都怼到数据库上，而对数据库 CPU 和内存造成巨大压力，从而导致数据库连接异常，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。<br>
缓存雪崩的解决方案如下：</p>
<ol>
<li>
<p>使用互斥锁，但是该方案吞吐量明显下降了，适用于并发量不是特别多的情况下。具体地来说，使用最多的方案是加锁排队，伪代码如下：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    String lockKey = cacheKey;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        synchronized (lockKey) &#123;</span><br><span class="line">            cacheValue = getFromRedis(cacheKey);</span><br><span class="line">            if (cacheValue != null) &#123;</span><br><span class="line">                return cacheValue;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                cacheValue = getFromDB();</span><br><span class="line">                putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这时过来1000个请求、999个都在阻塞，同样会导致用户等待超时，属于治标不治本的方案，而且还需要解决分布式锁的问题。</p>
</li>
<li>
<p>设置过期标志更新缓存。给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存，实现伪代码如下所示：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    // 缓存标记</span><br><span class="line">    String signKey = cacheKey + &quot;_sign&quot;;</span><br><span class="line"></span><br><span class="line">    String signValue = getFromRedis(signKey);</span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (signValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        putToRedis(signKey, &quot;1&quot;, cacheTime);</span><br><span class="line">        threadPool.submit(() -&gt; &#123;</span><br><span class="line">            cacheValue = getFromDB();</span><br><span class="line">            putToRedis(cacheKey, cacheValue, cacheTime * 2);</span><br><span class="line">        &#125;);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>缓存标记记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。<br>
缓存数据的过期时间比缓存标记的时间延长 1 倍，例如：标记缓存时间 30 分钟，数据缓存 60 分钟，这样，当缓存标记 key 过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。</p>
</li>
<li>
<p>给缓存的失效时间，加上一个随机值，避免集体失效。</p>
</li>
<li>
<p>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。然后细分以下几个小点：</p>
<ol>
<li>从缓存 A 读数据库，有则直接返回</li>
<li>A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程。</li>
<li>更新线程同时更新缓存 A 和缓存 B。</li>
</ol>
</li>
</ol>
<h3 id="缓存预热"><a class="header-anchor" href="#缓存预热">¶</a>缓存预热</h3>
<p>缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统，避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户可以直接查询事先被预热的缓存数据。常见的缓存预热方案包括：</p>
<ol>
<li>直接写个缓存刷新页面，上线时手工操作下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存。</li>
</ol>
<h3 id="缓存淘汰-缓存失效策略和主键失效机制"><a class="header-anchor" href="#缓存淘汰-缓存失效策略和主键失效机制">¶</a>缓存淘汰（缓存失效策略和主键失效机制）</h3>
<p>作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略，比如 Redis 只能存 5G 数据，可是你写了 10G，那多出来的 5G 数据怎么删？你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高？这就需要深入到 Redis 的主键失效和淘汰策略中去了。</p>
<h4 id="key-的过期时间控制"><a class="header-anchor" href="#key-的过期时间控制">¶</a>key 的过期时间控制</h4>
<p>在 Redis 当中，有生存期的 key 被称为 volatile。在创建缓存时，要为给定的 key 设置生存期，当 key 过期的时候（生存期为 0），它可能会被删除。</p>
<ol>
<li>影响生存时间的一些操作<br>
生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改 key 对应的 value 和使用另外相同的 key 和 value 来覆盖以后，当前数据的生存时间不同。<br>
比如说，对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。<br>
RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用 PERSIST 命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个 persistent key 。</li>
<li>如何更新生存时间<br>
可以对一个已经带有生存时间的 key 执行 EXPIRE 命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在 1ms 之内，主键失效的时间复杂度是 O（1），<br>
EXPIRE 和 TTL 命令搭配使用，TTL 可以查看 key 的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。</li>
<li>最大缓存配置<br>
在 redis 中，允许用户设置最大使用内存大小 <code>server.maxmemory</code><br>
默认为 0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使 redis 崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</li>
</ol>
<h4 id="key-的删除策略"><a class="header-anchor" href="#key-的删除策略">¶</a>key 的删除策略</h4>
<p>redis 采用的是定期删除+惰性删除策略。</p>
<ol>
<li>为什么不用定时删除策略?<br>
定时删除,用一个定时器来负责监视 key,过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 key,因此没有采用这一策略.</li>
<li>定期删除+惰性删除是如何工作的呢?<br>
定期删除，redis 默认每个 100ms 检查，是否有过期的 key,有过期 key 则删除。需要说明的是，redis 不是每个 100ms 将所有的 key 检查一次，而是随机抽取进行检查(如果每隔 100ms,全部 key 进行检查，redis 岂不是卡死)。因此，如果只采用定期删除策略，会导致很多 key 到时间没有删除。<br>
于是，惰性删除派上用场。也就是说在你获取某个 key 的时候，redis 会检查一下，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</li>
<li>采用定期删除+惰性删除就没其他问题了么?<br>
不是的，如果定期删除没删除 key。然后你也没即时去请求 key，也就是说惰性删除也没生效。这样，redis 的内存会越来越高。那么就应该采用内存淘汰机制。</li>
</ol>
<h4 id="redis-的数据淘汰策略"><a class="header-anchor" href="#redis-的数据淘汰策略">¶</a>Redis 的数据淘汰策略</h4>
<p>在 redis.conf 中有一行配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># maxmemory-policy volatile-lru</span><br></pre></td></tr></table></figure>
<p>redis 提供 6种数据淘汰策略：</p>
<ol>
<li>no-enviction（驱逐）：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错（应该没人用）</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰（这种情况一般是把 redis 既当缓存，又做持久化存储的时候才用。不推荐）</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰（不推荐）</li>
<li>volatile-random：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰（不推荐）</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰（推荐）</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
</ol>
<p>注意这里的 6 种机制：</p>
<ul>
<li>volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据；</li>
<li>lru、ttl 以及 random 是三种不同的淘汰策略，ttl 和 random 比较容易理解、实现也会比较简单，lru 会对 key 按失效时间排序，然后取最先失效的 key 进行淘汰。</li>
<li>如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。</li>
</ul>
<p><strong>使用策略规则</strong></p>
<ol>
<li>如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru</li>
<li>如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 allkeys-random</li>
</ol>
<h4 id="自定义缓存淘汰策略"><a class="header-anchor" href="#自定义缓存淘汰策略">¶</a>自定义缓存淘汰策略</h4>
<p>除了缓存服务器自带的缓存失效策略之外（Redis 默认有 6 种策略可选），我们还可以根据具体的业务需求自定义缓存淘汰策略，常见的策略有两种：</p>
<ol>
<li>定时去清楚过期的缓存；</li>
<li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存；</li>
</ol>
<p>两种策略各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂。需要根据应用场景的特点来权衡选择。</p>
<h3 id="redis-和数据库双写一致性问题"><a class="header-anchor" href="#redis-和数据库双写一致性问题">¶</a>Redis 和数据库双写一致性问题</h3>
<p>一致性问题是分布式常见问题，讨论比较多的是最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。<br>
在回答这个问题前，必须先强调一个前提，就是<strong>如果对数据有强一致性要求，不能放缓存</strong>。我们所做的一切，只能保证最终一致性，从根本上来说，只是降低不一致发生的概率，无法完全避免，因此，我们说有强一致性要求的数据，不能放缓存。</p>
<ul>
<li>首先，采取正确更新策略，先更新数据库，再删缓存。</li>
<li>其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用<strong>消息队列</strong>。</li>
</ul>
<p>具体的设计方案和优缺点可以参考：<a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">【原创】分布式之数据库和缓存双写一致性方案解析</a></p>
<h3 id="如何解决-redis-的并发竞争-key-问题"><a class="header-anchor" href="#如何解决-redis-的并发竞争-key-问题">¶</a>如何解决 redis 的并发竞争 key 问题</h3>
<p>这个问题大致就是，同时有多个子系统去 set 一个 key。这个时候要注意什么呢？大家思考过么。百度上的答案基本都是推荐用 redis 事务机制，但这里<strong>不推荐使用 redis 的事务机制</strong>。因为我们的生产环境，基本都是 redis 集群环境，做了数据分片操作，你一个事务中有涉及到多个 key 操作的时候，这多个 key 不一定都存储在同一个 redis-server 上。因此，<strong>Redis 的事务机制，十分鸡肋</strong>。</p>
<ol>
<li>如果对这个 key 操作，<strong>不要求顺序</strong><br>
这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</li>
<li>如果对这个 key 操作，<strong>要求顺序</strong><br>
假设有一个 key1,系统 A 需要将 key1 设置为 valueA,系统 B 需要将 key1 设置为 valueB,系统 C 需要将 key1 设置为 valueC.<br>
期望按照 key1 的 value 值按照 valueA–&gt;valueB–&gt;valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下<br>
系统 A key 1 {valueA 3:00}<br>
系统 B key 1 {valueB 3:05}<br>
系统 C key 1 {valueC 3:10}<br>
那么，假设这会系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了。以此类推。<br>
其他方法，比如利用队列，将 set 方法变成串行访问也可以。</li>
</ol>
<h3 id="缓存降级"><a class="header-anchor" href="#缓存降级">¶</a>缓存降级</h3>
<p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。<br>
降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。<br>
在进行降级之前要对系统进行梳理，看看哪些服务是必须誓死保护的、哪些是可降级的。比如可以参考日志级别设置预案：</p>
<ol>
<li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li>
<li>警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降级或人工降级，并发送告警；</li>
<li>错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li>
<li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li>
</ol>
<h2 id="主从复制-master-slave-m-s"><a class="header-anchor" href="#主从复制-master-slave-m-s">¶</a>主从复制（master-slave、m-s）</h2>
<h3 id="操作"><a class="header-anchor" href="#操作">¶</a>操作</h3>
<ol>
<li>
<p>运行 Master<br>
调整 Master 内存中保存的缓冲积压部分（replication backlog），以便执行部分重同步。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 缓冲区越大，可断开连接再重连执行部分重同步的时间越长，缓冲区会在每次连接时分配。</span><br><span class="line">repl-backlog-size 1mb</span><br><span class="line">repl-backlog-ttl 3600</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>运行 Slave<br>
先在配置文件中设置 Master 和 logfile 路径再运行</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slaveof 172.16.205.141 6379</span><br><span class="line">logfile &quot;/usr/redis/log/slave.log&quot;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>级联复制（从从复制）<br>
之前是所有 Slave 连到一个 Master 上，这是一种中心化的办法，对 Master 的负担较大，事实上我们完全可以不全部连到 Master 上，而是 Master-&gt;Slave1-&gt;Slave2 这样传递。<br>
实现级联复制也较简单，只用修改 Slave2 配置文件的<code>slaveof</code>属性即可。</p>
</li>
<li>
<p>Master write，Slave read<br>
通过程序（客户端）实现数据的读写分离，即在程序中判断请求是读是写，让 Master 负责处理写请求，Slave 负责处理读请求；通过扩展 Slave 处理更多的并发请求，减轻 Master 端的负载。</p>
</li>
</ol>
<h3 id="同步复制和异步复制"><a class="header-anchor" href="#同步复制和异步复制">¶</a>同步复制和异步复制</h3>
<p>Redis 使用默认的异步复制，其特点是低延迟和高性能，不会影响 Redis 主线程的响应效率。</p>
<ul>
<li>Redis 复制在 master 侧是非阻塞的。这意味着 master 在一个或多个 slave 进行初次同步或者是部分重同步时，可以继续处理查询请求。</li>
<li>复制在 slave 侧大部分也是非阻塞的。当 slave 进行初次同步时，它可以使用旧数据集处理查询请求，假设你在 redis.conf 中配置了让 Redis 这样做的话。否则，你可以配置如果复制流断开， Redis slave 会返回一个 error 给客户端。但是，在初次同步之后，旧数据集必须被删除，同时加载新的数据集。 slave 在这个短暂的时间窗口内（如果数据集很大，会持续较长时间），会阻塞到来的连接请求。自 Redis 4.0 开始，可以配置 Redis 使删除旧数据集的操作在另一个不同的线程中进行，但是，加载新数据集的操作依然需要在主线程中进行并且会阻塞 slave 。</li>
</ul>
<blockquote>
<p>Redis 虽然声称是单线程模型，但是很多功能仍然是采用多线程实现的。</p>
</blockquote>
<h3 id="什么时候触发复制"><a class="header-anchor" href="#什么时候触发复制">¶</a>什么时候触发复制</h3>
<ul>
<li>当一个 Master 和一个 Slave 实例连接正常时，Master 通过向 Slave 发送命令流来<strong>增量同步</strong>自身数据集的改变情况，包括客户端的写入、key 的过期等；</li>
<li>Master 与 Slave 之间因为网络问题或宕机，之后 Slave 重新连上 Master 时会尝试进行<strong>部分重同步</strong>，即只获取在断开连接期间内丢失的命令流；<br>
为此，slave 会记住旧 master 的旧 replication ID 和复制偏移量，因此即使询问旧的 replication ID，其也可以将部分复制缓冲提供给连接的 slave 。</li>
<li>当无法进行部分重同步时，Slave 会请求进行全量重同步。Master 需要创建所有数据的快照，将之发送给 Slave，之后在数据集发生更改时持续发送命令流到 Slave。</li>
</ul>
<h3 id="主从复制原理"><a class="header-anchor" href="#主从复制原理">¶</a>主从复制原理</h3>
<p>当用户往 Master 端写入数据时，通过<code>Redis Sync</code>机制将数据文件发送至 Slave，Slave 也会执行相同的操作确保数据一致。</p>
<ol>
<li>同一个 Master 可以拥有多个 Slaves。Master 下的 Slave 还可以接受同一架构中其它 Slave 的链接与同步请求，实现数据的<strong>级联复制</strong>，即 Master-&gt;Slave-&gt;Slave 模式；<br>
<code>repl-diskless-sync-delay</code>参数可以延迟启动数据传输，目的可以在第一个 slave 就绪后，等待更多的 slave 就绪。</li>
<li>Master 以<strong>非阻塞</strong>的方式同步数据至 slave，这将意味着 Master 会继续处理一个或多个 slave 的读写请求；</li>
<li>Slave 端同步数据也可以修改为非阻塞的方式，当 slave 在执行新的同步时，它仍可以用旧的数据信息来提供查询；否则，当 slave 与 master 失去联系时，slave 会返回一个错误给客户端；</li>
<li>主从复制可以做到<strong>读写分离</strong>，保证了可扩展性，即多个 slave 专门提供只读查询与数据的冗余，Master 端专门提供写操作；</li>
<li>通过配置禁用 Master 数据持久化机制，将其数据持久化操作交给 Slaves 完成，避免在 Master 中要有独立的进程来完成此操作。</li>
<li>Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。</li>
</ol>
<p>标识同步进程：</p>
<ol>
<li>每个 Master 都有一个<code>Replication ID</code>：这是一个较大的伪随机字符串，标记了一个给定的数据集。</li>
<li>每个 Master 持有一个偏移量<code>offset</code>，Master 将自己产生的复制流发送给 slave 时，发送多少个字节的数据，自身的偏移量就会增加多少，目的是当有新的操作修改自己的数据集时，它可以以此更新 Slave 的状态。即使没有 Slave 连接到 Master，offset 也会自增，所以基本上每一对 <code>&lt;Replication ID, offset&gt;</code> 都会标识一个 Master 数据集的确切版本。</li>
<li>Slave 也维护了一个复制偏移量<code>offset</code>，代表从库同步的字节数，从库每收到主节点传来的 N 个字节数据时，从库的 offset 增加 N。<br>
Master 和 Slave 的<code>offset</code>总是不断增大，这也是判断主从数据是否同步的标志，若主从的 offset 相同则表示数据同步量，不通则表示数据不同步。</li>
</ol>
<p>复制积压缓冲区<br>
主节点(master)响应写命令时，不但会把命名发送给从节点，还会写入复制积压缓冲区，用于复制命令丢失的数据补救。<br>
Slave 连接中断时主节点仍然可以响应命令，但因复制连接中断命令无法发送给 Slave。之后，当 Slave 重启并触发部分复制时，Master 可以将复制积压缓冲区的内容同步给 Slave，从而提高复制效率；</p>
<p>部分重同步过程：</p>
<ol>
<li>当 Slave 连接到 Master，发送一个<code>PSYNC</code>命令表明自己记录的旧的 Master <code>Replication ID</code>和它们至今为止处理的偏移量<code>offset</code>；</li>
<li>Master 仅发送 Slave 所需的增量部分的命令流，即上次同步偏移量<code>offset</code>之后执行的写命令；</li>
<li>但是如果 master 的缓冲区中没有足够的命令积压缓冲记录，或者如果 slave 引用了不再知道的历史记录（replication ID），则会转而进行一个全量重同步：在这种情况下， slave 会得到一个完整的数据集副本，从头开始。</li>
</ol>
<p>全量同步（完整重同步）：</p>
<ol>
<li>Slave 向 Master 发送<code>PSYNC</code>命令；</li>
<li>Master 执行<code>BGSAVE</code>命令，开启一个后台进程用于生成一个 RDB 文件；</li>
<li>同时它开始缓冲所有从客户端接收到的新的写入命令；</li>
<li>当后台保存完成时， master 将数据集文件传输给 slave， slave 将之保存在磁盘上，然后加载文件到内存；</li>
<li>再然后 master 会将所有缓冲的写命令发给 slave，这个过程以指令流的形式完成并且和 Redis 协议本身的格式相同。</li>
</ol>
<blockquote>
<p>可以通过<code>telnet</code>连接到 Redis 服务器上然后发送<code>SYNC</code>命令来模拟这个过程，但是因为<code>SYNC</code>功能有限（比如不支持部分重同步），现在的版本用<code>PSYNC</code>作为代替。<br>
正常情况下，全量同步会先在磁盘上创建一个 RDB 文件，传输时将其加载进内存，然后 Slave 对此进行数据的同步，如果磁盘性能很低，这个过程压力会比较大，<code>Redis 2.8.18</code>之后支持直接传输 RDB 文件，可以使用<code>repl-diskless-sync</code>配置参数配置。</p>
</blockquote>
<p>全量同步完成以后，在此后的时间里主从维护着心跳检查来确认对方是否在线，每隔一段时间（默认 10 秒，通过<code>repl-ping-slave-period</code>参数指定）主节点向从节点发送 PING 命令判断从节点是否在线，而从节点每秒 1 次向主节点发送 REPLCONF ACK 命令，命令格式为：<code>REPLCONF ACK {offset}</code>，其中 offset 指的是从节点保存的复制偏移量，作用是：</p>
<ol>
<li>向主节点报告自己复制进度，主节点会对比复制偏移量向从节点发送未同步的命令；</li>
<li>判断主节点是否在线。</li>
</ol>
<h3 id="主从复制执行过程"><a class="header-anchor" href="#主从复制执行过程">¶</a>主从复制执行过程</h3>
<p><img src="http://47.88.24.11/imgs/Redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="主从复制" title="主从复制"></p>
<ol>
<li>启动 Slave，向 Master 发送一个 SYNC Command，请求同步连接；</li>
<li>无论是第一次连接还是重新连接，Master 都会启动一个后台进程，将<strong>数据快照</strong>保存到数据文件中，同时 Master 会记录<strong>所有修改数据的命令</strong>并缓存在数据文件中（持久化）；</li>
<li>Master 的后台进程缓存完毕后，将数据文件传回给 Slave；</li>
<li>Slave 将数据文件保存到磁盘上，然后再加载到内存中；</li>
<li>Master 将保存所有修改数据命令的文件发送给 Slave；</li>
</ol>
<h3 id="宕机恢复-v2"><a class="header-anchor" href="#宕机恢复-v2">¶</a>宕机恢复</h3>
<p>因为 slave 顶多只负责处理读请求，slave 挂掉不会造成数据丢失的问题。<br>
slave 宕机的情况下，应该要求客户端具有一定的熔断恢复能力，并且能在重启后快速恢复：</p>
<ol>
<li>恢复正常后重新连接；</li>
<li>Master 收到 Slave 的连接后，第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer；</li>
<li>Master 将其完整的 rdb 数据文件全量发送给 Slave；</li>
<li>Slave 接收完成后将 rdb 镜像文件加载到内存，加载完成后，再通知 Master 将期间修改的操作记录同步到 Slave 节点进行重放就完成了同步过程；</li>
<li>如果 Master 同时收到多个 Slave 发来的同步请求，Master 只会在后台启动一个进程保存数据文件，然后将其发送给所有的 Slave，确保 Slave 正常。</li>
</ol>
<p>主从复制无法应对 Master 挂掉的情况，实际上这种方案只能尽量保证数据不会丢失，不能保证服务的高可用性，为此，需要引入 Redis 的 Sentinel 机制。</p>
<p>客户端可以使用 <code>WAIT</code> 命令来请求同步复制某些特定的数据。但是，WAIT 命令只能确保在其他 Redis 实例中有指定数量的已确认的副本：在故障转移期间，由于不同原因的故障转移或是由于 Redis 持久性的实际配置，故障转移期间确认的写入操作可能仍然会丢失。</p>
<h3 id="是否可以关闭持久化"><a class="header-anchor" href="#是否可以关闭持久化">¶</a>是否可以关闭持久化</h3>
<p>作为复制方案中的一环，可以考虑关闭 Master 或 Slave 的持久化功能，但是并不建议关掉它们，因为：</p>
<ul>
<li>如果关闭 Master 的持久化：重启（重启功能可以由一些只能运维工具来保证，比如 K8S）的 Master 将从一个空数据集开始，如果一个 Slave 试图与它同步，那么这个 Slave 也会被清空。</li>
<li>如果关闭 Slave 的持久化：重启的 Slave 需要从 Master 全量同步数据。</li>
</ul>
<p>正如前所述，关闭了持久化并配置了自动重启的 Master 是危险的——会导致整个集群的数据全部被清空。<br>
如果 Sentinel 集群用于需要高可用的场景、且 Master 被关闭掉了持久化功能，也是非常危险的：</p>
<ul>
<li>如果重启比较慢，Sentinel 的故障迁移机制重新选主，一个 Slave 会上升为 Master；</li>
<li>如果重启得足够快，Sentinel 没有探测到故障，此时 Master 数据被清空了，而 Slave 仍从 Master 同步数据，这将引起上边提到的故障模式——数据将丢失。</li>
</ul>
<p>因此，如果考虑磁盘性能过慢会导致延迟、关掉了持久化，那么自动重启进程这项应该被禁用。</p>
<h3 id="只读-slave"><a class="header-anchor" href="#只读-slave">¶</a>只读 Slave</h3>
<p>Redis2.6 之后，Redis 支持只读模式，可以使用<code>slave-read-only</code>配置来控制这个行为。<br>
只读模式下的 slave 将会拒绝所有写入命令，因此实践中不可能由于某种出错而将数据写入 slave 。但这并不意味着该特性旨在将一个 slave 实例暴露到 Internet ，或者更广泛地说，将之暴露在存在不可信客户端的网络，因为像 DEBUG 或者 CONFIG 这样的管理员命令仍在启用。但是，在 redis.conf 文件中使用 rename-command 指令可以禁用上述管理员命令以提高只读实例的安全性。</p>
<h3 id="数据丢失窗口"><a class="header-anchor" href="#数据丢失窗口">¶</a>数据丢失窗口</h3>
<p>由于 Redis 使用异步复制，无法保证 Slave 是否实际接收到给定的写命令，因此总会有一个<strong>数据丢失窗口</strong>。既然无法避免，那么只能退一步、控制影响范围了，Redis 可以保证：</p>
<ol>
<li>Redis slave 每秒钟都会 ping master，确认已处理的复制流的数量。</li>
<li>Redis master 会记得上一次从每个 slave 都收到 ping 的时间。</li>
<li>用户可以配置一个最小的 slave 数量，使得它滞后 &lt;= 最大秒数。</li>
<li>如果至少有 N 个 slave ，并且滞后小于 M 秒，则写入将被接受。如果条件不满足，master 将会回复一个 error 并且写入将不被接受。</li>
</ol>
<p>对于给定的写入来说，不能保证一致性，但至少数据丢失的时间窗限制在给定的秒数内。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write &lt;slave 数量&gt;</span><br><span class="line">min-slaves-max-lag &lt;秒数&gt;</span><br></pre></td></tr></table></figure>
<h3 id="过期的-key"><a class="header-anchor" href="#过期的-key">¶</a>过期的 key</h3>
<p>由于复制的异步特性，对 key 设置过期时间和写入操作很容易导致 race condition 及导致数据集不一致，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(1) sadd x 1</span><br><span class="line">(2) expire x 100</span><br><span class="line">(3) sadd x 2</span><br></pre></td></tr></table></figure>
<p>在 Master 上，命令(3)是在过期前执行的，而 Slave 上可能因为延后导致命令(3)执行前 x 就已经过期了，此时 x 是没有过期时间的（ttl x 得到-1 表示不过期），这就导致了数据的不一致。</p>
<blockquote>
<p>set 命令不会出现这个问题，因为 set 会将过期时间给覆盖成-1。当然情况比较复杂，也有可能是我没有想到。</p>
</blockquote>
<p>为了保证针对过期的 key 的复制能够正确工作，Redis 提供如下保证：</p>
<ol>
<li>slave 不会让 key 过期，而是等待 master 让 key 过期。当一个 master 让一个 key 到期（或由于 LRU 算法将之驱逐）时，它会合成一个 DEL 命令并传输到所有的 slave。一旦一个 slave 被提升为一个 master ，它将开始独立地过期 key，而不需要任何旧 master 的帮助。</li>
<li>但是，由于这是 master 驱动的 key 过期行为，master 无法及时提供 DEL 命令，所以有时候 slave 的内存中仍然可能存在在逻辑上已经过期的 key 。为了处理这个问题，slave 使用它的逻辑时钟以报告只有在不违反数据集的一致性的读取操作（从主机的新命令到达）中才存在 key。用这种方法，slave 避免报告逻辑过期的 key 仍然存在。在实际应用中，使用 slave 程序进行缩放的 HTML 碎片缓存，将避免返回已经比期望的时间更早的数据项。</li>
<li>在 Lua 脚本执行期间，不执行任何 key 过期操作。当一个 Lua 脚本运行时，从概念上讲，master 中的时间是被冻结的，这样脚本运行的时候，一个给定的键要么存在要么不存在。这可以防止 key 在脚本中间过期，保证将相同的脚本发送到 slave ，从而在二者的数据集中产生相同的效果。</li>
</ol>
<h2 id="sentinel-ha-集群"><a class="header-anchor" href="#sentinel-ha-集群">¶</a>Sentinel（ha 集群）</h2>
<h3 id="操作-v2"><a class="header-anchor" href="#操作-v2">¶</a>操作</h3>
<ol>
<li>
<p>Master<br>
TODO</p>
</li>
<li>
<p>Slave</p>
</li>
<li>
<p>Sentinel</p>
</li>
<li>
<p>获取集群信息</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 26379 info Sentinel</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>获取 master 节点地址</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 26379 SENTINEL get-master-addr-by-name mymaster</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="sentinel-需要定期执行的任务"><a class="header-anchor" href="#sentinel-需要定期执行的任务">¶</a>Sentinel 需要定期执行的任务</h3>
<ul>
<li>每个 Sentinel 以每秒钟一次的频率向它所知的主服务器、从服务器以及其他 Sentinel 实例发送一个 PING 命令。</li>
<li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 那么这个实例会被 Sentinel 标记为主观下线。 一个有效回复可以是： +PONG 、 -LOADING 或者 -MASTERDOWN 。</li>
<li>如果一个主服务器被标记为主观下线， 那么正在监视这个主服务器的所有 Sentinel 要以每秒一次的频率确认主服务器的确进入了主观下线状态。</li>
<li>如果一个主服务器被标记为主观下线， 并且有足够数量的 Sentinel （至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。</li>
<li>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令。 当一个主服务器被 Sentinel 标记为客观下线时， Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</li>
<li>当没有足够数量的 Sentinel 同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING 命令返回有效回复时， 主服务器的主观下线状态就会被移除。</li>
</ul>
<h3 id="sentinel执行流程"><a class="header-anchor" href="#sentinel执行流程">¶</a>Sentinel执行流程</h3>
<p><img src="http://47.88.24.11/imgs/%E5%B9%B6%E5%8F%91/Sentinel.png" alt="Sentinel" title="Sentinel"><br>
在 Sentinel 模式下，客户端不是直接连接服务器的，而是先访问 Sentinel 拿到集群信息再尝试连接 Master。当 Master 发生故障时，客户端会重新向 Sentinel 要地址，并自动完成节点切换。</p>
<ul>
<li>Master 和 Slave 的配置和之前并无区别；</li>
<li>Sentinel 相当于对 Master 的代理，Sentinel 可以通过发布订阅功能获取到 Slave 和其他 Sentinel 的信息。</li>
</ul>
<blockquote>
<p>其实 Sentinel 的内核与其他形式的 Redis 服务器基本一致，只是支持的命令不同、负责的任务也不同。</p>
</blockquote>
<h3 id="主观下线和客观下线"><a class="header-anchor" href="#主观下线和客观下线">¶</a>主观下线和客观下线</h3>
<ul>
<li>主观下线（Subjectively Down， 简称 SDOWN）<br>
主观下线指的是单个 Sentinel 实例对服务器做出的下线判断。<br>
如果一个服务器没有在 <code>master-down-after-milliseconds</code> 选项所指定的时间内， 对向它发送 PING 命令的 Sentinel 返回一个有效回复（有效回复只有+PONG、-LOADING 错误或 -MASTERDOWN 错误）， 那么 Sentinel 就会将这个服务器标记为主观下线。</li>
</ul>
<blockquote>
<p>注意是在<code>master-down-after-milliseconds</code>时间内一直返回无效回复。</p>
</blockquote>
<ul>
<li>客观下线（Objectively Down， 简称 ODOWN）<br>
客观下线指的是多个 Sentinel 实例在对同一个 Master 做出 SDOWN 判断， 并且通过 SENTINEL <code>is-master-down-by-addr</code> 命令互相交流之后，得出的服务器下线判断。 （一个 Sentinel 可以通过向另一个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令来询问对方是否认为给定的服务器已下线。）<br>
从主观下线切换到客观下线并不是通过较严格的投票算法，而是采用了<code>流言协议（gossip protocol）</code>：只要 Sentinel 在给定时间内从其他 Sentinel 接收到足够数量的 Master 下线通知，那么 Sentinel 就会执行状态的切换；如果之后其他 Sentinel 不再报告 Master 已下线，则客观下线状态就会被移除。<br>
只要一个 Sentinel 发现某个 Master 进入客观下线状态，之后就会进入<strong>故障迁移</strong>阶段，选举出一个 Sentinel 对失效的 Master 执行自动故障迁移操作。</li>
</ul>
<blockquote>
<p>客观下线只适用于 Master，对 Slave 或 Sentinel 则不会达到客观下线状态。</p>
</blockquote>
<h3 id="故障迁移-master-挂掉"><a class="header-anchor" href="#故障迁移-master-挂掉">¶</a>故障迁移（Master 挂掉）</h3>
<p>单纯的主从架构并不能挽救 Master 挂掉的情况，因此引入了 Sentinel 集群。Sentinel 会不断地检查集群主服务器和从服务器是否运作正常，并在超过 n 个 Sentinel 同意后判断主节点失效（配置<code>sentinel monitor mymaster 127.0.0.1 6379 2</code>表示这个n=2），不过要注意，无论设置多少个 Sentinel 同意才能判断一个服务器失效， 一个 Sentinel 都需要获得系统中多数 Sentinel 的支持， 才能发起一次自动故障迁移。</p>
<ul>
<li>当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器；</li>
<li>当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。</li>
</ul>
<p>故障转移的具体流程如下：</p>
<ul>
<li>发现主服务器已经进入客观下线状态。</li>
<li>利用<code>Raft leader election</code>算法选举 Sentinel 中的 Leader，对我们的当前 epoch 进行自增， 并尝试在这个纪元中当选，之后，所有 Sentinel 都以更高的 epoch 为准，并主动用更新的 epoch 代替自己的配置。</li>
<li>如果当选失败， 那么在设定的故障迁移超时时间的两倍之后，重新尝试当选。 如果当选成功， 那么执行以下步骤。</li>
<li>选出一个从服务器，并将它升级为主服务器。</li>
<li>向被选中的从服务器发送 SLAVEOF NO ONE 命令，让它转变为主服务器。</li>
<li>通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。</li>
<li>向已下线主服务器的从服务器发送 SLAVEOF 命令， 让它们去复制新的主服务器。</li>
<li>当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作。</li>
</ul>
<p>主服务器选举的规则如下：</p>
<ul>
<li>在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被淘汰。</li>
<li>在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被淘汰。</li>
<li>在经历了以上两轮淘汰之后剩下来的从服务器中， 我们选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器； 如果复制偏移量不可用， 或者从服务器的复制偏移量相同， 那么带有最小运行 ID 的那个从服务器成为新的主服务器。</li>
</ul>
<h3 id="sentinel-选举的安全性"><a class="header-anchor" href="#sentinel-选举的安全性">¶</a>Sentinel 选举的安全性</h3>
<p>配置安全性：</p>
<ul>
<li>每当一个 Redis 实例被重新配置（reconfigured） —— 无论是被设置成主服务器、从服务器、又或者被设置成其他主服务器的从服务器 —— Sentinel 都会向被重新配置的实例发送一个 CONFIG REWRITE 命令， 从而确保这些配置会持久化在硬盘里。完成重新配置之后，从服务器会去复制正确的主服务器。</li>
<li>Sentinel 的状态会被持久化到 Sentinel 配置文件里，当 Sentinel 接收到新配置或 Leader Sentinel 为 Master 创建一个新配置时，这些配置都会与<code>epoch</code>一起被保存到磁盘；</li>
</ul>
<p>故障自动迁移的一致性：</p>
<ul>
<li>Raft 算法保证在一个 epoch 里只有一个 Leader Sentinel 产生，减少了脑裂的风险；</li>
<li>Sentinel 集群总是以更高的 epoch 为准，因为发生<code>网络分区（network partition）</code>时可能会有 Sentinel 包含老的配置，而当这个 Sentinel 服务器接收到其他 Sentinel 的版本更新配置时就会进行更新。</li>
<li>发生网络分区并且某些 Sentinel 仍在采用老的配置时，如果有客户端连接到这些 Sentinel 上，最终可能就会将请求转发到非 Master 服务器上，造成数据不一致。因此，应该使用 <code>min-slaves-to-write</code> 选项， 让主服务器在连接的从实例少于给定数量时停止执行写操作， 与此同时， 应该在每个运行 Redis 主服务器或从服务器的机器上运行 Redis Sentinel 进程。</li>
</ul>
<h3 id="tilt-模式"><a class="header-anchor" href="#tilt-模式">¶</a>TILT 模式</h3>
<p>TILT 模式是一种特殊的保护模式，Sentinel 每隔 100ms 会向实例发一次<code>PING</code>命令，并将上一次 PING 成功的时间和当前时间比对，从而知道与该实例有多长时间没有进行任何成功通讯：</p>
<ul>
<li>如果两次调用时间之间的差距为负值， 或者非常大（超过 2 秒钟）， 那么 Sentinel 进入 TILT 模式。</li>
<li>如果 Sentinel 已经进入 TILT 模式， 那么 Sentinel 延迟退出 TILT 模式的时间。</li>
</ul>
<blockquote>
<p>Sentinel严重依赖计算机的时间功能，一旦计算机的时间功能出现故障， 或者计算机非常忙碌， 又或者进程因为某些原因而被阻塞时， Sentinel 可能也会跟着出现故障。</p>
</blockquote>
<p>进入 TILT 模式后，Sentinel 仍然会继续监视所有目标，但是：</p>
<ul>
<li>它不再执行任何操作，比如故障转移。</li>
<li>当有实例向这个 Sentinel 发送 SENTINEL <code>is-master-down-by-addr</code> 命令时， Sentinel 返回负值： 因为这个 Sentinel 所进行的下线判断已经不再准确。</li>
</ul>
<p>TILT 相当于降级，如果 Sentinel 可以在 TILT 模式下正常维持 30s，那么 Sentinel 会退出 TILT 模式。</p>
<h3 id="busy-状态"><a class="header-anchor" href="#busy-状态">¶</a>BUSY 状态</h3>
<p>当 Lus 脚本执行时间超过阈值，Redis 会返回<code>BUSY</code>错误，当出现这种情况时， Sentinel 在尝试执行故障转移操作之前， 会先向服务器发送一个 <code>SCRIPT KILL</code> 命令， 如果服务器正在执行的是一个只读脚本的话， 那么这个脚本就会被杀死， 服务器就会回到正常状态。</p>
<h2 id="cluster"><a class="header-anchor" href="#cluster">¶</a>Cluster</h2>
<h3 id="操作-v3"><a class="header-anchor" href="#操作-v3">¶</a>操作</h3>
<ol>
<li>
<p>安装<br>
到官网找到：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-4.0.8.tar.gz</span><br><span class="line">make &amp;&amp; make install # 默认安装目录为/usr/local/bin</span><br></pre></td></tr></table></figure>
<p>ruby</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install ruby</span><br><span class="line">yum install rubygems</span><br></pre></td></tr></table></figure>
<p>还有gem文件在<a href="https://rubygems.org/gems/redis/versions/4.0.1" target="_blank" rel="noopener">此处下载</a>，安装：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install /usr/local/redis-3.0.0.gem</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>创建 redis 节点<br>
在一个目录（比如编译目录）下创建 redis_cluster 目录，再在这个目录下创建 7001、7002、7003、7004、7005、7006 的子目录，拷贝配置文件 redis.conf 到各个这些子目录中，并编辑以下内容</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">port 7000 //端口7000,7002,7003        </span><br><span class="line">bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群</span><br><span class="line">daemonize yes //redis后台运行</span><br><span class="line">pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7001,7002</span><br><span class="line">cluster-enabled yes //开启集群 把注释#去掉</span><br><span class="line">cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002</span><br><span class="line">cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置</span><br><span class="line">appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>创建集群<br>
先安装 ruby，因为 redis 的集群协调程序是用 ruby 写的</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ruby ruby-devel rubygems rpm-build</span><br></pre></td></tr></table></figure>
<p>再安装gem，在编译目录下执行</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install redis</span><br></pre></td></tr></table></figure>
<p>运行每个redis实例：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure>
<p>复制编译目录下的src目录中的redis-trib.rb到/usr/local/bin，然后运行<br>
在编译目录的src子目录下执行，其中host为各redis节点的绑定ip（如果绑定的ip是0.0.0.0则必须指定为对外开放的ip，否则会默认绑定127.0.0.1，在slot重定向时会报错），设置每个主分片有一个副本分片</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1 host1:port1 host2:port2 ...</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>测试<br>
为了连到集群上，需要在 redis-cli 请求后加上-c 参数，比如</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 192.168.31.245 -c -p 7002</span><br></pre></td></tr></table></figure>
<p>在普通set和get时，redis会自动计算出目标地址。</p>
</li>
<li>
<p>在 Spring 中配置 redis 集群</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 配置redis集群，每个节点一个 --&gt;</span><br><span class="line">&lt;bean id=&quot;redisClient&quot; class=&quot;redis.clients.jedis.JedisCluster&quot;&gt;</span><br><span class="line">    &lt;constructor-arg name=&quot;nodes&quot;&gt;</span><br><span class="line">        &lt;set&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7001&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7002&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7003&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7004&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7005&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">            &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;host&quot; value=&quot;172.16.205.141&quot;/&gt;</span><br><span class="line">                &lt;constructor-arg name=&quot;port&quot; value=&quot;7006&quot;/&gt;</span><br><span class="line">            &lt;/bean&gt;</span><br><span class="line">        &lt;/set&gt;</span><br><span class="line">    &lt;/constructor-arg&gt;</span><br><span class="line">    &lt;constructor-arg name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;/&gt;</span><br><span class="line">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>测试</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ApplicationContext context =</span><br><span class="line">        new ClassPathXmlApplicationContext(&quot;classpath:spring/spring-dao.xml&quot;);</span><br><span class="line">JedisCluster jedisCluster = (JedisCluster) context.getBean(&quot;redisClient&quot;);</span><br><span class="line">jedisCluster.set(&quot;kname&quot;, &quot;Mike&quot;);</span><br><span class="line">String str = jedisCluster.get(&quot;kname&quot;);</span><br><span class="line">System.out.println(str);</span><br><span class="line">jedisCluster.close();</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="cluster-优势"><a class="header-anchor" href="#cluster-优势">¶</a>Cluster 优势</h3>
<ol>
<li>线性的可扩展性：扩容即迁移槽，已有很多迁移案例；</li>
<li>没有合并操作：因为 Redis 中的 List 和 Set 中保存的 Value 通常是比较大的，可能会达数以百万计的元素，而它们可能被存储到了不同的 Redis 实例上，传输和合并这样的值将很容易称为一个主要的性能瓶颈；</li>
<li>写入安全（Write Safety）：只有在非常少见的 Master 宕机的情况下，写入才会失败，并且这个失败的时间窗口不大（由一个 Slave 顶替上来）；</li>
<li>可用性（Availability）：就算有部分 Master 不可用了，它们的 Slave 仍然可以通过选举提升为 Master。</li>
</ol>
<h3 id="cluster-缺点"><a class="header-anchor" href="#cluster-缺点">¶</a>Cluster 缺点</h3>
<ol>
<li>Redis 集群并不支持处理多个 keys 的命令，因为这需要在不同的节点间移动数据，从而达不到像 Redis 那样的性能，在高负载的情况下可能会导致不可预料的错误。</li>
<li>Redis 集群不像单机版本的 Redis 那样支持多个数据库，集群只有数据库 0，而且也不支持 SELECT 命令。</li>
</ol>
<h3 id="去中心化架构"><a class="header-anchor" href="#去中心化架构">¶</a>去中心化架构</h3>
<p><img src="http://47.88.24.11/imgs/Redis/Cluster.png" alt="Cluster" title="Cluster"><br>
redis cluster在设计的时候，就考虑到了<strong>去中心化</strong>，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。<strong>所有的 redis 节点彼此互联(PING-PONG 机制)</strong>，内部使用<strong>二进制协议</strong>优化传输速度和带宽，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。客户端与 redis 节点直连，不需要中间 proxy 层，客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</p>
<h3 id="存储结构"><a class="header-anchor" href="#存储结构">¶</a>存储结构</h3>
<p>Redis 集群没有并使用传统的<strong>一致性哈希</strong>来分配数据，而是采用另外一种叫做<strong>哈希槽 (hash slot)<strong>的方式来分配的。redis cluster 默认分配了 16384 个 slot，当我们 set 一个 key 时，会用</strong>CRC16</strong>算法来取模得到所属的 slot，然后将这个 key 分到哈希槽区间的节点上，具体算法就是：<code>CRC16(key) % 16384</code>。所以我们在测试的时候看到 set 和 get 的时候，直接跳转到了 7000 端口的节点。<br>
客户端在接收到重定向错误（redirections errors） -MOVED 和 -ASK 的时候， 将命令重定向到其他节点。客户端不需要存储集群信息（槽所在位置），但是如何客户端可以缓存键值和节点之间的映射关系，就可以明显提高命令执行的效率了（Redisson 中就是这么做的）。<br>
在 Cluster 架构中，slave 节点不分配槽，只拥有读权限，但是在代码中 cluster 执行读写操作的都是 master 节点，并不是读就是从节点、写就是主节点。</p>
<p>一致性哈希的示例实现可以参考Dubbo中的实现：<code>com.alibaba.dubbo.rpc.cluster.loadbalance.ConsistentHashLoadBalance</code><br>
关键代码如下：<br>
<img src="http://47.88.24.11/imgs/Redis/ConsistentHashLoadBalance.png" alt="ConsistentHashLoadBalance" title="ConsistentHashLoadBalance"></p>
<h3 id="容错"><a class="header-anchor" href="#容错">¶</a>容错</h3>
<p>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的 salve 之间进行数据同步。当读取数据时，也根据 hash 函数找到对应哈希槽所在的 master 节点获取数据。只有当一个 master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。</p>
<h4 id="判断一个节点是否宕机"><a class="header-anchor" href="#判断一个节点是否宕机">¶</a>判断一个节点是否宕机</h4>
<p>一些 CP 特性且中心化的集群来说，当出现节点宕机时经常需要选举新的 Leader 节点，但是 Redis-Cluster 是<strong>去中心化</strong>的，某个 Master 的宕机并不会影响其他节点的工作。但是，当节点失联时，需要考虑网络的抖动情况，毕竟不能因为某几个请求意外超时就推断集群失败了，所以这里引入了投票机制。<br>
投票过程是集群中所有 master 参与的，每个节点都存有整个集群所有主节点及从节点的信息，它们之间通过互相 ping-pong 来判断节点是否可以连上，如果半数以上 master 节点与当前 master 节点通信超时（cluster-node-timeout），则认为当前 master 节点挂掉。</p>
<h4 id="判断集群是否-fail"><a class="header-anchor" href="#判断集群是否-fail">¶</a>判断集群是否 fail</h4>
<p>当 master 挂掉时，并不意味着集群已无法再提供服务了，集群要进入<code>fail（不可用）</code>状态需要满足以下条件之一：</p>
<ol>
<li>集群的任意 master 挂掉，且该 master 没有 slave 或 slave 全挂掉了，则集群进入 fail 状态。</li>
<li>集群超过半数以上 master 挂掉，无论有无 slave 都进入 fail 状态。</li>
</ol>
<p>当集群不可用时，任何操作都将返回<code>((error) CLUSTERDOWN The cluster is down)</code>错误。需要注意的是，必须要 3 个或以上的主节点，否则在创建集群时会失败。</p>
<h3 id="一致性"><a class="header-anchor" href="#一致性">¶</a>一致性</h3>
<p>Redis 不能保证强一致性，因为：</p>
<ol>
<li>异步复制：写操作会被异步复制到 slave 节点，但可能由于出现网络分区、脑裂而导致数据丢失。<br>
<img src="http://47.88.24.11/imgs/Redis/%E7%BD%91%E7%BB%9C%E5%88%86%E5%8C%BA.png" alt="网络分区" title="网络分区"><br>
如上图所示，客户端 Z1 向 Master-B 写入数据后，集群出现了网络分区，且分区持续的时间足够长导致此时 B1 被选举为新的 Master，则在此期间 Z1 向 B 写入的数据就都丢失了。</li>
</ol>
<blockquote>
<p>网络分区出现期间，客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项。</p>
</blockquote>
<h3 id="集群迁移-单点-cluster"><a class="header-anchor" href="#集群迁移-单点-cluster">¶</a>集群迁移 单点 -&gt; Cluster</h3>
<p>在企业发展早期，因为业务规模小，一般会采用更方便、更节省资源的 1 主多从（一般是 1 主 2 从 3Sentinel）的架构，简称为 m-s 架构，而随着业务规模的扩展，这种架构的弊端就会显现出来，比如无法扩展、存在单点等。这时一般会考虑往 Cluster 架构迁移，但是，就像所有迁移规范那样，平滑地将数据和流量从老集群迁移到新集群、且过渡过程中不影响服务、随时能够切换回来，是所有迁移工作的前提，毕竟不能为了架构升级就把所有业务都停了。<br>
因为公司的 Redis 集群之前是直接使用 Lettuce 访问的，并没有 Twemproxy、Codis 这样的中间件，因此迁移只能一个一个集群地推进，而且难做的是，一个集群可能会被好几个服务同时使用，而每个服务又会有多个实例同时访问。</p>
<h4 id="迁移步骤"><a class="header-anchor" href="#迁移步骤">¶</a>迁移步骤</h4>
<ol>
<li>异步双写<br>
第一步需要打开双写开关，此时对 m-s 的写入会被异步写入到新 Cluster。<br>
此时 m-s 正常提供读写服务，异步双写并不会影响原来的功能（除非整出 Bug 来了），就像 Cluster 不存在一样，但是此时往 Cluster 写入的数据基本是错误的，因为其中并没有包含之前的数据，可以认为 Cluster 中都是脏数据。</li>
<li>复制<br>
这一步如果有时间有能力有需要可以自研一个迁移工具，但是实际上 Github 上已经有一些同步工具了，比如唯品会的<a href="https://github.com/vipshop/redis-migrate-tool" target="_blank" rel="noopener">redis-migrate-tool</a>、豌豆荚的<a href="https://github.com/CodisLabs/redis-port" target="_blank" rel="noopener">redis-port</a>、网易的<a href="https://github.com/helifu/redis-migration" target="_blank" rel="noopener">redis-migration</a>。<br>
像 redis-migrate-tool 提供了 m-s 向 Cluster 直接迁移的支持，但是更稳妥的方式可能还是先导出 m-s 的一份快照（从库即可），这样可以减小同步过程对线上业务的影响，且方便留作备份。</li>
<li>灰度<br>
为了减少出问题时对线上业务的影响，需要灰度开关的支持，实现 Redis QPS 流量逐渐地由单点向集群过渡，多次调大灰度开关值，使得 redis 集群系统逐渐承担起 redis 流量的主体，也避免了新部署的集群系统不可用或者我们的迁移出现失误导致的服务不可用现象。<br>
具体地讲，灰度过程应当含有以下几个步骤：
<ol>
<li>将 10%写流量同步写入 Cluster（其余的异步写入），观察一段时间；</li>
<li>同步写入 Cluster，观察一段时间；</li>
<li>异步读取 Cluster 中的数据，与 m-s 中的结果进行对比校验，确保新老数据是否同步，观察一段时间；</li>
<li>将所有读操作完全切到 Cluster，但仍保持对 m-s 的写入，观察一段时间；</li>
<li>停掉对 m-s 的写入，此时迁移完毕。</li>
</ol>
</li>
</ol>
<blockquote>
<p>注意每一步都采用配置进行控制，如果出现了不可预知的情况，可以快速的回退到初始状态。</p>
</blockquote>
<h4 id="迁移过程中可能发生的情况"><a class="header-anchor" href="#迁移过程中可能发生的情况">¶</a>迁移过程中可能发生的情况</h4>
<p>迁移过程中可能会出现以下几种情况：</p>
<ol>
<li>key 被复制后（注意复制过去是直接覆盖掉），m-s 更新了这个 key。这个更新之后会被双写到 Cluster，因此 m-s 和 Cluster 可以保持一致；</li>
<li>复制流程过后，key 新增了。同样会被双写同步到 Cluster；</li>
<li>复制前，双写 Cluster 失败了。由于复制过程中会将所有 key 都覆盖一次，所以这些失败的 key 不会造成影响；</li>
<li>双写失败问题：复制后、且写流量未迁移，双写失败了。这种情况下贸然打开开关会造成 m-s 和 Cluster 之间数据的不一致，可能会引起未知的问题；<br>
<img src="http://47.88.24.11/imgs/Redis/%E8%BF%81%E7%A7%BB-%E5%BC%82%E6%AD%A5%E5%86%99%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%83%85%E5%86%B5.png" alt="迁移-异步写失败的情况" title="迁移-异步写失败的情况"></li>
<li>并发双写乱序：如下图所示，由于乱序问题，老 Redis Server 最终保存下来的值是第二次请求触发的，而新 Redis Cluster 保存的是第一次的。<br>
<img src="http://47.88.24.11/imgs/Redis/%E8%BF%81%E7%A7%BB-%E5%B9%B6%E5%8F%91%E5%8F%8C%E5%86%99%E4%B9%B1%E5%BA%8F.png" alt="迁移-并发双写乱序" title="迁移-并发双写乱序"></li>
<li>双写与复制乱序：类似上面这种情况，只不过要把应用服务器 B 换成专门负责在 Redis 服务器之间复制数据的服务器。</li>
<li>写流量迁移后，写 Cluster 失败了。如果非常倒霉发生了这种事，还是赶紧切回到原来的 m-s 吧。</li>
</ol>
<p>由于这些问题的存在，数据迁移基本做不到百分之百的可靠安全，比较适合一些缓存数据并不太重要的场景，或者至少在灰度步骤小心一些。<br>
退一步讲，其实可以在夜间的业务低谷期把服务停了做迁移，这种方案最简单、可讨论的空间也最小。<br>
另外，一些 Redis 的 Cluster 解决方案已经提供了迁移功能，比如<a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener">Codis</a>。</p>
<h2 id="redis-监控"><a class="header-anchor" href="#redis-监控">¶</a>Redis 监控</h2>
<p>这里把一些常见的监控命令总结一下，时不时都会用到。</p>
<h3 id="redis-cli"><a class="header-anchor" href="#redis-cli">¶</a>redis-cli</h3>
<p>命令行客户端。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建连接，可以用PING-PONG来检查连接是否OK</span><br><span class="line">redis-cli -h localhost -p 6379</span><br><span class="line"># 监控Redis的连接和读写操作</span><br><span class="line">redis-cli -h localhost -p 6379 monitor</span><br><span class="line"># Redis服务器的统计信息</span><br><span class="line">redis-cli -h localhost -p 6379 info</span><br></pre></td></tr></table></figure>
<ul>
<li>内存使用<br>
<code>Memory</code>下可以查看 Redis 内存使用情况。如果 Redis 使用的内存超出了可用的物理内存大小，那么 Redis 很可能系统会被杀掉。针对这一点，你可以通过 info 命令对 used_memory 和 used_memory_peak 进行监控，为使用内存量设定阀值，并设定相应的报警机制。当然，报警只是手段，重要的是你得预先计划好，当内存使用量过大后，你应该做些什么，是清除一些没用的冷数据，还是把 Redis 迁移到更强大的机器上去。</li>
<li>持久化<br>
<code>Persistence</code>下可以查看 RDB 和 AOF 的备份情况。如果因为你的机器或 Redis 本身的问题导致 Redis 崩溃了，那么你唯一的救命稻草可能就是 dump 出来的 rdb 文件了，所以，对 Redis dump 文件进行监控也是很重要的。可以通过对 rdb_last_save_time 进行监控，了解最近一次 dump 数据操作的时间，还可以通过对 rdb_changes_since_last_save 进行监控来获得如果这时候出现故障，会丢失（即已改变）多少数据。</li>
<li>Keys<br>
通过获取 Keyspace 中的结果得到各个数据库中 key 的数量</li>
<li>QPS<br>
即每分钟执行的命令个数，即：(total_commands_processed2-total_commands_processed1)/span，为了实时得到 QPS，可以设定脚本在后台运行，记录过去几分钟的 total_commands_processed。在计算 QPS 时，利用过去的信息和当前的信息得出 QPS 的估计值。</li>
</ul>
<h3 id="redis-stat"><a class="header-anchor" href="#redis-stat">¶</a>redis-stat</h3>
<p>Redis 服务器的<strong>实时</strong>信息。<br>
这个命令不是 Redis 官方提供的，而是一个三方用 ruby 写的监控程序，安装起来有点麻烦，这里就不说明了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># usage:redis-stat [HOST[:PORT] ...] [INTERVAL [COUNT]]</span><br><span class="line"># 每1s收集一次</span><br><span class="line">redis-stat 1</span><br><span class="line"># 指定主机和服务器端口，间隔为1s，收集10次</span><br><span class="line">redis-stat localhost:6379 1 10</span><br><span class="line"># 启动一个redis-stat服务进程，提供一个Dashboard来查看Redis服务器的状态，按如下启动，可以访问 `localhost:8080` 查看</span><br><span class="line">redis-stat localhost:6379 --server=8080 5 --daemon</span><br></pre></td></tr></table></figure>
<p>-a, --auth=PASSWORD 密码<br>
-v, --verbose       展示更多信息<br>
–style=STYLE       输出样式：unicode|ascii<br>
–no-color          去掉颜色<br>
–csv[=CSV_FILE]    打印或将结果保存到 CSV 文件内<br>
–es=ELASTICSEARCH_URL  将结果发送到 ElasticSearch：[http://]HOST[:PORT][/INDEX]<br>
–server[=PORT]     启动 redis-stat 服务器（默认端口是 63790）<br>
–daemon            启动 redis-stat 作为守护进程，必须和 --server 选项一起使用<br>
–version           版本<br>
–help              帮助信息</p>
<h3 id="slowlog"><a class="header-anchor" href="#slowlog">¶</a>slowlog</h3>
<p>慢查询日志。<br>
可以在 redis.conf 中配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 记录执行时间超过5秒的查询</span><br><span class="line">config set slowlog-log-slower-than 5000</span><br><span class="line"># 最多保存25条日志</span><br><span class="line">config set slowlog-max-len 25</span><br></pre></td></tr></table></figure>
<p>使用 redis-cli 登录查看慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 获取10条日志</span><br><span class="line">slowlog get 10</span><br></pre></td></tr></table></figure>
<h3 id="redis-benchmark"><a class="header-anchor" href="#redis-benchmark">¶</a>redis-benchmark</h3>
<p>redis-benchmark 是 Redis 官方提供的 Redis 服务器性能基准测试工具：<br>
-t 选择你想测试的命令，比如 redis-benchmark -t set<br>
-p 指定 port redis-benchmark -p 6379<br>
-l 一直循环<br>
-c 指定客户端数量<br>
-n 指定 request 数量<br>
-q Quiet，不显示额外信息（多少时间内完成了多少条之类的），只显示 query/sec 的值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 测试并发连接性能，100个并发连接，总共发100000个请求</span><br><span class="line">redis-benchmark -h localhost -p 6379 -c 100 -n 100000</span><br><span class="line"># 测试大数据包读写性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q -d 100</span><br><span class="line"># 只测试某些操作的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -t set,lpush -n 100000 -q</span><br><span class="line"># 只测试某些数值存取的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q script load &quot;redis.call(&apos;set&apos;, &apos;foo&apos;, &apos;bar&apos;)&quot;</span><br></pre></td></tr></table></figure>
<h3 id="rdb-文件分析"><a class="header-anchor" href="#rdb-文件分析">¶</a>RDB 文件分析</h3>
<p>Redis 内存比较大的时候不容易查出是哪些 key 比较占空间，这时可以使用 <a href="https://github.com/sripathikrishnan/redis-rdb-tools" target="_blank" rel="noopener">redis-rdb-tools</a> 这种工具来查看报告。</p>
<h2 id="qa"><a class="header-anchor" href="#qa">¶</a>QA</h2>
<h3 id="有人说-redis-只适合用来做缓存-当数据库来用并不合适-为什么？"><a class="header-anchor" href="#有人说-redis-只适合用来做缓存-当数据库来用并不合适-为什么？">¶</a>有人说 Redis 只适合用来做缓存，当数据库来用并不合适，为什么？</h3>
<p>Redis 的事务并不严格：<br>
* A(原子性)：Redis 支持事务，所有命令会被保存到一个事务队列中，服务器接收到 exec 时才会被真正执行，注意如果中间出错，事务不会回滚，后面的指令还会继续执行；而且如果涉及到复杂的逻辑判断，则只能通过<strong>lua 脚本</strong>实现“伪原子性”，说它是“伪原子性”是因为虽然脚本可以一次性执行多条命令，如果中间某个命令出错还是会无法保证“要么全部执行，要么都不执行”的要求。<br>
* I(隔离性)：Redis 是单线程模型，因此可以保证隔离性。<br>
* D(持久性)：Redis 是内存数据库，服务器意外崩溃会导致内存中的数据丢失，除非开启 AOF，并且配置成每次写入都记日志，但是这样又会极大地影响效率，所以一般会配置成混合模式的持久化。</p>
<h3 id="redis-的底层数据结构有哪些"><a class="header-anchor" href="#redis-的底层数据结构有哪些">¶</a>Redis 的底层数据结构有哪些</h3>
<p>sds：string 使用，变长字符串，不够的情况下重新分配空间并将老字符串数据拷贝过去；<br>
dict：字典应用很多，包括 Redis 数据库中保存所有 key-value、hash、set、zset。dict 类似 Java 中的 HashMap，将 key 散列到哈希桶数组中，每个哈希桶都是一个链表，插入就是插入到链表头部，当元素超过了容量的一半后会启动渐进式 rehash 进行扩容。<br>
ziplist：相当于一个数组，查询时需要遍历一次，每次插入都需要 realloc 重新分配一个新的更大的数组，然后把老数组内容拷贝过去。<br>
quicklist：由于 linkedlist 附加空间成本高且容易产生碎片，因此 Redis 里的 quicklist 设计成了 linkedlist 和 ziplist 的结合，它将 linkedlist 按段切分，每一段使用 ziplist 存储；<br>
skiplist：skiplist 用于实现 zset 中按 score 排序的要求，插入时先自顶向下查位置，然后按概率计算该节点应该分配到几层。</p>
<h3 id="存储数据选择-string-还是-hash？"><a class="header-anchor" href="#存储数据选择-string-还是-hash？">¶</a>存储数据选择 string 还是 hash？</h3>
<p>从业务层面来看，如果要存好多字段的对象、而且这个对象的每个字段都会单独拿出来用，则可以考虑使用 hash，否则没有太多限制条件。<br>
从性能角度来看，如果存的字段少，hash 会使用 ziplist 结构存储，性能多少受点影响，而且还要考虑转换结构和渐进式扩容对性能的损耗。<br>
从节约空间的角度来看，string 的 key 一般都会加个前缀，一般会比 hash 占用更多的空间，不过差距不大。</p>
<h3 id="设计-redis-排序-数据结构是金额-花钱的时间-金额越大-时间越早越靠前"><a class="header-anchor" href="#设计-redis-排序-数据结构是金额-花钱的时间-金额越大-时间越早越靠前">¶</a>设计 redis 排序，数据结构是金额+花钱的时间，金额越大，时间越早越靠前</h3>
<p>用 zset 存，score 是金额拼上时间，金额放高位，MAX_INT 和时间作差放低位，查询时使用<code>ZREVRANGE</code>命令查询。</p>
<h3 id="hash-中哈希冲突怎么解决的"><a class="header-anchor" href="#hash-中哈希冲突怎么解决的">¶</a>hash 中哈希冲突怎么解决的</h3>
<p>分两种情况：hash 在数据量小时结构是 ziplist，这时插入不会做冲突检测，插入到目标位置后就向后统一移动数据，给新插入的数据项流出空间；在数据量大时结构是 dict，这种结构和 Java 中的 HashMap 类似，使用链表来处理冲突。</p>
<ol>
<li>说说 Redis 为什么那么快。<br>
单线程模型-&gt;减少了线程间上下文切换的开销。<br>
多路复用的 IO 模型-&gt;单线程监控多个连接。</li>
<li>为什么 Redis 记录 AOF 日志是先执行指令然后再记录 AOF 日志？而不是像其他存储引擎一样反过来？<br>
主要是因为 Redis 本身是缓存而不是 db，侧重点不同，db 先写日志是为了失败回滚，而 Redis 持久化是一个附加功能，只能保证数据不会完全丢失。</li>
</ol>
<h3 id="redis-淘汰时-如果读取-会不会数据不完整"><a class="header-anchor" href="#redis-淘汰时-如果读取-会不会数据不完整">¶</a>Redis 淘汰时，如果读取，会不会数据不完整</h3>
<p>redis 的淘汰分两种：</p>
<ul>
<li>一种是过期，这种不会导致这种问题，因为查询时会判断下过期时间，过期了就不返回；</li>
<li>另一种是超过内存容量淘汰，比如 LRU，这种也不会导致这种问题，因为执行每个命令时都会检查下缓存是否超出了阈值，可见代码<code>server.c/processCommand</code>：<br>
<img src="http://47.88.24.11/imgs/Redis/Redis-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%89%8D%E6%A3%80%E6%9F%A5%E7%BC%93%E5%AD%98%E6%98%AF%E5%90%A6%E6%BA%A2%E5%87%BA.jpeg" alt="Redis-执行命令前检查缓存是否溢出" title="Redis-执行命令前检查缓存是否溢出"></li>
</ul>
<h3 id="redis-的持久化原理是什么"><a class="header-anchor" href="#redis-的持久化原理是什么">¶</a>Redis 的持久化原理是什么</h3>
<p>Redis 有两种持久化方式：RDB 和 AOF<br>
RDB 是快照，AOF 记录了写操作，效率起见，一般 RDB 作为 checkpoint，checkpoint 后的数据通过 AOF 恢复。</p>
<h3 id="rdb-和-aof-之间的区别"><a class="header-anchor" href="#rdb-和-aof-之间的区别">¶</a>RDB 和 AOF 之间的区别</h3>
<p>RDB 二进制文件可以直接加载到内存速度较快；AOF 要重放命令，所以速度比较慢。<br>
RDB 需要全量备份，AOF 可以增量备份，二者的应用场景不同。</p>
<h3 id="redis的复制原理是什么？"><a class="header-anchor" href="#redis的复制原理是什么？">¶</a>Redis的复制原理是什么？</h3>
<p>master 会启动一个后台进程进行持久化（RDB or AOF），第一次连接时会将 RDB 文件发给 slave，slave 先保存到磁盘，之后加载到内存中；如果不是第一次连接，slave 连接 master 后通过 PSYNC 命令告知自己同步的起始位置，master 将增量部分 AOF 文件发送给 slave。</p>
<h3 id="redis-持久化期间-主进程还能对外提供服务吗？为什么"><a class="header-anchor" href="#redis-持久化期间-主进程还能对外提供服务吗？为什么">¶</a>Redis 持久化期间，主进程还能对外提供服务吗？为什么</h3>
<p>能。<br>
因为 Redis 的复制是通过 fork 子进程实现的，父进程仍然可以接收请求。</p>
<h3 id="持久化期间-redis如何处理新写入的数据呢-这个数据也会直接进行持久化吗？"><a class="header-anchor" href="#持久化期间-redis如何处理新写入的数据呢-这个数据也会直接进行持久化吗？">¶</a>持久化期间，Redis如何处理新写入的数据呢，这个数据也会直接进行持久化吗？</h3>
<p>不会。<br>
因为 Redis 复制是通过 fork 子进程实现的，由于 COW 机制，子进程只能看到老数据。</p>
<h3 id="主从复制为什么会发生延迟？怎么解决"><a class="header-anchor" href="#主从复制为什么会发生延迟？怎么解决">¶</a>主从复制为什么会发生延迟？怎么解决</h3>
<p>延迟无法避免，比如主从之间的网络抖动、slave 发生阻塞（如 IO）等情况。<br>
解决办法有两种：</p>
<ul>
<li><code>min-slave-to-write N</code>和<code>min-slave-max-lag M</code>，控制 Master，只有在至少有 N 个 slave 正在工作，并且滞后时间均小于 M 秒的情况下，Master 将不接受写入请求；</li>
<li><code>slave-serve-stale-data</code>，控制从库对主库失去响应或复制进行过程中从库的表现，为 yes 则从库会继续响应客户端的请求，为 no 则除去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个错误<code>SYNC with master in progress</code>；</li>
<li>编写外部监控程序，如果某个 slave 延迟较大，则通知 client 不要读这个 slave。</li>
</ul>
<h3 id="redis-怎么实现高可用"><a class="header-anchor" href="#redis-怎么实现高可用">¶</a>Redis 怎么实现高可用</h3>
<p>从复制、Sentinel 到 Cluster</p>
<h3 id="sentinel-中-使用客户端是怎么连接服务器的？-redisson-配置"><a class="header-anchor" href="#sentinel-中-使用客户端是怎么连接服务器的？-redisson-配置">¶</a>sentinel 中，使用客户端是怎么连接服务器的？（Redisson 配置）</h3>
<p>见《Redis 客户端》。</p>
<h3 id="哈希槽原理？和一致性哈希的区别？怎么落点"><a class="header-anchor" href="#哈希槽原理？和一致性哈希的区别？怎么落点">¶</a>哈希槽原理？和一致性哈希的区别？怎么落点</h3>
<p>redis cluster 默认分配了 16384 个 slot，当我们 set 一个 key 时，会用<strong>CRC16</strong>算法来取模得到所属的 slot，然后将这个 key 分到哈希槽区间的节点上，具体算法就是：<code>CRC16(key) % 16384</code>。所以我们在测试的时候看到 set 和 get 的时候，直接跳转到了 7000 端口的节点。<br>
哈希槽与一致性哈希的区别：哈希槽由客户端来重定向到目标 slot 所在节点，一致性哈希需要由服务器端重定向到目标节点，而且需要按顺时针方向一个一个节点递归地找。</p>
<h3 id="redis雪崩-击穿-穿透等现象是怎么出现的？怎么解决"><a class="header-anchor" href="#redis雪崩-击穿-穿透等现象是怎么出现的？怎么解决">¶</a>Redis雪崩、击穿、穿透等现象是怎么出现的？怎么解决</h3>
<ol>
<li>缓存穿透<br>
缓存穿透指查询一个不存在的数据，出于容错考虑这个查询会穿透到 DB 层，如果这种带穿透的查询特别多可能会把 DB 打挂掉。<br>
解决办法：使用布隆过滤器，保存所有可能存在的数据到一个足够大的 bitmap 中，由于布隆过滤器的特性，一定不存在的数据在 bitmap 中一定找不到，从而可以很大程度上避免对底层存储系统的查询压力；还有一种更简单的方法，就是在查询返回结果为空时也把这个空结果缓存起来，但是它的过期时间会短一些，最长时间不超过 5 分钟。</li>
<li>缓存雪崩<br>
缓存雪崩指的是设置缓存时采用了相同的过期时间，导致缓存在同一时间同时失效，请求全部打到 DB，DB 瞬时压力过大导致雪崩。<br>
解决办法：缓存失效时间随机化，在原有失效时间基础上加上一个随机值，可以使得过期时间的重复率降低；加锁并令请求排队，使得请求串行化，避免所有请求都查询数据库，不过这样会导致性能的降低。</li>
<li>缓存击穿<br>
缓存击穿指的是某个 key 在过期时正好有大量请求访问该 key，这些请求会同时回表，可能会瞬间将后端 DB 打挂。<br>
解决办法：使用互斥锁，缓存失效时先加锁，避免并发回表；一些长时间不变的数据完全可以不设置过期时间，或者过期时间特别长。</li>
</ol>
<h3 id="主从复制的流程？传的是文件吗？"><a class="header-anchor" href="#主从复制的流程？传的是文件吗？">¶</a>主从复制的流程？传的是文件吗？</h3>
<p>流程见《主从同步》。<br>
如果是全量同步，同步时会先同步 RDB 文件，再同步增量写命令；<br>
如果是部分重同步，则只同步增量写命令。</p>
<h3 id="中间传输失败怎么办？中间传输不一致怎么办"><a class="header-anchor" href="#中间传输失败怎么办？中间传输不一致怎么办">¶</a>中间传输失败怎么办？中间传输不一致怎么办</h3>
<p>如果上次传输中断，则下次同步时从中断位置开始执行部分重同步。</p>
<h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2>
<ol>
<li><a href="https://redis.io/topics/faq" target="_blank" rel="noopener">FAQ</a></li>
<li><a href="https://www.cxc233.com/blog/e1d54234.html" target="_blank" rel="noopener">使用vscode(gdb)调试redis</a></li>
</ol>
<h3 id="应用"><a class="header-anchor" href="#应用">¶</a>应用</h3>
<ol>
<li><a href="https://stackoverflow.com/questions/16375188/redis-strings-vs-redis-hashes-to-represent-json-efficiency" target="_blank" rel="noopener">Redis strings vs Redis hashes to represent JSON: efficiency?</a></li>
</ol>
<h3 id="数据结构"><a class="header-anchor" href="#数据结构">¶</a>数据结构</h3>
<ol>
<li><a href="https://www.jianshu.com/p/4992bed65b22" target="_blank" rel="noopener">Redis 源码涉及 C 语言</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261203&amp;idx=1&amp;sn=f7ff61ce42e29b874a8026683875bbb1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 内部数据结构详解(1)——dict</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261213&amp;idx=1&amp;sn=0ddddf48929610a4155bd82794cad4fa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 内部数据结构详解(2)——sds</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261237&amp;idx=1&amp;sn=380d183332d41d24ea6f88a54f533fc3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 内部数据结构详解(3)——robj</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261265&amp;idx=1&amp;sn=e105c4b86a5640c5fc8212cd824f750b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 内部数据结构详解(4)——ziplist</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261335&amp;idx=1&amp;sn=053d72a348be2e78040f3847f4092d92&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 内部数据结构详解(5)——quicklist</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261457&amp;idx=1&amp;sn=fe966f3825b81e9d50a2cf38dac9060c&amp;chksm=84479e48b330175ea07905e791856cca5fc50694db9fd4c3485ba5dc097443e69f5ed28a34b5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 为什么用跳表而不用平衡树？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261457&amp;idx=1&amp;sn=fe966f3825b81e9d50a2cf38dac9060c&amp;chksm=84479e48b330175ea07905e791856cca5fc50694db9fd4c3485ba5dc097443e69f5ed28a34b5&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis 中的集合类型是怎么实现的？</a></li>
</ol>
<h3 id="persistence"><a class="header-anchor" href="#persistence">¶</a>Persistence</h3>
<ol>
<li><a href="https://www.jianshu.com/p/c210851d3558" target="_blank" rel="noopener">剖析 Redis RDB 文件</a></li>
<li><a href="https://www.jianshu.com/p/131cf929a262" target="_blank" rel="noopener">Redis 源码分析–RDB 实现源码阅读</a></li>
<li><a href="https://www.jianshu.com/p/90cdd28c5e92" target="_blank" rel="noopener">Redis 源码分析–AOF 文件全量重写源码阅读</a></li>
<li><a href="https://www.jianshu.com/p/91cf48c8c082" target="_blank" rel="noopener">Redis 源码分析–AOF 文件增量追写源码阅读</a></li>
</ol>
<h3 id="客户端"><a class="header-anchor" href="#客户端">¶</a>客户端</h3>
<ol>
<li><a href="http://www.redis.cn/topics/clients.html" target="_blank" rel="noopener">Redis 如何处理客户端连接</a></li>
<li><a href="https://www.jianshu.com/p/36a5935db85b" target="_blank" rel="noopener">剖析 Redis 协议</a></li>
<li><a href="https://www.jianshu.com/p/78b94407f59c" target="_blank" rel="noopener">剖析 Redis 协议(续)</a></li>
</ol>
<h3 id="主从复制"><a class="header-anchor" href="#主从复制">¶</a>主从复制</h3>
<ol>
<li><a href="http://www.redis.cn/topics/replication.html" target="_blank" rel="noopener">复制</a></li>
<li><a href="https://www.cnblogs.com/wdliu/p/9407179.html" target="_blank" rel="noopener">redis 系列–主从复制以及 redis 复制演进</a></li>
</ol>
<h3 id="sentinel-cluster"><a class="header-anchor" href="#sentinel-cluster">¶</a>Sentinel &amp; Cluster</h3>
<ol>
<li><a href="http://www.redis.cn/topics/partitioning.html" target="_blank" rel="noopener">分区：怎样将数据分布到多个 redis 实例</a></li>
<li><a href="http://www.redis.cn/topics/sentinel.html" target="_blank" rel="noopener">Redis 的 Sentinel 文档</a></li>
<li><a href="http://www.redis.cn/topics/cluster-tutorial.html" target="_blank" rel="noopener">Redis 集群教程</a></li>
<li><a href="http://www.redis.cn/topics/cluster-spec.html" target="_blank" rel="noopener">Redis 集群规范</a></li>
<li><a href="https://www.jianshu.com/p/4163916a2a8a" target="_blank" rel="noopener">一致性哈希和哈希槽对比</a></li>
</ol>
<h3 id="架构迁移"><a class="header-anchor" href="#架构迁移">¶</a>架构迁移</h3>
<ol>
<li><a href="http://www.redis.cn/articles/20170830103.html" target="_blank" rel="noopener">Redis 集群迁移案例</a></li>
<li><a href="https://github.com/vipshop/redis-migrate-tool" target="_blank" rel="noopener">redis-migrate-tool</a></li>
<li><a href="https://github.com/CodisLabs/redis-port" target="_blank" rel="noopener">redis-port</a></li>
<li>redis-migration<br>
<a href="https://github.com/helifu/redis-migration" target="_blank" rel="noopener">redis-migration</a><br>
<a href="https://mp.weixin.qq.com/s?__biz=MzAxNjc1MTk5Nw==&amp;mid=401404354&amp;idx=1&amp;sn=36225e1e72aa1402d2fb79928addadd9&amp;scene=1&amp;srcid=0304rSI42ziy0Qfb9wvNDzBi&amp;key=8dcebf9e179c9f3a6f34ddb7f5de1b77fe12f5078f6a2ac7bf9f7c0d8485989ab2d848694250dec6c20a3f96f42c0e09&amp;ascene=0&amp;uin=MzM4Njg2NDU1&amp;devicetype=iMac+MacBookPro12%2C1+OSX+OSX+10.10.3+build(14D136)&amp;version=11020201&amp;pass_ticket=MGWnMZAOg9KlbJTWgO9ARaZA3po2c%2BLDVDHD6Xtt9cZYpjpc9ygP%2BpjWQz3D6NBE" target="_blank" rel="noopener">redis-migration：独创的 redis 在线数据迁移工具</a></li>
</ol>
<h3 id="twemproxy"><a class="header-anchor" href="#twemproxy">¶</a>Twemproxy</h3>
<ol>
<li><a href="https://github.com/twitter/twemproxy" target="_blank" rel="noopener">Twemproxy</a></li>
</ol>
<h3 id="codis"><a class="header-anchor" href="#codis">¶</a>Codis</h3>
<ol>
<li><a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener">Codis</a></li>
</ol>
<h3 id="redisson"><a class="header-anchor" href="#redisson">¶</a>Redisson</h3>
<ol>
<li><a href="https://github.com/redisson/redisson" target="_blank" rel="noopener">Redisson</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/358700b7.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/358700b7.html" itemprop="url">Redis 中的 LRU 淘汰策略</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">
                2019-09-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  263 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>Redis 中的数据淘汰机制</h1>
<ol>
<li>设置过期时间<br>
过期时间到了后，Redis 会在读的时候判断是否过期并清除，或者由一个定时任务执行清除操作。</li>
<li>超过 maxmemory 回收<br>
可以设置淘汰机制，比如 LRU、LFU。</li>
</ol>
<h1>LRU 算法的一种简单实现</h1>
<p>简单版本的 LRU 算法分两个部分：</p>
<ol>
<li>一个链表记录 key 的最终访问次序，比如最新访问的在链表头部，最久没访问的在链表末尾，LRU 淘汰机制就是删除链表末尾的节点；</li>
<li>一个散列表记录某个 key 是否存在，并可以找到其在链表中的位置；</li>
</ol>
<h1>Redis 中的 LRU</h1>
<p>代码位置：evict.c/freeMemoryIfNeeded<br>
Redis 中并没有直接使用上述的 LRU 算法，主要是因为维护 LRU 链表开销较大，而是退一步使用了抽样淘汰的机制：</p>
<ol>
<li>每次从缓存对象集合中随机取出一部分样本；</li>
<li>按 LRU 算法排序；</li>
<li>取 idle 值（评分）最小的淘汰。</li>
</ol>
<p><img src="http://47.88.24.11/imgs/Redis/Redis-LRU%E7%AE%97%E6%B3%95.png" alt="Redis-LRU算法" title="Redis-LRU算法"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/bcd62ed6.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/bcd62ed6.html" itemprop="url">并发和常见并发问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T21:07:49+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="并发问题解题模型"><a class="header-anchor" href="#并发问题解题模型">¶</a>并发问题解题模型</h2>
<ol>
<li>寻找角色，每个角色对应一个独立线程；</li>
<li>寻找共享资源，每个共享资源对应一个信号量（或其他并发控制类）；</li>
<li>按场景描述进行模拟；</li>
</ol>
<h2 id="卖票问题"><a class="header-anchor" href="#卖票问题">¶</a>卖票问题</h2>
<p>一个火车站有多个窗口，它们同时卖票，而票数使用一个 ticket 变量进行计算，对票数有查询和修改两个操作，这两个操作不能同时进行，并且写操作可能不是原子的，两个写操作也不能同时进行</p>
<ul>
<li>使用 Atom 类型来保存票数，这样写之间就不需要进行同步了</li>
</ul>
<h2 id="producer-consumer"><a class="header-anchor" href="#producer-consumer">¶</a>Producer-Consumer</h2>
<p>解决生产者/消费者问题需要维护一个队列，生产者向队列添加，消费者从队列获取，同步问题出现在队列为空或满的情况，因此我们需要对队列进行同步化。<br>
为了简化问题，可以使用 juc 引入的 BlockingQueue（阻塞队列），这种数据结构能在下面两种情况下阻塞当前线程</p>
<ul>
<li>当队列为空时，调用 take 或 poll</li>
<li>当队列满时，调用 put 或 offer</li>
</ul>
<p>下面是使用 BlockingQueue 实现的生产者/消费者代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">public class Producer implements Runnable &#123;</span><br><span class="line">    private final BlockingQueue&lt;String&gt; queue;</span><br><span class="line"></span><br><span class="line">    public Producer(BlockingQueue&lt;String&gt; queue) &#123;</span><br><span class="line">        this.queue = queue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        for(int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                queue.put(&quot;Course&quot; + (i + 1));</span><br><span class="line">                System.out.println(&quot;Complete production:Course&quot; + (i + 1));</span><br><span class="line">                Thread.sleep(100);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class Consumer implements Runnable &#123;</span><br><span class="line">    private final BlockingQueue&lt;String&gt; queue;</span><br><span class="line"></span><br><span class="line">    public Consumer(BlockingQueue&lt;String&gt; queue) &#123;</span><br><span class="line">        this.queue = queue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        for(int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                String course = queue.take();</span><br><span class="line">                System.out.println(&quot;Complete consumption:&quot; + course);</span><br><span class="line">                Thread.sleep(100);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;String&gt;(2);</span><br><span class="line">        Thread t1 = new Thread(new Producer(queue));</span><br><span class="line">        Thread t2 = new Thread(new Consumer(queue));</span><br><span class="line">        t1.start();</span><br><span class="line">        t2.start();</span><br><span class="line">        try &#123;</span><br><span class="line">            t1.join();</span><br><span class="line">            t2.join();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="readers-writers"><a class="header-anchor" href="#readers-writers">¶</a>Readers-writers</h2>
<h2 id="dining-philosophers-哲学家就餐"><a class="header-anchor" href="#dining-philosophers-哲学家就餐">¶</a>Dining philosophers（哲学家就餐）</h2>
<h2 id="cigarette-smokers"><a class="header-anchor" href="#cigarette-smokers">¶</a>Cigarette smokers</h2>
<h2 id="the-dining-savages-野人就餐"><a class="header-anchor" href="#the-dining-savages-野人就餐">¶</a>The dining savages（野人就餐）</h2>
<h2 id="the-barbershop-理发师问题"><a class="header-anchor" href="#the-barbershop-理发师问题">¶</a>The barbershop（理发师问题）</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">#define N 10 //最多10个顾客</span><br><span class="line">typedef struct queue&#123;</span><br><span class="line">    int nums[N];</span><br><span class="line">    int front;</span><br><span class="line">    int rear;</span><br><span class="line">&#125;queue;</span><br><span class="line">int isFull(queue *q)&#123;</span><br><span class="line">    return q-&gt;front + 1 == q-&gt;rear;</span><br><span class="line">&#125;</span><br><span class="line">int isEmpty(queue *q)&#123;</span><br><span class="line">    return q-&gt;front == q-&gt;rear;</span><br><span class="line">&#125;</span><br><span class="line">//返回顾客标志</span><br><span class="line">int dequeue(queue *q)&#123;</span><br><span class="line">    if(isEmpty(q))&#123;</span><br><span class="line">        puts(&quot;error: empty!&quot;);</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">        int num = q-&gt;nums[q-&gt;rear];</span><br><span class="line">        q-&gt;rear = (q-&gt;rear + 1) % N;</span><br><span class="line"></span><br><span class="line">        return num;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">void enqueue(queue *q, int num)&#123;</span><br><span class="line">    if(isFull(q))&#123;</span><br><span class="line">        puts(&quot;error: full queue!&quot;);</span><br><span class="line">        return ;</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">        q-&gt;nums[q-&gt;front] = num;</span><br><span class="line">        q-&gt;front = (q-&gt;front + 1) % N;</span><br><span class="line">        q-&gt;front++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//顾客每次等待，若队列已满将会被忽略</span><br><span class="line">void customerWait(semaphore *barber, int num)&#123;</span><br><span class="line">    if(barber-&gt;busy == no)&#123;</span><br><span class="line">        barber-&gt;busy = yes;</span><br><span class="line">        enqueue(&amp;barber-&gt;customers, num);</span><br><span class="line">        printf(&quot;这个顾客开始接受服务&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">        //将当前顾客加入等待队列，似乎不是原子操作？</span><br><span class="line">        enqueue(&amp;barber-&gt;customers, num);</span><br><span class="line">        printf(&quot;加入顾客%d&quot;, num);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">//理发师每次等待新用户，</span><br><span class="line">void barberSignal(semaphore *barber)&#123;</span><br><span class="line">    if(isEmpty(&amp;barber-&gt;customers))&#123;</span><br><span class="line">        barber-&gt;busy = no;</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">        int num = dequeue(&amp;barber-&gt;customers);</span><br><span class="line">        printf(&quot;顾客%d开始交易&quot;, num);</span><br><span class="line">        sleep(3000);//每个顾客睡三秒</span><br><span class="line">        printf(&quot;结束交易&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">    用一个主函数开启一个理发师进程，理发师进程等待新顾客，对每一个顾客sleep(3000)作为服务时间，然后signal，</span><br><span class="line">    主函数等待用户输入用户id，对每一个用户id开启一个进程，</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">semaphore barber;</span><br><span class="line">void simulate()&#123;</span><br><span class="line">    barber.busy = no;</span><br><span class="line">    barber.customers.front = barber.customers.rear = 0;</span><br><span class="line">    </span><br><span class="line">    int pid = fork();</span><br><span class="line">    if(pid == 0)&#123;</span><br><span class="line">        //说明是理发师</span><br><span class="line">        while(1)&#123;</span><br><span class="line">            barberSignal(&amp;barber);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">        int num;</span><br><span class="line">        while(1)&#123;</span><br><span class="line">            scanf(&quot;%d&quot;, &amp;num);</span><br><span class="line">            printf(&quot;%d&quot;, num);</span><br><span class="line">            //int pid1 = fork();</span><br><span class="line">            //if(pid1 != 0)&#123;</span><br><span class="line">                //顾客进程</span><br><span class="line">                customerWait(&amp;barber, num);</span><br><span class="line">            //  printf(&quot;哈哈哈&quot;);</span><br><span class="line">            //  return ;</span><br><span class="line">            //&#125;</span><br><span class="line">            //父进程继续运行</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;pthread.h&gt;</span><br><span class="line">#include &lt;semaphore.h&gt;</span><br><span class="line"></span><br><span class="line">#define N 10 //最多10个顾客</span><br><span class="line">/***********************信号量**************************/</span><br><span class="line">sem_t barbers;</span><br><span class="line">sem_t customers;</span><br><span class="line">sem_t mutex;</span><br><span class="line">int customerCount = 0;</span><br><span class="line"></span><br><span class="line">void haircut()&#123;</span><br><span class="line">	printf(&quot;理发师剪头中\n&quot;);</span><br><span class="line">	sleep(3);//服务时间</span><br><span class="line">&#125;</span><br><span class="line">void get_haircut()&#123;</span><br><span class="line">	sleep(3);</span><br><span class="line">&#125;</span><br><span class="line">void *barber(void *arg)&#123;</span><br><span class="line">	while(1)&#123;</span><br><span class="line">		if(customerCount == 0)&#123;</span><br><span class="line">			printf(&quot;理发师打瞌睡\n&quot;);</span><br><span class="line">			sem_wait(&amp;customers);//等顾客</span><br><span class="line">			printf(&quot;理发师被叫醒了\n&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">		else&#123;</span><br><span class="line">			sem_wait(&amp;customers);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		sem_post(&amp;barbers);//唤醒理发师</span><br><span class="line">		haircut();//开始服务</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">void *customer(void *arg)&#123;</span><br><span class="line">	while(1)&#123;</span><br><span class="line">		if(customerCount &gt; 0)&#123;</span><br><span class="line">			printf(&quot;顾客等理发师\n&quot;);</span><br><span class="line">			sem_wait(&amp;barbers);//等理发师	</span><br><span class="line">			</span><br><span class="line">			sem_wait(&amp;mutex);</span><br><span class="line">			customerCount--;	</span><br><span class="line">			sem_post(&amp;mutex);</span><br><span class="line">			</span><br><span class="line">			get_haircut();//接受服务			</span><br><span class="line">			printf(&quot;理完头这个顾客离开了\n&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">void *customer_arrive(void *arg)&#123;</span><br><span class="line">	int num;</span><br><span class="line">	while(1)&#123;</span><br><span class="line">		scanf(&quot;%d&quot;, &amp;num);</span><br><span class="line">		printf(&quot;来了一个顾客\n&quot;);</span><br><span class="line">		sem_wait(&amp;mutex);</span><br><span class="line">		if(customerCount &lt; N)&#123;//如果还有空位</span><br><span class="line">		sem_post(&amp;mutex);</span><br><span class="line">			sem_post(&amp;customers);//添加一个顾客资源</span><br><span class="line">			customerCount++;//顾客增加</span><br><span class="line">		&#125;</span><br><span class="line">		else&#123;</span><br><span class="line">		sem_post(&amp;mutex);</span><br><span class="line">			printf(&quot;没椅子了，顾客离开了\n&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void simulate()&#123;</span><br><span class="line">	pthread_t barber_t, customer_t, customer_arrive_t;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	if(sem_init(&amp;barbers, 0, 1) != 0)&#123;</span><br><span class="line">		printf(&quot;sem init failed&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	if(sem_init(&amp;customers, 0, 0) != 0)&#123;</span><br><span class="line">		printf(&quot;sem init failed&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	if(sem_init(&amp;mutex, 0, 1) != 0)&#123;</span><br><span class="line">		printf(&quot;sem init failed&quot;);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	printf(&quot;begin barber_t\n&quot;);</span><br><span class="line">	pthread_create(&amp;barber_t, NULL, barber, NULL);</span><br><span class="line">	printf(&quot;begin customer_t\n&quot;);</span><br><span class="line">	pthread_create(&amp;customer_t, NULL, customer, NULL);</span><br><span class="line">	printf(&quot;begin customer_arrive_t\n&quot;);</span><br><span class="line">	pthread_create(&amp;customer_arrive_t, NULL, customer_arrive, NULL);</span><br><span class="line">	</span><br><span class="line">	while(1)&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main(void )&#123;</span><br><span class="line">	simulate();</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2>
<ol>
<li><a href="https://greenteapress.com/wp/semaphores/" target="_blank" rel="noopener">The Little Book of Semaphores</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e913f4bd.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/e913f4bd.html" itemprop="url">JVM 与动态内存管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T15:26:49+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  19.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  71 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>在 Java 体系中，提到并发就不得不提到 JMM，因为所有并发安全都是围绕内存来展开的，可以说不懂内存结构就不懂并发。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/e913f4bd.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b27f4a82.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b27f4a82.html" itemprop="url">JVM与垃圾收集器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T15:26:49+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  15.6k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  59 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="垃圾收集-gc"><a class="header-anchor" href="#垃圾收集-gc">¶</a>垃圾收集（GC）</h2>
<h3 id="垃圾检测"><a class="header-anchor" href="#垃圾检测">¶</a>垃圾检测</h3>
<p>在实际回收垃圾对象前，我们必须标识出哪些对象该被回收，即垃圾检测。</p>
<h4 id="对象引用类型"><a class="header-anchor" href="#对象引用类型">¶</a>对象引用类型</h4>
<ol>
<li>强引用(StrongReference)<br>
<code>Object obj = new Object()</code>的 obj 就是一个强引用。<br>
当内存不足，JVM 宁愿抛出 <code>OutOfMemoryError</code> 错误，使程序异常终止，也不会回收强引用对象来释放内存，除非已经没有引用关联这些对象了。<br>
除了强引用之外，其他三种引用都在<code>java.lang.ref</code>包中。</li>
<li>软引用(SoftReference)<br>
GC 发现了只具有软引用的对象并不会立即进行回收，而是让它活的尽可能久一些，在内存不足前再进行回收。<br>
在使用<strong>缓存的场景</strong>的时候会经常采用此种引用方式，来增加系统可用性的弹性空间。Spring 和 cache 里面大量采用了此种引用方式。</li>
<li>弱引用(WeakReference)<br>
GC 一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。如果有场景，发现创建完对象很少可能会用到，就采用这种方式，不过实际工作确实很少见到有人用到3，4两个引用。</li>
<li>虚引用(PhantomReference)<br>
“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期；如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。<br>
虚引用主要用来跟踪对象被 GC 回收的活动，虚引用必须和引用队列（ReferenceQueue）配合使用。</li>
</ol>
<h4 id="reference"><a class="header-anchor" href="#reference">¶</a>Reference</h4>
<p>Reference 抽象类是除强引用外的所有引用类型的父类，有以下几种子类</p>
<ol>
<li>SoftReference 类：软引用</li>
</ol>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MyObject obj = new MyObject();  </span><br><span class="line">SoftReference&lt;MyObject&gt; ref = new SoftReference&lt;MyObject&gt;(obj);</span><br></pre></td></tr></table></figure>
<ol>
<li>WeakReference 类：弱引用</li>
<li>PhantomReference 类：虚引用</li>
<li>ReferenceQueue 类：引用队列</li>
</ol>
<h4 id="垃圾检测算法-引用计数"><a class="header-anchor" href="#垃圾检测算法-引用计数">¶</a>垃圾检测算法 - 引用计数</h4>
<p>堆中的每一个对象的对象域包含一个引用计数器。该计数器的维护规则如下：</p>
<ul>
<li>当一个对象被创建，并把指向该对象的引用赋值给一个变量时，引用计数置为1</li>
<li>当再把这个引用赋值给其他变量时，引用计数加1</li>
<li>当一个对象的引用超过了生命周期或者被设置为新值时，对象的引用计数减 1，任何引用计数为 0 的对象都可以被当成垃圾回收。</li>
<li>当一个对象被回收时，它所引用的任何对象计数减1，这样，可能会导致其他对象也被当垃圾回收。</li>
</ul>
<p>但是一般垃圾回收器并不会采用这种算法，主要是因为引用计数算法存在循环引用的问题（注意不是栈帧里的引用，而是堆中实例的互相引用）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public class ReferenceCountingGC &#123;</span><br><span class="line">    public Object instance = null;</span><br><span class="line">    private static final int _1MB = 1024 * 1024;</span><br><span class="line">    /**</span><br><span class="line">     * 这个成员属性的唯一意义就是占点内存,以便能在GC日志中看清楚是否被回收过</span><br><span class="line">     */</span><br><span class="line">    private byte[] bigSize = new byte[2 * _1MB];</span><br><span class="line"></span><br><span class="line">    public static void testGC() &#123;</span><br><span class="line">        // 定义两个对象</span><br><span class="line">        ReferenceCountingGC objA = new ReferenceCountingGC();</span><br><span class="line">        ReferenceCountingGC objB = new ReferenceCountingGC();</span><br><span class="line"></span><br><span class="line">        // 给对象的成员赋值，即存在相互引用情况</span><br><span class="line">        objA.instance = objB;</span><br><span class="line">        objB.instance = objA;</span><br><span class="line"></span><br><span class="line">        // 将引用设为空，即没有到堆对象的引用了</span><br><span class="line">        objA = null;</span><br><span class="line">        objB = null;</span><br><span class="line"></span><br><span class="line">        // 进行垃圾回收</span><br><span class="line">        System.gc();    </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testGC();    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如上边代码所示，执行<code>objA = null</code>和<code>objB = null</code>后，它们二者的 instance 域仍然互相是对方的引用。</p>
<h4 id="垃圾检测算法-可达性分析"><a class="header-anchor" href="#垃圾检测算法-可达性分析">¶</a>垃圾检测算法 - 可达性分析</h4>
<p>若一个对象没有引用链与任一个 GC Roots 相连时，此对象可回收<br>
包括虚拟机栈中引用的对象、方法区中类的静态成员变量引用的对象、方法区中的常量引用的对象、本地方法栈中 Native 方法引用的对象<br>
<strong>根部（Roots）</strong>：表示引用链的头部<br>
<strong>引用链（Reference Chain）</strong>：多个引用形成的一条链<br>
<strong>引用</strong>：是 reference 类型的对象，其中存储的数据代表的是另外一块内存的起始位置，有强引用（Strong）、软引用（Soft）、弱引用（Weak）、虚引用（Phantom）四种。</p>
<p>此算法的基本思想就是选取一系列 GC Roots 对象作为起点，开始向下遍历搜索其他相关的对象，搜索所走过的路径成为引用链，遍历完成后，如果一个对象到 GCRoots 对象没有任何引用链，则证明此对象是不可用的，可以被当做垃圾进行回收。<br>
那么问题又来了，如何选取 GCRoots 对象呢？在 Java 语言中，可以作为 GCRoots 的对象包括下面几种：</p>
<ol>
<li>虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象。</li>
<li>方法区中的类静态属性引用的对象。</li>
<li>方法区中常量引用的对象。</li>
<li>本地方法栈中 JNI(Native 方法)引用的对象。</li>
</ol>
<p><img src="http://47.88.24.11/imgs/JVM/%E5%8F%AF%E8%BE%BE%E6%80%A7%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95.png" alt="可达性分析算法" title="可达性分析算法"><br>
如上图所示，Obj8、Obj9、Obj10 都没有到 GC Root 的引用链，因此它们会被标记为垃圾，即便 Obj9 和 Obj10 之间有引用关系。</p>
<h4 id="引用与垃圾检测算法"><a class="header-anchor" href="#引用与垃圾检测算法">¶</a>引用与垃圾检测算法</h4>
<p>对于可达性分析算法而言，未到达的对象并非是“非死不可”的，若要宣判一个对象死亡，至少需要经历两次标记阶段。</p>
<ol>
<li>如果对象在进行可达性分析后发现没有与 GCRoots 相连的引用链，则该对象被第一次标记并进行一次筛选，筛选条件为是否有必要执行该对象的<strong>finalize</strong>方法，若对象没有覆盖 finalize 方法或者该 finalize 方法是否已经被虚拟机执行过了，则均视作不必要执行该对象的 finalize 方法，即该对象将会被回收。反之，若对象覆盖了 finalize 方法并且该 finalize 方法并没有被执行过，那么，这个对象会被放置在一个叫<strong>F-Queue</strong>的队列中，之后会由虚拟机自动建立的、优先级低的<strong>Finalizer线程</strong>去执行，而虚拟机不必要等待该线程执行结束，即虚拟机只负责建立线程，其他的事情交给此线程去处理。</li>
<li>对 F-Queue 中对象进行第二次标记，<strong>如果对象在 finalize 方法中拯救了自己，即关联上了 GCRoot 引用链，如把 this 关键字赋值给其他变量，那么在第二次标记的时候该对象将从“即将回收”的集合中移除</strong>，如果对象还是没有拯救自己，那就会被回收。如下代码演示了一个对象如何在 finalize 方法中拯救了自己，然而，它只能拯救自己一次，第二次就被回收了。具体代码如下</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * 此代码演示了两点：</span><br><span class="line"> * 1.对象可以再被GC时自我拯救</span><br><span class="line"> * 2.这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次</span><br><span class="line"> * */</span><br><span class="line">public class FinalizeEscapeGC &#123;</span><br><span class="line">    public static FinalizeEscapeGC SAVE_HOOK = null;</span><br><span class="line">    @Override</span><br><span class="line">    protected void finalize() throws Throwable &#123;</span><br><span class="line">        super.finalize();</span><br><span class="line">        System.out.println(this + &quot;: finalize method executed!&quot;);</span><br><span class="line">        FinalizeEscapeGC.SAVE_HOOK = this;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        SAVE_HOOK = new FinalizeEscapeGC();</span><br><span class="line">        System.out.println(SAVE_HOOK);</span><br><span class="line">        // 对象第一次拯救自己</span><br><span class="line">        SAVE_HOOK = null;</span><br><span class="line">        System.out.println(SAVE_HOOK);</span><br><span class="line">        System.gc();</span><br><span class="line">        // 因为finalize方法优先级很低，所以暂停0.5秒以等待它</span><br><span class="line">        Thread.sleep(500);</span><br><span class="line">        System.out.println(SAVE_HOOK);</span><br><span class="line">        // 下面这段代码与上面的完全相同,但是这一次自救却失败了</span><br><span class="line">        // 一个对象的finalize方法只会被调用一次</span><br><span class="line">        SAVE_HOOK = null;</span><br><span class="line">        System.gc();</span><br><span class="line">        // 因为finalize方法优先级很低，所以暂停0.5秒以等待它</span><br><span class="line">        Thread.sleep(500);</span><br><span class="line">        System.out.println(SAVE_HOOK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="垃圾收集算法"><a class="header-anchor" href="#垃圾收集算法">¶</a>垃圾收集算法</h3>
<h4 id="标记清除-mark-sweep"><a class="header-anchor" href="#标记清除-mark-sweep">¶</a>标记清除（Mark-Sweep）</h4>
<p>先标记所有需要清除的对象，再统一回收。是最基础的垃圾回收算法，后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。<br>
<strong>问题</strong></p>
<ul>
<li>效率低，标记和清除都需要一次线性扫描；</li>
<li>产生大量内存碎片，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</li>
</ul>
<p>首先标记出所有需要回收的对象，使用可达性分析算法判断一个对象是否为可回收，在标记完成后统一回收所有被标记的对象。下图是算法具体的一次执行过程后的结果对比。<br>
<img src="http://47.88.24.11/imgs/JVM/%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95.png" alt="标记清除算法" title="标记清除算法"></p>
<h4 id="复制算法-copying"><a class="header-anchor" href="#复制算法-copying">¶</a>复制算法（Copying）</h4>
<p>将可用内存划分为大小相等的两半，对每一块使用<strong>指针碰撞</strong>（从已分配内存向空闲内存空间移动对象大小的空间）的方法为对象分配空间，如果这一块内存用完，就将还存活的对象复制到另一半块上，将原来的这一半一次清理掉。<br>
HotSpot 中使用的是 Eden-Survivor 方法，大体上每次使用一个 Eden 和一个 Survivor 来分配对象空间，当回收时，将这两块中还存活的对象一次性复制到另一块 Survivor 中，Eden 和 Survivor 的比例为<code>8:1</code>。如果 Survivor 的空间不够了，就会使用老年代进行<strong>分配担保（Handle Promotion）</strong>。</p>
<ul>
<li>将现有的内存空间分为两快，每次只使用其中一块；</li>
<li>当其中一块时候完的时候，就将还存活的对象复制到另外一块上去；</li>
<li>再把已使用过的内存空间一次清理掉。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>由于是每次都对整个半区进行内存回收，内存分配时不必考虑内存碎片问题；</li>
<li>只要移动堆顶指针，按顺序分配内存即可，可以利用**Bump-the-pointer（指针碰撞）**实现，实现简单，运行高效；</li>
</ul>
<blockquote>
<p>像标记-清除算法清理后的内存空间并不规整，可能会有很多碎片，因此只能使用**空闲列表（Free List）**的方式分配内存。</p>
</blockquote>
<p><strong>缺点</strong>：</p>
<ul>
<li>内存减少为原来的一半，太浪费了（用空间换时间）；</li>
<li>对象存活率较高的时候就要执行较多的复制操作，效率变低；</li>
<li>如果不使用50%的对分策略，老年代需要考虑空间担保策略，复杂度变高。</li>
</ul>
<p><img src="http://47.88.24.11/imgs/JVM/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95.png" alt="复制算法" title="复制算法"><br>
将内存分为两等块，每次使用其中一块。当这一块内存用完后，就将还存活的对象复制到另外一个块上面，然后再把已经使用过的内存空间一次清理掉。图是算法具体的一次执行过程后的结果对比。</p>
<h4 id="标记-整理算法-mark-compact"><a class="header-anchor" href="#标记-整理算法-mark-compact">¶</a>标记-整理算法（Mark-Compact）</h4>
<p>标记过程和Mark-Sweep一样，但是不直接清除，而是让存活的对象向前移，再清理端边界外的内存。<br>
标记过程还是和标记-清除算法一样，之后让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存，标记 - 整理算法示意图如下<br>
<img src="http://47.88.24.11/imgs/JVM/%E6%A0%87%E8%AE%B0%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95.png" alt="标记整理算法" title="标记整理算法"></p>
<p>标记-整理算法往往与标记-清除同时使用，优先执行标记-清除，当内存空间碎片过多时，才运行标记-整理压缩内存空间。</p>
<h4 id="分代收集算法-generational-collection"><a class="header-anchor" href="#分代收集算法-generational-collection">¶</a>分代收集算法（Generational Collection）</h4>
<p>将 Java 堆分为新生代和老生代，根据各个年代的特点采取最适当的收集算法。在新生代中死得快，就选用复制算法（要复制的少），老生代中对象存活率高，就使用标记整理或标记清除算法。</p>
<h2 id="hotspot-gc-触发时机及实现"><a class="header-anchor" href="#hotspot-gc-触发时机及实现">¶</a>HotSpot GC 触发时机及实现</h2>
<h3 id="gc-目标内存区域"><a class="header-anchor" href="#gc-目标内存区域">¶</a>GC 目标内存区域</h3>
<p>对于虚拟机中<strong>线程私有的区域</strong>，如<strong>程序计数器</strong>、<strong>虚拟机栈</strong>、<strong>本地方法栈</strong>都不需要进行垃圾回收，因为它们是自动进行的，随着线程的消亡而消亡，不需要我们去回收，比如栈的栈帧结构，当进入一个方法时，就会产生一个栈帧，栈帧大小也可以借助类信息确定，然后栈帧入栈，执行方法体，退出方法时，栈帧出栈，于是其所占据的内存空间也就被自动回收了。<br>
而对于虚拟机中<strong>线程共享的区域</strong>，则需要进行垃圾回收，如<strong>堆</strong>和<strong>方法区</strong>，线程都会在这两个区域产生自身的数据，占据一定的内存大小，并且这些数据又可能会存在相互关联的关系，所以，这部分的区域不像线程私有的区域那样可以简单自动的进行垃圾回收，此部分区域的垃圾回收非常复杂，而垃圾回收也主要是针对这部分区域。</p>
<h3 id="可达性分析"><a class="header-anchor" href="#可达性分析">¶</a>可达性分析</h3>
<p>对于<strong>可达性分析</strong>而言，我们知道，首先需要选取 GCRoots 结点，而 GCRoots 结点主要在全局性的引用（如常量或类静态属性）与执行上下文（如栈帧中的局部变量表）中。方法区可以很大，这对于寻找 GCRoots 结点来说会非常耗时。当选取了 GCRoots 结点之后，<strong>进行可达性分析时必须要保证一致性</strong>，即在进行分析的过程中整个执行系统看起来就好像被冻结在某个时间点上，不可以在分析的时候，对象的关系还在动态变化，这样的话分析的准确性就得不到保证，所以可达性分析是时间非常敏感的。<br>
为了保证分析结果的准确性，就会导致<strong>GC 进行时必须停顿所有 Java 执行线程（Stop the world）</strong>，为了尽可能的减少 Stop the world 的时间，Java 虚拟机使用了一组称为<strong>OopMap</strong>的数据结构，该数据结构用于存放对象引用的地址，这样，<strong>进行可达性分析的时候就可以直接访问 OopMap 就可以获得对象的引用，从而加快分析过程，减少 Stop the world 时间</strong>。<br>
OopMap 数据结构有利于进行 GC，是不是虚拟机无论何时想要进行 GC 都可以进行 GC，即无论虚拟机在执行什么指令都可以进行 GC？答案是否定的，因为要想让虚拟机无论在执行什么指令的时候都可以进行 GC 的话，需要为每条指令都生成 OopMap，显然，这样太浪费空间了。为了节约宝贵的空间，虚拟机只在”特定的位置“存放了 OopMap 数据结构，这个特定的位置我们称之为<strong>安全点</strong>。<strong>程序执行时并非在所有地方都能够停顿下来开始 GC（可达性分析），只有到达安全点的时候才能暂停</strong>。<strong>安全点可以由方法调用、循环跳转、异常跳转等指令产生，因为这些指令会让程序长时间执行</strong>。<br>
现在我们已经知道了安全点的概念，即进行 GC 必须要到达安全点，那么在发生 GC 时如何让所有线程到达安全点再暂停呢？有两种方法：</p>
<ol>
<li><strong>抢先式中断</strong>，在发生 GC 时，首先把所有线程全部中断，如果发现线程中断的地方不在安全点上，就恢复线程，让它跑到安全点上。</li>
<li><strong>主动式中断</strong>，在发生 GC 时，不中断线程，而是设置一个标志，所有线程执行时主动轮询这个标志，发生标志位真就自己中断挂起，轮询标志的地方和安全点是重合的，也有可能是创建对象需要分配内存的地方。</li>
</ol>
<p>现在问题又来了，当程序不执行的时候，如何让所有线程达到安全点呢？典型的就是线程处于 Sleep 状态或者 Blocked 状态，这时候线程是无法跑到安全点再中断自己的，虚拟机也肯定不可能等待该线程被唤醒并重新分配 CPU 时间后，跑到安全点再暂停。为了解决这个问题，引入<strong>安全区域</strong>的概念。<strong>安全区域是对安全点的扩展，可以看成由很多安全点组成，安全区域是指一段代码片段之中，引用关系不会发生变化</strong>。在这个区域的任何地方开始 GC 都是安全的。当线程执行到安全区域的代码时，首先标示自己已经进入了安全区域，那么，在这段时间里 JVM 发起 GC 时，就不用管标示自己为安全区域状态的线程了。在线程要离开安全区域时，它要检查系统是否已经完成了根节点枚举（或者整个 GC 过程），若完成，线程继续执行；否则，它必须等待直到收到可以安全离开安全区域的信号。</p>
<h3 id="分代回收-gc-类型及对象晋升-新生代-老年代"><a class="header-anchor" href="#分代回收-gc-类型及对象晋升-新生代-老年代">¶</a>分代回收 GC 类型及对象晋升（新生代 -&gt; 老年代）</h3>
<p>根据作用区域的不同，GC 主要分为 3 种：</p>
<ul>
<li>Minor GC：对象通常在新生代的 Eden 区进行分配，当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC，非常频繁，速度较快；</li>
<li>Major GC：指发生在老年代的 GC，出现 Major GC，经常会伴随一次 Minor GC，同时 Minor GC 也会引起 Major GC，一般在 GC 日志中统称为 GC，不频繁。</li>
<li>Full GC：指发生在老年代和新生代的GC，速度很慢，需要Stop The World。可以用System.gc() 强制执行 Full GC，但这在生产环境中是需要被禁止的。</li>
</ul>
<p>对象的晋升机制：</p>
<ol>
<li>对象优先在新生代区中分配，若没有足够空间，则触发 Minor GC，经过 Minor GC 仍存活的对象年龄 +1，若年龄超过一定限制（默认为 15），则被晋升到老年态；</li>
<li>大对象（需要大量连续内存空间）直接进入老年态；</li>
<li>长期存活的对象进入老年态。</li>
</ol>
<h3 id="不同算法触发的时机"><a class="header-anchor" href="#不同算法触发的时机">¶</a>不同算法触发的时机</h3>
<ol>
<li>Minor GC（年轻代 GC）<br>
触发时机：在 Enden 满了之后将被触发<br>
GC 在优先级最低的线程中运行，一般在应用程序空闲即没有应用线程在运行时被调用。<br>
当发生 Minor GC 后空间仍不够，触发 Major GC</li>
<li>Full GC / Major GC（老年代GC）<br>
触发时机：
<ol>
<li>调用 System.gc 时，系统建议执行 Full GC，但是不必然执行。（可通过通过<code>-XX:+ DisableExplicitGC</code>来禁止 RMI 调用 System.gc。）</li>
<li>方法区空间不足，如果没有动态加载，一般是发生在启动的时候的，但是JDK1.8之后元空间替换了方法区，因此不会有这种情况了。</li>
<li>老年代空间不足，引起FullGC，这种情况比较复杂，有以下几种情况：<br>
3.1、通过对象的正常晋升机制触发对象向老年代移动时，老年代空间不足，由<code>-XX:MaxTenureThreshold</code>参数定义；<br>
3.2、大对象直接进入老年代，此时老年代空间不足，由<code>-XX:PretenureSizeThreshold</code>参数定义；<br>
3.3、动态年龄判定机制会将对象提前转移至老年代。年龄从小到大累加，当加入某个年龄段后，这个年龄对象占用空间大小总和超过survivor区域 * <code>-XX:TargetSurvivorRatio</code>的时候，<strong>从这个年龄段往上年龄的对象进入老年代</strong>；<br>
3.4、由 Eden 区、From Space 区向 To Space 区复制时，对象大小大于 To Space 可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。</li>
</ol>
</li>
</ol>
<p>在进行MinorGC之前，JVM的空间分配担保机制可能会触发3.2、3.3、3.4的发生，也就是触发一次FullGC。<br>
所谓的<strong>空间分配担保机制</strong>，就是在MinorGC之前，虚拟机会检查老年代<strong>最大可用连续内存空间</strong>是否大于新生代所有对象的总空间。</p>
<ul>
<li>如果大于，则此次Minor是安全的；</li>
<li>如果小于，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次MinorGC，但这次MinorGC依然是有风险的，失败后会重新发起一次FullGC，如果小于或者HandlePromotionFailure=false，则改为直接进行一次FullGC。</li>
</ul>
<p>最后，当发生 FullGC 之后空间还是不够，将抛出 OutOfMemoryError。</p>
<h3 id="对象分配和回收策略"><a class="header-anchor" href="#对象分配和回收策略">¶</a>对象分配和回收策略</h3>
<p>对象的内存分配，绝大部分都是在堆上分配，少数经过<strong>JIT</strong>编译后被拆散为标量类型并间接在栈上分配。<br>
在堆上的分配又可以有如下分配，主要在新生代的 Eden 区分配，如果启动了本地线程分配缓冲，将按照线程优先在<strong>TLAB</strong>上分配，少数直接在 Tenured 区分配，虚拟机也提供了一些参数供我们来控制对象内存空间的分配。<br>
总而言之，对象分配具有以下几种策略：</p>
<h4 id="对象优先在-eden-区分配"><a class="header-anchor" href="#对象优先在-eden-区分配">¶</a>对象优先在 Eden 区分配</h4>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-Xms20M -Xmx20M -Xmn10M</span><br><span class="line">-XX:SurvivorRatio=8</span><br><span class="line">-XX:+PrintGCDetails</span><br><span class="line">-XX:+UseSerialGC</span><br><span class="line">public class AllocEdenTest &#123;</span><br><span class="line">    private static final int _1MB = 1024 * 1024;</span><br><span class="line"></span><br><span class="line">    public static void testAllocation() &#123;</span><br><span class="line">        byte[] alloc1, alloc2, alloc3, alloc4;</span><br><span class="line">        alloc1 = new byte[2 * _1MB];</span><br><span class="line">        alloc2 = new byte[2 * _1MB];</span><br><span class="line">        alloc3 = new byte[2 * _1MB];</span><br><span class="line">        alloc4 = new byte[4 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        testAllocation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">GC日志：</span><br><span class="line">[GC (Allocation Failure) [DefNew: 7223K-&gt;685K(9216K), 0.0125141 secs] 7223K-&gt;4781K(19456K), 0.0125503 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] </span><br><span class="line">Heap</span><br><span class="line"> def new generation   total 9216K, used 7071K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)</span><br><span class="line">  eden space 8192K,  77% used [0x00000007bec00000, 0x00000007bf23c948, 0x00000007bf400000)</span><br><span class="line">  from space 1024K,  66% used [0x00000007bf500000, 0x00000007bf5ab658, 0x00000007bf600000)</span><br><span class="line">Disconnected from the target VM, address: &apos;127.0.0.1:58261&apos;, transport: &apos;socket&apos;</span><br><span class="line">  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)</span><br><span class="line"> tenured generation   total 10240K, used 4096K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">   the space 10240K,  40% used [0x00000007bf600000, 0x00000007bfa00020, 0x00000007bfa00200, 0x00000007c0000000)</span><br><span class="line"> Metaspace       used 2989K, capacity 4568K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 318K, capacity 392K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure>
<p>新生代可用的空间：9M = 8M(Eden 空间容量) + 1M(一个 Survivor 空间的容量)<br>
老年代可用的空间：10M<br>
分配完 alloc1、alloc2、alloc3 之后，无法再分配 alloc4，会发生分配失败，则需要进行一次 Minor GC，survivor to 区域的容量为 1M，无法容纳总量为 6M 的三个对象，则会通过担保机制将 alloc1、allo2 转移到老年代，然后再将 alloc4 分配在 Eden 区。</p>
<h4 id="大对象直接进入-tenured-区"><a class="header-anchor" href="#大对象直接进入-tenured-区">¶</a>大对象直接进入 Tenured 区</h4>
<p>大对象需要大块连续内存空间，大对象的出现容易提前触发 GC 以获取更大的连续空间来供分配大对象，可以设置<code>-XX:PretenureSizeThreshold</code>的值来控制多大的对象直接分配到 Tenured 区，默认是 0，即所有对象不管多大都先在 Eden 区中分配空间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * -Xms20M -Xmx20M -Xmn10M</span><br><span class="line"> * -XX:SurvivorRatio=8</span><br><span class="line"> * -XX:+PrintGCDetails</span><br><span class="line"> * -XX:+UseSerialGC</span><br><span class="line"> * -XX:PretenureSizeThreshold=3145728</span><br><span class="line"> */</span><br><span class="line">public class AllocBigObjectTest &#123;</span><br><span class="line">    private static final int _1MB = 1024 * 1024;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        byte[] alloc = new byte[5 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Heap</span><br><span class="line"> def new generation   total 9216K, used 1180K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)</span><br><span class="line">  eden space 8192K,  14% used [0x00000007bec00000, 0x00000007bed27010, 0x00000007bf400000)</span><br><span class="line">  from space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)</span><br><span class="line">  to   space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)</span><br><span class="line"> tenured generation   total 10240K, used 5120K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">   the space 10240K,  50% used [0x00000007bf600000, 0x00000007bfb00010, 0x00000007bfb00200, 0x00000007c0000000)</span><br><span class="line"> Metaspace       used 2662K, capacity 4486K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 287K, capacity 386K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure>
<p>因为设置了<code>-XX:PretenureSizeThreshold=3145728</code>控制大小超过 3M 的对象直接进入 Tenured 区，可以看到 5M 的对象直接被分配到了 Tenured 区。</p>
<h4 id="长期存活的对象进入-tenured-区"><a class="header-anchor" href="#长期存活的对象进入-tenured-区">¶</a>长期存活的对象进入 Tenured 区</h4>
<p>每个对象有一个对象年龄计数器，与前面的对象的存储布局中的 GC 分代年龄对应。对象出生在 Eden 区、经过一次 Minor GC 后仍然存活，并能够被 Survivor 容纳，则设置年龄为 1，对象在 Survivor 区每次经过一次 Minor GC，年龄就加 1，当年龄达到阈值（默认 15），就晋升到老年代，虚拟机提供了<code>-XX:MaxTenuringThreshold</code>来进行设置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * -Xms20M -Xmx20M -Xmn10M </span><br><span class="line"> * -XX:SurvivorRatio=8 </span><br><span class="line"> * -XX:+PrintGCDetails</span><br><span class="line"> * -XX:+UseSerialGC</span><br><span class="line"> * -XX:MaxTenuringThreshold=1</span><br><span class="line"> * -XX:+PrintTenuringDistribution</span><br><span class="line"> */</span><br><span class="line">public class AllocLongTimeTest &#123;</span><br><span class="line">    private static final int _1MB = 1024 * 1024;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        byte[] alloc1, alloc2, alloc3;</span><br><span class="line">        alloc1 = new byte[_1MB / 4];</span><br><span class="line">        alloc2 = new byte[4 * _1MB];</span><br><span class="line">        alloc3 = new byte[4 * _1MB];</span><br><span class="line">        alloc3 = null;</span><br><span class="line">        alloc3 = new byte[4 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[GC (Allocation Failure) [DefNew</span><br><span class="line">Desired survivor size 524288 bytes, new threshold 1 (max 1)</span><br><span class="line">- age   1:     964208 bytes,     964208 total</span><br><span class="line">: 7479K-&gt;941K(9216K), 0.0063212 secs] 7479K-&gt;5037K(19456K), 0.0063540 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] </span><br><span class="line">[GC (Allocation Failure) [DefNew</span><br><span class="line">Desired survivor size 524288 bytes, new threshold 1 (max 1)</span><br><span class="line">: 5037K-&gt;0K(9216K), 0.0014434 secs] 9133K-&gt;4814K(19456K), 0.0014629 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] </span><br><span class="line">Heap</span><br><span class="line"> def new generation   total 9216K, used 4178K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)</span><br><span class="line">  eden space 8192K,  51% used [0x00000007bec00000, 0x00000007bf014930, 0x00000007bf400000)</span><br><span class="line">  from space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)</span><br><span class="line">  to   space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)</span><br><span class="line"> tenured generation   total 10240K, used 4814K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">   the space 10240K,  47% used [0x00000007bf600000, 0x00000007bfab3b38, 0x00000007bfab3c00, 0x00000007c0000000)</span><br><span class="line"> Metaspace       used 2988K, capacity 4568K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 318K, capacity 392K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure>
<p>如 GC 日志中所示，总共发生了两次 Minor GC：</p>
<ol>
<li>第一次是在给 alloc3 分配的时候，此时 Survivor 区不能容纳 alloc2，但是可以容纳 alloc1，所以 alloc1 进入了 Survivor 区并且年龄变成 1、达到了阈值，将在下一次 GC 时晋升到老年代，而 alloc2 则通过担保机制进入了老年代；</li>
<li>第二次 GC 是在第二次给 alloc3 分配空间时，这时 alloc1 年龄+1，晋升到老年代，此时 GC 也可以清理出原来 alloc3 占据的 4MB 空间，将 alloc3 分配在 Eden 区。</li>
</ol>
<p>因此，最后的结果是 alloc1、alloc2 在老年代，alloc3 在 Eden 区。</p>
<h4 id="动态对象年龄判断"><a class="header-anchor" href="#动态对象年龄判断">¶</a>动态对象年龄判断</h4>
<p>除了对象年龄自然达到<code>-XX:MaxTenuringThreshold</code>而被转移到 Tenured 区外，如果在 Survivor 区中相同年龄所有对象大小的总和大于 Survivor 区的一半，则年龄大于等于该年龄的对象也可以直接转移到 Tenured 区、而无需等年龄达到<code>-XX:MaxTenuringThreshold</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * -Xms20M -Xmx20M -Xmn10M </span><br><span class="line"> * -XX:SurvivorRatio=8 </span><br><span class="line"> * -XX:+PrintGCDetails</span><br><span class="line"> * -XX:+UseSerialGC</span><br><span class="line"> * -XX:MaxTenuringThreshold=15</span><br><span class="line"> * -XX:+PrintTenuringDistribution</span><br><span class="line"> */</span><br><span class="line">public class AllocDynamicAgeTest &#123;</span><br><span class="line">    private static final int _1MB = 1024 * 1024;</span><br><span class="line">    </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        byte[] alloc1, alloc2, alloc3, alloc4;</span><br><span class="line">        alloc1 = new byte[_1MB / 4];</span><br><span class="line">        alloc2 = new byte[_1MB / 4];</span><br><span class="line">        alloc3 = new byte[4 * _1MB];</span><br><span class="line">        alloc4 = new byte[4 * _1MB];</span><br><span class="line">        alloc4 = null;</span><br><span class="line">        alloc4 = new byte[4 * _1MB];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[GC (Allocation Failure) [DefNew</span><br><span class="line">Desired survivor size 524288 bytes, new threshold 1 (max 15)</span><br><span class="line">- age   1:    1048568 bytes,    1048568 total</span><br><span class="line">: 7735K-&gt;1023K(9216K), 0.0066947 secs] 7735K-&gt;5293K(19456K), 0.0067283 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] </span><br><span class="line">[GC (Allocation Failure) [DefNew</span><br><span class="line">Desired survivor size 524288 bytes, new threshold 15 (max 15)</span><br><span class="line">: 5120K-&gt;0K(9216K), 0.0015566 secs] 9389K-&gt;5244K(19456K), 0.0015767 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] </span><br><span class="line">Heap</span><br><span class="line"> def new generation   total 9216K, used 4178K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)</span><br><span class="line">  eden space 8192K,  51% used [0x00000007bec00000, 0x00000007bf014930, 0x00000007bf400000)</span><br><span class="line">  from space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)</span><br><span class="line">  to   space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)</span><br><span class="line"> tenured generation   total 10240K, used 5244K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">   the space 10240K,  51% used [0x00000007bf600000, 0x00000007bfb1f248, 0x00000007bfb1f400, 0x00000007c0000000)</span><br><span class="line"> Metaspace       used 2986K, capacity 4568K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 318K, capacity 392K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure>
<p>发生了两次 Minor GC：</p>
<ol>
<li>第一次发生在给 alloc4 分配内存时，此时 alloc1、alloc2 将会进入 Survivor 区，而 alloc3 通过担保机制将会进入老年代；</li>
<li>第二次发生在给 alloc4 分配内存时，此时，Survivor 区的 alloc1、alloc2 达到了 Survivor 区容量的一半，将会进入老年代，此时 GC 可以清理出 alloc4 原来的 4MB 空间，并将 alloc4 分配在 Eden 区。</li>
</ol>
<p>最终，alloc1、alloc2、alloc3 在老年代，alloc4 在 Eden 区。</p>
<h4 id="空间分配担保"><a class="header-anchor" href="#空间分配担保">¶</a>空间分配担保</h4>
<p>老年代连续空间大于新生代对象总大小、或者历次晋升的平均大小，就会执行 Minor GC，否则将进行 Full GC。GC 期间，如果 Survivor 区空闲空间小于存活对象，则需要老年代进行分配担保，把 Survivor 区无法容纳的对象直接转移到老年代。<br>
例子在上一节中已经给出，这里不再赘述。</p>
<h3 id="对垃圾回收算法的改进"><a class="header-anchor" href="#对垃圾回收算法的改进">¶</a>对垃圾回收算法的改进</h3>
<h4 id="复制算法"><a class="header-anchor" href="#复制算法">¶</a>复制算法</h4>
<p>两个区域 A 和 B，初始对象在 A，继续存活的对象被转移到 B。<br>
这两个区域并不需要根据 1:1 划分内存空间，而是将内存划分为一块较大的 Eden Space 和两块较小的 Survivor Space，在 HotSpot 中默认大小比例为 8:1。<br>
当执行年轻代回收时会将 Eden 区存活的对象复制到一个空闲的 Survivor，下一次 GC 时将 Eden 区和这个 Survivor 区存活的对象复制到另一个 Survivor 区，因此总是会有一块 Survivor 区是空闲的。<br>
当 Survivor 空间不够用的时候，需要依赖于老年代的空间担保。</p>
<h4 id="标记-清除算法"><a class="header-anchor" href="#标记-清除算法">¶</a>标记-清除算法</h4>
<p>一块区域，标记可达对象（可达性分析），然后回收不可达对象，这会引入碎片，因此在空间碎片过多导致无法继续分配时往往会执行一次整理来压缩空间。</p>
<h4 id="标记-整理算法"><a class="header-anchor" href="#标记-整理算法">¶</a>标记-整理算法</h4>
<p>相对标记清理算法来说多了碎片整理的过程，可以整理出更大的内存放更大的对象。<br>
复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费 50%的空间，就需要有额外的空间进行<strong>分配担保</strong>，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。<br>
根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存（有点 copy 的意思，但是比 copy 省空间。比清理好的一点是没有碎片）。</p>
<h4 id="分代回收"><a class="header-anchor" href="#分代回收">¶</a>分代回收</h4>
<p>新生代：初始对象，生命周期短的<br>
永久代：长时间存在的对象<br>
整个 java 的垃圾回收是新生代和年老代的协作，这种叫做分代回收。</p>
<p>在大的分代回收的思想下面，不同的代区可以选择不同的收集器，而不同的收集器在不同的代区又会用到不同的算法。</p>
<h3 id="方法区回收策略"><a class="header-anchor" href="#方法区回收策略">¶</a>方法区回收策略</h3>
<p>方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。<br>
Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。<br>
方法区的垃圾回收主要回收两部分内容：</p>
<ol>
<li>从常量池回收废弃常量。<br>
如何判断废弃常量呢？以字面量回收为例，如果一个字符串“abc”已经进入常量池，但是当前系统没有任何一个 String 对象引用了叫做“abc”的字面量，那么，如果发生垃圾回收并且有必要时，“abc”就会被系统移出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。</li>
<li>卸载无用的类。既然进行垃圾回收，就需要判断哪些是废弃常量，哪些是无用的类。<br>
如何判断无用的类呢？需要满足以下三个条件
<ul>
<li>该类的所有实例都已经被回收，即 Java 堆中不存在该类的任何实例。</li>
<li>加载该类的 ClassLoader 已经被回收。</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。<br>
满足以上三个条件的类可以进行垃圾回收，但是并不是无用就被回收，虚拟机额外提供了一些参数供我们配置。</li>
</ul>
</li>
</ol>
<h3 id="直接内存-堆外内存"><a class="header-anchor" href="#直接内存-堆外内存">¶</a>直接内存（堆外内存）</h3>
<p>直接内存并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现。<br>
NIO 类可以直接通过 Native 函数分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。<br>
使用堆外内存时需要注意：</p>
<ul>
<li>由于垃圾收集器不涉及堆外内存，因此堆外内存何时分配何时回收都需要用户自己来定义；</li>
<li>直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。</li>
</ul>
<p>由 DirectMemory 导致的内存溢出，一个明显的特征是在 Heap Dump 文件中不会看见明显的异常，如果我们发现 OOM 之后 Dump 文件很小，而程序中有直接或间接使用了 NIO ，那就可以考虑检查一下是不是这方面的原因。</p>
<h2 id="jvm-垃圾收集器的演进"><a class="header-anchor" href="#jvm-垃圾收集器的演进">¶</a>JVM 垃圾收集器的演进</h2>
<p>垃圾收集器是内存回收算法的具体实现，随着 JDK 的升级我们已经有很多种垃圾收集器可供选择：</p>
<ul>
<li>JDK1.4 &amp;&amp; JDK1.5 很少用了，基本上是 Serial（Serial Old）。</li>
<li>JDK1.6 是ParNew或者Parallel(Parallel Old)。</li>
<li>JDK1.7 Parallel、Parallel Old。</li>
<li>JDK1.8 Parallel Scavenge（新生代）、Parallel Old（老年代） 配合 CMS。</li>
<li>JDK1.9+ G1出现，且为默认收集器</li>
</ul>
<h2 id="准备工作"><a class="header-anchor" href="#准备工作">¶</a>准备工作</h2>
<h3 id="如何知道-jvm-进程当前使用的是哪种垃圾收集器？"><a class="header-anchor" href="#如何知道-jvm-进程当前使用的是哪种垃圾收集器？">¶</a>如何知道 JVM 进程当前使用的是哪种垃圾收集器？</h3>
<ol>
<li>java -XX:+PrintCommandLineFlags<br>
打印启动时参数，根据启动时参数可以推断 JVM 进程使用的是什么垃圾收集器，但是这并不准确。</li>
<li>jmap <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -heap &lt;PID&gt;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="垃圾统计配置"><a class="header-anchor" href="#垃圾统计配置">¶</a>垃圾统计配置</h3>
<ul>
<li>-XX:+PrintGC</li>
<li>-XX:+PrintGCDetails</li>
<li>-XX:+PrintGCTimeStamps：可与上面参数一起使用</li>
<li>-XX:+PrintGCApplicationConcurrentTime：打印每次垃圾回收前，程序未中断的执行时间，可与上面参数一起使用</li>
<li>-XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间，可与上面参数一起使用</li>
<li>-XX:PrintHeapAtGC：打印 GC 前后的详细堆栈信息</li>
<li>-Xloggc:filename：与上面几个配合使用，把日志信息记录到文件来分析</li>
</ul>
<h3 id="使用什么垃圾回收器"><a class="header-anchor" href="#使用什么垃圾回收器">¶</a>使用什么垃圾回收器</h3>
<ul>
<li>-XX:+UseG1GC 在整个 Java 堆使用 G1 进行垃圾回收</li>
<li>-XX:+UseConcMarkSweepGC 设定新生代使用 ParNew（并发复制）收集器，老年代使用 CMS Concurrent Mark-Sweep（并发标记清除）收集器执行内存回收</li>
<li>-XX:+UseParallelOldGC 手动指定新生代使用 Parallel Scavenge（并行复制）收集器，老年代使用 Parallel Old（并行标记-压缩）收集器执行内存回收</li>
<li>-XX:+UseSerialGC 手动指定新生代使用 Serial Coping（串行复制）收集器，老年代使用 Serial Old （串行标记-清理-压缩）收集器执行内存回收</li>
<li>-XX:+UseParNewGC 手动指定新生代使用 ParNew（并发复制）收集器，老年代使用 Serial Old （串行标记-清理-压缩）收集器执行内存回收</li>
<li>-XX:+UseParallelGC 手动指定新生代使用 Parallel Scavenge（并行复制）收集器，老年代使用 Serial Old （串行标记-清理-压缩）收集器执行内存回收</li>
</ul>
<h2 id="serial-serial-old-收集器"><a class="header-anchor" href="#serial-serial-old-收集器">¶</a>Serial / Serial Old 收集器</h2>
<p>Serial（串行）收集器是最基本、发展历史最悠久的串行收集器，JDK 1.5 之前默认都是此收集器，因为那时候 CPU 都是单核的。</p>
<h3 id="使用"><a class="header-anchor" href="#使用">¶</a>使用</h3>
<ul>
<li>-XX:+UseSerialGC<br>
这个配置指定年轻代为 Serial，同时会指定老年代采用 Serial Old。</li>
</ul>
<h3 id="实现原理"><a class="header-anchor" href="#实现原理">¶</a>实现原理</h3>
<p><img src="http://47.88.24.11/imgs/JVM/Serial%EF%BC%88SerialOld%EF%BC%89%E6%94%B6%E9%9B%86%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="Serial（SerialOld）收集器工作过程" title="Serial（SerialOld）收集器工作过程"></p>
<ul>
<li>单线程阻塞队列。</li>
<li>年轻代采用复制算法，老年代采用标记整理算法，作用于老年代时称作 Serial Old 收集器。</li>
</ul>
<h3 id="优点"><a class="header-anchor" href="#优点">¶</a>优点</h3>
<p>简单而高效（与其他收集器的单线程相比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得更高的单线程收集效率。</p>
<h3 id="缺点"><a class="header-anchor" href="#缺点">¶</a>缺点</h3>
<ul>
<li>它是一个单线程收集器，只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，无法有效利用多核 CPU；</li>
<li>它在进行垃圾收集时，必须暂停其他所有的工作线程，直至 Serial 收集器收集结束为止（<strong>Stop The World</strong>）。</li>
</ul>
<h3 id="应用场景"><a class="header-anchor" href="#应用场景">¶</a>应用场景</h3>
<ul>
<li>HotSpot 虚拟机运行在 Client 模式下的默认的新生代收集器。</li>
<li>单 CPU 虚拟机里面。</li>
<li>JDK 1.3.1 之前，是虚拟机新生代收集的唯一选择。JDK 1.5.0 之前老年代的唯一选择。</li>
<li>内存比较小的情况下，效率还是很高的。</li>
</ul>
<h2 id="parnew-收集器"><a class="header-anchor" href="#parnew-收集器">¶</a>ParNew 收集器</h2>
<h3 id="使用-v2"><a class="header-anchor" href="#使用-v2">¶</a>使用</h3>
<ul>
<li>-XX:+UseParNewGC<br>
如果使用此配置默认年轻代，老年代采用 Serial Old。</li>
<li>-XX:ParallerGCThreads=3<br>
ParNew 默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多的情况下可使用 -XX:ParallerGCThreads 参数设置。</li>
</ul>
<h3 id="实现原理-v2"><a class="header-anchor" href="#实现原理-v2">¶</a>实现原理</h3>
<p><img src="http://47.88.24.11/imgs/JVM/ParNew%E6%94%B6%E9%9B%86%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="ParNew收集器工作过程" title="ParNew收集器工作过程"><br>
ParNew 收集器就是 Serial 收集器的多线程版本（即并发模式），除了使用多线程进行垃圾收集外，其余行为包括 Serial 收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与 Serial 收集器完全相同，两者共用了相当多的代码。</p>
<h3 id="优点-v2"><a class="header-anchor" href="#优点-v2">¶</a>优点</h3>
<ul>
<li>多 CPU 环境下 GC 时更有效利用系统资源，是 Server 模式下虚拟机的首选新生收集器。</li>
<li>可以与 CMS 搭配使用。</li>
</ul>
<h3 id="缺点-v2"><a class="header-anchor" href="#缺点-v2">¶</a>缺点</h3>
<ul>
<li>只能用于新生代。</li>
<li>ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越。</li>
</ul>
<h2 id="parallel-scavenge-并行收集器"><a class="header-anchor" href="#parallel-scavenge-并行收集器">¶</a>Parallel Scavenge 并行收集器</h2>
<h3 id="使用-v3"><a class="header-anchor" href="#使用-v3">¶</a>使用</h3>
<ul>
<li>-XX:+UseParallelGC</li>
<li>-XX:+UseParallelOldGC</li>
<li>-XX:+UseAdaptiveSizePolicy<br>
这是一个动态调整各个代区的内存大小的开关参数，打开参数后，就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种方式称为 <strong>GC 自适应调节策略（GC Ergonomics）</strong>。</li>
<li>-XX:ParallelGCThreads=n<br>
并行 GC 线程数。</li>
<li>-XX:MaxGCpauseMillis=5<br>
默认 GC 最大停留时间。</li>
<li>-xx:GCTimeRatio<br>
GC 占用总时间的最大比率。</li>
</ul>
<h3 id="实现原理-v3"><a class="header-anchor" href="#实现原理-v3">¶</a>实现原理</h3>
<p><img src="http://47.88.24.11/imgs/JVM/ParallelScavenge%EF%BC%88ParallelOld%EF%BC%89%E6%94%B6%E9%9B%86%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="ParallelScavenge（ParallelOld）收集器工作过程" title="ParallelScavenge（ParallelOld）收集器工作过程"></p>
<ul>
<li>并行</li>
<li>可控的吞吐量</li>
</ul>
<blockquote>
<p>吞吐量（Throughput），即 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即“吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）”。<br>
假设虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99%。</p>
</blockquote>
<ul>
<li>自适应调节策略</li>
</ul>
<h3 id="优点-v3"><a class="header-anchor" href="#优点-v3">¶</a>优点</h3>
<ul>
<li>可以调整吞吐量，减少停顿时间，从而提升用户体验<br>
停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</li>
</ul>
<h3 id="缺点-v3"><a class="header-anchor" href="#缺点-v3">¶</a>缺点</h3>
<p>Parallel Scavenge 收集器无法与 CMS 收集器配合使用。</p>
<h2 id="并发标记清理-concurrent-mark-sweep-cms-收集器"><a class="header-anchor" href="#并发标记清理-concurrent-mark-sweep-cms-收集器">¶</a>并发标记清理（Concurrent Mark-Sweep，CMS）收集器</h2>
<h3 id="使用-v4"><a class="header-anchor" href="#使用-v4">¶</a>使用</h3>
<ul>
<li>-XX:+UseConcMarkSweepGC，使用 CMS 收集器；</li>
<li>-XX:+UseCMSCompactAtFullCollection<br>
Full GC 后，进行一次碎片整理，整理过程是独占的，会引起停顿时间变长。</li>
<li>-XX:+CMSFullGCsBeforeCompaction<br>
设置进行几次 Full GC 后，进行一次碎片整理。</li>
<li>-XX:ParallelCMSThreads，设定 CMS 的线程数量（一般情况约等于可用 CPU 数量）。</li>
</ul>
<h3 id="实现原理-v4"><a class="header-anchor" href="#实现原理-v4">¶</a>实现原理</h3>
<p>CMS 收集器运行过程中各步骤所涉及的并发和所需的停顿时间如下图所示：<br>
<img src="http://47.88.24.11/imgs/JVM/CMS%E6%94%B6%E9%9B%86%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="CMS收集器工作过程" title="CMS收集器工作过程"><br>
CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。<br>
顾名思义，CMS 采用标记清除算法，它的工作流程分为以下 4 个步骤：</p>
<ol>
<li>初始标记（CMS initial mark）：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要<strong>Stop The World（stw）</strong>。<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-InitialMark.png" alt="CMS-InitialMark" title="CMS-InitialMark"></li>
<li>并发标记（CMS concurrent mark）：进行 GC Roots Tracing 的过程，在整个过程中耗时最长。<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-ConcurrentMark.png" alt="CMS-ConcurrentMark" title="CMS-ConcurrentMark"><br>
根据上个阶段找到的 GC Roots 遍历查找，并不是上一阶段存活的对象都会被标记，因为在标记期间用户的程序可能会改变一些引用，如上图所示。</li>
<li>并发预清理（CMS Concurrent Preclean）：并发过程，标记并发执行过程中的脏区域（Card）。<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-ConcurrentPreclean.png" alt="CMS-ConcurrentPreclean" title="CMS-ConcurrentPreclean"><br>
如上图所示，在并发运行过程中（包括上一阶段），一些对象的引用可能会发生变化，预清理过程将包含这个对象的区域（Card）标记为 Dirty，这也就是<strong>Card Marking</strong>。<br>
然后，由这些脏可达的对象也会被重新标记：<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-ConcurrentPreclean-Mark.png" alt="CMS-ConcurrentPreclean-Mark" title="CMS-ConcurrentPreclean-Mark"></li>
<li>可中断预清理（CMS Concurrent Abortable Preclean）：这也是一个并发阶段，这个阶段的主要目的是尽量承担最终标记阶段的工作。<br>
因为重新标记阶段阶段需要全堆扫描，此时如果先进行了MinorGC则可以大大较少需要扫描的对象数量，因此Abortable Preclean阶段的目的就是等一段时间，看看能不能在重新标记前执行一次MinorGC。<br>
为什么重新标记阶段需要做全堆扫描？因为判断对象是否可达需要使用根搜索算法，而只有MinorGC时才会使用根搜索算法，否则CMS也不知道之前的并发阶段是否产生了新的不可达对象。</li>
<li>重新标记（CMS remark）：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要<strong>Stop The World</strong>。<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-Remark.png" alt="CMS-Remark" title="CMS-Remark"><br>
通常 Remark 阶段会在年轻代尽可能干净的时候运行，目的是为了减少连续 STW 发生的可能性。</li>
<li>并发清除（CMS concurrent sweep）：清除不再使用的对象。<br>
<img src="http://47.88.24.11/imgs/JVM/CMS-ConcurrentSweep.png" alt="CMS-ConcurrentSweep" title="CMS-ConcurrentSweep"></li>
</ol>
<p>下面以一个真实环境中的FullGC日志为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2020-08-20T04:37:36.159+0800: 638682.623: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1930043K(2097152K)] 2000027K(4793536K), 0.2664430 secs] [Times: user=0.11 sys=0.02, real=0.26 secs]</span><br><span class="line">2020-08-20T04:37:36.426+0800: 638682.890: [CMS-concurrent-mark-start]</span><br><span class="line">2020-08-20T04:37:42.956+0800: 638689.420: [CMS-concurrent-mark: 6.513/6.529 secs] [Times: user=2.11 sys=0.40, real=6.53 secs]</span><br><span class="line">2020-08-20T04:37:42.956+0800: 638689.420: [CMS-concurrent-preclean-start]</span><br><span class="line">2020-08-20T04:37:42.982+0800: 638689.445: [CMS-concurrent-preclean: 0.024/0.026 secs] [Times: user=0.03 sys=0.01, real=0.03 secs]</span><br><span class="line">2020-08-20T04:37:42.982+0800: 638689.446: [CMS-concurrent-abortable-preclean-start]</span><br><span class="line"> CMS: abort preclean due to time 2020-08-20T04:37:48.340+0800: 638694.804: [CMS-concurrent-abortable-preclean: 5.356/5.358 secs] [Times: user=6.26 sys=0.24, real=5.36 secs]</span><br><span class="line">2020-08-20T04:37:48.344+0800: 638694.807: [GC (CMS Final Remark) [YG occupancy: 571811 K (2696384 K)]2020-08-20T04:37:48.344+0800: 638694.808: [Rescan (parallel) , 0.0743374 secs]2020-08-20T04:37:48.418+0800: 638694.882: [weak refs processing, 0.0004330 secs]2020-08-20T04:37:48.419+0800: 638694.882: [class unloading, 3.9423498 secs]2020-08-20T04:37:52.361+0800: 638698.825: [scrub symbol table, 0.5589452 secs]2020-08-20T04:37:52.920+0800: 638699.384: [scrub string table, 0.0015701 secs][1 CMS-remark: 1930043K(2097152K)] 2501855K(4793536K), 4.5824373 secs] [Times: user=0.47 sys=0.04, real=4.58 secs]</span><br><span class="line">2020-08-20T04:37:52.927+0800: 638699.391: [CMS-concurrent-sweep-start]</span><br><span class="line">2020-08-20T04:37:56.807+0800: 638703.271: [CMS-concurrent-sweep: 3.877/3.880 secs] [Times: user=2.69 sys=0.11, real=3.88 secs]</span><br><span class="line">2020-08-20T04:37:56.808+0800: 638703.271: [CMS-concurrent-reset-start]</span><br><span class="line">2020-08-20T04:37:56.815+0800: 638703.279: [CMS-concurrent-reset: 0.007/0.007 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]</span><br></pre></td></tr></table></figure>
<p>上面的GC日志中：</p>
<ul>
<li>第 1 行、初始标记阶段，会发生<strong>STW</strong>，标记GC Root<strong>直接引用</strong>的对象，GC Root直接引用的对象不多，因此很快。<br>
<code>1930043K</code>：当前老年代使用的容量；<br>
<code>2097152K</code>：老年代可用的最大容量；<br>
<code>2000027K</code>：整个堆目前使用的容量；<br>
<code>4793536K</code>：整个堆的可用容量；<br>
<code>0.2664430 secs</code>：这个阶段的持续时间；<br>
<code>[Times: user=0.11 sys=0.02, real=0.26 secs]</code>：对应 user、system 和 real 的时间统计。</li>
<li>第 2~3 行、并发标记阶段，由第一阶段标记过的对象出发所有可达的对象都在本阶段标记。<br>
<code>6.513/6.529 secs</code>：这个阶段的持续时间与时钟时间；<br>
<code>[Times: user=2.11 sys=0.40, real=6.53 secs]</code>：时间统计，但是因为是并发执行的，并不仅仅包含 GC 线程的工作。</li>
<li>第 4~5 行、并发预清理阶段，查找前一阶段执行过程中，从新生代晋升或新分配或被更新的对象，通过并发地重新扫描这些对象，可以减少下一个 STW 重新标记阶段的工作量。<br>
<code>0.024/0.026 secs</code>：持续时间与时钟时间；<br>
<code>Times: user=0.03 sys=0.01, real=0.03 secs</code>：时间统计。</li>
<li>第 6~7 行、并发可终止的预清理阶段，这个阶段其实跟上一个阶段做的东西一样，也是为了减少下一个 STW 重新标记阶段的工作量。增加这一阶段是为了让我们可以控制这个阶段的结束时机，比如扫描多长时间（默认 5 秒）或者 Eden 区使用占比达到期望比例（默认 50%）就结束本阶段。</li>
<li>第 8 行、Final Remark 重新标记阶段，会发生<strong>STW</strong>，暂停所有用户线程，从 GC Root 开始重新扫描整个堆，标记存活的对象。这一阶段是为了修正并发标记期间因用户线程继续运行而导致标记产生变动的那一部分对象的标记记录。这一阶段停顿时间一般比初始标记阶段稍长，但远比并发标记时间短。需要注意的是，虽然 CMS 只回收老年代的垃圾对象，但是这个阶段依然需要扫描新生代，因为很多 GC Root 都在新生代，而这些 GC Root 指向的对象又在老年代，这称为<strong>跨代引用</strong>。<br>
<code>YG occupancy: 571811 K (2696384 K)</code>：年轻代当前占用量及容量；<br>
<code>Rescan (parallel) , 0.0743374 secs</code>：Rescan 是当应用暂停的情况下完成对所有存活对象的标记，这个阶段是并行处理的；<br>
<code>weak refs processing, 0.0004330 secs</code>：第 1 个子阶段，处理弱引用；<br>
<code>class unloading, 3.9423498 secs</code>：第 2 个子阶段，卸载不再使用的 class；<br>
<code>scrub symbol table, 0.5589452 secs ... scrub string table, 0.0015701 secs</code>：最后一个子阶段，清理符号表和字符表。<br>
<code>1 CMS-remark: 1930043K(2097152K)</code>：这一阶段之后老年代的使用量与总量；<br>
<code>2501855K(4793536K)</code>：这一阶段后堆的使用量与总量（包括年轻代）；<br>
<code>4.5824373 secs</code>：这一阶段的持续时间，也就是 STW 的时间。<br>
<code>[Times: user=0.47 sys=0.04, real=4.58 secs]</code>：这一阶段统计的持续时间。<br>
经过这5个阶段之后，老年代所有存活的对象就都被标记过了，之后可以通过清除算法去清理老年代不再使用的对象。</li>
<li>第 9~10 行、并发清除；</li>
<li>第 11~12 行、重置，重新初始化 CMS 内部数据结构，以备下一轮 GC 使用。</li>
</ul>
<p>普通串行标记清除算法与并行标记清除算法（CMS）的比较如下图所示：<br>
<img src="http://47.88.24.11/imgs/JVM/%E4%B8%B2%E8%A1%8C%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95%E4%B8%8E%E5%B9%B6%E8%A1%8C%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83.png" alt="串行标记清除算法与并行标记清除算法之间的比较" title="串行标记清除算法与并行标记清除算法之间的比较"><br>
如上图可知，并发标记清除算法与串行标记清除算法之间的区别主要在于，前者将标记过程分成了 3 个部分，其中占用时间最长的<code>Concurrent Mark</code>不需要<code>stw</code>。 <br>
由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。</p>
<h3 id="优点-v4"><a class="header-anchor" href="#优点-v4">¶</a>优点</h3>
<p>并发收集、低停顿，因此 CMS 收集器也被称为并发低停顿收集器（Concurrent Low Pause Collector）。</p>
<h3 id="缺点-v4"><a class="header-anchor" href="#缺点-v4">¶</a>缺点</h3>
<ul>
<li>对 CPU 资源非常敏感。其实，面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说 CPU 资源）而导致应用程序变慢，总吞吐量会降低。CMS 默认启动的回收线程数是（CPU 数量+3）/4，也就是当 CPU 在 4 个以上时，并发回收时垃圾收集线程不少于 25%的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个时（比如 2 个），CMS 对用户程序的影响就可能变得很大，如果本来 CPU 负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了 50%，其实也让人无法接受。</li>
<li>无法处理<strong>浮动垃圾（Floating Garbage）</strong>，可能出现“Concurrent Mode Failure”失败而导致另一次 Full GC 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉。这一部分垃圾就被称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。</li>
<li>标记-清除算法导致的<strong>内存碎片</strong>。CMS 是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生，可能会提前触发一次 FullGC。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。</li>
</ul>
<h3 id="应用场景-v2"><a class="header-anchor" href="#应用场景-v2">¶</a>应用场景</h3>
<ul>
<li>CMS 以最短回收停顿时间为目标，非常符合那些集中在互联网站或者 B/S 系统的服务端上的 Java 应用，这些应用都非常重视服务的响应速度，不能有明显的暂停时间。</li>
<li>当你的应用程序需要有较短的应用程序暂停，而可以接受垃圾收集器与应用程序共享应用程序时，则可以选择 CMS 垃圾收集器。</li>
<li>典型情况下，有很多长时间保持 live 状态的数据对象（一个较大的老年代）的应用程序，和运行在多处理上的应用程序，更适合使用 CMS 垃圾收集器。例如 Web 服务器。</li>
</ul>
<h2 id="g1-收集器"><a class="header-anchor" href="#g1-收集器">¶</a>G1 收集器</h2>
<p>G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一。它是一款面向服务端应用的垃圾收集器。</p>
<h3 id="使用-v5"><a class="header-anchor" href="#使用-v5">¶</a>使用</h3>
<p>G1 可以用于年轻代和老年代，且算法分 3 个步骤，所以配置种类比较多。<br>
只作用于年轻代的配置：</p>
<ul>
<li>-XX:G1NewSizePercent<br>
年轻代最小值，默认值 5%。</li>
<li>-XX:G1MaxNewSizePercent<br>
年轻代最大值，默认值 60%。</li>
</ul>
<p>作用于老年代的配置：</p>
<ul>
<li>-XX:CMSInitiatingOccupancyFraction=80<br>
当老年代的使用率达到80%时，就会触发一次 CMS GC</li>
<li>-XX:InitiatingHeapOccupancyPercent<br>
当老年代大小占整个堆大小百分比达到该阈值时，会触发一次 <strong>Mixed GC</strong>。</li>
<li>-XX:+UseCMSInitiatingOccupancyOnly</li>
</ul>
<p>其他配置：</p>
<ul>
<li>-XX:MaxGCPauseMillis<br>
设置 G1 收集过程目标时间，默认值 200ms。</li>
<li>-XX:G1ReservePercent<br>
默认值 10%，预留的空闲空间的百分比</li>
<li>-XX:G1HeapRegionSize<br>
配置 Region 块的大小，范围 1MB 到 32MB，设置后会根据最小堆 Java 堆内存划分出 2048 个 Region 块</li>
</ul>
<h3 id="实现原理-内存结构与gc算法"><a class="header-anchor" href="#实现原理-内存结构与gc算法">¶</a>实现原理 - 内存结构与GC算法</h3>
<p>在 G1 算法中，采用了另外一种完全不同的方式组织堆内存，堆内存被划分为多个大小相等的内存块，称为<strong>Region</strong>，每个 Region 是逻辑连续的一段内存，结构如下：<br>
<img src="http://47.88.24.11/imgs/JVM/G1%E6%94%B6%E9%9B%86%E5%99%A8%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="G1收集器内存结构" title="G1收集器内存结构"><br>
由上图可见：</p>
<ul>
<li>新生代与老年代并不是连续的，而是一些 Region 的集合；</li>
<li>为了避免全堆扫描，对其他 Region 对象的引用会被记录到一个<strong>Remembered Set</strong>中，每个 Region 都对应一个 Remembered Set，虚拟机发现程序在对 Reference 类型的数据进行写操作时，会插入一个 Write Barrier 暂时中断写操作，检查 Reference 引用的对象是否位于其他 Region 中，如果是则将其引用信息记录到该 Region 对应的 Remembered Set 中，当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证及时不对全堆扫描也不会产生遗漏。</li>
<li>一些Regine被标明了H，代表<strong>Humongous</strong>，这表示这些Region存储的是巨大对象（Humongous object，H-obj），即大小大于等于Region一半的对象，对这些大对象有一些特殊的规则。</li>
</ul>
<p>堆内存中一个 Region 的大小可以通过 <code>-XX:G1HeapRegionSize</code> 参数指定，大小区间只能是 1M、2M、4M、8M、16M 和 32M，总之是 2 的幂次方，如果 <code>G1HeapRegionSize</code> 为默认值，则在堆初始化时计算 Region 的实践大小。<br>
G1 可以独立管理整个堆空间，但是能够采用不同方式来处理新创建对象和已经存活了一段时间、经历过多次 GC 的老对象，以获取更好的收集效果。G1 中提供了三种模式垃圾回收模式：<strong>Young GC</strong>、<strong>Mixed GC</strong> 和 <strong>Full GC</strong>，在不同的条件下被触发。</p>
<h4 id="young-gc"><a class="header-anchor" href="#young-gc">¶</a>Young GC</h4>
<p>发生在年轻代的 GC 算法，一般对象（除了巨型对象）都是在 <strong>Eden Region</strong> 中分配内存，当所有 Eden Region 被耗尽无法申请内存时，就会触发一次 Young GC，这种触发机制和之前的 Young GC 差不多，执行完一次 Young GC，活跃对象会被拷贝到 <strong>Survivor Region</strong> 或者晋升到 <strong>Old Region</strong> 中，空闲的 Region 会被放入<strong>空闲列表</strong>中，等待下次被使用。</p>
<h4 id="mixed-gc"><a class="header-anchor" href="#mixed-gc">¶</a>Mixed GC</h4>
<p>当越来越多的对象晋升到老年代 Old Region 时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即 Mixed GC，该算法并不是一个 old gc，除了回收整个 Young Region，还会回收一部分的 Old Region，这里需要注意：是一部分老年代，而不是全部老年代，可以选择哪些 Old Region 进行收集，从而可以对垃圾回收的耗时时间进行控制。<br>
<img src="http://47.88.24.11/imgs/JVM/G1%E6%94%B6%E9%9B%86%E5%99%A8%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="G1收集器工作过程" title="G1收集器工作过程"><br>
Mixed GC 的执行过程有点类似 CMS，主要分为以下几个步骤：</p>
<ul>
<li>initial mark: 初始标记过程，整个过程需要 STW，但耗时比较短，标记了从 GC Root 可达的对象，它们能被 GC Root 直接关联到；</li>
<li>concurrent marking: 并发标记过程，整个过程 gc collector 线程与应用线程可以并行执行，标记出 GC Root 可达对象衍生出去的存活对象，并收集各个 Region 的存活对象信息；</li>
<li>remark: 最终标记过程，整个过程需要 STW，GC 线程与用户线程并行执行，耗时较短，标记出那些在并发标记过程中遗漏的、或者由于用户线程继续运行导致的标记变动，变动记录将被记录在 Remembered Set Logs 中，此阶段会把其整合到 Remembered Set 中；</li>
<li>clean up: 垃圾清除过程，与用户线程并发执行，时间用户可控，对各个 Region 的回收价值和成本进行排序，根据用户期望的 GC 时间进行回收，如果发现一个 Region 中没有存活对象，则把该 Region 加入到空闲列表中。</li>
</ul>
<h4 id="full-gc"><a class="header-anchor" href="#full-gc">¶</a>Full GC</h4>
<p>如果对象内存分配速度过快，Mixed GC 来不及回收，导致老年代被填满，就会触发一次 Full GC，G1 的 Full GC 算法就是单线程执行的 <strong>Serial Old GC</strong>，使用标记-整理算法，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免 Full GC。</p>
<h3 id="实现原理-并行和并发"><a class="header-anchor" href="#实现原理-并行和并发">¶</a>实现原理 - 并行和并发</h3>
<p>G1 使用多个 CPU 来缩短 Stop The World 停顿时间，与用户线程并发执行。</p>
<h3 id="实现原理-可预测的停顿"><a class="header-anchor" href="#实现原理-可预测的停顿">¶</a>实现原理 - 可预测的停顿</h3>
<p>G1 建立了可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。</p>
<h3 id="优点-v5"><a class="header-anchor" href="#优点-v5">¶</a>优点</h3>
<h3 id="缺点-v5"><a class="header-anchor" href="#缺点-v5">¶</a>缺点</h3>
<h3 id="应用场景-v3"><a class="header-anchor" href="#应用场景-v3">¶</a>应用场景</h3>
<h2 id="各垃圾收集器之间的比较"><a class="header-anchor" href="#各垃圾收集器之间的比较">¶</a>各垃圾收集器之间的比较</h2>
<p><img src="http://47.88.24.11/imgs/JVM/%E5%90%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="各垃圾收集器之间的关系" title="各垃圾收集器之间的关系"></p>
<ol>
<li>CMS 与 Serial Old 是可以相互配合的</li>
<li>G1 既可以用于年轻代又可以用于老年代</li>
</ol>
<table>
<thead>
<tr>
<th>收集器</th>
<th>串行、并行or并发</th>
<th>新生代/老年代</th>
<th>算法</th>
<th>目标</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serial</td>
<td>串行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度优先</td>
<td>单 CPU 环境下的 Client 模式</td>
</tr>
<tr>
<td>Serial Old</td>
<td>串行</td>
<td>老年代</td>
<td>标记-整理</td>
<td>响应速度优先</td>
<td>单 CPU 环境下的 Client 模式、CMS 的后备预案</td>
</tr>
<tr>
<td>ParNew</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度优先</td>
<td>多 CPU 环境时在 Server 模式下与 CMS 配合</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>吞吐量优先</td>
<td>在后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>Parallel Old</td>
<td>并行</td>
<td>老年代</td>
<td>标记-整理</td>
<td>吞吐量优先</td>
<td>在后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>CMS</td>
<td>并发</td>
<td>老年代</td>
<td>标记-清除</td>
<td>响应速度优先</td>
<td>集中在互联网站或 B/S 系统服务端上的 Java 应用</td>
</tr>
<tr>
<td>G1</td>
<td>并发</td>
<td>both</td>
<td>标记-整理+复制算法</td>
<td>响应速度优先</td>
<td>面向服务端应用，将来替换 CMS</td>
</tr>
</tbody>
</table>
<h2 id="qa"><a class="header-anchor" href="#qa">¶</a>QA</h2>
<h3 id="哪些对象的引用会被当作-gc-root-呢"><a class="header-anchor" href="#哪些对象的引用会被当作-gc-root-呢">¶</a>哪些对象的引用会被当作 GC Root 呢</h3>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象<br>
下面的变量a即为一个GC Root。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int main() &#123;</span><br><span class="line">    int a = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>方法区中类静态属性（类变量）引用的对象<br>
下面的b即一个GC Root。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class A &#123;</span><br><span class="line">    int b = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>方法区中常量引用的对象<br>
下面的字符串&quot;123&quot;会被加载到方法区中的字符串常量表，也是一个GC Root。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class A &#123;</span><br><span class="line">    static final String c = &quot;123&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>本地方法栈中 JNI（native 方法）引用的对象<br>
实现JNI方法时，在方法体内创建的局部变量。</li>
</ul>
<h3 id="弱引用和软引用有什么区别？"><a class="header-anchor" href="#弱引用和软引用有什么区别？">¶</a>弱引用和软引用有什么区别？</h3>
<p>强引用比较简单，虚引用很少见，容易混淆的是弱引用和软引用：</p>
<ol>
<li>弱引用<br>
只要垃圾回收时弱引用对象没有任何其他强引用，则对象会被回收。</li>
<li>软引用<br>
在系统将要发生溢出异常之前，将会把这些对象列进回收范围进行第二次回收，如果这次回收没有足够内存，才会抛出内存溢出异常。</li>
</ol>
<blockquote>
<p>JVM 在分配空间时，若果 Heap 空间不足，就会进行相应的 GC，但是这次 GC 并不会收集软引用关联的对象，但是在 JVM 发现就算进行了一次回收后还是不足（Allocation Failure），JVM 会尝试第二次 GC，回收软引用关联的对象。</p>
</blockquote>
<h3 id="为什么新生代采取复制算法而老年代采取标记-整理算法"><a class="header-anchor" href="#为什么新生代采取复制算法而老年代采取标记-整理算法">¶</a>为什么新生代采取复制算法而老年代采取标记-整理算法</h3>
<p>这个问题等价于为什么在不同的代中使用不同的垃圾收集器。<br>
主要原因来自新生代和老年代的区别，新生代新陈代谢快，采用复制算法，Survivor 区可以相对较小，不会有太大的空间浪费，并且保证了较高的效率；老年代反之。</p>
<h3 id="为什么不用标记清除算法"><a class="header-anchor" href="#为什么不用标记清除算法">¶</a>为什么不用标记清除算法</h3>
<p>效率低，标记和清除都需要一次线性扫描，相当于比别的算法慢一倍，而且产生大量内存碎片，内存碎片的问题也出现在 C 语言的 malloc/free 中。</p>
<h3 id="垃圾收集器中的并发和并行分别代表什么？"><a class="header-anchor" href="#垃圾收集器中的并发和并行分别代表什么？">¶</a>垃圾收集器中的并发和并行分别代表什么？</h3>
<p>并行指各垃圾收集器线程可以同时运行，此时用户线程仍然处于等待状态。<br>
并发指用户线程可以和垃圾收集器同时（可能是交替）运行，它们不在同一个CPU上执行。</p>
<h3 id="为什么-cms-要-3-次标记"><a class="header-anchor" href="#为什么-cms-要-3-次标记">¶</a>为什么 CMS 要 3 次标记</h3>
<ul>
<li>第 1 次标记（Initial Mark）：标记 GCRoot 可直达的对象，耗时短。</li>
<li>第 2 次标记（Concurrent Mark）：从上一部分标记对象出发标记引用链。<br>
为什么这个阶段可以并发标记？如果新创建了一个 GC Root 引用的对象或者引用链变更了怎么办？实际上这个步骤已经能将绝大多数需要标记的对象标记上了，如果有遗漏都是在下一阶段弥补的。</li>
<li>第 3 次标记（Remark）：重新标记阶段将上一阶段执行过程中用户线程新创建的对象和引用链中新引用的对象都标记上，这个过程相对较短，因此 STW 也可以接受。</li>
</ul>
<p>从 3 次标记过程的特征可以看出，CMS 将耗时长的部分并行化了，从而保证整个 gc 过程的高性能。</p>
<h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2>
<ol>
<li><a href="https://www.open-open.com/lib/view/open1429883238291.html" target="_blank" rel="noopener">Minor GC、Major GC 和 Full GC 之间的区别</a></li>
<li><a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="noopener">JAVA GARBAGE COLLECTION HANDBOOK</a></li>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector" target="_blank" rel="noopener">Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide</a></li>
<li><a href="https://tech.meituan.com/2017/12/29/jvm-optimize.html" target="_blank" rel="noopener">从实际案例聊聊Java应用的GC优化</a></li>
<li><a href="https://tech.meituan.com/2016/09/23/g1.html" target="_blank" rel="noopener">Java Hotspot G1 GC的一些关键技术</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/92a28d62.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/92a28d62.html" itemprop="url">SpringCloud 配置总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T13:09:11+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Spring Cloud 是一系列框架的有序集合，它利用 Spring Boot 的开发便利性简化了分布式系统的开发，比如服务发现、服务网关、服务路由、链路追踪等。Spring Cloud 并不重复造轮子，而是将市面上开发得比较好的模块集成进去，进行封装，从而减少了各模块的开发成本。换句话说：Spring Cloud 提供了构建分布式系统所需的“全家桶”。<br>
Spring Cloud 常常被拿来和 Dubbo 比较，实际上 Dubbo 只实现了服务治理，接入 Dubbo 的服务能够实现自动上下线、能通过 Dubbo 协议（其实 Dubbo 还支持其他很多协议）互联，但是 Dubbo 并不提供网关、配置中心、链路追踪等一系列微服务架构常用的技术，需要单独引入。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/92a28d62.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/3e0c4ce6.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/3e0c4ce6.html" itemprop="url">Spring 总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T13:09:11+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  671 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1>Spring 三级缓存</h1>
<h2 id="spring-中产生循环依赖的三种情况"><a class="header-anchor" href="#spring-中产生循环依赖的三种情况">¶</a>Spring 中产生循环依赖的三种情况</h2>
<ol>
<li>构造器注入循环依赖 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class A &#123;</span><br><span class="line">    public A(B b) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">@Service</span><br><span class="line">public class B &#123;</span><br><span class="line">    public B(A a) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>构造器注入构成的循环依赖，此种循环依赖方式是无法解决的，只能抛出 BeanCurrentlyInCreationException 异常表示循环依赖。<br>
不能解决的原因是：Spring 解决循环依赖的原理是实例化 Bean 后先把引用存到一个 Map 中，之后初始化成员变量时，可以直接从这个 Map 中取。但是构造器注入相当于<strong>实例化和初始化是同时进行的</strong>，因此无法解决。</p>
<ol>
<li>
<p>singleton 模式 field 属性注入循环依赖</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class A &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private B b;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">@Service</span><br><span class="line">public class B &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>prototype 模式 field 属性注入循环依赖</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)</span><br><span class="line">@Service</span><br><span class="line">public class A &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private B b;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)</span><br><span class="line">@Service</span><br><span class="line">public class B &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="spring-创建-bean-的流程"><a class="header-anchor" href="#spring-创建-bean-的流程">¶</a>Spring 创建 Bean 的流程</h2>
<ol>
<li>createBeanInstance：实例化，其实也就是调用对象的构造方法实例化对象</li>
<li>populateBean：填充属性，这一步主要是对 bean 的依赖属性进行注入(@Autowired)</li>
<li>initializeBean：回到一些形如 initMethod、InitializingBean 等方法</li>
</ol>
<p>其中，循环依赖可能发生在第一步和第二步，其中第一步是因为构造方法中可能会需要传入其他 Bean。</p>
<h2 id="spring-三级缓存如何解决循环依赖"><a class="header-anchor" href="#spring-三级缓存如何解决循环依赖">¶</a>Spring 三级缓存如何解决循环依赖</h2>
<h3 id="缓存生效时间"><a class="header-anchor" href="#缓存生效时间">¶</a>缓存生效时间</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123;</span><br><span class="line"></span><br><span class="line">    // 用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用</span><br><span class="line">	/** Cache of singleton objects: bean name --&gt; bean instance */</span><br><span class="line">	private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);</span><br><span class="line"></span><br><span class="line">    // 提前曝光的单例对象的cache，存放原始的 bean 对象（尚未填充属性），用于解决循环依赖</span><br><span class="line">	/** Cache of early singleton objects: bean name --&gt; bean instance */</span><br><span class="line">	private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);</span><br><span class="line">	</span><br><span class="line">	// 单例对象工厂的cache，存放 bean 工厂对象，用于解决循环依赖</span><br><span class="line">	/** Cache of singleton factories: bean name --&gt; ObjectFactory */</span><br><span class="line">    private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);</span><br></pre></td></tr></table></figure>
<h3 id="获取单例-bean-的过程"><a class="header-anchor" href="#获取单例-bean-的过程">¶</a>获取单例 Bean 的过程</h3>
<p><code>org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#getSingleton(java.lang.String)</code></p>
<ol>
<li>先从一级缓存 singletonObjects 中去获取，如果获取到就直接 return。</li>
<li>如果获取不到或者对象正在创建中（isSingletonCurrentlyInCreation()），那就再从二级缓存 earlySingletonObjects 中获取，如果获取到就直接 return。</li>
<li>如果还是获取不到，且允许 singletonFactories（allowEarlyReference=true）通过 getObject()获取。就从三级缓存 singletonFactory.getObject()获取，如果获取到了就从 singletonFactories 中移除，并且放进 earlySingletonObjects，其实也就是从三级缓存移动到了二级缓存。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/485e1bd7.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/485e1bd7.html" itemprop="url">Vim 使用总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-14T20:09:11+08:00">
                2019-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  501 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>平时在 Linux 环境下待的久了，免不了和 Vim 打交道。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/485e1bd7.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">107</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">52</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
