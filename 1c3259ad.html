<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="ElasticSearch,">










<meta name="description" content="¶为什么用 ElasticSearch Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。大致上，它有以下重要特征：  面向文档 Lucene 索引 分布式  ¶搭建调试环境 Idea - File - open，打开 build.gradle 文件 选择 gradlew，gradle wrapper 需要设置 JAVA_HOME 环境变量， 1234GlobalBui">
<meta name="keywords" content="ElasticSearch">
<meta property="og:type" content="article">
<meta property="og:title" content="ES 原理分析">
<meta property="og:url" content="https://tallate.github.io/1c3259ad.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:description" content="¶为什么用 ElasticSearch Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。大致上，它有以下重要特征：  面向文档 Lucene 索引 分布式  ¶搭建调试环境 Idea - File - open，打开 build.gradle 文件 选择 gradlew，gradle wrapper 需要设置 JAVA_HOME 环境变量， 1234GlobalBui">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E9%97%AE%E9%A2%98.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%96%B0%E5%A2%9E%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%A0%E9%99%A4.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E5%8F%96%E5%9B%9E%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E5%B1%80%E9%83%A8%E6%9B%B4%E6%96%B0.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%89%B9%E9%87%8F%E8%AF%BB.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%89%B9%E9%87%8F%E6%94%B9.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%9F%A5%E8%AF%A2%E9%98%B6%E6%AE%B5.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E5%8F%96%E5%9B%9E%E9%98%B6%E6%AE%B5.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E4%B8%80%E4%B8%AALucene%E7%B4%A2%E5%BC%95%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4%E7%82%B9%E5%92%8C%E4%B8%89%E4%B8%AA%E6%AE%B5.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%96%B0%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E7%BC%93%E5%AD%98.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E7%BC%93%E5%86%B2%E5%8C%BA%E8%A2%AB%E5%86%99%E5%85%A5%E6%AE%B5%E4%BD%86%E6%9C%AA%E5%AE%8C%E6%88%90%E6%8F%90%E4%BA%A4.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%8F%90%E4%BA%A4%E5%90%8E%E7%94%9F%E6%88%90%E6%96%B0%E6%AE%B5%E4%B8%94%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%96%B0%E7%9A%84%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%E5%B9%B6%E4%B8%94%E8%A2%AB%E8%BF%BD%E5%8A%A0%E5%88%B0%E4%BA%86%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/Refresh%E5%AE%8C%E6%88%90%E5%90%8E%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%BD%86%E6%98%AF%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E4%BC%9A.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E6%96%AD%E7%A7%AF%E7%B4%AF%E6%96%87%E6%A1%A3.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/Flush%E4%B9%8B%E5%90%8E%E6%AE%B5%E8%A2%AB%E5%85%A8%E9%87%8F%E6%8F%90%E4%BA%A4%E5%B9%B6%E4%B8%94%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E8%A2%AB%E6%B8%85%E7%A9%BA.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E4%B8%A4%E4%B8%AA%E6%8F%90%E4%BA%A4%E4%BA%86%E7%9A%84%E6%AE%B5%E5%92%8C%E4%B8%80%E4%B8%AA%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%90%88%E5%B9%B6%E5%88%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E7%9A%84%E6%AE%B5.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E5%90%88%E5%B9%B6%E7%BB%93%E6%9D%9F%E5%90%8E%E8%80%81%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%88%A0%E9%99%A4.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B91.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B92.png">
<meta property="og:image" content="http://47.88.24.11/imgs/ES/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.png">
<meta property="og:updated_time" content="2020-09-28T13:11:01.945Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ES 原理分析">
<meta name="twitter:description" content="¶为什么用 ElasticSearch Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。大致上，它有以下重要特征：  面向文档 Lucene 索引 分布式  ¶搭建调试环境 Idea - File - open，打开 build.gradle 文件 选择 gradlew，gradle wrapper 需要设置 JAVA_HOME 环境变量， 1234GlobalBui">
<meta name="twitter:image" content="http://47.88.24.11/imgs/ES/%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/1c3259ad.html">







  <title>ES 原理分析 | Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/1c3259ad.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">ES 原理分析</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-21T09:03:54+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/技术点总结/" itemprop="url" rel="index">
                    <span itemprop="name">技术点总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  16.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  57 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <a id="more"></a>
<h2 id="为什么用-elasticsearch"><a class="header-anchor" href="#为什么用-elasticsearch">¶</a>为什么用 ElasticSearch</h2>
<p>Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。大致上，它有以下重要特征：</p>
<ul>
<li>面向文档</li>
<li>Lucene 索引</li>
<li>分布式</li>
</ul>
<h2 id="搭建调试环境"><a class="header-anchor" href="#搭建调试环境">¶</a>搭建调试环境</h2>
<p>Idea - File - open，打开 <code>build.gradle</code> 文件<br>
选择 gradlew，gradle wrapper<br>
需要设置 JAVA_HOME 环境变量，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GlobalBuildInfoPlugin.java</span><br><span class="line"></span><br><span class="line">// String compilerJavaHome = System.getenv(&quot;JAVA_HOME&quot;);</span><br><span class="line">String compilerJavaHome = &quot;/Users/huanggaochi/Downloads/jdk-12.0.2.jdk/Contents/Home&quot;;</span><br></pre></td></tr></table></figure>
<p>如果需要直接在命令行编译，可以运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gradlew idea</span><br></pre></td></tr></table></figure>
<p>需要设置<code>JAVA_HOME</code>环境变量，或者直接在项目根目录下的 gradlew 文件里加上一行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/Users/huanggaochi/Downloads/jdk-12.0.2.jdk/Contents/Home</span><br></pre></td></tr></table></figure>
<h2 id="索引-映射和文档概念"><a class="header-anchor" href="#索引-映射和文档概念">¶</a>索引、映射和文档概念</h2>
<p>Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns<br>
Elasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields</p>
<blockquote>
<p>将 Type 类比为 Table 并不恰当，因为 ES 中一个索引下的多个类型共用相同的空间。</p>
</blockquote>
<h3 id="索引-类型和映射-index-type-mapping"><a class="header-anchor" href="#索引-类型和映射-index-type-mapping">¶</a>索引、类型和映射 - Index、Type、Mapping</h3>
<p>一个<strong>索引(index)<strong>就像是传统关系数据库中的数据库，它是相关文档存储的地方，实际上是组织数据的逻辑</strong>命名空间</strong>。<br>
在一个索引中，可以定义一种或多种<strong>类型</strong>。</p>
<ul>
<li>作为名词，一个 索引 类似于传统关系数据库中的一个 数据库，是一个存储关系型文档的地方；</li>
<li>作为动词，索引一个文档 就是存储一个文档到一个 索引 （名词）中以便它可以被检索和查询到，文档已存在时会被覆盖掉。</li>
</ul>
<p>一个<strong>类型</strong>是索引的一个逻辑上的分类，代表一类相似的文档，类型由 <strong>名称</strong>（比如 user 或 blogpost）和 <strong>映射</strong> 组成。但是在 ES 6.0.0 以后，这个概念会被废弃。<br>
类型可以很好的抽象划分相似但不相同的数据，但由于 Lucene 的处理方式，类型的使用有些限制。Lucene 没有文档类型的概念，每个文档的类型名被存储在一个叫 _type 的元数据字段上。 当我们要检索某个类型的文档时, Elasticsearch 通过在 _type 字段上使用过滤器限制只返回这个类型的文档。<br>
每个 Lucene 索引中的所有字段都包含一个单一的、扁平的模式。一个特定字段可以映射成 string 类型也可以是 number 类型，但是不能两者兼具（比如两个类型都有一个 name 字段，但是他们映射到不同的数据类型）。</p>
<p><strong>映射</strong>就像数据库中的 schema ，描述了数据在每个字段内如何存储，包括文档可能具有的字段或 属性 、 每个字段的数据类型—比如 string, integer 或 date —以及 Lucene 是如何索引和存储这些字段的。<br>
Lucene 也没有映射的概念，映射是 Elasticsearch 将复杂 JSON 文档 映射 成 Lucene 需要的扁平化数据的方式。</p>
<ul>
<li>比如下面的索引名叫 data，其中定义了 people 和 transactions 类型：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;data&quot;: &#123;</span><br><span class="line">      &quot;mappings&quot;: &#123;</span><br><span class="line">         &quot;people&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">               &quot;name&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">               &#125;,</span><br><span class="line">               &quot;address&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;transactions&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">               &quot;timestamp&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">                  &quot;format&quot;: &quot;strict_date_optional_time&quot;</span><br><span class="line">               &#125;,</span><br><span class="line">               &quot;message&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会被转换为类似下面的映射保存：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;data&quot;: &#123;</span><br><span class="line">      &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;_type&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">          &quot;index&quot;: &quot;not_analyzed&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;address&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;timestamp&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;message&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以虽然创建一个文档后其类型就确定了，但是实际上这个<strong>文档所占用的空间是该索引内所有字段的总和</strong>。<br>
所以有一条建议：一个索引中的类型应当都是相似的，他们有类似的字段，比如 man 和 woman 共享 name 属性；如果两个类型的字段集互不相同，创建一个 类型的文档后将浪费很多空间，而是应该将他们分到不同的索引中。</p>
<h3 id="动态映射机制"><a class="header-anchor" href="#动态映射机制">¶</a>动态映射机制</h3>
<p>在索引一个新的文档时，es 会自动为每个字段推断类型，这个过程称为<strong>动态映射</strong>。这意味着如果你通过引号( “123” )索引一个数字，它会被映射为 string 类型，而不是 long 。但是，如果这个域已经映射为 long ，那么 Elasticsearch 会尝试将这个字符串转化为 long ，如果无法转化，则抛出一个异常。</p>
<h3 id="分析和搜索-analysis-search"><a class="header-anchor" href="#分析和搜索-analysis-search">¶</a>分析和搜索 - Analysis、Search</h3>
<p>分析表示全文是如何处理使之可以被搜索的。<br>
Elasticsearch 除了支持在各种字段上的结构化查询，还支持排序、全文检索并分析相关性。</p>
<h3 id="query-dsl"><a class="header-anchor" href="#query-dsl">¶</a>Query DSL</h3>
<p>特定的查询语言，查询主要分为<strong>评分查询（query）<strong>和</strong>不评分查询（filter）</strong>，前者在查询完毕后还需要为文档进行评分，主要用于全文搜索，而后者只需要决定是否采用结果，所以速度会快一些。<br>
es 提供的查询 DSL 将语句分为<strong>叶子语句（如 match）<strong>和</strong>复合语句（如 bool）</strong>，通过组合可以表达复杂的语义。</p>
<h3 id="倒排索引"><a class="header-anchor" href="#倒排索引">¶</a>倒排索引</h3>
<p>关系型数据库通过增加一个 索引，比如一个 B 树（B-tree）索引 到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 <strong>倒排索引</strong> 的结构来达到相同的目的。</p>
<h3 id="根对象"><a class="header-anchor" href="#根对象">¶</a>根对象</h3>
<p>映射的最高一层被称为 根对象 ，它可能包含下面几项：</p>
<ul>
<li>一个 properties 节点，列出了文档中可能包含的每个字段的映射</li>
<li>各种元数据字段，它们都以一个下划线开头，例如 _type 、 _id 和 _source</li>
<li>设置项，控制如何动态处理新的字段，例如 analyzer 、 dynamic_date_formats 和 dynamic_templates</li>
<li>其他设置，可以同时应用在根对象和其他 object 类型的字段上，例如 enabled 、 dynamic 和 include_in_all</li>
</ul>
<h3 id="文档和字段-document-field"><a class="header-anchor" href="#文档和字段-document-field">¶</a>文档和字段 - Document、Field</h3>
<p>一个文档是一个可被索引的基础信息单元，文档以 JSON 格式来表示。<br>
在一个 index/type 里面，可以存储任意多的文档，每个文档都有唯一 id。<br>
每个文档包含多个字段(fields)，即 json 数据里的字段。</p>
<h3 id="文档元数据"><a class="header-anchor" href="#文档元数据">¶</a>文档元数据</h3>
<p>一个文档不仅仅包含它的数据，也包含 元数据 —— 有关 文档的信息。 三个必须的元数据元素如下：</p>
<ul>
<li>_index<br>
一个 索引 应该是因共同的特性被分组到一起的文档集合。<br>
索引名字必须小写，不能以下划线开头，不能包含逗号。</li>
<li>_type<br>
Lucene 没有文档类型的概念，而是使用一个元数据字段_type 文档表示的对象类别，数据可能在索引中只是松散的组合在一起，但是通常明确定义一些数据中的子分区是很有用的，不同 types 的文档可能有不同的字段，但最好能够非常相似。<br>
一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号， 并且长度限制为 256 个字符。<br>
当我们要检索某个类型的文档时, Elasticsearch 通过在 _type 字段上使用过滤器限制只返回这个类型的文档。</li>
<li>_id<br>
文档唯一标识，和 _index 以及 _type 组合就可以唯一确定 Elasticsearch 中的一个文档。<br>
id 也可以由 Elasticsearch 自动生成。</li>
<li>_version<br>
在 Elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时（包括删除）， _version 的值会递增。这个字段用来确保这些改变在跨多节点时以正确的顺序执行。<br>
版本号——不管是内部的还是引用外部的——都必须是在(0, 9.2E+18)范围内的一个 long 类型的正数。</li>
<li>_source<br>
即索引数据时发送给 Elasticsearch 的原始 JSON 文档。</li>
<li>其他元数据</li>
</ul>
<h3 id="文档属性"><a class="header-anchor" href="#文档属性">¶</a>文档属性</h3>
<p>文档里有几个最重要的设置：</p>
<ul>
<li>
<p>type<br>
字段的数据类型，例如 string 或 date</p>
</li>
<li>
<p>index<br>
字段是否应当被当成全文来搜索（ analyzed ），或被当成一个准确的值（ not_analyzed ），还是完全不可被搜索（ no ）</p>
</li>
<li>
<p>analyzer<br>
确定在索引和搜索时全文字段使用的 analyzer</p>
</li>
<li>
<p>_source<br>
存储代表文档体的 JSON 字符串，和所有被存储的字段一样， _source 字段在被写入磁盘之前先会被压缩。这个字段有以下作用：</p>
<ol>
<li>搜索结果包括了整个可用的文档——不需要额外的从另一个的数据仓库来取文档。</li>
<li>如果没有 _source 字段，部分 update 请求不会生效。</li>
<li>当你的映射改变时，你需要重新索引你的数据，有了_source 字段你可以直接从 Elasticsearch 这样做，而不必从另一个（通常是速度更慢的）数据仓库取回你的所有文档。</li>
<li>当你不需要看到整个文档时，单个字段可以从 _source 字段提取和通过 get 或者 search 请求返回。</li>
</ol>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125;&#125;,</span><br><span class="line">    &quot;_source&quot;: [ &quot;title&quot;, &quot;created&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>调试查询语句更加简单，因为你可以直接看到每个文档包括什么，而不是从一列 id 猜测它们的内容。<br>
也可以调用下面的映射来禁用_source 字段：</li>
</ol>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;my_type&quot;: &#123;</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">                &quot;enabled&quot;: false</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="对象和文档"><a class="header-anchor" href="#对象和文档">¶</a>对象和文档</h3>
<p>通常情况下，我们使用的术语 对象 和 文档 是可以互相替换的。不过，有一个区别： 一个对象仅仅是类似于 hash 、 hashmap 、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。 对象可能包含了另外一些对象。<br>
文档指最顶层或者根对象，这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID 及一些必须的文档元数据。</p>
<h3 id="精确值和全文"><a class="header-anchor" href="#精确值和全文">¶</a>精确值和全文</h3>
<p><strong>精确值</strong>是结构化的，如日期或者用户 ID，字符串也可以表示精确值，例如用户名或邮箱地址，对于精确值来讲，Foo 和 foo 是不同的，2014 和 2014-09-15 也是不同的。<br>
查询精确值很容易，结果是二进制的：要么匹配查询，要么不匹配。<br>
<strong>全文</strong>是指文本数据（通常以人类容易识别的语言书写），例如一个推文的内容或一封邮件的内容。<br>
查询全文数据要微妙的多。我们问的不只是“这个文档匹配查询吗”，而是“该文档匹配查询的程度有多大？”换句话说，该文档与给定查询的相关性如何？es 解决这个需求的办法是为文档建立倒排索引。</p>
<h2 id="分布式概念-distribution"><a class="header-anchor" href="#分布式概念-distribution">¶</a>分布式概念（Distribution）</h2>
<h3 id="集群-cluster"><a class="header-anchor" href="#集群-cluster">¶</a>集群 - Cluster</h3>
<p>一个集群就是由一个或多个节点组织在一起，它们共同持有全部的数据。<br>
一个集群有一个唯一的名字标识 <code>cluster.name</code> ，其节点只能通过指定某个集群的名字，来加入这个集群。</p>
<h3 id="节点-node"><a class="header-anchor" href="#节点-node">¶</a>节点 - Node</h3>
<p>一个节点是集群中的一个服务器，即一个 Elasticsearch 实例。<br>
作为集群的一部分，它存储数据，参与集群的索引和搜索功能。</p>
<h3 id="主节点-master"><a class="header-anchor" href="#主节点-master">¶</a>主节点 - Master</h3>
<p>当一个节点被选举成为主节点时，它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。<br>
主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量增加它也不会成为瓶颈。</p>
<h3 id="分片-shard"><a class="header-anchor" href="#分片-shard">¶</a>分片 - Shard</h3>
<p>一个 分片 是一个底层的 工作单元 ，它仅保存了 <strong>全部数据中的一部分</strong>，是一个 Lucene 的实例，所以它本身就是一个完整的搜索引擎。<br>
一个索引可以被划分成多个分片，创建索引时可指定分片数量，默认是 5。<br>
每个分片是一个 Lucene 实例，它本身也是一个功能完善并且独立的“索引”，这个“索引” 可以被放置到集群中的任何节点上。<br>
分片是 ES 中集群管理的最小单位，在此基础上，ES 允许：</p>
<ul>
<li>允许你水平分割/扩展你的内容容量</li>
<li>允许你在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量</li>
</ul>
<p>分片类似 DB 里的分库分表，是为了解决数据量很大查询效率低下的问题，同时突破单节点磁盘限制。<br>
集群的配置非常灵活，比如对于一个需要占据 100G 磁盘空间的索引，5 个分片每个分片大小 20G，假设单节点磁盘上限 100G，可以有以下几种方案：</p>
<ol>
<li>单节点一个分片：单次只能在 100G 数据里查询一条数据，磁盘占用率 100%。</li>
<li>单节点 5 个分片：每个分片存储 20G 数据，可以 5 个任务并行查询，磁盘占用率 100%，索引大小上限 100G，无法再插入新数据。</li>
<li>集群（2 个节点）5 个分片：一个节点 3 片，另一个节点 2 片，可以并行查找，同时单节点磁盘占用量 &lt;60%，索引最大存储上限为 200G。</li>
<li>集群（5 个节点）5 个分片：每个节点包含一个分片，单节点磁盘占用量 20%，索引最大存储上限为 500G。</li>
</ol>
<p>至于是否有最佳实践，我认为还是得根据实际场景来说话，比如就简单搭建一个开发环境来说，单节点（单分片或多分片）足够，当然，因为没有荣誉，硬件故障时会有数据丢失风险。</p>
<h3 id="主分片和副分片"><a class="header-anchor" href="#主分片和副分片">¶</a>主分片和副分片</h3>
<p>一个分片可以是 主分片或者 副本分片。<br>
索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量，在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。<br>
一个副本分片只是一个主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。</p>
<h3 id="索引-index"><a class="header-anchor" href="#索引-index">¶</a>索引（Index）</h3>
<p>索引实际上是指向一个或者多个物理 分片 的 <strong>逻辑命名空间</strong>。<br>
所以说一个节点包含多个分片没有问题，但是一个节点包含多个索引是不对的，因为索引包含的分片可以存在于多个节点内，且可以在后期添加。</p>
<h3 id="复制-replica"><a class="header-anchor" href="#复制-replica">¶</a>复制（Replica）</h3>
<p>Elasticsearch 允许创建分片的一份或多份拷贝（默认复制 1 份），这些拷贝叫做复制分片。<br>
在分片/节点失败的情况下，复制提供了高可用性。<br>
因为搜索可以在所有的复制上并行运行，复制可以扩展你的搜索量/吞吐量<br>
复制分片不与相同的主分片置于同一节点上，否则失去备份的意义。</p>
<p>总而言之：</p>
<ol>
<li>每个索引可以被分成多个分片。</li>
<li>一个索引也可以被复制 0 次（即没有复制） 或多次。</li>
<li>一旦复制了，每个索引就有了主分片（作为复制源的分片）和复制分片（主分片的拷贝）。</li>
<li>分片和复制的数量可以在索引创建的时候指定。在索引创建之后，可以在任何时候动态地改变复制的数量，但是不能再改变分片的数量。</li>
</ol>
<p>至于 ES 集群中如何分配分片与备份，都是 ES 内部维护管理的，对用户完全透明。</p>
<h2 id="es-整体架构"><a class="header-anchor" href="#es-整体架构">¶</a>ES 整体架构</h2>
<p>TODO</p>
<h2 id="es-节点启动和关闭"><a class="header-anchor" href="#es-节点启动和关闭">¶</a>ES 节点启动和关闭</h2>
<h3 id="检测外部环境"><a class="header-anchor" href="#检测外部环境">¶</a>检测外部环境</h3>
<p>Bootstrap#setup：初始化 node 时重写 validateNodeBeforeAcceptingRequests，在其中包含了检查逻辑<br>
-&gt; BootstrapChecks.check</p>
<h3 id="启动各模块"><a class="header-anchor" href="#启动各模块">¶</a>启动各模块</h3>
<p>Bootstrap#start<br>
-&gt; Node#start：调各子模块的 start 来初始化</p>
<h3 id="keepalive"><a class="header-anchor" href="#keepalive">¶</a>keepalive</h3>
<p>唯一的用户线程，作用是保持进程运行。</p>
<p>Bootstrap#keepAliveThread</p>
<h3 id="节点关闭"><a class="header-anchor" href="#节点关闭">¶</a>节点关闭</h3>
<p>Bootstrap#stop<br>
-&gt; IOUtils#close：关闭 node，注意 Node 实现了 Closable<br>
-&gt; Node#close</p>
<h2 id="选主"><a class="header-anchor" href="#选主">¶</a>选主</h2>
<p>ES 默认服务发现实现是内置的<code>Zen Discovery</code></p>
<h3 id="选举相关概念"><a class="header-anchor" href="#选举相关概念">¶</a>选举相关概念</h3>
<ul>
<li>选举（Election）</li>
<li>主从（主：Leader、Coordinator、Master，从：Follower、Slave）</li>
<li>分布式哈希表（DHT）</li>
<li>多数派（法定人数、Quorum）</li>
<li>分区和脑裂：集群中出现双主或多主。</li>
<li>Bully 算法</li>
<li>Paxos 算法</li>
</ul>
<h3 id="配置"><a class="header-anchor" href="#配置">¶</a>配置</h3>
<ul>
<li>node.master：决定当前节点是否具备 Master 资格</li>
<li>discovery.zen.minimum_master_nodes</li>
<li>discovery.zen.ignore_non_master_pings</li>
</ul>
<h3 id="本地节点实例的创建"><a class="header-anchor" href="#本地节点实例的创建">¶</a>本地节点实例的创建</h3>
<p>管理节点配置<br>
Node#localNodeFactory</p>
<h3 id="选主流程"><a class="header-anchor" href="#选主流程">¶</a>选主流程</h3>
<p>ZenDiscovery 的选主流程如下：</p>
<ol>
<li>每个节点计算最小的已知节点 ID，该节点为临时 Master，向该节点发送领导投票；</li>
<li>如果一个节点收到足够多的票数，并且该节点也为自己投票，那么它将扮演领导者的角色，开始发布集群状态。</li>
</ol>
<h3 id="选举临时-master"><a class="header-anchor" href="#选举临时-master">¶</a>选举临时 Master</h3>
<p>Node#start<br>
-&gt; ZenDiscovery#startInitialJoin<br>
-&gt; ZenDiscovery#JoinThreadControl#startNewThreadIfNotRunning<br>
-&gt; threadPool.generic().execute：使用 generic 线程池执行选主流程<br>
-&gt; ZenDiscovery#innerJoinCluster：加入集群<br>
-&gt; ZenDiscovery#findMaster：查找当前集群的活跃 Master，或者从候选者中选择新的 Master<br>
-&gt; ZenDiscovery#pingAndWait：ping 一下所有节点（除了本节点），获取 pingResponses<br>
-&gt; 构建<strong>activeMasters</strong>列表，将每个节点所认为的当前 Master 节点加入 activeMasters 列表<br>
-&gt; 构建<strong>masterCandidates</strong>列表，从 pingResponses 列表中去掉不具备 Master 资格的节点<br>
-&gt; 如果 activeMasters 为空，则从 masterCandidates 中选举，否则从 activeMasters 中选择最合适的作为 Master</p>
<h3 id="从-mastercandidates-选主"><a class="header-anchor" href="#从-mastercandidates-选主">¶</a>从 masterCandidates 选主</h3>
<p>activeMasters 为空一般发生在集群刚启动或大规模重启的情况下。</p>
<p>ZenDiscovery#findMaster<br>
-&gt; ElectMasterService#hasEnoughCandidates：当前候选人数是否达到法定人数，若未达到则直接令选举失败<br>
-&gt; ElectMasterService#electMaster：当候选者达到法定人数后，从中选出一个作为 Master，选择前需要先用自定义比较函数进行排序<br>
-&gt; MasterCandidate.compare 自定义的排序逻辑</p>
<p>排序条件：</p>
<ol>
<li>版本号大的优先；</li>
<li>具备 Master 资格的优先；</li>
<li>节点 ID 小的优先。</li>
</ol>
<h3 id="从-activemasters-列表中选主"><a class="header-anchor" href="#从-activemasters-列表中选主">¶</a>从 activeMasters 列表中选主</h3>
<p>此时列表中存储着集群当前活跃的 Master，从这些已知的 Master 节点中选择一个作为选举结果。</p>
<p>ZenDiscovery#findMaster<br>
-&gt; ElectMasterService#tieBreakActiveMasters：使用自定义比较函数排序后取第一个<br>
-&gt; ElectMasterService#compareNodes</p>
<p>排序条件：</p>
<ol>
<li>具备 Master 资格的优先；</li>
<li>节点 ID 小的优先。</li>
</ol>
<h3 id="收集投票进行统计"><a class="header-anchor" href="#收集投票进行统计">¶</a>收集投票进行统计</h3>
<p>ZenDiscovery#handleJoinRequest<br>
-&gt; NodeJoinController#handleJoinRequest<br>
-&gt; NodeJoinController.ElectionContext#addIncomingJoin 将收到的连接存储到 NodeJoinController.ElectionContext#joinRequestAccumulator 中</p>
<p>NodeJoinController.ElectionContext#getPendingMasterJoinsCount：节点检查收到的投票是否足够时，就是检查加入它的连接数是否足够，其中会去掉没有 Master 资格节点的投票</p>
<h3 id="加入集群"><a class="header-anchor" href="#加入集群">¶</a>加入集群</h3>
<p>如果按以上逻辑选举出的临时 Master 是本节点：</p>
<ol>
<li>等待足够多的具备 Master 资格的节点加入本节点，直到投票达到法定人数，完成选举；</li>
<li>超时（默认 30 秒且可配置）后还没有满足数量的 join 请求，则选举失败，需要进行新一轮选举；</li>
<li>成功后发布新的 clusterState。</li>
</ol>
<p>ZenDiscovery#innerJoinCluster<br>
NodeJoinController#waitToBeElectedAsMaster</p>
<p>如果按以上逻辑选举出的临时 Master 并非本节点：</p>
<ol>
<li>不再接受其他节点的 join 请求；</li>
<li>向 Master 发送 join 请求，并等待回复。超时时间默认为 1 分钟（可配置），如果遇到异常，则默认重试 3 次（可配置）。</li>
<li>最终当选的 Master 会先发布集群状态，再确认客户的 join 请求，因此，joinElectedMaster 返回代表收到了 join 请求的确认，并且已经收到了集群状态。本步骤检查收到的集群状态中的 Master 节点如果为空，或者当选的 Master 不是之前选择的节点，则重新选举。</li>
</ol>
<p>ZenDiscovery#innerJoinCluster<br>
-&gt; ZenDiscovery#joinElectedMaster</p>
<h2 id="数据副本模型"><a class="header-anchor" href="#数据副本模型">¶</a>数据副本模型</h2>
<p>主从模型是分布式的经典模型之一，通过主节点的选举可以实现高可用。的那个然主从只能提高可用性，如果要性能上的可伸缩性，一般还会对数据进行 hash。<br>
主从模型实际上也是下面将要讨论的分布式文档存储、搜索的基础。</p>
<blockquote>
<p>HDFS、Cassandra 等使用的是对等模型。</p>
</blockquote>
<h3 id="pacifica-算法"><a class="header-anchor" href="#pacifica-算法">¶</a>PacificA 算法</h3>
<p>ES 的主副本模型的实现参考了微软的 PacificA 算法，下面是算法中涉及到的几个概念：</p>
<ul>
<li>Replica Group</li>
<li>Configuration</li>
<li>Configuration Version</li>
<li>Serial Number（SN）</li>
</ul>
<p>PacificA 算法运行在分布式系统之上，对系统有以下几项假设：</p>
<ul>
<li>节点可以失效，对消息延迟的上限不做假设；</li>
<li>消息可以丢失、乱序，但不能被篡改，即不存在<strong>拜占庭问题</strong>；</li>
</ul>
<blockquote>
<p>拜占庭问题</p>
</blockquote>
<ul>
<li>网络分区可以发生，系统时钟可以不同步，但<strong>漂移</strong>是有限度的。</li>
</ul>
<blockquote>
<p>漂移</p>
</blockquote>
<h3 id="存储管理-写入"><a class="header-anchor" href="#存储管理-写入">¶</a>存储管理 - 写入</h3>
<p>数据的读取和更新策略，及使用多副本方式保证数据的可靠性和可用性。<br>
数据写流程如下：<br>
<img src="http://47.88.24.11/imgs/ES/%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png" alt="数据写入流程" title="数据写入流程"></p>
<ol>
<li>写请求进入主副本节点；</li>
<li>节点为该请求分配 SN，并使用该 SN 创建 UpdateRequest，然后将该 UpdateRequest 插入自己的 prepareList；</li>
<li>主副本将携带 SN 的 UpdateRequest 发往从副本节点，从节点收到后同样插入 prepareList；</li>
<li>主副本节点接收到所有从副本节点的 ACK 响应，确认该数据已经被写入到所有的从副本节点；</li>
<li>此时达到了可提交的状态，主副本将此 UpdateRequest 放入 committedList，committedList 向前移动；</li>
<li>主副本节点回复客户端更新成功。</li>
<li>主节点向从节点发送 commit 通知，告诉它们自己的 committed point 位置，从节点收到通知后根据指示来移动 committed point 到相同位置。</li>
</ol>
<p>数据存储流程中遵循不变式<code>Commit Invariant</code>：</p>
<ol>
<li>主节点 committedList 是任何一个从节点 prepareList 的前缀（子集）；</li>
<li>任一从节点上的 committedList 是主节点上 committedList 的前缀（子集）。</li>
</ol>
<h3 id="配置管理"><a class="header-anchor" href="#配置管理">¶</a>配置管理</h3>
<p>对配置信息进行管理，维护所有配置信息的一致性。<br>
配置同样遵循版本控制，由一个全局的配置管理器管理所有副本组的配置。<br>
当节点向管理器提出添加/移除副本的请求时，每次请求都需要附带当前配置版本号，只有这个版本号和管理器记录的版本号一致的情况下才能被执行，如果请求执行成功，则这个新配置会被赋予新的版本号。</p>
<h3 id="allocation-ids"><a class="header-anchor" href="#allocation-ids">¶</a>Allocation IDs</h3>
<p>TODO</p>
<h3 id="sequence-ids"><a class="header-anchor" href="#sequence-ids">¶</a>Sequence IDs</h3>
<p>TODO</p>
<h3 id="乐观并发控制"><a class="header-anchor" href="#乐观并发控制">¶</a>乐观并发控制</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E9%97%AE%E9%A2%98.png" alt="并发更新问题" title="并发更新问题"><br>
如上图所示 Web-2 不知道自己的对象拷贝已经过期，结果执行更新时会认为库存尚充足。<br>
像这样的变更越频繁，读数据和更新数据的间隙越长，也就越可能丢失变更。<br>
在数据库领域中，有两种策略通常被用来确保并发更新时变更不会丢失：</p>
<ul>
<li>悲观并发控制<br>
这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此<strong>阻塞访问资源以防止冲突</strong>。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。</li>
<li>乐观并发控制<br>
Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，<strong>如果源数据在读写当中被修改，更新将会失败</strong>。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。</li>
</ul>
<p>Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些<strong>复制请求被并行发送，并且到达目的地时也许 顺序是乱的</strong>。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。</p>
<ol>
<li>
<p>内部版本号<br>
当我们之前讨论 index ， GET 和 delete 请求时，我们指出每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。<br>
当我们在更新数据时，需要指定想要修改文档的_version，如果该版本不是当前版本号，我们的请求将会失败。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/1?version=1 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Starting to get the hang of this...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>外部版本号<br>
一个常见的设置是使用其它数据库作为主要的数据存储，使用 Elasticsearch 做数据检索，Elasticsearch 提供了一种机制来重用主数据库中已经存在的版本号字段。<br>
外部版本号的处理方式和我们之前讨论的内部版本号的处理方式有些不同， Elasticsearch 不是检查当前 _version 和请求中指定的版本号是否相同， 而是检查当前 _version 是否 小于 指定的版本号。 如果是则请求成功，外部的版本号作为文档的新 _version 进行存储，这意味着每次请求必须先在主数据库中增加版本号的值，再将新版本的数据索引到 Elasticsearch 中。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/2?version=5&amp;version_type=external</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first external blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Starting to get the hang of this...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="分布式文档存储"><a class="header-anchor" href="#分布式文档存储">¶</a>分布式文档存储</h2>
<h3 id="相关配置"><a class="header-anchor" href="#相关配置">¶</a>相关配置</h3>
<ul>
<li>wait_for_active_shards：开始执行写入操作前需要等待的活跃分片数量，主要用于维护写一致性。</li>
</ul>
<h3 id="文档路由"><a class="header-anchor" href="#文档路由">¶</a>文档路由</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>
<p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （<strong>主分片的数量</strong>）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。<br>
这就解释了为什么我们要在<strong>创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量</strong>：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。<br>
所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。</p>
<blockquote>
<p>主节点数固定不是一件好事，我们会在<strong>集群扩容</strong>里提到如何解决扩容问题。</p>
</blockquote>
<h3 id="分发机制"><a class="header-anchor" href="#分发机制">¶</a>分发机制</h3>
<p>可以将请求发送到 集群中的任何节点 ，包括主节点。<strong>每个节点都知道任意文档所处的位置</strong>，并且能够将我们的请求直接转发到存储我们所需文档的节点。无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。<br>
一个分片是一个 Lucene 实例，我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互的。Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。当你的集群规模扩大或者缩小时，Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。<br>
我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。但是为了更好地实现负载均衡，我们一般会轮询节点，每次接受请求的节点称为 <strong>（协调节点）</strong>，比如下面的 Node1。</p>
<h3 id="consistency"><a class="header-anchor" href="#consistency">¶</a>consistency</h3>
<p>为了保证一致性，在默认设置下，即使仅仅是在试图执行一个_写_操作之前，主分片都会要求 必须要有 <em>规定数量(quorum)</em>（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。</p>
<p>注意：下面的参数只对 ElasticSearch 5.0 以下的版本有效，在 ElasticSearch 5.0 之后貌似使用 wait_for_active_shards 代替了 consistency。所以之前的参数了解即可，实际可以参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-create-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-create-index.html</a><br>
consistency 有三种取值：</p>
<ol>
<li>
<p>quorum（规定大多数，默认）</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int( (primary + number_of_replicas) / 2 ) + 1</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>one（只要主分片 ok 就可以）</p>
</li>
<li>
<p>all（必须要主分片和所有副本分片的状态都没问题才允许执行写操作）</p>
</li>
</ol>
<h3 id="timeout"><a class="header-anchor" href="#timeout">¶</a>timeout</h3>
<p>如果没有足够的副本分片数，Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待 1 分钟。可以设置 timeout 的值来修改等待时间。</p>
<h3 id="创建-索引-删除"><a class="header-anchor" href="#创建-索引-删除">¶</a>创建、索引、删除</h3>
<p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片，所以需要：</p>
<ol>
<li>先<strong>根据 id 确定其所属的主分片位置</strong>；</li>
<li>主分片若执行成功，将请求并行转发到副本分片上；</li>
<li>Node3 上的主分片执行成功，向协调节点报告成功，协调节点再汇报给客户端；<br>
<img src="http://47.88.24.11/imgs/ES/%E6%96%B0%E5%A2%9E%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%A0%E9%99%A4.png" alt="新增、索引、删除" title="新增、索引、删除"></li>
</ol>
<h3 id="取回单个文档"><a class="header-anchor" href="#取回单个文档">¶</a>取回单个文档</h3>
<p>可以从主分片或者从其它任意副本分片检索文档：</p>
<ol>
<li>向协调节点发送请求，请求方式是轮询，比如上次从 2 获取到数据，则这次从 3 开始；</li>
<li>使用 id 确定文档所处主分片位置，如果存在多份则返回第一份即可；</li>
<li>协调节点将文档返回给客户端<br>
<img src="http://47.88.24.11/imgs/ES/%E5%8F%96%E5%9B%9E%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png" alt="取回单个文档" title="取回单个文档"></li>
</ol>
<h3 id="局部更新"><a class="header-anchor" href="#局部更新">¶</a>局部更新</h3>
<p>部分更新包括读取和写入两个过程：</p>
<ol>
<li>同样先向协调节点发送更新请求；</li>
<li>从 id 计算出文档所在的主分片位置；</li>
<li>从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</li>
<li>如果成功地更新文档，它将新版本的文档（而<strong>不是更新请求本身</strong>，因为如果以错误的顺序到达，可能导致文档损坏）并行转发到其他节点的副本分片，重新建立索引。</li>
<li>一旦所有副本分片都返回成功，向协调节点也返回成功，协调节点向客户端返回成功。<br>
<img src="http://47.88.24.11/imgs/ES/%E5%B1%80%E9%83%A8%E6%9B%B4%E6%96%B0.png" alt="局部更新" title="局部更新"></li>
</ol>
<h3 id="mget-批量读"><a class="header-anchor" href="#mget-批量读">¶</a>mget（批量读）</h3>
<p>mget 和 bulk API 的 模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。</p>
<ol>
<li>将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点；</li>
<li>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。<br>
<img src="http://47.88.24.11/imgs/ES/%E6%89%B9%E9%87%8F%E8%AF%BB.png" alt="批量读" title="批量读"></li>
</ol>
<h3 id="bulk-批量改"><a class="header-anchor" href="#bulk-批量改">¶</a>bulk（批量改）</h3>
<ol>
<li>协调节点接受请求，为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机；</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<blockquote>
<p>bulk API 格式中有换行符，这是因为请求文档可能属于不同的主分片，如果将这些文档放到一个 JSON 数组中，则需要解析它们并重新创建请求数组，这需要占用大量 RAM 空间来存储原数据的副本，JVM 将不得不花费时间进行垃圾回收。<br>
<img src="http://47.88.24.11/imgs/ES/%E6%89%B9%E9%87%8F%E6%94%B9.png" alt="批量改" title="批量改"></p>
</blockquote>
<h3 id="写入流程-协调节点"><a class="header-anchor" href="#写入流程-协调节点">¶</a>写入流程 - 协调节点</h3>
<p>TransportAction#execute<br>
-&gt; ActionRequest#validate：参数检查<br>
处理 pipeline 请求<br>
-&gt; TransportAction.RequestFilterChain#proceed<br>
-&gt; TransportBulkAction#doExecute<br>
-&gt; TransportBulkAction#createIndex：自动创建索引<br>
-&gt; TransportBulkAction#executeBulk：索引创建成功后，执行批量操作<br>
-&gt; TransportBulkAction.BulkOperation#doRun<br>
-&gt;</p>
<ol>
<li>对请求的预先处理</li>
<li>检测集群状态</li>
</ol>
<h3 id="写入流程-主分片节点"><a class="header-anchor" href="#写入流程-主分片节点">¶</a>写入流程 - 主分片节点</h3>
<h2 id="分布式搜索"><a class="header-anchor" href="#分布式搜索">¶</a>分布式搜索</h2>
<p>在分布式环境中执行的搜索是一个两阶段的过程，我们称之为 <strong>query then fetch</strong> 。</p>
<h3 id="查询阶段"><a class="header-anchor" href="#查询阶段">¶</a>查询阶段</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E6%9F%A5%E8%AF%A2%E9%98%B6%E6%AE%B5.png" alt="查询阶段" title="查询阶段"></p>
<ul>
<li>
<p>客户端发送一个 search 请求到协调节点（也就是 Node 3），协调节点会创建一个大小为 <code>from+size</code> 的<strong>空优先队列</strong></p>
</li>
<li>
<p>协调节点将请求广播到索引中每一个分片拷贝（主分片或者副本分片）。</p>
</li>
<li>
<p>每个分片在本地执行搜索并构建一个匹配文档的 <strong>优先队列</strong>。<br>
一个 优先队列 仅仅是一个存有 top-n 匹配文档的有序列表。优先队列的大小取决于分页参数 from 和 size ，其值为 from + size，比如下面的搜索请求需要足够大的优先队列来放入 100 条文档。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;from&quot;: 90,</span><br><span class="line">    &quot;size&quot;: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>协调节点将在之后的请求中轮询所有的分片拷贝来分摊负载，因此更多的副本（结合更多的硬件）能增加搜索吞吐率。<br>
每个分片返回各自优先队列中所有文档的 ID 和排序值（_score）给协调节点 ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</p>
</li>
</ul>
<h3 id="取回阶段"><a class="header-anchor" href="#取回阶段">¶</a>取回阶段</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E5%8F%96%E5%9B%9E%E9%98%B6%E6%AE%B5.png" alt="取回阶段" title="取回阶段"></p>
<ul>
<li>协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。</li>
<li>每个分片加载并 丰富 文档（_source），如果有需要的话，接着返回文档给协调节点。</li>
<li>一旦所有的文档都被取回了，协调节点需要对 number_of_shards * (from + size) 大小的文档集合排序，协调节点返回结果给客户端。</li>
</ul>
<h3 id="深分页问题-deep-pagination"><a class="header-anchor" href="#深分页问题-deep-pagination">¶</a>深分页问题（Deep Pagination）</h3>
<p>先查后取的过程支持用 <code>from</code> 和 <code>size</code> 参数分页，但是这是 有限制的 。 要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 <code>number_of_shards * (from + size)</code> 排序文档，来找到被包含在 size 里的文档。<br>
取决于你的文档的大小，分片的数量和你使用的硬件，给 10,000 到 50,000 的结果文档深分页（ 1,000 到 5,000 页）是完全可行的。但是使用足够大的 from 值，排序过程可能会变得非常沉重，使用大量的 CPU、内存和带宽。因为这个原因，我们强烈建议你不要使用深分页。<br>
实际上，深分页很少符合人的行为。当 2 到 3 页过去以后，人会停止翻页，并且改变搜索标准。会不知疲倦地一页一页的获取网页直到你的服务崩溃的罪魁祸首一般是机器人或者 web spider。<br>
如果你确实需要从你的集群取回大量的文档，你可以通过用 <code>scroll</code> 查询禁用排序使这个取回行为更有效率</p>
<h3 id="偏好"><a class="header-anchor" href="#偏好">¶</a>偏好</h3>
<p>偏好这个参数 <code>preference</code> 允许 用来控制由哪些分片或节点来处理搜索请求。 它接受像 <code>_primary, _primary_first, _local, _only_node:xyz, _prefer_node:xyz, 和 _shards:2,3</code> 这样的值，在<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/search-request-preference.html" target="_blank" rel="noopener">search Preference</a>有说明。<br>
偏好字段可以用于解决<strong>Bouncing Results</strong>问题。</p>
<blockquote>
<p>Bouncing Results<br>
想象一下有两个文档有同样值的时间戳字段，搜索结果用 timestamp 字段来排序。 由于搜索请求是在所有有效的分片副本间轮询的，那就有可能发生主分片处理请求时，这两个文档是一种顺序， 而副本分片处理请求时又是另一种顺序。<br>
这就是所谓的 bouncing results 问题: 每次用户刷新页面，搜索结果表现是不同的顺序。 让同一个用户始终使用同一个分片，这样可以避免这种问题， 可以设置 preference 参数为一个特定的任意值比如用户会话 ID 来解决。</p>
</blockquote>
<h3 id="超时"><a class="header-anchor" href="#超时">¶</a>超时</h3>
<p>通常分片处理完它所有的数据后再把结果返回给协调节点，协调节点把收到的所有结果合并为最终结果。这意味着花费的时间是最慢分片的处理时间加结果合并的时间。如果有一个节点有问题，就会导致所有的响应缓慢。<br>
参数 <code>timeout</code> 告诉 分片允许处理数据的最大时间。如果没有足够的时间处理所有数据，这个分片的结果可以是部分的，甚至是空数据。<br>
搜索的返回结果会用属性 timed_out 标明分片是否返回的是部分结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">&quot;time_out&quot;: true // 表示搜索请求超时了</span><br></pre></td></tr></table></figure>
<p>很有可能查询会超过设定的超时时间，这种情况可能有两个原因：</p>
<ol>
<li>超时检查是基于每文档做的。 但是某些查询类型有大量的工作在文档评估之前需要完成。 这种 “setup” 阶段并不考虑超时设置，所以太长的建立时间会导致超过超时时间的整体延迟。</li>
<li>因为时间检查是基于每个文档的，一次长时间查询在单个文档上执行并且在下个文档被评估之前不会超时。 这也意味着差的脚本（比如带无限循环的脚本）将会永远执行下去。</li>
</ol>
<h3 id="路由"><a class="header-anchor" href="#路由">¶</a>路由</h3>
<p>路由能够在索引时提供来确保相关的文档，比如属于某个用户的文档被存储在某个分片上。 在搜索的时候，不用搜索索引的所有分片，而是通过指定几个 routing 值来限定只搜索几个相关的分片：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?routing=user_1,user2</span><br></pre></td></tr></table></figure>
<h3 id="搜索类型"><a class="header-anchor" href="#搜索类型">¶</a>搜索类型</h3>
<p>缺省的搜索类型是 <code>query_then_fetch</code> 。 在某些情况下，你可能想明确设置 <code>search_type</code> 为 <code>dfs_query_then_fetch</code> 来改善相关性精确度：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?search_type=dfs_query_then_fetch</span><br></pre></td></tr></table></figure>
<p>搜索类型 <code>dfs_query_then_fetch</code> 有预查询阶段，这个阶段可以从所有相关分片获取词频来计算全局词频。</p>
<h3 id="游标查询-scroll"><a class="header-anchor" href="#游标查询-scroll">¶</a>游标查询 Scroll</h3>
<p><code>scroll</code> 查询 可以用来对 Elasticsearch 有效地执行大批量的文档查询，而又不用付出深度分页那种代价。<br>
游标查询允许我们 先做查询初始化，然后再批量地拉取结果。 这有点儿像传统数据库中的 <code>cursor</code> 。<br>
游标查询会取某个时间点的快照数据。 查询初始化之后索引上的任何变化会被它忽略。 它通过保存旧的数据文件来实现这个特性，结果就像保留初始化时的索引 <code>视图</code> 一样。<br>
深度分页的代价根源是结果集全局排序，如果去掉全局排序的特性的话查询结果的成本就会很低。 游标查询用字段 <code>_doc</code> 来排序。 这个指令让 Elasticsearch 仅仅从还有结果的分片返回下一批结果。<br>
启用游标查询可以通过在查询的时候设置参数 scroll 的值为我们期望的游标查询的过期时间。 游标查询的过期时间会在每次做查询的时候刷新，所以这个时间只需要足够处理当前批的结果就可以了，而不是处理查询结果的所有文档的所需时间。 这个过期时间的参数很重要，因为保持这个游标查询窗口需要消耗资源，所以我们期望如果不再需要维护这种资源就该早点儿释放掉。 设置这个超时能够让 Elasticsearch 在稍后空闲的时候自动释放这部分资源。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /old_index/_search?scroll=1m // 保持游标查询窗口一分钟。</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125;&#125;,</span><br><span class="line">    &quot;sort&quot; : [&quot;_doc&quot;], // 关键字 _doc 是最有效的排序顺序。</span><br><span class="line">    &quot;size&quot;:  1000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个查询的返回结果包括一个字段 <code>_scroll_id</code>， 它是一个 base64 编码的长字符串。现在我们能传递字段 <code>_scroll_id</code> 到 <code>_search/scroll</code> 查询接口获取下一批结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    &quot;scroll&quot;: &quot;1m&quot;, // 注意再次设置游标查询过期时间为一分钟。</span><br><span class="line">    &quot;scroll_id&quot; : &quot;cXVlcnlUaGVuRmV0Y2g7NTsxMDk5NDpkUmpiR2FjOFNhNnlCM1ZDMWpWYnRROzEwOTk1OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MTA5OTM6ZFJqYkdhYzhTYTZ5QjNWQzFqVmJ0UTsxMTE5MDpBVUtwN2lxc1FLZV8yRGVjWlI2QUVBOzEwOTk2OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MDs=&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个游标查询返回的下一批结果。 尽管我们指定字段 size 的值为 1000，我们有可能取到超过这个值数量的文档。 当查询的时候， 字段 size 作用于单个分片，所以每个批次实际返回的文档数量最大为 <code>size * number_of_primary_shards</code>。<br>
当没有更多结果返回的时候，我们就处理完所有匹配的文档了。</p>
<h2 id="索引原理"><a class="header-anchor" href="#索引原理">¶</a>索引原理</h2>
<p>基于 Lucene，ES 实现了分布式的索引管理。</p>
<h3 id="索引策略"><a class="header-anchor" href="#索引策略">¶</a>索引策略</h3>
<p>在 Elasticsearch 中， <strong>每个字段的所有数据 都是 默认被索引的</strong> 。 即每个字段都有为了快速检索设置的专用<strong>倒排索引</strong>。<br>
倒排索引由一些词项组成，每个词项包含了它所有曾出现过的文档的列表。<br>
Term  | Doc 1 | Doc 2 | Doc 3 |</p>
<hr>
<p>brown |   X   |       |  X    | …<br>
fox   |   X   |   X   |  X    | …<br>
quick |   X   |   X   |       | …<br>
the   |   X   |       |  X    | …</p>
<p>另外，这个倒排索引相比特定词项出现过的文档列表，会包含更多其它信息。它会保存每一个词项出现过的文档总数， 在对应的文档中一个具体词项出现的总次数，词项在文档中的顺序，每个文档的长度，所有文档的平均长度，等等。这些统计信息允许 Elasticsearch 决定哪些词比其它词更重要，哪些文档比其它文档更重要，用于搜索时计算文档的相关性。</p>
<h3 id="不变性"><a class="header-anchor" href="#不变性">¶</a>不变性</h3>
<p>倒排索引被写入磁盘后是 不可改变 的:它永远不会修改。 不变性有重要的价值：</p>
<ul>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li>
<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
<li>其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
<li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。</li>
</ul>
<p>当然，一个不变的索引也有不好的地方：</p>
<ul>
<li>由于不变性，你不能修改它，如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这对一个索引能包含的数据量和被更新频率造成很大限制。</li>
</ul>
<h3 id="段和提交点"><a class="header-anchor" href="#段和提交点">¶</a>段和提交点</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E4%B8%80%E4%B8%AALucene%E7%B4%A2%E5%BC%95%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4%E7%82%B9%E5%92%8C%E4%B8%89%E4%B8%AA%E6%AE%B5.png" alt="一个Lucene索引包含一个提交点和三个段" title="一个Lucene索引包含一个提交点和三个段"></p>
<ul>
<li>每一个段本身都是一个倒排索引，索引在 Lucene 中表示所有段的集合。</li>
</ul>
<blockquote>
<p>一个 Lucene 索引在 Elasticsearch 中被称作分片，一个 Elasticsearch 索引是分片的集合，当 Elasticsearch 在索引中搜索的时候，会发送查询请求到每一个属于该索引的分片，然后合并每个分片的结果到一个全局的结果集中。</p>
</blockquote>
<ul>
<li>提交点是一个列出了所有已知段的文件，Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</li>
</ul>
<h3 id="动态更新索引"><a class="header-anchor" href="#动态更新索引">¶</a>动态更新索引</h3>
<ol>
<li>新文档首先被添加到内存索引缓存中；<br>
<img src="http://47.88.24.11/imgs/ES/%E6%96%B0%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E7%BC%93%E5%AD%98.png" alt="新文档被添加到缓存" title="新文档被添加到缓存"></li>
<li>提交是针对缓存进行的：
<ul>
<li>生成一个新的段（倒排索引）并被写入磁盘；</li>
<li>一个新的包含新段名字的<strong>提交点</strong>被写入磁盘，此时文档在缓存中、还未被刷新到磁盘，如下图所示；</li>
<li>磁盘同步（<code>fsync</code>），所有在文件系统缓存中等待的写入都被刷新到磁盘，以确保它们被写入物理文件。<br>
<img src="http://47.88.24.11/imgs/ES/%E7%BC%93%E5%86%B2%E5%8C%BA%E8%A2%AB%E5%86%99%E5%85%A5%E6%AE%B5%E4%BD%86%E6%9C%AA%E5%AE%8C%E6%88%90%E6%8F%90%E4%BA%A4.png" alt="缓冲区被写入段但未完成提交" title="缓冲区被写入段但未完成提交"></li>
</ul>
</li>
<li>新的段被开启，它包含的文档可以被搜索；</li>
<li>内存缓存被清空，等待接收新的文档。<br>
<img src="http://47.88.24.11/imgs/ES/%E6%8F%90%E4%BA%A4%E5%90%8E%E7%94%9F%E6%88%90%E6%96%B0%E6%AE%B5%E4%B8%94%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA.png" alt="提交后生成新段且缓存被清空" title="提交后生成新段且缓存被清空"></li>
</ol>
<p>当一个查询被触发时，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。</p>
<h3 id="删除和更新索引"><a class="header-anchor" href="#删除和更新索引">¶</a>删除和更新索引</h3>
<p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个 <code>.del</code> 文件，文件中会列出这些被删除文档的段信息。<br>
当一个文档被 <strong>删除</strong> 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。<br>
文档<strong>更新</strong>也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p>
<h3 id="准实时搜索与刷新策略"><a class="header-anchor" href="#准实时搜索与刷新策略">¶</a>准实时搜索与刷新策略</h3>
<p>对一个文档进行更新操作后可能会发现属性还是旧的值，我们称之为<strong>准实时现象</strong>：更新的数据还存在于内存中、还未刷新到磁盘上。</p>
<ul>
<li>在索引期新文档会写入<strong>索引段</strong>，这些索引段是独立的，这意味着查询是可以与索引并行的，只是不时会有新增的索引段被添加到可被搜索的索引段集合之中。</li>
<li>Lucene 通过创建后续的（基于索引只写一次的特性）segments_N 文件来实现此功能，且该文件列举了索引中的索引段。这个过程称为<strong>提交（committing）</strong>，Lucene 以一种安全的方式来执行该操作，能确保索引更改以原子操作方式写入索引，即便有错误发生，也能保证索引数据的一致性。</li>
</ul>
<p>随着按段搜索（per-segment）的发展，一个新的文档从索引到可被搜索的延迟显著降低，新文档在几分钟内即可被检索，但是这个速度还是不够快。磁盘在这里称为了瓶颈，提交（Commiting）一个新的段到磁盘需要一个 <code>fsync</code> 来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 <code>fsync</code> 操作代价很大，如果每次索引一个文档都去执行一次的话会造成很大的性能问题。<br>
在 Lucene 中提交后，内存索引缓冲区中的文档会被写入到一个新的段中，但是这里新段会被先写入到文件系统缓存——这一步代价会比较低，稍后再被刷新到磁盘——这一步代价比较高，不过只要文件已经在缓存中就可以像其他文件一样被打开和读取了。<br>
另外，Lucene 使用了一个叫作<strong>Searcher</strong>的抽象类来执行索引的读取，如果索引更新提交了，但 Searcher 实例并没有重新打开，那么它觉察不到新索引段的加入。写入和 Searcher 重新打开新段的过程叫作<strong>刷新（refresh）</strong>。出于性能考虑，Lucene 推迟了耗时的刷新，因此它不会在每次新增一个文档（或批量增加文档）的时候刷新，但 Searcher 会<strong>默认每秒刷新一次</strong>。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。<br>
因此新索引的数据找不到可能有以下两个原因：</p>
<ol>
<li>可能还未执行提交 commit 操作</li>
<li>Searcher 未重新打开执行刷新</li>
</ol>
<p>如果有必要执行强制刷新，可以使用下面的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 刷新所有索引</span><br><span class="line">POST /_refresh</span><br><span class="line"># 只刷新一个索引</span><br><span class="line">POST /my_index/_refresh</span><br></pre></td></tr></table></figure>
<p>可以更改 ElasticSearch 配置文件中的 index.refresh_interval，，或者使用下面的命令来修改自动刷新时间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;5m&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;refresh_interval&quot;: &quot;30s&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>刷新操作是很耗资源的，因此刷新间隔时间越长，索引速度越快。如果需要长时间高速建索引、或建一个比较大的新索引，并且在建索引结束之前暂不执行查询，那么可以考虑将 index.refresh_interval 参数值设置为-1，然后在建索引结束以后再将该参数恢复为初始值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 关闭自动刷新</span><br><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;refresh_interval&quot;: -1</span><br><span class="line">&#125;</span><br><span class="line"># 每秒自动刷新</span><br><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;refresh_interval&quot;: &quot;1s&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意 refresh_interval 的单位，设置为 1 实际上表示的是 1 毫秒，这显然会导致集群陷入瘫痪。<br>
尽管刷新是比提交轻量很多的操作，它还是会有性能开销。 当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</p>
</blockquote>
<h3 id="事务日志-translog"><a class="header-anchor" href="#事务日志-translog">¶</a>事务日志（TransLog）</h3>
<h4 id="lucene-不能保证索引数据不丢失"><a class="header-anchor" href="#lucene-不能保证索引数据不丢失">¶</a>Lucene 不能保证索引数据不丢失</h4>
<p>Lucene 能保证索引的一致性，但是这并不能保证当往索引中写数据（fsync）失败时不会损失数据（如磁盘空间不足、设备损坏，或没有足够的文件句柄供索引文件使用）。<br>
另外，频繁提交操作会导致严重的性能问题（因为每提交一次就会触发一个索引段的创建操作，同时也可能触发索引段的合并）。<br>
即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。</p>
<h4 id="使用事务日志记录未提交事务"><a class="header-anchor" href="#使用事务日志记录未提交事务">¶</a>使用事务日志记录未提交事务</h4>
<p>Elasticsearch 增加了一个 <code>translog</code> ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。<br>
ElasticSearch 通过使用<code>translog</code>保存所有的未提交的事务，而 ElasticSearch 会不时创建一个新的日志文件用于记录每个事务的后续操作。当有错误发生时，就会检查事务日志，必要时会再次执行某些操作，以确保没有丢失任何更改信息。而且，事务日志的相关操作都是自动完成的，用户并不会意识到某个特定时刻触发的更新提交。事务日志中的信息与存储介质之间的同步（同时清空事务日志）称为事务日志刷新（<code>Flush</code>），Flush 操作会截断 translog。<br>
注意事务日志刷新与 Searcher 刷新的区别。大多数情况下，Searcher 刷新是你所期望的，即搜索到最新的文档。而事务日志刷新用来确保数据正确写入了索引并清空了事务日志。</p>
<p>通过<code>translog</code>，整个流程看起来是下面这样：</p>
<ol>
<li>一个文档被索引之后，就会被添加到内存缓冲区，并且 追加到了 translog；<br>
<img src="http://47.88.24.11/imgs/ES/%E6%96%B0%E7%9A%84%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%E5%B9%B6%E4%B8%94%E8%A2%AB%E8%BF%BD%E5%8A%A0%E5%88%B0%E4%BA%86%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97.png" alt="新的文档被添加到内存缓冲区并且被追加到了事务日志" title="新的文档被添加到内存缓冲区并且被追加到了事务日志"></li>
<li>分片每秒被刷新（refresh）一次：
<ul>
<li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。</li>
<li>这个段被打开，使其可被搜索。</li>
<li>内存缓冲区被清空。<br>
<img src="http://47.88.24.11/imgs/ES/Refresh%E5%AE%8C%E6%88%90%E5%90%8E%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%BD%86%E6%98%AF%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E4%BC%9A.png" alt="Refresh完成后缓存被清空但是事务日志不会" title="Refresh完成后缓存被清空但是事务日志不会"></li>
</ul>
</li>
<li>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志；<br>
<img src="http://47.88.24.11/imgs/ES/%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E6%96%AD%E7%A7%AF%E7%B4%AF%E6%96%87%E6%A1%A3.png" alt="事务日志不断积累文档" title="事务日志不断积累文档"></li>
<li>每隔一段时间，索引会被刷新（Flush），一个新的 translog 被创建，并且一个全量提交被执行。
<ul>
<li>所有在内存缓冲区的文档都被写入一个新的段。</li>
<li>缓冲区被清空。</li>
<li>一个提交点被写入硬盘。</li>
<li>文件系统缓存通过 fsync 被刷新（flush）。</li>
<li>老的 translog 被删除。<br>
translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。<br>
translog 也被用来提供实时 CRUD 。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。<br>
<img src="http://47.88.24.11/imgs/ES/Flush%E4%B9%8B%E5%90%8E%E6%AE%B5%E8%A2%AB%E5%85%A8%E9%87%8F%E6%8F%90%E4%BA%A4%E5%B9%B6%E4%B8%94%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E8%A2%AB%E6%B8%85%E7%A9%BA.png" alt="Flush之后段被全量提交并且事务日志被清空" title="Flush之后段被全量提交并且事务日志被清空"></li>
</ul>
</li>
</ol>
<h4 id="手动执行事务日志刷新"><a class="header-anchor" href="#手动执行事务日志刷新">¶</a>手动执行事务日志刷新</h4>
<p>分片每 30 分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /_flush</span><br><span class="line">POST /my_index/_flush</span><br><span class="line"># Flush所有的索引并且并且等待所有刷新在返回前完成。 </span><br><span class="line">POST /_flush?wait_for_ongoing</span><br><span class="line"># 在事务日志刷新之后，调用Searcher刷新操作，打开一个新的Searcher实例</span><br><span class="line">POST /my_index/_refresh</span><br></pre></td></tr></table></figure>
<p>一般不需要自己手动执行<code>Flush</code>操作，自动刷新就足够了。一般重启节点或关闭索引之前都需要执行一次<code>Flush</code>。<br>
当 Elasticsearch 尝试恢复或重新打开一个索引， 它需要重放 translog 中所有的操作，如果日志越短，恢复越快。</p>
<h4 id="异步-fsync"><a class="header-anchor" href="#异步-fsync">¶</a>异步 fsync</h4>
<p>默认 translog 是每 5 秒被 fsync 刷新到硬盘，或者在每次写请求（index, delete, update, bulk）完成之后执行。这个过程在主分片和复制分片都会发生，这意味着在整个请求被 fsync 到主分片和复制分片的 translog 之前，客户端不会得到一个 200 OK 响应。<br>
对于一些大容量的偶尔丢失几秒数据问题也不严重的集群，使用异步的 fsync 相对来说更好，比如，写入的数据被缓存到内存中，再每 5 秒执行一次 fsync ，可以使用如下命令配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然，如果不确定丢失几秒数据的后果能否接受，最好还是使用默认的参数：<code>&quot;index.translog.durability&quot;: &quot;request&quot;</code>。</p>
<h4 id="配置-v2"><a class="header-anchor" href="#配置-v2">¶</a>配置</h4>
<p>以下参数既可以通过修改 elasticsearch.yml 文件来配置，也可以通过索引配置更新 API 来更改。</p>
<ul>
<li>index.translog.flush_threshold_period：该参数的默认值为 30 分钟，它控制了强制自动事务日志刷新的时间间隔，即便是没有新数据写入。强制进行事务日志刷新通常会导致大量的 I/O 操作，因此当事务日志涉及少量数据时，才更适合进行这项操作。</li>
<li>index.translog.flush_threshold_ops：该参数确定了一个最大操作数，即在上次事务日志刷新以后，当索引更改操作次数超过该参数值时，强制进行事务日志刷新操作，默认值为 5000。</li>
<li>index.translog.flush_threshold_size：该参数确定了事务日志的最大容量，当容量大于等于该参数值，就强制进行事务日志刷新操作，默认值为 200MB。</li>
<li>index.translog.disable_flush:禁用事务日志刷新。尽管默认情况下事务日志刷新是可用的，但对它临时性地禁用能带来其他方面的便利。例如，向索引中导入大量文档的时候。</li>
</ul>
<p>或者调用 API 动态修改配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;translog.disable_flush&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>前述命令在向索引导入大量数据之前执行、可以大幅提高索引的速度。但是请记住，当数据导入完毕之后，要重新设置事务日志刷新相关参数。</p>
<h3 id="段合并"><a class="header-anchor" href="#段合并">¶</a>段合并</h3>
<p>由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增，而段数目太多会带来较大的麻烦：</p>
<ul>
<li>每一个段都会消耗文件句柄、内存和 cpu 运行周期；</li>
<li>更重要的是，每个搜索请求都必须轮流检查每个段，所以段越多，搜索也就越慢。</li>
</ul>
<p>Elasticsearch 通过在后台进行段合并来解决这个问题：</p>
<ul>
<li>小的段被合并到大的段，然后这些大的段再被合并到更大的段。</li>
<li>段合并的时候会将那些旧的已删除文档 从文件系统中清除。 被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</li>
</ul>
<h4 id="段合并流程"><a class="header-anchor" href="#段合并流程">¶</a>段合并流程</h4>
<p>进行索引和搜索时会自动进行段合并：</p>
<ol>
<li>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</li>
<li>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。<br>
<img src="http://47.88.24.11/imgs/ES/%E4%B8%A4%E4%B8%AA%E6%8F%90%E4%BA%A4%E4%BA%86%E7%9A%84%E6%AE%B5%E5%92%8C%E4%B8%80%E4%B8%AA%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%90%88%E5%B9%B6%E5%88%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E7%9A%84%E6%AE%B5.png" alt="两个提交了的段和一个未提交的段被合并到一个更大的段" title="两个提交了的段和一个未提交的段被合并到一个更大的段"></li>
<li>合并完成后：
<ul>
<li>新的段被刷新（flush）到了磁盘。写入一个包含新段且排除旧的和较小的段的新提交点。</li>
<li>新的段被打开用来搜索。</li>
<li>老的段被删除。<br>
<img src="http://47.88.24.11/imgs/ES/%E5%90%88%E5%B9%B6%E7%BB%93%E6%9D%9F%E5%90%8E%E8%80%81%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%88%A0%E9%99%A4.png" alt="合并结束后老的段被删除" title="合并结束后老的段被删除"></li>
</ul>
</li>
</ol>
<h4 id="optimize-api"><a class="header-anchor" href="#optimize-api">¶</a>optimize API</h4>
<p>optimize API 用于手动触发段合并。<br>
将一个分片强制合并到 max_num_segments 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。<br>
optimize API 不应该被用在一个活跃的索引上，Elasticsearch 后台会自动触发合并。<br>
在特定情况下，使用 optimize API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的，它们也并不太可能会发生变化，将历史段合并成一个单独的段就很有用了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 合并索引中的每个分片为一个单独的段 </span><br><span class="line">POST /logstash-2014-10/_optimize?max_num_segments=1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用 optimize API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的 I/O 资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配把索引移到一个安全的节点，再执行。</p>
</blockquote>
<h2 id="集群扩容"><a class="header-anchor" href="#集群扩容">¶</a>集群扩容</h2>
<h3 id="配置节点"><a class="header-anchor" href="#配置节点">¶</a>配置节点</h3>
<p>集群是由一个或者多个拥有相同 <strong><a href="http://cluster.name" target="_blank" rel="noopener">cluster.name</a></strong> 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会<strong>重新平均分布所有的数据</strong>。</p>
<h3 id="水平扩容"><a class="header-anchor" href="#水平扩容">¶</a>水平扩容</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B91.png" alt="水平扩容1" title="水平扩容1"><br>
主分片的数目在索引创建时 就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。但是，<strong>读操作</strong>——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。<br>
动态调整副本分片数目的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT /blogs/_settings</span><br><span class="line">&#123;</span><br><span class="line">   &quot;number_of_replicas&quot; : 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://47.88.24.11/imgs/ES/%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B92.png" alt="水平扩容2" title="水平扩容2"><br>
为了提高性能，要么是为已有的结点分配更多的资源，要么是分配更多的结点并扩展当前集群。但是不能通过为已有的分片分配更多的资源或者为一个结点分配更多的分片来提高性能，因为一个结点内的所有分片共享这个结点（JVM）的资源，最终还是必须增加更多的硬件资源来提升吞吐量。<br>
更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点的情况下不丢失任何数据（因为每个结点上要么存在一个分片要么存在一个分片的冗余）。</p>
<p>更多关于扩容的知识需要阅读相关文献，比如：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/scale.html" target="_blank" rel="noopener">扩容设计</a>。</p>
<h2 id="故障转移"><a class="header-anchor" href="#故障转移">¶</a>故障转移</h2>
<h3 id="同机多节点"><a class="header-anchor" href="#同机多节点">¶</a>同机多节点</h3>
<p>当在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 <a href="http://cluster.name" target="_blank" rel="noopener">cluster.name</a> 配置，它就会自动发现集群并加入到其中。</p>
<h3 id="不同机器多节点"><a class="header-anchor" href="#不同机器多节点">¶</a>不同机器多节点</h3>
<p>在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表，设置其他节点的 ip:port 列表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="故障转移机制"><a class="header-anchor" href="#故障转移机制">¶</a>故障转移机制</h3>
<p><img src="http://47.88.24.11/imgs/ES/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.png" alt="故障转移" title="故障转移"><br>
所有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档，即使主分片不可用了，服务仍然可用。如上图所示。<br>
如果集群缺失主节点，集群不能正常工作。所以发生的第一件事情就是选举一个新的主节点。但是需要注意的是<strong>集群必须存在且仅存在一个主节点</strong>，否则会出现<strong>脑裂</strong>现象，因此 Elasticsearch 提供了很多参数来避免这个情况。<br>
如果索引缺失主分片，索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片<strong>提升</strong>为主分片， 此时集群的状态将会为 yellow ，因为在创建索引时设置了每个主分片需要对应 2 份副本分片：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number_of_replicas : 2</span><br></pre></td></tr></table></figure>
<p>重启节点后，集群可以将缺失的副本分片再次进行分配，如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。</p>
<h2 id="qa"><a class="header-anchor" href="#qa">¶</a>QA</h2>
<ol>
<li>为什么搜索是近实时的？</li>
<li>为什么文档的 CRUD (创建-读取-更新-删除) 操作是 实时 的？</li>
<li>Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据?</li>
<li>为什么删除文档不会立刻释放空间？</li>
<li>refresh, flush, 和 optimize API 都做了什么, 你什么情况下应该使用他们？</li>
</ol>
<h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2>
<h3 id="文档"><a class="header-anchor" href="#文档">¶</a>文档</h3>
<ol>
<li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html" target="_blank" rel="noopener">Elasticsearch: 权威指南</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener">Elasticsearch Reference</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rest-apis.html" target="_blank" rel="noopener">REST APIs</a></li>
</ol>
<h3 id="索引-映射和文档"><a class="header-anchor" href="#索引-映射和文档">¶</a>索引、映射和文档</h3>
<ol>
<li><a href="https://blog.csdn.net/napoay/article/details/52032931" target="_blank" rel="noopener">Elasticsearch 索引的父子关系(index parent-child)</a></li>
<li><a href="https://www.elastic.co/blog/elasticsearch-versioning-support" target="_blank" rel="noopener">Elasticsearch Versioning Support</a></li>
</ol>
<h3 id="搜索"><a class="header-anchor" href="#搜索">¶</a>搜索</h3>
<ol>
<li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/search-in-depth.html" target="_blank" rel="noopener">深入搜索</a></li>
</ol>
<h3 id="集群"><a class="header-anchor" href="#集群">¶</a>集群</h3>
<ol>
<li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/scale.html" target="_blank" rel="noopener">扩容设计</a></li>
</ol>
<h3 id="源码"><a class="header-anchor" href="#源码">¶</a>源码</h3>
<ol>
<li><a href="https://blog.csdn.net/sinat_14913533/article/details/85833635" target="_blank" rel="noopener">elasticsearch 源码编译问题</a></li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ElasticSearch/" rel="tag"># ElasticSearch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/e43d540f.html" rel="next" title="使用 Arthas 排查线上问题">
                <i class="fa fa-chevron-left"></i> 使用 Arthas 排查线上问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/226416.html" rel="prev" title="使用 jq 解析 json 数据">
                使用 jq 解析 json 数据 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>

  

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">120</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">57</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#为什么用-elasticsearch"><span class="nav-number">1.</span> <span class="nav-text">¶为什么用 ElasticSearch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#搭建调试环境"><span class="nav-number">2.</span> <span class="nav-text">¶搭建调试环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#索引-映射和文档概念"><span class="nav-number">3.</span> <span class="nav-text">¶索引、映射和文档概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#索引-类型和映射-index-type-mapping"><span class="nav-number">3.1.</span> <span class="nav-text">¶索引、类型和映射 - Index、Type、Mapping</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#动态映射机制"><span class="nav-number">3.2.</span> <span class="nav-text">¶动态映射机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析和搜索-analysis-search"><span class="nav-number">3.3.</span> <span class="nav-text">¶分析和搜索 - Analysis、Search</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#query-dsl"><span class="nav-number">3.4.</span> <span class="nav-text">¶Query DSL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#倒排索引"><span class="nav-number">3.5.</span> <span class="nav-text">¶倒排索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#根对象"><span class="nav-number">3.6.</span> <span class="nav-text">¶根对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档和字段-document-field"><span class="nav-number">3.7.</span> <span class="nav-text">¶文档和字段 - Document、Field</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档元数据"><span class="nav-number">3.8.</span> <span class="nav-text">¶文档元数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档属性"><span class="nav-number">3.9.</span> <span class="nav-text">¶文档属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对象和文档"><span class="nav-number">3.10.</span> <span class="nav-text">¶对象和文档</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#精确值和全文"><span class="nav-number">3.11.</span> <span class="nav-text">¶精确值和全文</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式概念-distribution"><span class="nav-number">4.</span> <span class="nav-text">¶分布式概念（Distribution）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#集群-cluster"><span class="nav-number">4.1.</span> <span class="nav-text">¶集群 - Cluster</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#节点-node"><span class="nav-number">4.2.</span> <span class="nav-text">¶节点 - Node</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主节点-master"><span class="nav-number">4.3.</span> <span class="nav-text">¶主节点 - Master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分片-shard"><span class="nav-number">4.4.</span> <span class="nav-text">¶分片 - Shard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主分片和副分片"><span class="nav-number">4.5.</span> <span class="nav-text">¶主分片和副分片</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#索引-index"><span class="nav-number">4.6.</span> <span class="nav-text">¶索引（Index）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#复制-replica"><span class="nav-number">4.7.</span> <span class="nav-text">¶复制（Replica）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#es-整体架构"><span class="nav-number">5.</span> <span class="nav-text">¶ES 整体架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#es-节点启动和关闭"><span class="nav-number">6.</span> <span class="nav-text">¶ES 节点启动和关闭</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#检测外部环境"><span class="nav-number">6.1.</span> <span class="nav-text">¶检测外部环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动各模块"><span class="nav-number">6.2.</span> <span class="nav-text">¶启动各模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#keepalive"><span class="nav-number">6.3.</span> <span class="nav-text">¶keepalive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#节点关闭"><span class="nav-number">6.4.</span> <span class="nav-text">¶节点关闭</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#选主"><span class="nav-number">7.</span> <span class="nav-text">¶选主</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#选举相关概念"><span class="nav-number">7.1.</span> <span class="nav-text">¶选举相关概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置"><span class="nav-number">7.2.</span> <span class="nav-text">¶配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#本地节点实例的创建"><span class="nav-number">7.3.</span> <span class="nav-text">¶本地节点实例的创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选主流程"><span class="nav-number">7.4.</span> <span class="nav-text">¶选主流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选举临时-master"><span class="nav-number">7.5.</span> <span class="nav-text">¶选举临时 Master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从-mastercandidates-选主"><span class="nav-number">7.6.</span> <span class="nav-text">¶从 masterCandidates 选主</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从-activemasters-列表中选主"><span class="nav-number">7.7.</span> <span class="nav-text">¶从 activeMasters 列表中选主</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#收集投票进行统计"><span class="nav-number">7.8.</span> <span class="nav-text">¶收集投票进行统计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加入集群"><span class="nav-number">7.9.</span> <span class="nav-text">¶加入集群</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据副本模型"><span class="nav-number">8.</span> <span class="nav-text">¶数据副本模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pacifica-算法"><span class="nav-number">8.1.</span> <span class="nav-text">¶PacificA 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存储管理-写入"><span class="nav-number">8.2.</span> <span class="nav-text">¶存储管理 - 写入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置管理"><span class="nav-number">8.3.</span> <span class="nav-text">¶配置管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#allocation-ids"><span class="nav-number">8.4.</span> <span class="nav-text">¶Allocation IDs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sequence-ids"><span class="nav-number">8.5.</span> <span class="nav-text">¶Sequence IDs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#乐观并发控制"><span class="nav-number">8.6.</span> <span class="nav-text">¶乐观并发控制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式文档存储"><span class="nav-number">9.</span> <span class="nav-text">¶分布式文档存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#相关配置"><span class="nav-number">9.1.</span> <span class="nav-text">¶相关配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档路由"><span class="nav-number">9.2.</span> <span class="nav-text">¶文档路由</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发机制"><span class="nav-number">9.3.</span> <span class="nav-text">¶分发机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#consistency"><span class="nav-number">9.4.</span> <span class="nav-text">¶consistency</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#timeout"><span class="nav-number">9.5.</span> <span class="nav-text">¶timeout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建-索引-删除"><span class="nav-number">9.6.</span> <span class="nav-text">¶创建、索引、删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#取回单个文档"><span class="nav-number">9.7.</span> <span class="nav-text">¶取回单个文档</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#局部更新"><span class="nav-number">9.8.</span> <span class="nav-text">¶局部更新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mget-批量读"><span class="nav-number">9.9.</span> <span class="nav-text">¶mget（批量读）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bulk-批量改"><span class="nav-number">9.10.</span> <span class="nav-text">¶bulk（批量改）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#写入流程-协调节点"><span class="nav-number">9.11.</span> <span class="nav-text">¶写入流程 - 协调节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#写入流程-主分片节点"><span class="nav-number">9.12.</span> <span class="nav-text">¶写入流程 - 主分片节点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式搜索"><span class="nav-number">10.</span> <span class="nav-text">¶分布式搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#查询阶段"><span class="nav-number">10.1.</span> <span class="nav-text">¶查询阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#取回阶段"><span class="nav-number">10.2.</span> <span class="nav-text">¶取回阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#深分页问题-deep-pagination"><span class="nav-number">10.3.</span> <span class="nav-text">¶深分页问题（Deep Pagination）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#偏好"><span class="nav-number">10.4.</span> <span class="nav-text">¶偏好</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#超时"><span class="nav-number">10.5.</span> <span class="nav-text">¶超时</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#路由"><span class="nav-number">10.6.</span> <span class="nav-text">¶路由</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#搜索类型"><span class="nav-number">10.7.</span> <span class="nav-text">¶搜索类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#游标查询-scroll"><span class="nav-number">10.8.</span> <span class="nav-text">¶游标查询 Scroll</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#索引原理"><span class="nav-number">11.</span> <span class="nav-text">¶索引原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#索引策略"><span class="nav-number">11.1.</span> <span class="nav-text">¶索引策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不变性"><span class="nav-number">11.2.</span> <span class="nav-text">¶不变性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#段和提交点"><span class="nav-number">11.3.</span> <span class="nav-text">¶段和提交点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#动态更新索引"><span class="nav-number">11.4.</span> <span class="nav-text">¶动态更新索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除和更新索引"><span class="nav-number">11.5.</span> <span class="nav-text">¶删除和更新索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#准实时搜索与刷新策略"><span class="nav-number">11.6.</span> <span class="nav-text">¶准实时搜索与刷新策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#事务日志-translog"><span class="nav-number">11.7.</span> <span class="nav-text">¶事务日志（TransLog）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#lucene-不能保证索引数据不丢失"><span class="nav-number">11.7.1.</span> <span class="nav-text">¶Lucene 不能保证索引数据不丢失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用事务日志记录未提交事务"><span class="nav-number">11.7.2.</span> <span class="nav-text">¶使用事务日志记录未提交事务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#手动执行事务日志刷新"><span class="nav-number">11.7.3.</span> <span class="nav-text">¶手动执行事务日志刷新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异步-fsync"><span class="nav-number">11.7.4.</span> <span class="nav-text">¶异步 fsync</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置-v2"><span class="nav-number">11.7.5.</span> <span class="nav-text">¶配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#段合并"><span class="nav-number">11.8.</span> <span class="nav-text">¶段合并</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#段合并流程"><span class="nav-number">11.8.1.</span> <span class="nav-text">¶段合并流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#optimize-api"><span class="nav-number">11.8.2.</span> <span class="nav-text">¶optimize API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集群扩容"><span class="nav-number">12.</span> <span class="nav-text">¶集群扩容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置节点"><span class="nav-number">12.1.</span> <span class="nav-text">¶配置节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#水平扩容"><span class="nav-number">12.2.</span> <span class="nav-text">¶水平扩容</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#故障转移"><span class="nav-number">13.</span> <span class="nav-text">¶故障转移</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#同机多节点"><span class="nav-number">13.1.</span> <span class="nav-text">¶同机多节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不同机器多节点"><span class="nav-number">13.2.</span> <span class="nav-text">¶不同机器多节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#故障转移机制"><span class="nav-number">13.3.</span> <span class="nav-text">¶故障转移机制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#qa"><span class="nav-number">14.</span> <span class="nav-text">¶QA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">15.</span> <span class="nav-text">¶参考</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#文档"><span class="nav-number">15.1.</span> <span class="nav-text">¶文档</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#索引-映射和文档"><span class="nav-number">15.2.</span> <span class="nav-text">¶索引、映射和文档</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#搜索"><span class="nav-number">15.3.</span> <span class="nav-text">¶搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群"><span class="nav-number">15.4.</span> <span class="nav-text">¶集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#源码"><span class="nav-number">15.5.</span> <span class="nav-text">¶源码</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '72bdd1c9479eb0679788',
          clientSecret: '62c9c0cb45aadb1478ca66cfc3c69c9623f50290',
          repo: 'tallate.github.io',
          owner: 'tallate',
          admin: ['tallate'],
          id: location.pathname,
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>



  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
