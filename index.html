<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/5f3f10ab.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/5f3f10ab.html" itemprop="url">分布式事务-从本地事务到分布式事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-06T10:26:49+08:00">
                2020-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/分布式事务/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>这篇文档集中于概念的梳理，不会谈太多实现上的细节。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/5f3f10ab.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/0.html" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-01T00:49:28+08:00">
                2020-12-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.8k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  20 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的 IP 地址，使服务提供方可以平滑增加或减少机器。</p>
<h2 id="角色分类"><a class="header-anchor" href="#角色分类">¶</a>角色分类</h2>
<p>以功能角度来说服务可以分成以下几种：</p>
<ul>
<li>服务提供者；</li>
<li>服务消费者；</li>
<li>服务提供者兼消费者。</li>
</ul>
<h2 id="注册中心分类"><a class="header-anchor" href="#注册中心分类">¶</a>注册中心分类</h2>
<p>可以分成以下几种注册中心：</p>
<ul>
<li>Simple 注册中心 点对点直连</li>
<li>Multicast 注册中心 多播</li>
<li>Zookeeper 注册中心</li>
<li>Redis 注册中心</li>
</ul>
<h2 id="配置"><a class="header-anchor" href="#配置">¶</a>配置</h2>
<p>服务提供者（provider）配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 应用名称，可显示依赖关系 --&gt;</span><br><span class="line">&lt;dubbo:application name=&quot;dubbo-order-server&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 注册中心是ZooKeeper，也可以选择Redis做注册中心 --&gt;</span><br><span class="line">&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot;</span><br><span class="line">    client=&quot;zkclient&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 通过dubbo协议在注册中心（127.0.0.1表示本机）的20880端口暴露服务 --&gt;</span><br><span class="line">&lt;dubbo:protocol name=&quot;dubbo&quot; host=&quot;127.0.0.1&quot; port=&quot;20880&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 提供服务用地的是service标签，将该接口暴露到dubbo中 --&gt;</span><br><span class="line">&lt;dubbo:service interface=&quot;com.dubbo.service.OrderService&quot;</span><br><span class="line">    ref=&quot;orderService&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Spring容器加载具体的实现类--&gt;</span><br><span class="line">&lt;bean id=&quot;orderService&quot; class=&quot;dubbo.service.impl.OrderServiceImpl&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:monitor protocol=&quot;registry&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>服务消费者（consumer）配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 应用名称，可显示依赖关系 --&gt;</span><br><span class="line">&lt;dubbo:application name=&quot;dubbo-user-consumer&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- zookeeper作为注册中心 ，也可以选择Redis做注册中心 --&gt;</span><br><span class="line">&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot;</span><br><span class="line">    client=&quot;zkclient&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:protocol host=&quot;127.0.0.1&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 调用服务使用reference标签，从注册中心中查找服务 --&gt;</span><br><span class="line">&lt;dubbo:reference id=&quot;orderService&quot; interface=&quot;com.dubbo.service.OrderService&quot; /&gt;</span><br></pre></td></tr></table></figure>
<h2 id="查看服务注册-暴露结果"><a class="header-anchor" href="#查看服务注册-暴露结果">¶</a>查看服务注册/暴露结果</h2>
<p><img src="http://47.88.24.11/imgs/Dubbo/Dubbo%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%BF%A1%E6%81%AF.png" alt="Dubbo服务注册信息" title="Dubbo服务注册信息"><br>
Dubbo 在 ZooKeeper 中以树形结构维护服务注册信息：</p>
<ul>
<li>服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址；</li>
<li>服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址；</li>
<li>监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。</li>
</ul>
<p>ZooKeeper 启动的时候会把配置信息加载进内存并持久化到数据库，然后启动定时器脏数据检查定时器 DirtyCheckTask，分别检查消费者和提供者的地址列表缓存、消费者和提供者地址列表的数据库数据，清理不存活的消费者和提供者数据，对于缓存中的存在的消费者和提供者而数据库不存在，提供者重新注册和消费者重新订阅。</p>
<p>Dubbo 提供了一些异常情况下的兜底方案：</p>
<ul>
<li>当提供者出现断电等异常停机时，注册中心能自动删除提供者信息</li>
<li>当注册中心重启时，能自动恢复注册数据，以及订阅请求</li>
<li>当会话过期时，能自动恢复注册数据，以及订阅请求</li>
<li>当设置 &lt;dubbo:registry check=“false” /&gt; 时，记录失败注册和订阅请求，后台定时重试</li>
</ul>
<p>在了解 ZooKeeper 基础上，还可以增加一些配置来修改注册细节：<br>
可通过 <code>&lt;dubbo:registry username=&quot;admin&quot; password=&quot;1234&quot; /&gt;</code> 设置 ZooKeeper 登录信息<br>
可通过 <code>&lt;dubbo:registry group=&quot;dubbo&quot; /&gt;</code> 设置 ZooKeeper 的根节点，不设置将使用无根树<br>
支持 * 号通配符 <code>&lt;dubbo:reference group=&quot;*&quot; version=&quot;*&quot; /&gt;</code> ，可订阅服务的所有分组和所有版本的提供者</p>
<p>在 Provider 启动完毕后，可以登录到 ZooKeeper 上查看注册的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 11] ls /</span><br><span class="line">[dubbo, zookeeper]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 12] ls /dubbo</span><br><span class="line">[com.alibaba.dubbo.monitor.MonitorService, com.tallate.UserServiceBo]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 13] ls /dubbo/com.tallate.UserServiceBo</span><br><span class="line">[configurators, consumers, providers, routers]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 14] ls /dubbo/com.tallate.UserServiceBo/providers</span><br><span class="line">[dubbo%3A%2F%2F192.168.96.194%3A20880%2Fcom.tallate.UserServiceBo%3Fanyhost%3Dtrue%26application%3DdubboProvider%26dubbo%3D2.0.2%26generic%3Dfalse%26group%3Ddubbo%26interface%3Dcom.tallate.UserServiceBo%26methods%3DsayHello%2CtestPojo%2CsayHello2%26pid%3D28129%26revision%3D1.0.0%26side%3Dprovider%26timeout%3D3000%26timestamp%3D1575202776615%26version%3D1.0.0]</span><br></pre></td></tr></table></figure>
<h2 id="服务自动发现流程"><a class="header-anchor" href="#服务自动发现流程">¶</a>服务自动发现流程</h2>
<p>服务自动发现功能完成下面这个流程，我们接下来分点概述：</p>
<ol>
<li>服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>服务消费者，从提供者地址列表中，基于软负载均衡算法（基于软件的负载均衡，与 F5 相对），选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
</ol>
<h2 id="注册和注销服务-provider-执行流程"><a class="header-anchor" href="#注册和注销服务-provider-执行流程">¶</a>注册和注销服务（Provider 执行流程）</h2>
<p>服务的注册与注销，是对服务提供方角色而言，大致流程如下所示：<br>
<img src="http://47.88.24.11/imgs/Dubbo/%E6%B3%A8%E5%86%8C%E5%92%8C%E6%B3%A8%E9%94%80%E6%9C%8D%E5%8A%A1.png" alt="注册和注销服务" title="注册和注销服务"></p>
<ol>
<li>在接口提供者初始化时，每个接口都会创建一个 Invoker 和 Exporter，Exporter 持有 Invoker 实例，通过 Invocation 中的信息就可找到对应的 Exporter 和 Invoker</li>
<li>同 Consumer 的过程类似，调用 Invoker 前会调用 Invoker-Filter。</li>
<li>调用 Invoker.invoke() 时，通过反射调用最终的服务实现执行相关逻辑。</li>
</ol>
<p>ServiceBean 负责了服务的暴露：</p>
<ul>
<li>继承自 ServiceConfig，export 方法实现了服务暴露的逻辑；</li>
<li>实现了 Spring 中的 InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<contextrefreshedevent>, BeanNameAware</contextrefreshedevent></li>
</ul>
<p>启动时，ServiceBean 主要负责以下任务：</p>
<ul>
<li>生成 DubboExporter 对象并缓存起来</li>
<li>添加过滤器和监听器支持</li>
<li>在 zk 上注册相关信息，暴露服务，方便被感知到</li>
<li>监听端口，等待通信的到来</li>
</ul>
<p><img src="http://47.88.24.11/imgs/Dubbo/Dubbo%E6%9C%8D%E5%8A%A1%E5%AF%BC%E5%87%BA.png" alt="Dubbo服务导出" title="Dubbo服务导出"></p>
<ol>
<li>前置工作，主要用于检查参数和组装 URL；<br>
ServiceBean#onApplicationEvent: 接收 Spring 上下文刷新事件后执行服务导出操作<br>
-&gt; ServiceBean#export: 导出服务<br>
-&gt; ProviderConfig.getExport、getDelay 获取配置，如果 export 为 false 则无法提供给其他服务调用、一般只提供给本地调试时使用，如果需要 delay 则将任务交给一个 ScheduledExecutorService 延迟执行，否则调用 doExport 暴露服务<br>
-&gt; ServiceConfig.doExport 一堆配置检查</li>
<li>导出服务，包含导出服务到本地（JVM）和导出服务到远程两个过程；<br>
<code>ServiceConfig.doExportUrls</code><br>
导出服务，Dubbo 中所有服务都通过 URL 导出，支持多协议多注册中心导出服务（遍历 ProtocolConfig 集合导出每个服务）<br>
<code>AbstractInterfaceConfig#loadRegistries</code><br>
加载注册中心链接<br>
<code>ServiceConfig#doExportUrlsFor1Protocol</code><br>
组装 URL，将服务注册到注册中心<br>
<code>JavassistProxyFactory#getInvoker</code><br>
获取 Invoker 实例，用于接收请求<br>
<code>ServiceConfig#exportLocal、DubboProtocol#export</code><br>
根据配置信息导出服务到本地或远程，远程默认取Dubbo协议<br>
<code>DubboProtocol#openServer</code><br>
开始监听请求</li>
<li>向注册中心注册服务，用于服务发现<br>
Dubbo 服务注册本质是在 zk 指定目录下创建临时节点，路径是<code>{group}/{Interface}/providers/{url}</code>。<br>
RegistryProtocol#register<br>
-&gt; RegistryFactory#getRegistry<br>
-&gt; AbstractRegistry#register</li>
</ol>
<p>因为Dubbo一般使用ZooKeeper作为注册中心，所以完全可以利用ZooKeeper的临时节点自动删除机制来实现服务器下线自动踢出的机制。</p>
<h2 id="服务订阅和取消-consumer-执行流程"><a class="header-anchor" href="#服务订阅和取消-consumer-执行流程">¶</a>服务订阅和取消（Consumer 执行流程）</h2>
<p>为了满足应用系统的需求，服务消费方的可能需要从服务注册中心订阅指定的有服务提供方发布的服务，在得到通知可以使用服务时，就可以直接调用服务。反过来，如果不需要某一个服务了，可以取消该服务。<br>
<img src="http://47.88.24.11/imgs/Dubbo/%E6%9C%8D%E5%8A%A1%E8%AE%A2%E9%98%85%E5%92%8C%E5%8F%96%E6%B6%88.png" alt="服务订阅和取消" title="服务订阅和取消"></p>
<p>有两种服务引入方式：</p>
<ol>
<li>饿汉式：Spring 容器调用 ReferenceBean 的 afterPropertiesSet 方法时引用服务，可通过配置 <code>&lt;dubbo:reference&gt;</code> 的 init 属性开启。</li>
<li>懒汉式：ReferenceBean 对应的服务被注入到其他类中时引用</li>
</ol>
<p>服务提供的方式有三种：</p>
<ol>
<li>引用本地 (JVM) 服务；</li>
<li>通过直连方式引用远程服务；</li>
<li>通过注册中心引用远程服务。</li>
</ol>
<p>不管是哪种引用方式，最后都会得到一个 Invoker 实例。如果有多个注册中心，多个服务提供者，这个时候会得到一组 Invoker 实例，此时需要通过集群管理类 Cluster 将多个 Invoker 合并成一个实例。</p>
<p>获取客户端Proxy：</p>
<ol>
<li>在 Consumer 初始化的时候，会生成一个代理注册到容器中，该代理回调中持有一个 Invoker 实例，消费调用服务接口时它的 invoke() 方法会被调用。<br>
spring.ReferenceBean#getObject<br>
ReferenceConfig#createProxy<br>
创建代理实例，根据 url 的协议、scope 以及 injvm 等参数检测是否需要本地引用，不是本地引用的情况下默认采用Dubbo协议。<br>
Protocol#refer<br>
-&gt; DubboProtocol#getClients 获取客户端实例，实例类型为 ExchangeClient，ExchangeClient 不具备通信能力，它需要依赖更底层的客户端实例<br>
-&gt; DubboProtocol#getSharedClient 默认获取共享客户端<br>
-&gt; DubboProtocol#initClient 创建客户端实例，默认为 Netty<br>
-&gt; Exchangers#connect(URL url, ExchangeHandler handler)</li>
<li>使用 Cluster 合并 Invoker<br>
org.apache.dubbo.rpc.cluster.Cluster#join<br>
如果配置了多个 URL，则使用 Cluster 合并多个 Invoker</li>
<li>创建动态代理<br>
-&gt; ProxyFactory#getProxy(Invoker<t> invoker)<br>
常用的动态代理技术有 javassist、cglib、jdk，其中 dubbo 使用的是 javassist。</t></li>
</ol>
<blockquote>
<p>根据早期 Dubbo 作者梁飞（<a href="http://javatar.iteye.com/blog/814426%EF%BC%89%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E4%BD%BF%E7%94%A8" target="_blank" rel="noopener">http://javatar.iteye.com/blog/814426）的说法，使用</a> javassist 是为了性能。</p>
</blockquote>
<h2 id="consumer端服务调用过程"><a class="header-anchor" href="#consumer端服务调用过程">¶</a>Consumer端服务调用过程</h2>
<p><img src="http://47.88.24.11/imgs/Dubbo/Dubbo%E7%BB%84%E4%BB%B6.png" alt="Dubbo组件" title="Dubbo组件"></p>
<h3 id="调用代理类的方法"><a class="header-anchor" href="#调用代理类的方法">¶</a>调用代理类的方法</h3>
<p>请求实际调用的是<code>InvokerInvocationHandler.invoke</code>。</p>
<h3 id="registry-directory"><a class="header-anchor" href="#registry-directory">¶</a>Registry &amp; Directory</h3>
<h4 id="registry-将注册信息保存到本地的directory"><a class="header-anchor" href="#registry-将注册信息保存到本地的directory">¶</a>Registry 将注册信息保存到本地的Directory</h4>
<p>启动服务时需要给一个Dubbo接口创建代理，这时需要将注册URL转换为Invoker对象：<br>
<code>org.apache.dubbo.registry.integration.RegistryProtocol#refer</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123;</span><br><span class="line">    url = getRegistryUrl(url);</span><br><span class="line">    Registry registry = registryFactory.getRegistry(url);</span><br><span class="line">    if (RegistryService.class.equals(type)) &#123;</span><br><span class="line">        return proxyFactory.getInvoker((T) registry, type, url);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // group=&quot;a,b&quot; or group=&quot;*&quot;</span><br><span class="line">    Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY));</span><br><span class="line">    String group = qs.get(GROUP_KEY);</span><br><span class="line">    if (group != null &amp;&amp; group.length() &gt; 0) &#123;</span><br><span class="line">        if ((COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || &quot;*&quot;.equals(group)) &#123;</span><br><span class="line">            return doRefer(getMergeableCluster(), registry, type, url);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return doRefer(cluster, registry, type, url);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>引用一个服务时，会注册一个<code>zkListener</code>，监听注册服务的命名空间的变更情况。<br>
<code>org.apache.dubbo.registry.zookeeper.ZookeeperRegistry#doSubscribe</code><br>
那么服务是怎么注册的呢？其实就是上边Provider注册服务的过程。<br>
监听到注册中心的变更后，更新本地的Invoker列表，同时删除不可用的。<br>
<code>org.apache.dubbo.registry.integration.RegistryDirectory#refreshInvoker</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">private void refreshInvoker(List&lt;URL&gt; invokerUrls) &#123;</span><br><span class="line">    Assert.notNull(invokerUrls, &quot;invokerUrls should not be null&quot;);</span><br><span class="line"></span><br><span class="line">    if (invokerUrls.size() == 1</span><br><span class="line">            &amp;&amp; invokerUrls.get(0) != null</span><br><span class="line">            &amp;&amp; EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123;</span><br><span class="line">        this.forbidden = true; // Forbid to access</span><br><span class="line">        this.invokers = Collections.emptyList();</span><br><span class="line">        routerChain.setInvokers(this.invokers);</span><br><span class="line">        destroyAllInvokers(); // Close all invokers</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        this.forbidden = false; // Allow to access</span><br><span class="line">        Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference</span><br><span class="line">        </span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line">        Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            logger.warn(&quot;destroyUnusedInvokers error. &quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="invoker使用directory"><a class="header-anchor" href="#invoker使用directory">¶</a>Invoker使用Directory</h4>
<p>为了服务高可用同一个服务一般会有多个应用服务器提供，要先挑选一个提供者提供服务。在服务接口消费者初始化时，接口方法和提供者 Invoker 对应关系保存在 Directory。 中，通过调用的方法名称（或方法名称+第一个参数）获取该方法对应的提供者 Invoker 列表，如注册中心设置了路由规则，对这些 Invoker 根据路由规则进行过滤。<br>
启动时订阅某个服务：<br>
<code>org.apache.dubbo.registry.integration.RegistryProtocol#doRefer</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123;</span><br><span class="line">    RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);</span><br><span class="line">    directory.setRegistry(registry);</span><br><span class="line">    directory.setProtocol(protocol);</span><br><span class="line">    // all attributes of REFER_KEY</span><br><span class="line">    Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters());</span><br><span class="line">    URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters);</span><br><span class="line">    if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) &#123;</span><br><span class="line">        directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl, url));</span><br><span class="line">        registry.register(directory.getRegisteredConsumerUrl());</span><br><span class="line">    &#125;</span><br><span class="line">    directory.buildRouterChain(subscribeUrl);</span><br><span class="line">    // 订阅providers、configurators、routers这几个namespace</span><br><span class="line">    directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY,</span><br><span class="line">            PROVIDERS_CATEGORY + &quot;,&quot; + CONFIGURATORS_CATEGORY + &quot;,&quot; + ROUTERS_CATEGORY));</span><br><span class="line"></span><br><span class="line">    // 使用Cluster组合Invoker</span><br><span class="line">    Invoker invoker = cluster.join(directory);</span><br><span class="line">    return invoker;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>添加监听器：<br>
<code>org.apache.dubbo.registry.integration.RegistryDirectory#subscribe</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public void subscribe(URL url) &#123;</span><br><span class="line">    setConsumerUrl(url);</span><br><span class="line">    CONSUMER_CONFIGURATION_LISTENER.addNotifyListener(this);</span><br><span class="line">    serviceConfigurationListener = new ReferenceConfigurationListener(this, url);</span><br><span class="line">    registry.subscribe(url, this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Consumer端监听服务变更事件，刷新Invoker列表：<br>
<code>org.apache.dubbo.registry.integration.RegistryDirectory#refreshInvoker</code></p>
<h4 id="directory的几种实现"><a class="header-anchor" href="#directory的几种实现">¶</a>Directory的几种实现</h4>
<ul>
<li>RegistryDirectory<br>
保存注册中心的服务注册信息，包括routers、configurators、provider。</li>
<li>StaticDirectory<br>
Invoker列表是固定的。</li>
</ul>
<h3 id="cluster"><a class="header-anchor" href="#cluster">¶</a>Cluster</h3>
<p>封装了服务降级和容错机制，比如，如果调用失败则执行其他（<code>FailoverClusterInvoker</code>）、仍然调用失败则降级执行 mock（<code>MockClusterInvoker</code>）。<br>
调用的第一层是<code>MockClusterInvoker</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">public Result invoke(Invocation invocation) throws RpcException &#123;</span><br><span class="line">    Result result = null;</span><br><span class="line">    </span><br><span class="line">    String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim();</span><br><span class="line">    // 没有设置mock属性或设置为false，则直接调就完了</span><br><span class="line">    if (value.length() == 0 || &quot;false&quot;.equalsIgnoreCase(value)) &#123;</span><br><span class="line">        //no mock</span><br><span class="line">        result = this.invoker.invoke(invocation);</span><br><span class="line">    &#125;</span><br><span class="line">    // 配成force了，直接调mock方法</span><br><span class="line">    else if (value.startsWith(&quot;force&quot;)) &#123;</span><br><span class="line">        if (logger.isWarnEnabled()) &#123;</span><br><span class="line">            logger.warn(&quot;force-mock: &quot; + invocation.getMethodName() + &quot; force-mock enabled , url : &quot; + directory.getUrl());</span><br><span class="line">        &#125;</span><br><span class="line">        //force:direct mock</span><br><span class="line">        result = doMockInvoke(invocation, null);</span><br><span class="line">    &#125;</span><br><span class="line">    // fail-mock的方式</span><br><span class="line">    else &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            result = this.invoker.invoke(invocation);</span><br><span class="line"></span><br><span class="line">            //fix:#4585</span><br><span class="line">            if(result.getException() != null &amp;&amp; result.getException() instanceof RpcException)&#123;</span><br><span class="line">                RpcException rpcException= (RpcException)result.getException();</span><br><span class="line">                if(rpcException.isBiz())&#123;</span><br><span class="line">                    throw  rpcException;</span><br><span class="line">                &#125;else &#123;</span><br><span class="line">                    result = doMockInvoke(invocation, rpcException);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125; catch (RpcException e) &#123;</span><br><span class="line">            if (e.isBiz()) &#123;</span><br><span class="line">                throw e;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (logger.isWarnEnabled()) &#123;</span><br><span class="line">                logger.warn(&quot;fail-mock: &quot; + invocation.getMethodName() + &quot; fail-mock enabled , url : &quot; + directory.getUrl(), e);</span><br><span class="line">            &#125;</span><br><span class="line">            result = doMockInvoke(invocation, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际invoke调用的是父类<code>AbstractClusterInvoker</code>的invoke方法，这个方法的主要功能是提供负载均衡：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public Result invoke(final Invocation invocation) throws RpcException &#123;</span><br><span class="line">    checkWhetherDestroyed();</span><br><span class="line"></span><br><span class="line">    // binding attachments into invocation.</span><br><span class="line">    Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments();</span><br><span class="line">    if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123;</span><br><span class="line">        ((RpcInvocation) invocation).addAttachments(contextAttachments);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 找到所有可调用的服务器</span><br><span class="line">    List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);</span><br><span class="line">    // 发送时要经过负载均衡</span><br><span class="line">    LoadBalance loadbalance = initLoadBalance(invokers, invocation);</span><br><span class="line">    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);</span><br><span class="line">    return doInvoke(invocation, invokers, loadbalance);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的<code>doInvoke</code>是一个模板方法，由子类实现，默认子类是<code>FailoverClusterInvoker</code>，可以看到，它先通过负载均衡策略得到一个Invoker，再调用该Invoker，Invoker的默认实现是<code>DubboInvoker</code>，表示使用的是Dubbo协议。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">private Result doInvoke(List&lt;Invoker&lt;T&gt;&gt; invokers,</span><br><span class="line">                        final List&lt;Invoker&lt;T&gt;&gt; invoked,</span><br><span class="line">                        Holder&lt;RpcException&gt; lastException,</span><br><span class="line">                        final Set&lt;String&gt; providers,</span><br><span class="line">                        final Invocation invocation,</span><br><span class="line">                        final LoadBalance loadbalance,</span><br><span class="line">                        final int totalRetries,</span><br><span class="line">                        int retries,</span><br><span class="line">                        Holder&lt;Invoker&lt;T&gt;&gt; lastInvoked) throws RpcException &#123;</span><br><span class="line">    if (retries &lt; totalRetries) &#123;</span><br><span class="line">        checkWheatherDestoried();</span><br><span class="line">        invokers = list(invocation);</span><br><span class="line">        checkInvokers(invokers, invocation);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 负载均衡</span><br><span class="line">    final Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, invoked);</span><br><span class="line">    invoked.add(invoker);</span><br><span class="line">    lastInvoked.value = invoker;</span><br><span class="line">    RpcContext.getContext().setInvokers((List) invoked);</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        return invoker.invoke(invocation);</span><br><span class="line">    &#125; catch (RpcException e) &#123;</span><br><span class="line">        //业务异常不重试</span><br><span class="line">        if (e.isBiz()) &#123;</span><br><span class="line">            throw e;</span><br><span class="line">        &#125;</span><br><span class="line">        lastException.value = e;</span><br><span class="line">    &#125; catch (Throwable e) &#123;</span><br><span class="line">        lastException.value = new RpcException(e.getMessage(), e);</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        providers.add(invoker.getUrl().getAddress());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (--retries == 0) &#123;</span><br><span class="line">        throw populateException(invokers, lastException.value, providers, invocation, totalRetries);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return doInvoke(invokers, invoked, lastException, providers, invocation, loadbalance, totalRetries, retries, lastInvoked);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="cluster的实现"><a class="header-anchor" href="#cluster的实现">¶</a>Cluster的实现</h4>
<ul>
<li>MockClusterInvoker<br>
调用失败降级到mock接口；</li>
<li>BroadcastClusterInvoker<br>
每个Invoker都调一次，忽略了LoadBalance；</li>
<li>AvailableClusterInvoker<br>
把处于可用状态的Invoker都调一遍。</li>
<li>FailoverClusterInvoker<br>
一个Invoker失败就换个Invoker重试几次。</li>
<li>FailbackClusterInvoker<br>
如果调用失败就放到一个线程池中延迟5秒再发，一般用于发消息。</li>
<li>FailfastClusterInvoker<br>
失败立刻报错</li>
<li>FailsafeClusterInvoker<br>
失败就忽略，一般是用于记日志这种失败了影响也不大的场景。</li>
<li>ForkingClusterInvoker<br>
一次性选n个Invoker，并行调用，只要有一个调用成功就返回，线程间通过<code>LinkedBlockingQueue</code>通信。</li>
</ul>
<h3 id="loadbalance"><a class="header-anchor" href="#loadbalance">¶</a>LoadBalance</h3>
<p>Cluster 层包含多个 Invoker，LoadBalance 负责从中选出一个来调用，有多种 LoadBalance 策略，比如随机选一个（<code>RandomLoadBalance</code>）、轮询（<code>RoundRobinLoadBalance</code>）、一致性hash（ConsistentHashLoadBalance）。<br>
实例化LoadBalance：<code>com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker#invoke</code><br>
使用LoadBalance选择一个Invoker：<code>com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker#select</code></p>
<h4 id="loadbalance的多种实现"><a class="header-anchor" href="#loadbalance的多种实现">¶</a>LoadBalance的多种实现</h4>
<ul>
<li>RandomLoadBalance<br>
计算权重，然后根据每个Invoker的权重调一个。</li>
<li>LeastActiveLoadBalance<br>
找最近最不活跃的Invoker调用，如果这样的Invoker有多个，则按权重来随机选一个。</li>
<li>RoundRobinLoadBalance<br>
轮询</li>
<li>ConsistentHashLoadBalance<br>
一致性哈希，启动时会将Invoker排列在一个圆环上：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) &#123;</span><br><span class="line">    this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;();</span><br><span class="line">    this.identityHashCode = identityHashCode;</span><br><span class="line">    URL url = invokers.get(0).getUrl();</span><br><span class="line"></span><br><span class="line">    String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, &quot;hash.arguments&quot;, &quot;0&quot;));</span><br><span class="line">    argumentIndex = new int[index.length];</span><br><span class="line">    for (int i = 0; i &lt; index.length; i++) &#123;</span><br><span class="line">        argumentIndex[i] = Integer.parseInt(index[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int replicaNumber = url.getMethodParameter(methodName, &quot;hash.nodes&quot;, 160);</span><br><span class="line">    for (Invoker&lt;T&gt; invoker : invokers) &#123;</span><br><span class="line">        String address = invoker.getUrl().getAddress();</span><br><span class="line">        // 多复制几个，更均匀，避免所有请求都被hash到同一个Invoker</span><br><span class="line">        for (int i = 0; i &lt; replicaNumber / 4; i++) &#123;</span><br><span class="line">            byte[] digest = md5(address + i);</span><br><span class="line">            for (int h = 0; h &lt; 4; h++) &#123;</span><br><span class="line">                long m = hash(digest, h);</span><br><span class="line">                // 放入圆环上</span><br><span class="line">                virtualInvokers.put(m, invoker);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将Invoker保存到virtualInvokers上，但是virtualInvokers本身是一个HashMap，如果新来的请求不能精确hash到其中的某个Invoker怎么办？是通过tailMap找到的下一个Invoker：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">private Invoker&lt;T&gt; selectForKey(long hash) &#123;</span><br><span class="line">    Invoker&lt;T&gt; invoker;</span><br><span class="line">    Long key = hash;</span><br><span class="line"></span><br><span class="line">    if (!virtualInvokers.containsKey(key)) &#123;</span><br><span class="line">        SortedMap&lt;Long, Invoker&lt;T&gt;&gt; tailMap = virtualInvokers.tailMap(key);</span><br><span class="line">        if (tailMap.isEmpty()) &#123;</span><br><span class="line">            key = virtualInvokers.firstKey();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            key = tailMap.firstKey();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    invoker = virtualInvokers.get(key);</span><br><span class="line">    return invoker;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="filter-invoker-层"><a class="header-anchor" href="#filter-invoker-层">¶</a>Filter &amp; Invoker 层</h3>
<p>不过，在实际网络调用之前，Dubbo还提供Filter功能，Cluster会先激活Filter链然后最终调到<code>DubboInvoker.invoke(RpcInvocation)</code>：</p>
<ol>
<li><code>ConsumerContextFilter</code>可以将请求对象<code>Invocation</code>添加到上下文<code>RpcContext</code>中，其实就是存储到一个ThreadLocal变量中。</li>
<li><code>FutureFilter</code>在调用完毕后唤醒调用者线程。</li>
<li>或许还会有一些自定义的Filter，比如增加线程的TraceId、打印一些调用日志之类的，Filter结束后才最终调用到<code>DubboInvoker</code>。</li>
</ol>
<p><code>DubboInvoker</code>封装了同步和异步调用，Dubbo 实现同步和异步调用比较关键的一点就在于由谁调用 ResponseFuture 的 get 方法。同步调用模式下，由框架自身调用 ResponseFuture 的 get 方法。异步调用模式下，则由用户调用该方法。<br>
DubboInvoker是通过Netty发送消息的，消息本身如何发送的就不多说了。</p>
<h3 id="exchange"><a class="header-anchor" href="#exchange">¶</a>Exchange</h3>
<p>封装了网络客户端的发送逻辑，包括：</p>
<ul>
<li>HeaderExchangeChannel<br>
对 Request 的序列化</li>
<li>ReferenceCountExchangeClient<br>
无引用时自动关闭客户端</li>
<li>HeaderExchangeClient<br>
心跳检测</li>
</ul>
<h3 id="数据编码-发送"><a class="header-anchor" href="#数据编码-发送">¶</a>数据编码 &amp; 发送</h3>
<p>DubboCodec<br>
NettyChannel#send</p>
<h2 id="provider端接受调用的过程"><a class="header-anchor" href="#provider端接受调用的过程">¶</a>Provider端接受调用的过程</h2>
<ol>
<li>接收请求<br>
NettyClient<br>
请求被接收后，通过 Netty 调用链向下传递执行<br>
NettyHandler#messageReceived<br>
NettyChannel</li>
<li>解码<br>
<code>ExchangeCodec</code></li>
<li>线程派发<br>
<code>Dispatcher</code><br>
IO 线程接收请求后分发给事件处理线程执行，具体的派发逻辑在<code>ChannelHandler</code>中实现，比如<code>AllChannelHandler</code>。</li>
<li>请求分发<br>
<code>ChannelEventRunnable</code><br>
根据请求类型将请求分发给不同的<code>ChannelHandler</code>处理。</li>
</ol>
<p>Provider 端响应</p>
<p>Consumer 端接收响应</p>
<ol>
<li>发送完请求后阻塞<br>
<code>HeaderExchangeHandler</code><br>
用户线程在发送完请求后，会调用 <code>DefaultFuture</code> 的 <code>get</code> 方法等待响应对象的到来，这时每个<code>DefaultFuture</code>都会关联一个<strong>调用编号</strong>，用于在接收到响应时能对应上请求的<code>DefaultFuture</code>。<br>
当响应对象到来后，IO 线程根据<strong>调用编号</strong>可以找到<code>DefaultFuture</code>，之后会将响应对象保存到<code>DefaultFuture</code>，并唤醒用户线程。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/0.html" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-01T00:49:28+08:00">
                2020-12-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.3k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Dubbo 支持多种协议，如下图所示：<br>
<img src="http://47.88.24.11/imgs/Dubbo/Protocol%E6%89%A9%E5%B1%95.png" alt="Protocol扩展" title="Protocol扩展"><br>
在通信过程中，不同的服务等级一般对应着不同的服务质量，那么选择合适的协议便是一件非常重要的事情，需要根据应用的特征来选择。例如，使用 RMI 协议，一般会受到防火墙的限制，所以对于外部与内部进行通信的场景，就不要使用 RMI 协议，而是基于 HTTP 协议或者 Hessian 协议。</p>
<h3 id="hessian-协议"><a class="header-anchor" href="#hessian-协议">¶</a>Hessian 协议</h3>
<ul>
<li>连接个数：多连接</li>
<li>连接方式：短连接</li>
<li>传输协议：HTTP</li>
<li>传输方式：同步传输</li>
<li>序列化：Hessian 二进制序列化</li>
<li>适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。</li>
<li>适用场景：页面传输，文件传输，Hessian 是 Caucho 开源的一个 RPC 框架，其通讯效率高于 WebService 和 Java 自带的序列化，Hessian 底层采用 Http 通讯，采用 Servlet 暴露服务，Dubbo 缺省内嵌 Jetty 作为服务器实现。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--定义 hessian 协议 --&gt;</span><br><span class="line">&lt;dubbo:protocol name=&quot;hessian&quot; port=&quot;8080&quot; server=&quot;jetty&quot; /&gt;</span><br><span class="line">&lt;!--设置默认协议 --&gt;</span><br><span class="line">&lt;dubbo:service protocol=&quot;hessian&quot; /&gt;</span><br><span class="line">&lt;!--设置 service 协议 --&gt;</span><br><span class="line">&lt;dubbo:service protocol=&quot;hessian&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.caucho&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hessian&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;4.0.33&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h3 id="http-协议"><a class="header-anchor" href="#http-协议">¶</a>Http 协议</h3>
<ul>
<li>连接个数：多连接</li>
<li>连接方式：短连接</li>
<li>传输协议：HTTP</li>
<li>传输方式：同步传输</li>
<li>序列化：表单序列化</li>
<li>适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或 URL 传入参数，暂不支持传文件。</li>
<li>适用场景：需同时给应用程序和浏览器 JS 使用的服务。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--配置协议 --&gt;</span><br><span class="line">&lt;dubbo:protocol name=&quot;http&quot; port=&quot;8080&quot; /&gt;</span><br></pre></td></tr></table></figure>
<h3 id="thrift-协议"><a class="header-anchor" href="#thrift-协议">¶</a>Thrift 协议</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;libthrift&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.8.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:protocol name=&quot;thrift&quot; port=&quot;3030&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>Dubbo 使用的 Thrift 和原生的 Thrift 协议不兼容，在原生协议的基础上添加了一些额外的头信息，比如 service name，magic number 等。</p>
<h3 id="rest-协议"><a class="header-anchor" href="#rest-协议">¶</a>Rest 协议</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 用rest协议在8080端口暴露服务 --&gt;</span><br><span class="line">&lt;dubbo:protocol name=&quot;rest&quot; port=&quot;8080&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 声明需要暴露的服务接口 --&gt;</span><br><span class="line">&lt;dubbo:service interface=&quot;com.service.OrderService&quot; ref=&quot;orderService&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 和本地bean一样实现服务 --&gt;</span><br><span class="line">&lt;bean id=&quot;orderService&quot; class=&quot;com.service.OrderServiceImpl&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>在代码中需要通过注解指定访问路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class OrderService &#123;    </span><br><span class="line">   void createOrder(Order order);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Path(&quot;orders&quot;) // 访问Url的相对路径</span><br><span class="line">public class OrderServiceImpl implements OrderService &#123;</span><br><span class="line"></span><br><span class="line">    @POST</span><br><span class="line">    @Path(&quot;create&quot;) // 访问Url的相对路径</span><br><span class="line">    // 将传递过来的JSON数据反序列化为Order对象</span><br><span class="line">    @Consumes(&#123;MediaType.APPLICATION_JSON&#125;) </span><br><span class="line">    public void createOrder(Order order) &#123;</span><br><span class="line">        // create the order...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="长连接-or-短连接"><a class="header-anchor" href="#长连接-or-短连接">¶</a>长连接 OR 短连接</h3>
<p>Dubbo 协议缺省每服务每提供者每消费者使用单一长连接，如果数据量较大，可以使用多个连接。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 表示该服务使用 JVM 共享长连接 --&gt;</span><br><span class="line">&lt;dubbo:service connections=&quot;0&quot;&gt; </span><br><span class="line">&lt;dubbo:reference connections=&quot;0&quot;&gt;</span><br><span class="line">&lt;!-- 表示该服务使用独立长连接 --&gt;</span><br><span class="line">&lt;dubbo:service connections=&quot;1&quot;&gt; </span><br><span class="line">&lt;dubbo:reference connections=&quot;1&quot;&gt;</span><br></pre></td></tr></table></figure>
<h3 id="为什么要消费者比提供者个数多"><a class="header-anchor" href="#为什么要消费者比提供者个数多">¶</a>为什么要消费者比提供者个数多</h3>
<p>因为 dubbo 协议采用单一长连接，假设网络为千兆网卡 3，根据测试经验数据每条连接最多只能压满 7MByte（不同的环境可能不一样），理论上 1 个服务提供者需要 20 个服务消费者才能压满网卡。</p>
<h3 id="为什么不能传大包"><a class="header-anchor" href="#为什么不能传大包">¶</a>为什么不能传大包</h3>
<p>因 dubbo 协议采用单一长连接，如果每次请求的数据包大小为 500KByte，假设网络为千兆网卡 3，每条连接最大 7MByte(不同的环境可能不一样，供参考)，单个服务提供者的 TPS(每秒处理事务数)最大为：128MByte / 500KByte = 262。单个消费者调用单个服务提供者的 TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。如果能接受，可以考虑使用，否则网络将成为瓶颈。</p>
<h3 id="为什么采用异步单一长连接"><a class="header-anchor" href="#为什么采用异步单一长连接">¶</a>为什么采用异步单一长连接</h3>
<p>因为服务的现状大都是服务提供者少，通常只有几台机器，而服务的消费者多，可能整个网站都在访问该服务，比如 Morgan 的提供者只有 6 台提供者，却有上百台消费者，每天有 1.5 亿次调用，如果采用常规的 hessian 服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用异步 IO，复用线程池，防止 C10K 问题（服务器无法服务 1w 左右的并发连接）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 配置协议端口和服务提供方最大连接数，防止服务被压垮 --&gt;</span><br><span class="line">&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; accepts=&quot;1000&quot; /&gt;</span><br><span class="line">&lt;!--配置dubbo默认协议 --&gt;</span><br><span class="line">&lt;dubbo:provider protocol=&quot;dubbo&quot; /&gt;</span><br><span class="line">&lt;!--配置dubbo设置服务协议 --&gt;</span><br><span class="line">&lt;dubbo:service protocol=&quot;dubbo&quot; /&gt;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/0.html" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-01T00:49:28+08:00">
                2020-12-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.6k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="接口扩展策略注解-spi"><a class="header-anchor" href="#接口扩展策略注解-spi">¶</a>接口扩展策略注解 @SPI</h2>
<p>Dubbo中的很多扩展接口，如 Protocol、Transporter、Filter 等，都是通过 JDK 的 SPI 机制实现的，也就是说这些功能都可被用户自定义的扩展所替换，接口扩展点由注解<code>@SPI</code>定义。<br>
JDK 中 SPI（Service Provider Interface）的设计与策略模式如出一辙，开发者可以替换掉 Dubbo 原扩展接口的默认实现，完成自定义需求，即可以自定义实现策略。<br>
Dubbo 在 JDK 现有 SPI 实现的基础上做了如下改进：</p>
<ol>
<li>JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。</li>
<li>如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK 标准的 ScriptEngine，通过 getName();获取脚本类型的名称，但如果 RubyScriptEngine 因为所依赖的 jruby.jar 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时，会报不支持 ruby，而不是真正失败的原因。</li>
<li>增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。</li>
</ol>
<p>那么 Dubbo 的 SPI 机制是怎么实现的呢？以协议扩展为例，Dubbo 中协议被抽象为 Protocol 接口。</p>
<h3 id="读取扩展点"><a class="header-anchor" href="#读取扩展点">¶</a>读取扩展点</h3>
<p>ServiceConfig#protocol</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()</span><br></pre></td></tr></table></figure>
<p>Dubbo 使用 ExtensionLoader 实现扩展点加载。</p>
<ul>
<li>ExtensionLoader#getExtensionLoader()<br>
获取 ExtensionLoader 实现，保证每种扩展点一个单例。</li>
<li>ExtensionLoader#getAdaptiveExtension()<br>
根据不同的 SPI 扩展点，即不同的 interface，生成不同的 Adaptive 实例的代码。<br>
-&gt; getAdaptiveExtensionClass()<br>
-&gt; getExtensionClasses()<br>
-&gt; loadExtensionClasses()<br>
加载所有的扩展点实现，直到扩展点方法执行时才决定调用是一个扩展点实现，即从众多的实现策略中决定具体使用哪一个策略。<br>
ExtensionLoader 会依次从<code>META-INF/dubbo/internal</code>（Dubbo 内部实现）、<code>META-INF/dubbo/</code>（开发者自定义策略）、<code>META-INF/services/</code>这几个目录下读取扩展点实现，目录下的同名文件配置了对应扩展点的实现策略，调用 loadFile 来加载对应的扩展策略。<br>
-&gt; loadFile(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir)</li>
</ul>
<h3 id="生成-adaptive-实例"><a class="header-anchor" href="#生成-adaptive-实例">¶</a>生成 Adaptive 实例</h3>
<ul>
<li>ExtensionLoader#loadFile<br>
-&gt; String fileName = dir + type.getName()<br>
拼接文件路径<br>
-&gt; ClassLoader classLoader = findClassLoader()<br>
拿到 ExtensionLoader 的类加载器。<br>
-&gt; Class&lt;?&gt; clazz = Class.forName(line, true, classLoader);<br>
文件每行是一个实现类的全路径名，通过反射加载并拿到具体类型。<br>
-&gt; extensionClasses.put(n, clazz)<br>
添加到 map 里返回。</li>
<li>ExtensionLoader#cachedClasses<br>
-&gt; cachedClasses.set(classes)<br>
添加到缓存。</li>
<li>ExtensionLoader#createAdaptiveExtensionClass<br>
-&gt; ExtensionLoader#createAdaptiveExtensionClassCode<br>
生成 Adaptive 类。<br>
-&gt; compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension()<br>
拿到编译接口扩展点的一个具体实现，dubbo 内部支持 jdk 和 javassist，默认是 javassist。<br>
-&gt; compiler.compile(code, classLoader)<br>
编译代码，生成 Adaptive 实例类。</li>
</ul>
<p>上面提到 Compiler 也是一个扩展点，同样也依赖这个流程来实例化，在运行时生成 Adaptive 实例的时候，需要生成 Compiler 接口的 Adaptive 实例，即运行生成 Adaptive 实例的时候需要先有一个 Compiler 接口的 Adaptive 实例，那这样岂不是陷入了死循环，这里就要提到显示指定 Adaptive 实例的情况。<code>@Adaptive</code>注解支持类级别和方法级别：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、类级别：只能拥有一个，注解打在接口实现类上，显示的注册一个Adaptive实例，在编译期就存在，如`AdaptiveCompiler`，解决了上面的死循环问题，由`AdaptiveCompiler`依据dubbo配置决定使用哪个编译类；</span><br><span class="line">2、方法级别：在运行期动态的生成Adaptive实例。</span><br></pre></td></tr></table></figure>
<h3 id="通过-url-动态选择协议"><a class="header-anchor" href="#通过-url-动态选择协议">¶</a>通过 URL 动态选择协议</h3>
<p>ExtensionLoader#createAdaptiveExtensionClassCode<br>
生成的 Protocol 的 Adaptive 实例类，依据 URL 中 protocol key-value 的值，选择对应的 Protocol 策略来暴露和引用服务。<br>
扩展点方法调用会有 URL 参数（或是参数有 URL 成员），这样依赖的扩展点可以从 URL 拿到配置信息，所有的扩展点自己定好配置的 Key 后，配置信息从 URL 上从最外层传入，URL 在配置传递上即是一条总线。<br>
以 dubbo+zookeeper 为例，暴露和引用远程服务都是注册在 zookeeper 上的，服务注册在 zookeeper 上本质其实是一个 URL，远程服务调用的过程中依据 URL 的 key-value 来动态决定执行 Protocol、Filter 等接口扩展点的执行策略。<br>
下面是 Provider 端暴露 HelloService 服务时在 zookeeper 上注册的 URL，在 zookeeper 上的路径为/dubbo/com.dubbo.test.service.HelloService/providers，URL 表示了采用 dubbo 协议，接口为 com.dubbo.test.service.HelloService，方法为 say，要执行的 Filter 为 whiteFilter 等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk： localhost：2181(CONNECTED) 1] Is /dubbo/com.dubbo.test.service.HelloService/providers</span><br><span class="line">[dubbo://127.0.0.1:2O881/com.dubbo.test.service.HelloService?anyhost=true&amp;application=dubbo-test-service&amp;dubbo=2.4.10&amp;group=test-prod&amp;interface=com.dubbo.test.service.HelloService&amp;methods=say&amp;pid=21242&amp;revision=l.0&amp;service.filter=whiteFilter&amp;side=providerxtamp=1495436105078&amp;version=l.0]</span><br></pre></td></tr></table></figure>
<h3 id="缓存"><a class="header-anchor" href="#缓存">¶</a>缓存</h3>
<ul>
<li>volatile Class&lt;~&gt; cachedAdaptiveClass<br>
这个是缓存 AdaptiveClass，如果一个扩展类的类上面带有 @Adaptive 注解，那么这个类就会被缓存在这个地方，每一种类型的扩展类只有一个 AdaptiveClass，如果发现有多个，则会报错。另外，当通过 getAdaptiveExtensionClass 来获取自适应扩展类时，如果当前还没有 AdaptiveClass，则会自动创建一个（动态生成 Java 代码，再编译，典型的比如 Protocol$Adaptive 就是这么生成的）</li>
<li>Set&lt;~&gt; cachedWrapperClasses<br>
这个是缓存包装类的，Dubbo 判断一个扩展类是否是包装类比较简单，通过构造函数来判断，如果这个扩展类有一个构造函数，其中参数是当前扩展类的类型，那么就是包装类，举个例子，ProtocolFilterWrapper 就是 protocol 扩展类的包装类，因为有这个构造函数：<code>public ProtocolFilterWrapper(Protocol protocol)</code></li>
<li>Map&lt;~&gt; cachedActivates<br>
这个是缓存激活的扩展类，当然，@Activate 注解还可以规定激活的条件和时机</li>
<li>Holder&lt;~&gt; cachedClasses<br>
这个是缓存 Adaptive 和 Wrapper 扩展类之外的普通扩展类</li>
</ul>
<p>扩展类被加载后会根据一定的规则放入以上 4 个缓存中，比如带有 @Adaptive 注解的会被放入 cachedAdaptiveClass。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/22fb3f5f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/22fb3f5f.html" itemprop="url">从Spring改造成SpringBoot项目</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-18T17:39:29+08:00">
                2020-11-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Spring/" itemprop="url" rel="index">
                    <span itemprop="name">Spring</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="为什么要改造"><a class="header-anchor" href="#为什么要改造">¶</a>为什么要改造</h2>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/6a07ad6.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/6a07ad6.html" itemprop="url">Redis 性能调优</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-10T12:21:48+08:00">
                2020-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  26 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Redis 监控</h1>
<p>这里把一些常见的监控命令总结一下，时不时都会用到。</p>
<h2 id="redis-cli"><a class="header-anchor" href="#redis-cli">¶</a>redis-cli</h2>
<p>命令行客户端。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建连接，可以用PING-PONG来检查连接是否OK</span><br><span class="line">redis-cli -h localhost -p 6379</span><br><span class="line"># 监控Redis的连接和读写操作</span><br><span class="line">redis-cli -h localhost -p 6379 monitor</span><br><span class="line"># Redis服务器的统计信息</span><br><span class="line">redis-cli -h localhost -p 6379 info</span><br></pre></td></tr></table></figure>
<ul>
<li>内存使用<br>
<code>Memory</code>下可以查看 Redis 内存使用情况。如果 Redis 使用的内存超出了可用的物理内存大小，那么 Redis 很可能系统会被杀掉。针对这一点，你可以通过 info 命令对 used_memory 和 used_memory_peak 进行监控，为使用内存量设定阀值，并设定相应的报警机制。当然，报警只是手段，重要的是你得预先计划好，当内存使用量过大后，你应该做些什么，是清除一些没用的冷数据，还是把 Redis 迁移到更强大的机器上去。</li>
<li>持久化<br>
<code>Persistence</code>下可以查看 RDB 和 AOF 的备份情况。如果因为你的机器或 Redis 本身的问题导致 Redis 崩溃了，那么你唯一的救命稻草可能就是 dump 出来的 rdb 文件了，所以，对 Redis dump 文件进行监控也是很重要的。可以通过对 rdb_last_save_time 进行监控，了解最近一次 dump 数据操作的时间，还可以通过对 rdb_changes_since_last_save 进行监控来获得如果这时候出现故障，会丢失（即已改变）多少数据。</li>
<li>Keys<br>
通过获取 Keyspace 中的结果得到各个数据库中 key 的数量</li>
<li>QPS<br>
即每分钟执行的命令个数，即：(total_commands_processed2-total_commands_processed1)/span，为了实时得到 QPS，可以设定脚本在后台运行，记录过去几分钟的 total_commands_processed。在计算 QPS 时，利用过去的信息和当前的信息得出 QPS 的估计值。</li>
</ul>
<h2 id="redis-stat"><a class="header-anchor" href="#redis-stat">¶</a>redis-stat</h2>
<p>Redis 服务器的<strong>实时</strong>信息。<br>
这个命令不是 Redis 官方提供的，而是一个三方用 ruby 写的监控程序，安装起来有点麻烦，这里就不说明了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># usage:redis-stat [HOST[:PORT] ...] [INTERVAL [COUNT]]</span><br><span class="line"># 每1s收集一次</span><br><span class="line">redis-stat 1</span><br><span class="line"># 指定主机和服务器端口，间隔为1s，收集10次</span><br><span class="line">redis-stat localhost:6379 1 10</span><br><span class="line"># 启动一个redis-stat服务进程，提供一个Dashboard来查看Redis服务器的状态，按如下启动，可以访问 `localhost:8080` 查看</span><br><span class="line">redis-stat localhost:6379 --server=8080 5 --daemon</span><br></pre></td></tr></table></figure>
<p>-a, --auth=PASSWORD 密码<br>
-v, --verbose       展示更多信息<br>
–style=STYLE       输出样式：unicode|ascii<br>
–no-color          去掉颜色<br>
–csv[=CSV_FILE]    打印或将结果保存到 CSV 文件内<br>
–es=ELASTICSEARCH_URL  将结果发送到 ElasticSearch：[http://]HOST[:PORT][/INDEX]<br>
–server[=PORT]     启动 redis-stat 服务器（默认端口是 63790）<br>
–daemon            启动 redis-stat 作为守护进程，必须和 --server 选项一起使用<br>
–version           版本<br>
–help              帮助信息</p>
<h2 id="slowlog"><a class="header-anchor" href="#slowlog">¶</a>slowlog</h2>
<p>慢查询日志。<br>
可以在 redis.conf 中配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 记录执行时间超过5秒的查询</span><br><span class="line">config set slowlog-log-slower-than 5000</span><br><span class="line"># 最多保存25条日志</span><br><span class="line">config set slowlog-max-len 25</span><br></pre></td></tr></table></figure>
<p>使用 redis-cli 登录查看慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 获取10条日志</span><br><span class="line">slowlog get 10</span><br></pre></td></tr></table></figure>
<h2 id="redis-benchmark"><a class="header-anchor" href="#redis-benchmark">¶</a>redis-benchmark</h2>
<p>redis-benchmark 是 Redis 官方提供的 Redis 服务器性能基准测试工具：<br>
-t 选择你想测试的命令，比如 redis-benchmark -t set<br>
-p 指定 port redis-benchmark -p 6379<br>
-l 一直循环<br>
-c 指定客户端数量<br>
-n 指定 request 数量<br>
-q Quiet，不显示额外信息（多少时间内完成了多少条之类的），只显示 query/sec 的值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 测试并发连接性能，100个并发连接，总共发100000个请求</span><br><span class="line">redis-benchmark -h localhost -p 6379 -c 100 -n 100000</span><br><span class="line"># 测试大数据包读写性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q -d 100</span><br><span class="line"># 只测试某些操作的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -t set,lpush -n 100000 -q</span><br><span class="line"># 只测试某些数值存取的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q script load &quot;redis.call(&apos;set&apos;, &apos;foo&apos;, &apos;bar&apos;)&quot;</span><br></pre></td></tr></table></figure>
<h2 id="rdb-文件分析"><a class="header-anchor" href="#rdb-文件分析">¶</a>RDB 文件分析</h2>
<p>Redis 内存比较大的时候不容易查出是哪些 key 比较占空间，这时可以使用 <a href="https://github.com/sripathikrishnan/redis-rdb-tools" target="_blank" rel="noopener">redis-rdb-tools</a> 这种工具来查看报告。</p>
<h1>Redis性能问题排查</h1>
<h2 id="哪些场景会导致redis阻塞？"><a class="header-anchor" href="#哪些场景会导致redis阻塞？">¶</a>哪些场景会导致Redis阻塞？</h2>
<p>Redis实例运行期间会和多种对象进行交互：</p>
<ul>
<li>客户端：网络 IO，键值对增删改查操作，数据库操作；</li>
<li>磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；</li>
<li>主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件；</li>
<li>切片集群实例：向其他实例传输哈希槽信息，数据迁移。</li>
</ul>
<h2 id="如果redis变慢-可能是什么导致的？"><a class="header-anchor" href="#如果redis变慢-可能是什么导致的？">¶</a>如果Redis变慢，可能是什么导致的？</h2>
<ol>
<li>Redis是单线程模型，如果前面有请求执行比较慢，后面的都要排队等着；<br>
耗时的操作包括：
<ul>
<li>集合全量查询和聚合操作：比如HGETALL、SMEMBERS</li>
<li>操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；<br>
特别是删除大key时需要释放内存，操作系统需要将释放掉的内存块插入到一个空闲内存块的链表，以便后续进行管理和再分配（指malloc/free）。</li>
<li>使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</li>
<li>大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</li>
<li>淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</li>
<li>AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</li>
<li>主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；<br>
对此，需要业务人员主动规避上述可能导致超时的情况；</li>
</ul>
</li>
<li>并发非常大，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。<br>
对此，Redis6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据。</li>
</ol>
<h2 id="如何检测redis是否变慢？"><a class="header-anchor" href="#如何检测redis是否变慢？">¶</a>如何检测Redis是否变慢？</h2>
<p>如何排查Redis是否真的变慢，一个直接的方法是查看Redis的<strong>响应延迟</strong>，但是响应延迟多长算慢呢？不同硬件性能不同，这个值的判断也是不同的，并没有绝对的标准。<br>
另一种方法是测算当前环境下的 Redis <strong>基线性能</strong>，也就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。<br>
从 2.8.7 版本开始，<code>redis-cli</code> 命令提供了<code>–intrinsic-latency</code> 选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能。<br>
一般我们可以把Redis基线性能和响应延迟结合起来判断Redis是否变慢了，如果观察到Redis延迟是其基线性能的2倍以上，就可以认定Redis变慢了。</p>
<h1>Redis性能优化</h1>
<h2 id="内存优化"><a class="header-anchor" href="#内存优化">¶</a>内存优化</h2>
<ol>
<li>压缩的类型<br>
在数据量比较少时，Redis会使用占用内存更少的数据类型，包括hash、list、set、zset均为如此，占用的内存大小甚至可以达到普通类型的1/5。<br>
hash-max-ziplist-entries 512<br>
hash-max-ziplist-value 64<br>
zset-max-ziplist-entries 128<br>
zset-max-ziplist-value 64<br>
set-max-intset-entries 512<br>
压缩的类型是“拿时间换空间”，因此效率肯定是比不上普通类型的，只是数据量比较小的情况下二者是差不多的，试想：虽然一个压缩类型对象并不能省多少空间，但是如果很多很多对象都经过压缩，那么最终总体上就能省很多空间了。<br>
当对象占用内存超过配置的最大值，Redis会自动将其转换为普通类型。</li>
<li>尽量使用散列表<br>
小散列表占用的内存非常小</li>
</ol>
<h2 id="慢查询命令"><a class="header-anchor" href="#慢查询命令">¶</a>慢查询命令</h2>
<p>使用Redis前必须先了解各种指令的复杂度，比如get、set是O(1)的，set的smembers是O(N)的。<br>
当发现性能变慢时，可以通过：</p>
<ol>
<li>Redis日志查询变慢的请求；</li>
<li>latency monitor工具查询变慢请求；</li>
</ol>
<p>如果确实有大量满查询命令，可以：</p>
<ol>
<li>用其他高效命令代替；</li>
<li>sort、sunion、sinter这些复杂操作可以将逻辑转移到客户端完成。<br>
如果业务逻辑就是得用慢查询命令完成，那可以考虑采用性能更好的CPU，从而更快地完成查询命令。</li>
</ol>
<h2 id="过期key操作"><a class="header-anchor" href="#过期key操作">¶</a>过期key操作</h2>
<p>Redis4.0之前，淘汰key的机制中，删除操作是阻塞的，而淘汰机制会不断抽样，直到过期的key只占不到25%的比例，因此淘汰很有可能会影响主线程；在Redis4.0之后采用异步线程机制来减少阻塞影响）。<br>
比如同一时间有很多key设置了相同的过期时间，就会导致这种情况。</p>
<h2 id="批量请求优化"><a class="header-anchor" href="#批量请求优化">¶</a>批量请求优化</h2>
<p>使用管道Pipelineing：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ (printf &quot;PING\r\nPING\r\nPING\r\n&quot;; sleep 1) | nc localhost 6379</span><br></pre></td></tr></table></figure>
<p>优点：</p>
<ol>
<li>一次连接就可以执行多次请求；</li>
</ol>
<p>缺点：</p>
<ol>
<li>使用管道发送命令时，服务器将被迫回复一个队列答复，占用很多内存。所以，如果你需要发送大量的命令，最好是把他们按照合理数量分批次的处理，例如10K的命令，读回复，然后再发送另一个10k的命令，等等。这样速度几乎是相同的，但是在回复这10k命令队列需要非常大量的内存用来组织返回数据内容。</li>
</ol>
<h2 id="大量数据插入"><a class="header-anchor" href="#大量数据插入">¶</a>大量数据插入</h2>
<p>大量数据插入时会面临以下问题：</p>
<ol>
<li>一个一个插入的话会有很多时间浪费在请求的往返上，因此需要批量执行<br>
批量执行可以是：管道、lua脚本</li>
<li>批量插入的过程怎么保证所有key都能插入成功</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SET Key0 Value0</span><br><span class="line">SET Key1 Value1</span><br><span class="line">...</span><br><span class="line">SET KeyN ValueN</span><br></pre></td></tr></table></figure>
<p>如果是如下的pipeline，其实并不可靠，因为执行过程中不能检查错误。<br>
<code>(cat data.txt; sleep 10) | nc localhost 6379 &gt; /dev/null</code><br>
一种更好的方式是使用redis-cli中的<strong>pipe mode</strong>，期间会把错误输出到终端：<br>
<code>cat data.txt | redis-cli --pipe</code></p>
<h2 id="大-key-问题"><a class="header-anchor" href="#大-key-问题">¶</a>大 Key 问题</h2>
<blockquote>
<p>大key大的是value。</p>
</blockquote>
<p>大 Key 有两种状况：</p>
<ol>
<li>Redis 中单个简单的 Key 存储的 value 很大</li>
<li>hash、set、zset、list 中存储的元素过多（以万为单位）。</li>
</ol>
<p>由于 Redis 的单线程模型，读写大 Key 时服务器的耗时可能会比较长、甚至阻塞。</p>
<p>分析大key可以通过<code>--bigkeys</code>进行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hgc@hgc-X555LD:~$ redis-cli -h 127.0.0.1 -p 6379 -n 0 --bigkeys</span><br><span class="line"></span><br><span class="line"># Scanning the entire keyspace to find biggest keys as well as</span><br><span class="line"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span><br><span class="line"># per 100 SCAN commands (not usually needed).</span><br><span class="line"></span><br><span class="line">[00.00%] Biggest string found so far &apos;143&apos; with 35 bytes</span><br><span class="line">[00.00%] Biggest string found so far &apos;a&apos; with 184 bytes</span><br><span class="line">[73.33%] Biggest hash   found so far &apos;b&apos; with 1 fields</span><br><span class="line"></span><br><span class="line">-------- summary -------</span><br><span class="line"></span><br><span class="line">Sampled 15 keys in the keyspace!</span><br><span class="line">Total key length in bytes is 41 (avg len 2.73)</span><br><span class="line"></span><br><span class="line">Biggest   hash found &apos;b&apos; has 1 fields</span><br><span class="line">Biggest string found &apos;a&apos; has 184 bytes</span><br><span class="line"></span><br><span class="line">0 lists with 0 items (00.00% of keys, avg size 0.00)</span><br><span class="line">1 hashs with 1 fields (06.67% of keys, avg size 1.00)</span><br><span class="line">14 strings with 639 bytes (93.33% of keys, avg size 45.64)</span><br><span class="line">0 streams with 0 entries (00.00% of keys, avg size 0.00)</span><br><span class="line">0 sets with 0 members (00.00% of keys, avg size 0.00)</span><br><span class="line">0 zsets with 0 members (00.00% of keys, avg size 0.00)</span><br></pre></td></tr></table></figure>
<p><code>bigkeys</code>是通过scan指令来实现的，所以并不会造成服务器长时间的阻塞，当然这种数据库全扫命令最好还是少用。</p>
<p>解决方案一般是能拆则拆，对于单个大 Key 的情况：<br>
1.1 将大 Key 进行分割，拆成几个小的 key-value，使用 multiGet 获取值。<br>
这样分拆的意义是将单次操作的压力分摊到多个 Redis 实例上，降低对单个 Redis 的 IO 影响，而且大 Key 拆分之后每次只查询一部分，减小了 IO 阻塞的风险。<br>
为了均匀分割，可以对 field 进行 hash 并通过质数 N 取余，将余数加到 key 上面。<br>
1.2 将大 Key 拆分成多个 key-value，并将这些存储在一个 hash 中，每个 field 代表一个具体的属性，使用 hget、hmget 来获取部分的 value，使用 hset、hmset 来更新部分属性</p>
<p>对于 hash、set、zset、list 中存储的元素过多的情况，可以控制将 field 分散到多个集合内。<br>
比如以下代码将属于一个大 hash 内的 field 分散到 10000 个拆分后的小 hash 内：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">newHashKey = hashKey + (hash(field) % 10000)</span><br><span class="line">hset(newHashKey, field, value)</span><br><span class="line">hget(newHashKey, field)</span><br></pre></td></tr></table></figure>
<p>对于一些需要考虑顺序的场景，比如 lpop、zrange，需要在 hash 函数上做些文章，比如按照时间来拆分。</p>
<h2 id="redis与cpu的关系"><a class="header-anchor" href="#redis与cpu的关系">¶</a>Redis与CPU的关系</h2>
<p>在现代CPU架构中，每个物理核心都会有一个私有的L1 cache和L2 cache，不同核之间共用一个L3缓存，尽可能避免访问主存。<br>
应用程序会被分配到一个CPU上执行，但是进程调度机制可能会将Redis进程调度到另一个核心上，导致之前加载的缓存都白费了。<br>
可以通过taskset命令将Redis进程绑定在一个核上运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># -c 用于设置要绑定的核编号</span><br><span class="line">taskset -c 0 ./redis-server</span><br></pre></td></tr></table></figure>
<h2 id="内存碎片"><a class="header-anchor" href="#内存碎片">¶</a>内存碎片</h2>
<p>Redis底层分配内存函数是jmalloc，它分配的内存大小总是2的幂倍数，如果分配的内存大小比实际使用的要多一些，就会产生内存碎片，内存碎片多了后就会有很多内存的浪费情况，特别是<strong>分配键值对的大小不一的情况下，内存碎片会尤其严重</strong>。</p>
<h3 id="查看内存碎片"><a class="header-anchor" href="#查看内存碎片">¶</a>查看内存碎片</h3>
<p>查看内存碎片情况很容易，可以直接使用<code>info</code>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">10.32.140.14:6211&gt; info memory</span><br><span class="line"># Memory</span><br><span class="line">used_memory:1441123632</span><br><span class="line">used_memory_human:1.34G</span><br><span class="line">used_memory_rss:1853603840</span><br><span class="line">used_memory_rss_human:1.73G</span><br><span class="line">...</span><br><span class="line">mem_fragmentation_ratio:1.29</span><br></pre></td></tr></table></figure>
<p>其中<code>mem_fragmentation_ratio</code>这个指标就是Redis当前的内存碎片率，它的值其实就是<code>used_memory_rss</code>和<code>used_memory</code>相除的结果（<code>used_memory_rss/used_memory</code>），前者是OS分配给Redis的内存空间，包含碎片，后者不包含碎片。</p>
<ul>
<li><code>mem_fragmentation_ratio</code>在<code>[1,1.5]</code>范围内是合理的，因为内存碎片无法完全避免</li>
<li><code>mem_fragmentation_ratio</code>大于1.5则需要采取一些措施来减小内存碎片率。</li>
</ul>
<h3 id="处理内存碎片"><a class="header-anchor" href="#处理内存碎片">¶</a>处理内存碎片</h3>
<ul>
<li>重启Redis实例。这是最简单的方法，但是重启后Redis内存中的数据会全部丢失，除非进行了持久化，但恢复也是需要不少时间的。</li>
<li>从Redis4.0-RC3后，Redis自身提供了内存碎片清理的功能，也即将内存数据拷贝到一块新的内存位置，可以设置参数控制碎片清理的开始、结束时机、占用的内存比例等：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 开启内存碎片清理功能</span><br><span class="line">config set activedefrag yes</span><br><span class="line"># 表示内存碎片达到100MB时开始清理</span><br><span class="line">active-defrag-ignore-bytes 100mb</span><br><span class="line"># 表示内存碎片空间占Redis总空间大小的10%时</span><br><span class="line">tive-defrag-threshold-lower 10</span><br><span class="line"># 控制清理过程占用CPU时间比例不低于25%，保证清理能正常</span><br><span class="line">adtive-defrag-cycle-min 25</span><br><span class="line"># 控制清理过程占用CPU时间比例不高于75%，尽量不要影响主线程</span><br><span class="line">active-defrag-cycle-max 75</span><br></pre></td></tr></table></figure>
<h2 id="其他优化点"><a class="header-anchor" href="#其他优化点">¶</a>其他优化点</h2>
<ul>
<li>单进程单线程，无法充分发挥服务器多核 cpu 的性能；大流量下造成 IO 阻塞，同样是由于单进程单线程, cpu 在处理业务逻辑的时候,网络 IO 被阻塞住, 造成无法处理更多的请求.<br>
多线程 master + N<em>work 工作模式.master 线程负责监听网络事件, 在接收到一个新的连接后, master 会把新的 fd 注册到 worker 的 epoll 事件中, 交由 worker 处理这个 fd 的所有读写事件, 这样 master 线程就可以完全被释放出来接收更多的连接, 同时又不妨碍 worker 处理业务逻辑和 IO 读写.<br>
采用这种 master + N</em>worker 的网络层事件模型,可以实现 redis 性能的平行扩展. 真正的让 redis 在面临高并发请求时可以丛容面对.</li>
<li>维护成本高, 如果想要充分发挥服务器的所有资源包括 cpu, 网络 io 等, 就必须建立多个 instance, 但此时不可避免会增加维护成本. 拿 24 核服务器举例来讲, 如果部署 24 个单机版的 instance,理论上可以实现 10w*24core= 240wQPS 的总体性能.但是每个 instance 有各自独立的数据,占用资源如内存也会同比上升,反过来制约一台服务器又未必能支持这么多的 instance. 如果部署 24 个 Instance 来构成单机集群, 虽然可以共享数据，但是因为节点增加, redis 的状态通讯更加频繁和费时,性能也下会降很多. 并且两种方式都意味着要维护 24 个 Instance，运维成本都会成倍增加.</li>
<li>持久化：redis 提供了两种 save 方式 1)save 触发. 2)bgsave. 当然也可以使用 3)aof 来实现持久化, 但是这 3 点都有弊端.
<ul>
<li>save: 由于是单进程单线程, redis 会阻塞住所有请求, 来遍历所有 redisDB, 把 key-val 写入 dump.rdb. 如果内存数据量过大, 会造成短时间几秒到几十秒甚至更长的时间停止服务, 这种方案对于 twitter, taobao 等大流量的网站, 显然是不可取的.</li>
<li>bgsave: 在触发 bgsave 时, redis 会 fork 自身, child 进程会进入 1)的处理方式,这意味着服务器内存要有一半的冗余才可以, 如今内存已变得越来越廉价, 但是对于存储海量数据的情况,内存以及服务器的成本还是不容忽视的.</li>
<li>aof: 说到持久化, redis 提供的 aof 算是最完美的方案了, 但是有得必有失, 严重影响性能! 因为 redis 每接收到一条请求, 就要把命令内容完整的写到磁盘文件, 且不说频繁读写会影响磁盘寿命,写磁盘的时间足以拖垮 redis 整体性能 . 当然熟悉 redis 的开发者会想到用 appendfsync 等参数来调整, 但都不是完美.即使使用 SSD，性能也只是略有提升，并且性价比不高。</li>
</ul>
</li>
<li>优化 jemalloc, 采用大内存页. Redis 在使用内存方面可谓苛刻至极, 压缩, string 转 number 等, 能省就省, 但是在实际生产环境中, 为了追求性能, 对于内存的使用可以适度（不至于如 bgsave 般浪费）通融处理, 因此 AliRedis 对 jemalloc 做了微调, 通过调整 pagesize 来让一次 je_malloc 分配更多 run 空间来储备更多的用户态可用内存, 同时可以减轻换页表的负载, 降低 user sys 的切换频率, 来提高申请内存的性能, 对 jemalloc 有兴趣的开发者可以参考 jemalloc 源码中的 bin, run, chunk 数据结构进行分析.</li>
</ul>
<h1>Redis配置</h1>
<h2 id="内存"><a class="header-anchor" href="#内存">¶</a>内存</h2>
<p>因为系统的内存大小有限，所以我们在使用 Redis 的时候可以配置 Redis 能使用的最大的内存大小。<br>
redis.conf：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Redis最大占用内存大小</span><br><span class="line">maxmemory 100mb</span><br></pre></td></tr></table></figure>
<p>通过命令修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set maxmemory 100mb</span><br><span class="line">127.0.0.1:6379&gt; config get maxmemory</span><br></pre></td></tr></table></figure>
<p>如果不设置最大内存大小或设置最大内存大小为 0，在 64 位操作系统下不限制内存大小，在 32 位操作系统下最大使用 3GB 内存。</p>
<h2 id="修改数据库配置"><a class="header-anchor" href="#修改数据库配置">¶</a>修改数据库配置</h2>
<p>redis 默认创建 16 个数据库（类似一个数组），默认值对应在 redis.conf 配置文件中 database 的值。<br>
默认使用 0 号库，可以使用 select 命令来选择其他库。</p>
<h2 id="过期时间的设置"><a class="header-anchor" href="#过期时间的设置">¶</a>过期时间的设置</h2>
<p>如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。</p>
<h2 id="连接设置"><a class="header-anchor" href="#连接设置">¶</a>连接设置</h2>
<h3 id="redis连接配置"><a class="header-anchor" href="#redis连接配置">¶</a>Redis连接配置</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>port 16371</td>
<td>指定Redis监听端口，默认端口为6379</td>
<td></td>
</tr>
<tr>
<td>bind 10.56.50.164</td>
<td>绑定的主机地址</td>
<td></td>
</tr>
<tr>
<td>timeout 2000</td>
<td>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</td>
<td>在压测时需要修改</td>
</tr>
<tr>
<td>tcp-keepalive 0</td>
<td>redis服务端主动向空闲的客户端发起ack请求，以判断连接是否有效，0表示未启用。定时向client发送tcp_ack包来探测client是否存活的。默认不探测，官方建议值为60秒</td>
<td>建议开启，避免连接意外中断后，服务端不能释放</td>
</tr>
<tr>
<td>maxclients 30000</td>
<td>设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="修改最大tcp连接"><a class="header-anchor" href="#修改最大tcp连接">¶</a>修改最大TCP连接</h3>
<p>1、编辑文件 sudo vim /etc/security/limits.conf ，添加如下内容</p>
<ul>
<li>soft nproc 60240</li>
<li>hard nproc 60240</li>
<li>soft nofile 65535</li>
<li>hard nofile 65535<br>
2、编辑文件 vi /etc/pam.d/login，在末尾添加如下内容<br>
session required /usr/lib64/security/pam_limits.so<br>
3、编辑文件 /etc/pam.d/system-auth ，添加如下内容<br>
session required /lib/security/$ISA/pam_limits.so<br>
4、重启虚机</li>
</ul>
<h3 id="修改tcp连接等待队列长度"><a class="header-anchor" href="#修改tcp连接等待队列长度">¶</a>修改TCP连接等待队列长度</h3>
<p>编辑系统控制文件，加入tcp最长队列参数<br>
1、编辑文件 vim /etc/sysctl.conf 添加如下内容<br>
net.core.somaxconn=5120<br>
2、查看修改<br>
sudo sysctl -p<br>
3、同步修改<br>
sudo sysctl vm.overcommit_memory=1<br>
4、关闭透明大页</p>
<ul>
<li>具有sudo权限的用户 （尝试过echo 命令 ，权限不允许）<br>
sudo vim  /etc/grub2.cfg 文件尾加上<br>
transparent_hugepage=never<br>
【或者使用root用户执行 echo “transparent_hugepage=never”&gt;&gt; /etc/grub2.cfg 】</li>
<li>root用户</li>
</ul>
<h1>echo never&gt;/sys/kernel/mm/transparent_hugepage/enabled</h1>
<ul>
<li>验证结果 返回 0 说明生效<br>
$ grep -i HugePages_Total /proc/meminfo<br>
HugePages_Total:       0<br>
$ cat /proc/sys/vm/nr_hugepages<br>
0</li>
</ul>
<h2 id="持久化"><a class="header-anchor" href="#持久化">¶</a>持久化</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>
<p>指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合<br>
save <seconds> <changes><br>
分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。<br>
建议值：</changes></seconds></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 20</span><br><span class="line">save 300 2000</span><br><span class="line">save 60 200000</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>stop-writes-on-bgsave-error yes</td>
<td>配置项stop-writes-on-bgsave-error no （默认值为yes），即当bgsave快照操作出错时停止写数据到磁盘，这样后面写错做均会失败，为了不影响后续写操作，故需将该项值改为no。</td>
<td>强制关闭Redis快照可能会导致不能持久化。MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.</td>
</tr>
<tr>
<td>rdbcompression yes</td>
<td>指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大</td>
<td>开启压缩</td>
</tr>
<tr>
<td>rdbchecksum yes</td>
<td>(对rdb数据进行校验,耗费CPU资源,默认为yes)默认值是yes。在存储快照后，让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td>
<td>建议关闭</td>
</tr>
<tr>
<td>appendfsync everysec	指定更新日志条件，共有3个可选值：no表示等操作系统进行数据缓存同步到磁盘（快）；always表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）；everysec表示每秒同步一次（折衷，默认值）</td>
<td></td>
<td></td>
</tr>
<tr>
<td>no-appendfsync-on-rewrite no</td>
<td>是否在后台写时同步单写，默认值no(表示需要同步).这里的后台写，表示后台正在重写文件(包括bgsave和bgrewriteaof.bgrewriteaof网上很多资料都没有涉及到。其实关掉bgsave之后，主要的即是aof重写文件了).no表示新的主进程的set操作会被阻塞掉，而yes表示新的主进程的set不会被阻塞，待整个后台写完成之后再将这部分set操作同步到aof文件中。但这可能会存在数据丢失的风险(机率很小)，如果对性能有要求，可以设置为yes，仅在后台写时会异步处理命令.</td>
<td>压测时建议修改成yes</td>
</tr>
<tr>
<td>auto-aof-rewrite-percentage 100</td>
<td>aof文件增长比例，指当前aof文件比上次重写的增长比例大小。aof重写即在aof文件在一定大小之后，重新将整个内存写到aof文件当中，以反映最新的状态(相当于bgsave)。这样就避免了，aof文件过大而实际内存数据小的问题(频繁修改数据问题).</td>
<td></td>
</tr>
<tr>
<td>auto-aof-rewrite-min-size 64mb</td>
<td>aof文件重写最小的文件大小，即最开始aof文件必须要达到这个文件时才触发，后面的每次重写就不会根据这个变量了(根据上一次重写完成之后的大小).此变量仅初始化启动redis有效.如果是redis恢复时，则lastSize等于初始aof文件大小.</td>
<td></td>
</tr>
<tr>
<td>aof-load-truncated yes</td>
<td>指redis在恢复时，会忽略最后一条可能存在问题的指令。默认值yes。即在aof写入时，可能存在指令写错的问题(突然断电，写了一半)，这种情况下，yes会log并继续，而no会直接恢复失败.</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="主从配置"><a class="header-anchor" href="#主从配置">¶</a>主从配置</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>slave-serve-stale-data yes</td>
<td>slave-serve-stale-data参数设置成yes，主从复制中，从服务器可以响应客户端请求</td>
<td></td>
</tr>
<tr>
<td>slave-read-only yes</td>
<td>如果为 yes，代表为只读状态，但并不表示客户端用集群方式以从节点为入口连入集群时，不可以进行 set 操作，且 set 操作的数据不会被放在从节点的槽上，会被放到某主节点的槽上</td>
<td></td>
</tr>
<tr>
<td>repl-diskless-sync no</td>
<td>一个RDB文件从master端传到slave端，分为两种情况：1、支持disk：master端将RDB file写到disk，稍后再传送到slave端；2、无磁盘diskless：master端直接将RDB file传到slave socket，不需要与disk进行交互。</td>
<td></td>
</tr>
<tr>
<td>无磁盘diskless方式适合磁盘读写速度慢但网络带宽非常高的环境。repl-diskless-sync no 默认不使用diskless同步方式</td>
<td></td>
<td></td>
</tr>
<tr>
<td>repl-diskless-sync-delay 5</td>
<td>无磁盘diskless方式在进行数据传递之前会有一个时间的延迟，以便slave端能够进行到待传送的目标队列中，这个时间默认是5秒</td>
<td></td>
</tr>
<tr>
<td>repl-disable-tcp-nodelay no</td>
<td>是否启用TCP_NODELAY，如果启用则会使用少量的TCP包和带宽去进行数据传输到slave端，当然速度会比较慢；如果不启用则传输速度比较快，但是会占用比较多的带宽。</td>
<td></td>
</tr>
<tr>
<td>slave-priority 100</td>
<td>slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。</td>
<td></td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/1942bbd0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/1942bbd0.html" itemprop="url">Redis事务和Lua</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-09T22:42:14+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="缓存系统如何工作"><a class="header-anchor" href="#缓存系统如何工作">¶</a>缓存系统如何工作</h2>
<h3 id="缓存的两个特征"><a class="header-anchor" href="#缓存的两个特征">¶</a>缓存的两个特征</h3>
<ol>
<li>在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。</li>
<li>缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。</li>
</ol>
<h3 id="redis作为旁路缓存"><a class="header-anchor" href="#redis作为旁路缓存">¶</a>Redis作为旁路缓存</h3>
<p>作为缓存，我们在访问数据时可能会：</p>
<ul>
<li>命中：直接将缓存中的数据返回；</li>
<li>miss：缓存缺失，回源到MySQL读取数据，加载到缓存中；</li>
</ul>
<p>这种情况下，Redis就作为旁路缓存使用，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>
<ul>
<li>如果是只读缓存，那么上述的旁路缓存设计就足够了；</li>
<li>如果是读写缓存，还有同步直写（写缓存的同时写DB）和异步写回（写缓存后异步写DB）这两种策略，各有优缺点。<br>
同步直写效率低，但是一致性高；<br>
异步写回效率高，但是一致性低。</li>
</ul>
<h2 id="缓存满了怎么办？"><a class="header-anchor" href="#缓存满了怎么办？">¶</a>缓存满了怎么办？</h2>
<h3 id="缓存淘汰-缓存失效策略和主键失效机制"><a class="header-anchor" href="#缓存淘汰-缓存失效策略和主键失效机制">¶</a>缓存淘汰（缓存失效策略和主键失效机制）</h3>
<p>作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略，比如 Redis 只能存 5G 数据，可是你写了 10G，那多出来的 5G 数据怎么删？你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高？这就需要深入到 Redis 的主键失效和淘汰策略中去了。</p>
<h4 id="key-的过期时间控制"><a class="header-anchor" href="#key-的过期时间控制">¶</a>key 的过期时间控制</h4>
<p>在 Redis 当中，有生存期的 key 被称为 volatile。在创建缓存时，要为给定的 key 设置生存期，当 key 过期的时候（生存期为 0），它可能会被删除。</p>
<ol>
<li>影响生存时间的一些操作<br>
生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改 key 对应的 value 和使用另外相同的 key 和 value 来覆盖以后，当前数据的生存时间不同。<br>
比如说，对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。<br>
RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用 PERSIST 命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个 persistent key 。</li>
<li>如何更新生存时间<br>
可以对一个已经带有生存时间的 key 执行 EXPIRE 命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在 1ms 之内，主键失效的时间复杂度是 O（1），<br>
EXPIRE 和 TTL 命令搭配使用，TTL 可以查看 key 的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。</li>
<li>最大缓存配置<br>
在 redis 中，允许用户设置最大使用内存大小 <code>server.maxmemory</code><br>
默认为 0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使 redis 崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</li>
</ol>
<h4 id="key-的删除策略"><a class="header-anchor" href="#key-的删除策略">¶</a>key 的删除策略</h4>
<p>redis 采用的是定期删除+惰性删除策略。</p>
<ol>
<li>为什么不用定时删除策略?<br>
定时删除,用一个定时器来负责监视 key,过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 key,因此没有采用这一策略.</li>
<li>定期删除+惰性删除是如何工作的呢?<br>
定期删除，redis 默认每个 100ms 检查，是否有过期的 key,有过期 key 则删除。需要说明的是，redis 不是每个 100ms 将所有的 key 检查一次，而是随机抽取进行检查(如果每隔 100ms,全部 key 进行检查，redis 岂不是卡死)。因此，如果只采用定期删除策略，会导致很多 key 到时间没有删除。<br>
于是，惰性删除派上用场。也就是说在你获取某个 key 的时候，redis 会检查一下，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</li>
<li>采用定期删除+惰性删除就没其他问题了么?<br>
不是的，如果定期删除没删除 key。然后你也没即时去请求 key，也就是说惰性删除也没生效。这样，redis 的内存会越来越高。那么就应该采用内存淘汰机制。</li>
</ol>
<h4 id="redis-的数据淘汰策略"><a class="header-anchor" href="#redis-的数据淘汰策略">¶</a>Redis 的数据淘汰策略</h4>
<p>在 redis.conf 中有一行配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># maxmemory-policy volatile-lru</span><br></pre></td></tr></table></figure>
<p>redis 提供 6种数据淘汰策略：</p>
<ol>
<li>no-enviction（驱逐）：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错（应该没人用）</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰（这种情况一般是把 redis 既当缓存，又做持久化存储的时候才用。不推荐）</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰（不推荐）<br>
可以在一些需要“置顶”的业务场景里采用，比如一些新闻、视频需要置顶，这些数据不需要设置过期时间，<code>volatile-ttl</code>就不会删除它们。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰（不推荐）</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰（推荐）</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
</ol>
<p>注意这里的 6 种机制：</p>
<ul>
<li>volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据；</li>
<li>lru、ttl 以及 random 是三种不同的淘汰策略，ttl 和 random 比较容易理解、实现也会比较简单，lru 会对 key 按失效时间排序，然后取最先失效的 key 进行淘汰。</li>
<li>如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。</li>
</ul>
<p><strong>使用策略规则</strong></p>
<ol>
<li>如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru</li>
<li>如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 allkeys-random</li>
</ol>
<h4 id="自定义缓存淘汰策略"><a class="header-anchor" href="#自定义缓存淘汰策略">¶</a>自定义缓存淘汰策略</h4>
<p>除了缓存服务器自带的缓存失效策略之外（Redis 默认有 6 种策略可选），我们还可以根据具体的业务需求自定义缓存淘汰策略，常见的策略有两种：</p>
<ol>
<li>定时去清除过期的缓存；</li>
<li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存；</li>
</ol>
<p>两种策略各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂。需要根据应用场景的特点来权衡选择。</p>
<h4 id="缓存淘汰的实现"><a class="header-anchor" href="#缓存淘汰的实现">¶</a>缓存淘汰的实现</h4>
<ol>
<li>设置过期时间<br>
过期时间到了后，Redis 会在读的时候判断是否过期并清除，或者由一个定时任务执行清除操作。</li>
<li>超过 maxmemory 回收<br>
可以设置淘汰机制，比如 LRU、LFU。</li>
</ol>
<p>LRU 算法的一种简单实现<br>
简单版本的 LRU 算法分两个部分：</p>
<ol>
<li>一个链表记录 key 的最终访问次序，比如最新访问的在链表头部，最久没访问的在链表末尾，LRU 淘汰机制就是删除链表末尾的节点；</li>
<li>一个散列表记录某个 key 是否存在，并可以找到其在链表中的位置；</li>
</ol>
<p>Redis 中的 LRU<br>
<img src="http://47.88.24.11/imgs/Redis/Redis-LRU%E7%AE%97%E6%B3%95.png" alt="Redis-LRU算法" title="Redis-LRU算法"><br>
代码位置：<code>evict.c/freeMemoryIfNeeded</code><br>
Redis 中并没有直接使用上述的 LRU 算法，主要是因为维护LRU链表开销较大，而是退一步使用了抽样淘汰的机制：</p>
<ol>
<li>每次从缓存对象集合中随机取出一部分样本（20个key），进行下面的过期检测；</li>
<li>按 LRU 算法排序；</li>
<li>取 idle 值（评分）最小的淘汰；</li>
<li>如果有多于25%的key是过期了的，则重复步骤1。</li>
</ol>
<h2 id="缓存系统中存在的问题"><a class="header-anchor" href="#缓存系统中存在的问题">¶</a>缓存系统中存在的问题</h2>
<p><img src="http://47.88.24.11/imgs/JVM/%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E7%9A%84%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%E9%97%AE%E9%A2%98.jpg" alt="旁路缓存的雪崩、击穿、穿透问题" title="旁路缓存的雪崩、击穿、穿透问题"><br>
<img src="http://47.88.24.11/imgs/JVM/%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98.jpg" alt="旁路缓存的不一致问题" title="旁路缓存的不一致问题"></p>
<h3 id="缓存穿透"><a class="header-anchor" href="#缓存穿透">¶</a>缓存穿透</h3>
<p>缓存穿透即即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。这也是经常提的缓存命中率问题。<br>
应付大规模缓存穿透的方案如下：</p>
<ol>
<li>
<p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试</p>
</li>
<li>
<p>采用异步更新策略，无论 key 是否取到值，都直接返回。value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做<strong>缓存预热</strong>(项目启动前，先加载缓存)操作。</p>
</li>
<li>
<p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用<strong>布隆过滤器</strong>，内部维护一系列合法有效的 key，将这些数据 hash 到一个足够大的 bitmap 中。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p>
</li>
<li>
<p>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过 5 分钟，通过这个直接设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 击穿到db</span><br><span class="line">        cacheValue = getFromDB();</span><br><span class="line">        if (cacheValue == null) &#123;</span><br><span class="line">            // 如果发现为空，则缓存个默认值</span><br><span class="line">            cacheValue = &quot;&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把空结果也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。同时也可以单独设置一个缓存区域存储空值，对要查询的key进行进行预先校验，然后再放行给后面的正常缓存处理逻辑。</p>
</li>
</ol>
<h3 id="缓存雪崩"><a class="header-anchor" href="#缓存雪崩">¶</a>缓存雪崩</h3>
<p>缓存雪崩即缓存同一时间大面积的失效（例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期），这个时候又来了一波请求，结果请求都怼到数据库上，而对数据库 CPU 和内存造成巨大压力，从而导致数据库连接异常，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。<br>
缓存雪崩的解决方案如下：</p>
<ol>
<li>
<p>使用互斥锁，但是该方案吞吐量明显下降了，适用于并发量不是特别多的情况下。具体地来说，使用最多的方案是加锁排队，伪代码如下：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    String lockKey = cacheKey;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        synchronized (lockKey) &#123;</span><br><span class="line">            cacheValue = getFromRedis(cacheKey);</span><br><span class="line">            if (cacheValue != null) &#123;</span><br><span class="line">                return cacheValue;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                cacheValue = getFromDB();</span><br><span class="line">                putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这时过来1000个请求、999个都在阻塞，同样会导致用户等待超时，属于治标不治本的方案，而且还需要解决分布式锁的问题。</p>
</li>
<li>
<p>设置过期标志更新缓存。给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存，实现伪代码如下所示：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    // 缓存标记</span><br><span class="line">    String signKey = cacheKey + &quot;_sign&quot;;</span><br><span class="line"></span><br><span class="line">    String signValue = getFromRedis(signKey);</span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (signValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        putToRedis(signKey, &quot;1&quot;, cacheTime);</span><br><span class="line">        threadPool.submit(() -&gt; &#123;</span><br><span class="line">            cacheValue = getFromDB();</span><br><span class="line">            putToRedis(cacheKey, cacheValue, cacheTime * 2);</span><br><span class="line">        &#125;);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>缓存标记记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。<br>
缓存数据的过期时间比缓存标记的时间延长 1 倍，例如：标记缓存时间 30 分钟，数据缓存 60 分钟，这样，当缓存标记 key 过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。</p>
</li>
<li>
<p>给缓存的失效时间，加上一个随机值，避免集体失效。</p>
</li>
<li>
<p>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。然后细分以下几个小点：</p>
<ol>
<li>从缓存 A 读数据库，有则直接返回</li>
<li>A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程。</li>
<li>更新线程同时更新缓存 A 和缓存 B。</li>
</ol>
</li>
</ol>
<h3 id="缓存预热"><a class="header-anchor" href="#缓存预热">¶</a>缓存预热</h3>
<p>缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统，避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户可以直接查询事先被预热的缓存数据。常见的缓存预热方案包括：</p>
<ol>
<li>直接写个缓存刷新页面，上线时手工操作下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存。</li>
</ol>
<h3 id="缓存和数据库双写一致性问题"><a class="header-anchor" href="#缓存和数据库双写一致性问题">¶</a>缓存和数据库双写一致性问题</h3>
<p>一致性问题是分布式常见问题，讨论比较多的是最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。<br>
在回答这个问题前，必须先强调一个前提，就是<strong>如果对数据有强一致性要求，不能放缓存</strong>。我们所做的一切，只能保证最终一致性，从根本上来说，只是降低不一致发生的概率，无法完全避免，因此，我们说有强一致性要求的数据，不能放缓存。</p>
<ul>
<li>首先，采取正确更新策略，先更新数据库，再删缓存。</li>
<li>其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用<strong>消息队列</strong>。</li>
</ul>
<p>具体的设计方案和优缺点可以参考：<a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">【原创】分布式之数据库和缓存双写一致性方案解析</a></p>
<p>下面是对所有策略的分析：</p>
<h4 id="先失效缓存-后更新数据库数据"><a class="header-anchor" href="#先失效缓存-后更新数据库数据">¶</a>先失效缓存 -&gt; 后更新数据库数据</h4>
<ol>
<li>缺点<br>
如果缓存失效失败,根据策略可能会影响后续的正常的数据更新操作<br>
直接失效缓存会增加后续的一次缓存查询的 Miss</li>
<li>优点<br>
避免数据库更新成功,缓存失效失败,导致缓存中是旧数据</li>
<li>场景<br>
对缓存准确率要求比较高的业务</li>
<li>异常情况<br>
线程 A 需要更新数据库数据，失效缓存；<br>
线程 B 发现缓存没有命中，查询数据库中取出旧的值；<br>
线程 A 更新数据库数据，提交事务，线程 A 将数据放入缓存。</li>
</ol>
<h4 id="延时双删"><a class="header-anchor" href="#延时双删">¶</a>延时双删</h4>
<p>在《先失效缓存 -&gt; 后更新数据库数据》这种方案的基础上，增加了一个延时过期的步骤。<br>
即：过期Redis -&gt; 更新数据库 -&gt; 延迟一会再过期一次Redis<br>
这样就可以缓解上边提到的脏读问题了。<br>
但是缺点是过期两次，会占用更多的数据库资源。</p>
<h4 id="先更新数据库数据-后失效缓存"><a class="header-anchor" href="#先更新数据库数据-后失效缓存">¶</a>先更新数据库数据 -&gt; 后失效缓存</h4>
<ol>
<li>缺点<br>
如果数据更新成功,但是缓存失效失败,缓存中存放的是旧数据<br>
直接失效缓存会增加一次缓存查询的 Miss</li>
<li>优点<br>
更新数据不会强依赖缓存,就算失效缓存失败,也不会影响数据库的更新</li>
<li>场景<br>
对缓存和数据库的一致性要求不是很高的场景</li>
<li>异常情况<br>
在更新数据库数据和失效缓存之前的所有查询,查询到的都是旧数据</li>
</ol>
<h4 id="更新数据库数据-更新缓存"><a class="header-anchor" href="#更新数据库数据-更新缓存">¶</a>更新数据库数据 -&gt; 更新缓存</h4>
<ol>
<li>优点<br>
避免了一次额外的缓存查询 Miss<br>
实时性比较高</li>
<li>缺点<br>
数据库更新成功，但是更新缓存失败，缓存中存储的是旧数据<br>
选择同步还是异步来更新缓存呢？如果是同步更新，更新磁盘成功了，但是更新缓存失败了，你是不是要反复重试来保证更新成功？如果多次重试都失败，那这次更新是算成功还是失败呢？如果是异步更新缓存，怎么保证更新的时序？<br>
比如，我先把一个文件中的某个数据设置成 0，然后又设为 1，这个时候文件中的数据肯定是 1，但是缓存中的数据可不一定就是 1 了。因为把缓存中的数据更新为 0，和更新为 1 是两个并发的异步操作，不一定谁会先执行。<br>
这些问题都会导致缓存的数据和磁盘中的数据不一致，而且，在下次更新这条数据之前，这个不一致的问题它是一直存在的。当然，这些问题也不是不能解决的，比如，你可以使用分布式事务来解决，只是付出的性能、实现复杂度等代价比较大。</li>
<li>场景<br>
缓存粒度比较小,缓存的数据不需要经过计算(更新商品数据,但是缓存还需要用户数据)</li>
<li>异常情况<br>
A 线程查询缓存发现缓存中没有数据,查询数据库；<br>
B 线程更新数据库并且更新了缓存；<br>
A 再把查询的数据放入缓存,缓存中将会是旧数据</li>
</ol>
<h4 id="更新缓存-更新数据库数据"><a class="header-anchor" href="#更新缓存-更新数据库数据">¶</a>更新缓存 -&gt; 更新数据库数据</h4>
<ol>
<li>优点<br>
避免了一次额外的缓存查询 Miss</li>
<li>缺点<br>
缓存更新成功,但是数据库更新失败,导致缓存数据是旧数据;<br>
并且更新缓存失败,根据策略可能导致更新数据库失败。</li>
<li>场景<br>
缓存粒度比较小,缓存的数据不需要经过计算(更新商品数据,但是缓存还需要用户数据)</li>
<li>异常情况<br>
在更新缓存成功和更新数据库数据之前拿到的缓存是和数据库不一致的(不过这种情况造成的负面影响很小)</li>
</ol>
<h4 id="更新数据库数据-定时同步到缓存"><a class="header-anchor" href="#更新数据库数据-定时同步到缓存">¶</a>更新数据库数据 -&gt; 定时同步到缓存</h4>
<ol>
<li>优点<br>
实现简单、鲁棒性高<br>
就算某次同步过程中发生了错误，等到下一个同步周期也会自动把数据纠正过来。</li>
<li>缺点<br>
缓存更新不实时。<br>
如果缓存的数据太大，更新速度慢到无法接受，可以选择增量更新，每次只更新从上次缓存同步至今这段时间内变化的数据，代价是实现起来会稍微有些复杂。</li>
</ol>
<h4 id="缓存更新总结"><a class="header-anchor" href="#缓存更新总结">¶</a>缓存更新总结</h4>
<ul>
<li>如果对一致性要求没有那么高，一般是先更新数据库然后删除缓存。</li>
<li>如果对一致性要求比较高，那么在缓存删除失败后，需要把删除事件放到队列里消费。</li>
<li>如果对一致性要求更高点，那么需要将更新数据库、更新缓存、查询缓存的操作放到一个队列里消费</li>
</ul>
<h3 id="如何解决-redis-的并发竞争-key-问题"><a class="header-anchor" href="#如何解决-redis-的并发竞争-key-问题">¶</a>如何解决 redis 的并发竞争 key 问题</h3>
<p>这个问题大致就是，同时有多个子系统去 set 一个 key。这个时候要注意什么呢？大家思考过么。百度上的答案基本都是推荐用 redis 事务机制，但这里<strong>不推荐使用 redis 的事务机制</strong>。因为我们的生产环境，基本都是 redis 集群环境，做了数据分片操作，你一个事务中有涉及到多个 key 操作的时候，这多个 key 不一定都存储在同一个 redis-server 上。因此，<strong>Redis 的事务机制，十分鸡肋</strong>。</p>
<ol>
<li>如果对这个 key 操作，<strong>不要求顺序</strong><br>
这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</li>
<li>如果对这个 key 操作，<strong>要求顺序</strong><br>
假设有一个 key1,系统 A 需要将 key1 设置为 valueA,系统 B 需要将 key1 设置为 valueB,系统 C 需要将 key1 设置为 valueC.<br>
期望按照 key1 的 value 值按照 valueA–&gt;valueB–&gt;valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下<br>
系统 A key 1 {valueA 3:00}<br>
系统 B key 1 {valueB 3:05}<br>
系统 C key 1 {valueC 3:10}<br>
那么，假设这会系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了。以此类推。<br>
其他方法，比如利用队列，将 set 方法变成串行访问也可以。</li>
</ol>
<h3 id="缓存降级"><a class="header-anchor" href="#缓存降级">¶</a>缓存降级</h3>
<p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。<br>
降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。<br>
在进行降级之前要对系统进行梳理，看看哪些服务是必须誓死保护的、哪些是可降级的。比如可以参考日志级别设置预案：</p>
<ol>
<li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li>
<li>警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降级或人工降级，并发送告警；</li>
<li>错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li>
<li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li>
</ol>
<h3 id="缓存污染"><a class="header-anchor" href="#缓存污染">¶</a>缓存污染</h3>
<p>什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。</p>
<p>我们来看一下各种过期策略是否能解决缓存污染问题：</p>
<ul>
<li>allkeys-random：对所有key进行随机的淘汰，因为不确定之后同一个key是否还会被访问到，所以这个策略会导致缓存缺失问题。</li>
<li>volatile-random：和allkeys-random类似。</li>
<li>volatile-ttl：针对的是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉，这种策略并不能直接反映数据被再次访问的情况，也有导致缓存缺失的问题。<br>
一般业务会根据数据生效时间范围来决定数据的过期时间，因此过期时间短的很有可能就是用一下就不用的数据，所以这种情况下volatile-ttl是可以缓解缓存污染问题的。</li>
<li>lru<br>
把使用最少的淘汰掉。<br>
但是使用LRU策略在处理扫描式单次查询操作时，无法解决缓存污染，因为这些key被扫描过一次后最近访问时间都是一样的。因为存在这种问题，因此Redis4.0增加了LRU淘汰策略。</li>
<li>lfu<br>
与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。<br>
LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b4105807.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b4105807.html" itemprop="url">《设计数据密集型应用》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-08T11:12:18+08:00">
                2020-11-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/读书/" itemprop="url" rel="index">
                    <span itemprop="name">读书</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  905 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>可靠、弹性、可维护的应用</h1>
<h1>数据模型和查询语言</h1>
<ul>
<li>应用数据<br>
定义业务对象的数据结构，比如商品、菜单、用户等</li>
<li>数据模型<br>
存储的数据模型，如何表达它们，比如JSON、XML、关系数据库表、图模型等。</li>
<li>数据组织<br>
如何用缓存、磁盘、网络表达这些数据，来应对上层的查询、搜索、写入等操作。</li>
<li>物理层<br>
决定计算机如何存储数据。</li>
</ul>
<h2 id="关系模型和文档模型"><a class="header-anchor" href="#关系模型和文档模型">¶</a>关系模型和文档模型</h2>
<h2 id="数据查询语言"><a class="header-anchor" href="#数据查询语言">¶</a>数据查询语言</h2>
<h1>存储和检索</h1>
<h2 id="数据库的数据结构"><a class="header-anchor" href="#数据库的数据结构">¶</a>数据库的数据结构</h2>
<h2 id="事务处理"><a class="header-anchor" href="#事务处理">¶</a>事务处理</h2>
<h1>编码和演变</h1>
<h2 id="数据格式"><a class="header-anchor" href="#数据格式">¶</a>数据格式</h2>
<h2 id="数据流"><a class="header-anchor" href="#数据流">¶</a>数据流</h2>
<h1>复制（Replication）</h1>
<p>复制数据的原因：</p>
<ul>
<li>放到离用户更近的地方，减少延迟；</li>
<li>即使系统的部分fail了，系统仍旧是可用的；</li>
<li>扩容系统提高吞吐量以应对查询。</li>
</ul>
<p>复制的三种算法：</p>
<ol>
<li>单主（single-leader）</li>
<li>多主（multi-leader）</li>
<li>无主（leaderless）</li>
</ol>
<h2 id="主从复制"><a class="header-anchor" href="#主从复制">¶</a>主从复制</h2>
<p>可以通过主从复制来保证数据被保存到了所有的副本上：</p>
<blockquote>
<p>leader和master、follower和slave这里是同义词</p>
</blockquote>
<ol>
<li>写请求均被发给leader；</li>
<li>follower拷贝leader的replication log并重演到本地。</li>
<li>读请求被发给leader或follower都可以。</li>
</ol>
<h3 id="同步-or-异步复制"><a class="header-anchor" href="#同步-or-异步复制">¶</a>同步 OR 异步复制</h3>
<p>同步复制的优点：</p>
<ol>
<li>能确保数整体性能据被拷贝到了follower；</li>
</ol>
<p>同步复制的缺点：</p>
<ol>
<li>leader被复制过程阻塞了，会影响性能；</li>
<li>如果复制失败——比如follower短暂的不可用，整个请求也会失败。</li>
</ol>
<p>异步复制的优点：</p>
<ol>
<li>不影响leader响应请求的性能；</li>
</ol>
<p>异步复制的缺点：</p>
<ol>
<li>如果数据还没被复制到任何follower的情况下leader挂掉了，且leader不可恢复（或者暂时不可恢复），则数据就3额丢失了；</li>
</ol>
<p>一般会采用权衡的方案，即半同步（semi-synchronous）的模式。</p>
<h3 id="复制的一般过程"><a class="header-anchor" href="#复制的一般过程">¶</a>复制的一般过程</h3>
<ol>
<li>follower从leader下载一个全新的快照；</li>
<li>follower从leader请求最新数据，也就是上面快照之后写入的新数据；</li>
</ol>
<h3 id="故障恢复-follower故障"><a class="header-anchor" href="#故障恢复-follower故障">¶</a>故障恢复 - Follower故障</h3>
<p>Follower故障了只需要重启后从Leader下载log然后加载即可。</p>
<h3 id="故障转移-failover-leader故障"><a class="header-anchor" href="#故障转移-failover-leader故障">¶</a>故障转移（Failover） - Leader故障</h3>
<ol>
<li>判断leader宕机<br>
一般是<strong>大部分</strong>副本均PING leader超时就认为leader宕机了。</li>
<li>选择新leader<br>
通过选举或一个controller node来选择下一个新leader。<br>
一般优先选择数据最新的副本。</li>
<li>更新配置以选择新leader<br>
客户端需要将请求发给新的leader<br>
旧leader重启后，需要成为新leader的follower，以免发生脑裂。</li>
</ol>
<h3 id="replication-log的实现"><a class="header-anchor" href="#replication-log的实现">¶</a>Replication Log的实现</h3>
<p>Replication Log的实现方式：</p>
<ul>
<li>基于语句的<br>
日志中记录的写入语句，比如SQL的INSERT、UPDATE、DELETE。<br>
缺点是：一些每次执行结果都会变的语句，在leader和follower上执行结果不一致，比如now()、rand()，最好在写入日志时进行替换；一些语句的执行是有顺序要求的，复制指令的过程中不能乱序；一些语句有副作用，可能会导致不同副本上执行结果不一样。</li>
<li>WAL（写前日志）<br>
如MySQL里的redolog和undolog。</li>
<li>逻辑日志<br>
如MySQL里的binlog</li>
</ul>
<h2 id="复制延迟-replication-lag"><a class="header-anchor" href="#复制延迟-replication-lag">¶</a>复制延迟（Replication Lag）</h2>
<p>数据被拷贝到从服务器期间，主从是不一致的，一般情况下这个间隔时间是很短的，但是如果网络出现了问题就有可能会变得比较严重了。<br>
TODO：我需要先研究下MySQL中是怎么处理这种延迟的。</p>
<h2 id="多主复制-multi-leader-replication"><a class="header-anchor" href="#多主复制-multi-leader-replication">¶</a>多主复制（Multi-Leader Replication）</h2>
<h2 id="无主复制-leaderless-replication"><a class="header-anchor" href="#无主复制-leaderless-replication">¶</a>无主复制（Leaderless Replication）</h2>
<h1>分区</h1>
<h1>事务</h1>
<h1>分布式系统的挑战</h1>
<h1>一致性和共识</h1>
<h1>批处理</h1>
<h1>流处理</h1>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/52fcb70f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/52fcb70f.html" itemprop="url">Lab_2_Raft</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-04T19:26:49+08:00">
                2020-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/6-824/" itemprop="url" rel="index">
                    <span itemprop="name">6.824</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  15 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>前置知识</h1>
<h2 id="gfs"><a class="header-anchor" href="#gfs">¶</a>GFS</h2>
<h2 id="fault-tolerant-virtual-machines-容错虚拟机"><a class="header-anchor" href="#fault-tolerant-virtual-machines-容错虚拟机">¶</a>Fault-Tolerant Virtual Machines（容错虚拟机）</h2>
<h2 id="raft"><a class="header-anchor" href="#raft">¶</a>Raft</h2>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/ea705bce.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/ea705bce.html" itemprop="url">Apollo 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-20T18:14:10+08:00">
                2020-10-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Apollo/" itemprop="url" rel="index">
                    <span itemprop="name">Apollo</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>概念</h1>
<ul>
<li>App: App信息</li>
<li>AppNamespace: App下Namespace的元信息</li>
<li>Cluster: 集群信息</li>
<li>Namespace: 集群下的namespace</li>
<li>Item: Namespace的配置，每个Item是一个key, value组合</li>
<li>Release: Namespace发布的配置，每个发布包含发布时该Namespace的所有配置</li>
<li>Commit: Namespace下的配置更改记录</li>
<li>Audit: 审计信息，记录用户在何时使用何种方式操作了哪个实体。</li>
</ul>
<h1>Apollo架构</h1>
<p><img src="http://47.88.24.11/imgs/Apollo/Apollo%E6%9E%B6%E6%9E%84.png" alt="Apollo架构——图片来自Apollo-github"></p>
<ul>
<li>Apollo Client：为应用提供配置查询功能；</li>
<li>Apollo Config Service：提供配置的读取、推送等功能，服务对象是 Apollo Client；</li>
<li>Apollo Portal：Apollo管理界面，为开发者提供配置修改功能；</li>
<li>Apollo Admin Service：提供配置修改、发布等功能，服务对象是Apollo Portal。</li>
</ul>
<h1>服务发现和负载均衡</h1>
<p>在Apollo中，Config Service和Admin Service都是<strong>多实例</strong>、<strong>无状态</strong>部署的，需要将自己注册到<strong>Eureka</strong>。<br>
Eureka负责服务发现，在Eureka之上Apollo又架了一层<strong>Meta Server</strong>用于封装Eureka的服务发现接口：</p>
<ul>
<li>Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做<strong>load balance</strong>、<strong>错误重试</strong>；</li>
<li>Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做<strong>load balance</strong>、<strong>错误重试</strong>。</li>
</ul>
<p>为什么Apollo使用Eureka而不是别的服务发现组件，比如ZooKeeper？</p>
<ol>
<li>提供了完整的服务注册和发现实现，用起来省心；</li>
<li>项目基础是SpringCloud，已经有应用Eureka的基础；</li>
</ol>
<p>Meta Server部署在哪里？<br>
Meta Server只是一个逻辑角色，在部署时和Config Service是在一个JVM进程中的，所以IP、端口和Config Service一致</p>
<h1>服务端实现原理</h1>
<p>服务端的主要任务是维护配置信息，以及将配置信息推送到客户端。</p>
<h2 id="服务端推送大体流程"><a class="header-anchor" href="#服务端推送大体流程">¶</a>服务端推送大体流程</h2>
<ol>
<li>用户在Portal操作配置发布</li>
<li>Portal调用Admin Service的接口操作发布</li>
<li>Admin Service发布配置后，发送<strong>ReleaseMessage</strong>给各个Config Service</li>
<li>Config Service收到ReleaseMessage后，<strong>通知对应的客户端</strong></li>
</ol>
<h2 id="发送releasemessage给config-service的过程"><a class="header-anchor" href="#发送releasemessage给config-service的过程">¶</a>发送ReleaseMessage给Config Service的过程</h2>
<p><img src="http://47.88.24.11/imgs/Apollo/Apollo%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E7%9A%84%E5%8F%91%E5%B8%83.png" alt="Apollo配置信息的发布——图片来自Apollo-github"><br>
用户操作配置发布后，Admin Service会往<strong>ReleaseMessage</strong>表插入一条消息记录，然后Config Service<strong>定时轮询</strong>这张表来消费消息。<br>
ApolloPortol会调Admin服务发出<strong>消息</strong>，这时，Admin Service作为<strong>Producer</strong>发出消息，各个ConfigService作为<strong>Consumer</strong>消费消息，为了减少对外部的依赖，Apollo发送消息的功能是<strong>通过数据库自己实现的一个简单的消息队列</strong>。</p>
<ol>
<li>Admin操作Release：<code>com.ctrip.framework.apollo.portal.controller.ReleaseController#createRelease</code><br>
在Admin Service的后台操作界面上可以看到Release操作入口。</li>
<li>Admin向ReleaseMessage表插入一条消息记录：<code>com.ctrip.framework.apollo.adminservice.controller.ReleaseController#publish</code><br>
该消息的内容就是配置发布的AppId+Cluster+Namespace。<br>
注意在“发消息”前，先把发布信息存到了Release表中。</li>
<li>定时扫描消息，<br>
扫描消息：<code>com.ctrip.framework.apollo.biz.message.ReleaseMessageScanner</code><br>
定时任务逻辑：批量处理，每次扫描500条，每条消息分别触发所有消息监听器（ReleaseMessageListener）。<br>
定时任务线程池配置：每100毫秒执行一次，core线程数只有1，但是总线程数为Integer.MAX_INT。</li>
<li>Config Service通知客户端<br>
代码入口：<code>NotificationControllerV2#handleMessage</code><br>
注意NotificationControllerV2这个Controller本身也是个消息监听器。<br>
Config Service会从消息中获取配置发布的AppId+Cluster+Namespace，然后通知客户端（通知客户端的过程见下面）。</li>
</ol>
<h2 id="config-service通知客户端的过程"><a class="header-anchor" href="#config-service通知客户端的过程">¶</a>Config Service通知客户端的过程</h2>
<ol>
<li>客户端发起一个HTTP请求到Config Service<br>
入口：/notifications/v2，对应NotificationControllerV2（注意和上面的消息监听器是同一个类）。</li>
<li>Config Service将请求挂起<br>
通过Spring 的 DeferredResult将请求挂起，默认等待60秒。<br>
如果在等待期间有该客户端关注的配置（Namespace）发布，则NotificationControllerV2会调用DeferredResult#setResult传入变化的Namespace信息，同时该请求也会立刻返回。<br>
反之，如果60秒内都没有该客户端关注的配置发布，则返回HTTP状态码304给客户端。</li>
<li>客户端请求最新的Namespace配置<br>
如果Config Service返回了配置信息、客户端获取到变化的Namespace信息后，客户端就会立即请求Config Service获取该Namespace的最新配置。</li>
</ol>
<h1>客户端实现原理</h1>
<p>客户端主要任务是从Config Service获取配置信息（Push和Pull都有），并在本地维护一个配置文件缓存。<br>
<img src="http://47.88.24.11/imgs/Apollo/Apollo%E9%85%8D%E7%BD%AE%E5%9C%A8%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%BB%B4%E6%8A%A4.png" alt="Apollo配置在客户端的维护——图片来自Apollo-github"></p>
<h2 id="客户端long-polling"><a class="header-anchor" href="#客户端long-polling">¶</a>客户端long-polling</h2>
<p>客户端会和服务端维持一个长连接，以及时接收到配置的变更信息。<br>
入口：<code>com.ctrip.framework.apollo.internals.RemoteConfigLongPollService#startLongPolling</code><br>
客户端长轮询的是Config Service的配置变更通知接口。当有新通知时就会触发RemoteConfigRepository，立即轮询Config Service的配置读取<code>/configs/{appId}/{clusterName}/{namespace:.+}</code>接口。</p>
<h2 id="客户端定时pull"><a class="header-anchor" href="#客户端定时pull">¶</a>客户端定时Pull</h2>
<p>客户端定时从Config Service拉取应用的配置信息，使用的接口和上面的long-polling一样：<code>/configs/{appId}/{clusterName}/{namespace:.+}</code>。<br>
入口：<code>RemoteConfigRepository#scheduleLongPollingRefresh</code><br>
这是一个fallback机制，主要目的是防止推送机制失效导致配置不更新。<br>
客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified。<br>
定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。</p>
<h2 id="客户端本地对配置的维护"><a class="header-anchor" href="#客户端本地对配置的维护">¶</a>客户端本地对配置的维护</h2>
<ol>
<li>客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中</li>
<li>客户端会把从服务端获取到的配置在本地文件系统缓存一份<br>
在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置</li>
<li>应用程序可以从Apollo客户端获取最新的配置、订阅配置更新通知</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97" target="_blank" rel="noopener">Java客户端使用指南</a></li>
<li><a href="https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E8%AE%BE%E8%AE%A1#31-%E5%92%8Cspring%E9%9B%86%E6%88%90%E7%9A%84%E5%8E%9F%E7%90%86" target="_blank" rel="noopener">Apollo配置中心设计</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">130</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">64</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
