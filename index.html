<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tallate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/">







  <title>Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/0.html" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-16T13:51:49+08:00">
                2020-12-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  604 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>存储引擎所处的位置</h1>
<h1>MyISAM和InnoDB的区别</h1>
<ol>
<li>MyISAM不支持事务，而InnoDB支持。<br>
InnoDB的AUTOCOMMIT默认是打开的，即每条SQL语句会默认被封装成一个事务，自动提交，这样会影响速度，所以最好是把多条SQL语句显示放在begin和commit之间，组成一个事务去提交。</li>
<li>InnoDB支持数据行锁定，MyISAM不支持行锁定，只支持锁定整个表。即MyISAM同一个表上的读锁和写锁是互斥的，MyISAM并发读写时如果等待队列中既有读请求又有写请求，默认写请求的优先级高，即使读请求先到，所以MyISAM不适合于有大量查询和修改并存的情况，那样查询进程会长时间阻塞。因为MyISAM是锁表，所以某项读操作比较耗时会使其他写进程饿死。<br>
InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 4. InnoDB 不保存表</li>
<li>InnoDB支持外键，MyISAM不支持。</li>
<li>InnoDB的主键范围更大，最大是MyISAM的2倍。</li>
<li>InnoDB不支持全文索引，而MyISAM支持。全文索引是指对char、varchar和text中的每个词（停用词除外）建立倒排序索引。MyISAM的全文索引其实没啥用，因为它不支持中文分词，必须由使用者分词后加入空格再写到数据表里，而且少于4个汉字的词会和停用词一样被忽略掉。</li>
<li>InnoDB不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；<br>
InnoDB不保存具体行数的原因是事务隔离级别的存在需要保证执行中事务写入的行不能被统计进来。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/87dfb581.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/87dfb581.html" itemprop="url">算法题 Review</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-13T22:28:55+08:00">
                2020-12-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  16 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>参考</h1>
<ol>
<li><a href="https://www.zhihu.com/question/36738189" target="_blank" rel="noopener">LeetCode按照怎样的顺序来刷题比较好？</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/c6369e85.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/c6369e85.html" itemprop="url">分布式事务实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-06T11:30:49+08:00">
                2020-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/分布式事务/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  31 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="xa规范"><a class="header-anchor" href="#xa规范">¶</a>XA规范</h2>
<p>X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。<br>
通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。<br>
所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。 一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。</p>
<blockquote>
<p><strong>XA</strong> 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。</p>
</blockquote>
<p>二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现XA分布式事务的关键(确切地说：两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做)</p>
<h2 id="2pc-two-phasecommit"><a class="header-anchor" href="#2pc-two-phasecommit">¶</a>2PC（Two-phaseCommit）</h2>
<blockquote>
<p>二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，<strong>二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作</strong>。</p>
</blockquote>
<h3 id="准备阶段-投票阶段"><a class="header-anchor" href="#准备阶段-投票阶段">¶</a>准备阶段（投票阶段）</h3>
<p>事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。<br>
可以进一步将准备阶段分为以下三个步骤：</p>
<ol>
<li>协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。</li>
<li>参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）</li>
<li>各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。</li>
</ol>
<h3 id="提交阶段-执行阶段"><a class="header-anchor" href="#提交阶段-执行阶段">¶</a>提交阶段（执行阶段）</h3>
<p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)<br>
接下来分两种情况分别讨论提交阶段的过程。<br>
当协调者节点从所有参与者节点获得的相应消息都为”同意”时:<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/2PC%E6%8F%90%E4%BA%A4.png" alt="2PC提交" title="2PC提交"></p>
<ol>
<li>协调者节点向所有参与者节点发出”正式提交(commit)”的请求。</li>
<li>参与者节点正式完成操作，并释放在整个事务期间内占用的资源。</li>
<li>参与者节点向协调者节点发送”完成”消息。</li>
<li>协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。</li>
</ol>
<p>如果任一参与者节点在第一阶段返回的<strong>响应消息为”中止”</strong>，或者 <strong>协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息</strong>时：<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/2PC%E5%9B%9E%E6%BB%9A.png" alt="2PC回滚" title="2PC回滚"></p>
<ol>
<li>协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。</li>
<li>参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。</li>
<li>参与者节点向协调者节点发送”回滚完成”消息1. 协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。<br>
不管最后结果如何，第二阶段都会结束当前事务。</li>
</ol>
<h3 id="优点"><a class="header-anchor" href="#优点">¶</a>优点</h3>
<p>确实能保证事务的原子性</p>
<h3 id="缺点"><a class="header-anchor" href="#缺点">¶</a>缺点</h3>
<p><img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/2PC%E5%BC%82%E5%B8%B8%E7%82%B9.jpeg" alt="2PC异常点" title="2PC异常点"><br>
图中有问号的条目,是不确定的地方,但是不影响这个分布式事务的结果<br>
图中的感叹号条目,个人感觉其实也是允许先发消息再记录日志的,但是如果这样子做以后发生Down机,客户端或者TM都需要向其它机器询问结果才能得到结论(而这样子做的话会大大加长分布事务的阻塞时间和事务处理的复杂度,同时这样做会有一个致命的缺陷,抹除了一部分可以自恢复场景。</p>
<ol>
<li>同步阻塞问题<br>
执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。具体地说，两阶段提交中的第二阶段，协调者需要等待所有参与者发出yes请求，或者某个参与者发出no请求后，才能执行提交或者中断操作。这会造成长时间同时锁住多个资源, 造成性能瓶颈, 如果参与者有一个耗时长的操作, 性能损耗会更明显.</li>
<li>单点故障<br>
由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）</li>
<li>数据不一致/脑裂（聋哑事件）<br>
在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。此时就算重新选举出了一个新的协调者，也没有人知道系统最后的状态。而在这部分参与者接到commit请求之后就会执行commit操作，但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性现象。</li>
<li>实现复杂<br>
不利于系统的扩展。</li>
<li>二阶段无法解决的问题<br>
协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</li>
</ol>
<h2 id="3pc-three-phase-commit"><a class="header-anchor" href="#3pc-three-phase-commit">¶</a>3PC（Three-phase commit）</h2>
<blockquote>
<p>三阶段提交，也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。</p>
</blockquote>
<p>与两阶段提交不同的是，三阶段提交有两个改动点。</p>
<ol>
<li>引入超时机制。同时在协调者和参与者中都引入超时机制。</li>
<li>在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。</li>
</ol>
<p>也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/3PC.png" alt="3PC" title="3PC"></p>
<h3 id="cancommit阶段"><a class="header-anchor" href="#cancommit阶段">¶</a>CanCommit阶段</h3>
<p>3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。</p>
<ol>
<li>事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。</li>
<li>响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No</li>
</ol>
<h3 id="precommit阶段"><a class="header-anchor" href="#precommit阶段">¶</a>PreCommit阶段</h3>
<p>协调者根据参与者的反应情况来决定是否可以进行事务的PreCommit操作。根据响应情况，有以下两种可能，分别称为预执行和中断。<br>
假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的<strong>预执行</strong>。</p>
<ol>
<li>发送预提交请求：协调者向参与者发送PreCommit请求，并进入Prepared阶段。</li>
<li>事务预提交：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。</li>
<li>响应反馈：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。</li>
</ol>
<p>假如有任何一个参与者向协调者发送了No响应（CanCommit阶段），或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的<strong>中断</strong>。</p>
<ol>
<li>发送中断请求 协调者向所有参与者发送abort请求。</li>
<li>中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</li>
</ol>
<h3 id="docommit阶段"><a class="header-anchor" href="#docommit阶段">¶</a>doCommit阶段</h3>
<p>该阶段进行真正的事务提交，也可以分为以下两种情况。<br>
<strong>执行提交</strong></p>
<ol>
<li>发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。</li>
<li>事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</li>
<li>响应反馈 事务提交完之后，向协调者发送Ack响应。</li>
<li>完成事务 协调者接收到所有参与者的ack响应之后，完成事务。</li>
</ol>
<p><strong>中断事务</strong><br>
协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。</p>
<ol>
<li>发送中断请求 协调者向所有参与者发送abort请求</li>
<li>事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</li>
<li>反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息</li>
<li>中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。</li>
</ol>
<p>在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）</p>
<h3 id="优点和缺点"><a class="header-anchor" href="#优点和缺点">¶</a>优点和缺点</h3>
<ol>
<li>相对于2PC，3PC主要解决的单点故障问题<br>
当在第二阶段出现聋哑事件,那么这N-1台机器可以根据超时机制直接abort掉,因为客户端这时只是预提交,当该机器重启以后只要询问周边机器事务状态,简单的将事务回滚或者提交事务,就能保持事务的最终一致性；<br>
当进行到第三阶段的时候,如果发生聋哑事件,那么其它处于「不确定状态」的客户端会直接执行commit,而不会像2PC一样导致事务block,但是这样会有一个风险(进入到第三个阶段说明客户端在第一阶段投的都是Yes),因为在聋哑事件中,那台Down掉的机器在第二阶段中给协调者发送的不是prepared,这个时候协调者收到消息给客户端发送的是abort命令.所以3PC只是乐观的认为只要你第一阶段大家投的都是Yes,那么最后成功提交的几率很大。</li>
<li>减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit，而不会一直持有事务资源并处于阻塞状态。</li>
<li>但是这种机制也会导致数据一致性问题，因为，由于网络原因，<strong>协调者发送的abort响应没有及时被参与者接收到</strong>，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</li>
</ol>
<h2 id="tcc"><a class="header-anchor" href="#tcc">¶</a>TCC</h2>
<p><img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/TCC.png" alt="TCC" title="TCC"><br>
所谓的TCC编程模式，也是两阶段提交的一个变种。TCC提供了一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel三个操作。以在线下单为例，Try阶段会去扣库存，Confirm阶段则是去更新订单状态，如果更新订单失败，则进入Cancel阶段，会去恢复库存。总之，TCC就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，复杂度也不一样，因此，这种模式并不能很好地被复用。<br>
TCC补偿性方案，分为三个阶段TRYING-CONFIRMING-CANCELING。每个阶段做不同的处理。</p>
<ul>
<li>Trying阶段主要针对业务系统检测及作出预留资源请求, 若预留资源成功, 则返回确认资源的链接与过期时间</li>
<li>Confirm阶段主要是对业务系统的预留资源作出确认, 要求TCC服务的提供方要对确认预留资源的接口实现幂等性, 若Confirm成功则返回204，资源超时则证明已经被回收且返回404</li>
<li>Cancel阶段主要是在业务执行错误或者预留资源超时后执行的资源释放操作, Cancel接口是一个可选操作, 因为要求TCC服务的提供方实现自动回收的功能, 所以即便是不认为进行Cancel, 系统也会自动回收资源</li>
</ul>
<h3 id="优点-v2"><a class="header-anchor" href="#优点-v2">¶</a>优点</h3>
<ol>
<li>TCC能够对分布式事务中的各个资源进行分别锁定, 分别提交与释放, 例如, 假设有AB两个操作, 假设A操作耗时短, 那么A就能较快的完成自身的try-confirm-cancel流程, 释放资源. 无需等待B操作. 如果事后出现问题, 追加执行补偿性事务即可.</li>
<li>TCC是绑定在各个子业务上的(除了cancle中的全局回滚操作), 也就是各服务之间可以在一定程度上”异步并行”执行.</li>
</ol>
<h3 id="注意"><a class="header-anchor" href="#注意">¶</a>注意</h3>
<ul>
<li>事务管理器(协调器)这个节点必须以带同步复制语义的高可用集群(HAC)方式部署.</li>
<li>事务管理器(协调器)还需要使用多数派算法来避免集群发生脑裂问题.</li>
</ul>
<h3 id="适用场景"><a class="header-anchor" href="#适用场景">¶</a>适用场景</h3>
<ul>
<li>严格一致性</li>
<li>执行时间短</li>
<li>实时性要求高</li>
</ul>
<h3 id="例子1"><a class="header-anchor" href="#例子1">¶</a>例子1</h3>
<p>以<strong>支付场景</strong>为例，支付系统接收到会员的支付请求后，需要扣减会员账户余额、增加会员积分（暂时假设需要同步实现）增加商户账户余额<br>
再假设：会员系统、商户系统、积分系统是独立的三个子系统，无法通过传统的事务方式进行处理。</p>
<ol>
<li>TRYING阶段：我们需要做的就是会员资金账户的资金预留，即：冻结会员账户的金额（订单金额）</li>
<li>CONFIRMING阶段：我们需要做的就是会员积分账户增加积分余额，商户账户增加账户余额</li>
<li>CANCELING阶段：该阶段需要执行的就是解冻释放我们扣减的会员余额</li>
</ol>
<h3 id="例子2"><a class="header-anchor" href="#例子2">¶</a>例子2</h3>
<p>下面以<strong>客户购买商品时的付款操作</strong>为例进行讲解:</p>
<ol>
<li>Try<br>
完成所有的业务检查(一致性),预留必须业务资源(准隔离性);<br>
体现在本例中, 就是确认客户账户余额足够支付(一致性), 锁住客户账户, 商户账户(准隔离性).</li>
<li>Confirm<br>
使用Try阶段预留的业务资源执行业务(业务操作必须是幂等的), 如果执行出现异常, 要进行重试.<br>
在这里就是执行客户账户扣款, 商户账户入账操作.</li>
<li>Cancle<br>
释放Try阶段预留的业务资源, 在这里就是释放客户账户和商户账户的锁;</li>
</ol>
<h3 id="try设计"><a class="header-anchor" href="#try设计">¶</a>try设计</h3>
<p>try阶段起着一个预处理的作用。<br>
在整个分布式事务中预处理的含义其实很广泛,比如订单,所谓的预处理就是生成订单,但是用户真实是看不到这些订单的,至于具体实现是在一张新表中记录还是在原有的订单表是加上标记位,具体实现方式由自己统筹考虑(当然还需要考虑记录事务Id);像减库存这种预处理,可以直接减少原始库存,再通过另外一张表来记录这次事务Id操作了哪个Sku的库存数量,当然也可以不减少库存只记录操作,但是这种方式在计算实际库存的时候复杂度会提高(需要减掉预处理的那部分)</p>
<h3 id="confirm设计"><a class="header-anchor" href="#confirm设计">¶</a>confirm设计</h3>
<p>如果任一子业务在Confirm阶段有操作无法执行成功, 会造成对业务活动管理器的响应超时, 此时要对其他业务执行<strong>补偿性事务</strong>. 如果补偿操作执行也出现异常, 必须进行重试, 若实在无法执行成功, 则事务管理器必须能够感知到失败的操作, 进行log(用于事后人工进行补偿性事务操作或者交由中间件接管在之后进行补偿性事务操作)，我称这个过程为Unconfirm.<br>
其实像Github上的一些基于TCC设计的分布式事务框架（如tcc-transaction），都对Confirm的补偿没有作说明，也没有在代码里保证某一子任务的Confirm失败后、前面子任务的Confirm能回滚，Confirm操作出错是由用户承担的，经过测试确实会有这样的问题（在第一个Confirm中建一张表，第二个Confirm中故意抛出一个异常）。<br>
因此，我认为TCC应该被扩充为TCUC才对，其中的U代表Unconfirm操作。</p>
<h3 id="cancel设计"><a class="header-anchor" href="#cancel设计">¶</a>cancel设计</h3>
<p>cancel应当能起到释放try阶段占用资源的作用，事务管理器在执行cancel时<strong>需要判断哪些try是成功的再执行其cancel</strong>，因为执行失败的try由本地事务控制回滚了，而没有执行的本来就没有必要回滚，或者，由开发者将cancel设计为可重入的、不会因为反复调用而出错。但是由于这个需求是刚需，放到业务中进行处理势必会大大增加业务的复杂度，因此由TCC框架来处理是更好的选择，需要考虑如下处理策略：</p>
<ol>
<li>如果TCC事务框架发现某个服务的Try操作的本地事务尚未提交，应该直接将其回滚，而后就不必再执行该服务的cancel业务；</li>
<li>如果TCC事务框架发现某个服务的Try操作的本地事务已经回滚，则不必再执行该服务的cancel业务；</li>
<li>如果TCC事务框架发现某个服务的Try操作尚未被执行过，那么，也不必再执行该服务的cancel业务。</li>
</ol>
<p>总而言之，TCC框架必须保障：</p>
<ol>
<li>已生效的Try操作应该被其Cancel操作所回撤；</li>
<li>尚未生效的Try操作，则不应该执行其Cancel操作。</li>
</ol>
<h3 id="本地事务"><a class="header-anchor" href="#本地事务">¶</a>本地事务</h3>
<p>TCC事务必须在本地事务的基础上实现，因为每个接口都可能有多次写库操作，如果某次写库失败，cancel中就需要判断哪些操作是失败的再调用其回滚，这样cancel中也会存在多次的反向写库操作，一旦cancel也中途出错，后续的cancel（重试）还需要判断之前cancel的哪几个操作是执行成功了的，因此，如果没有本地事务的支持，TCC事务框架是无法有效管理TCC事务的。<br>
一种方法是在TCC框架中接管Spring的事务管理（PlatformTransactionManager），另一种办法是老老实实给每一个TCC接口添加@Transactional注解。</p>
<ol>
<li>必须确定本地事务的传播条件<br>
一个业务方法可能会包含多个RM本地事务。比如：A(REQUIRED)-&gt;B(REQUIRES_NEW)-&gt;C(REQUIRED)，这种情况下，A服务所参与的RM本地事务被提交时，B服务和C服务参与的RM本地事务则可能会被回滚。</li>
<li>必须手动指定本地事务的回滚条件<br>
并不是抛出了异常的业务方法，其参与的事务就回滚了。Spring容器的声明式事务定义了两类异常，其事务完成方向都不一样：系统异常（一般为Unchecked异常，默认事务完成方向是rollback）、应用异常（一般为Checked异常，默认事务完成方向是commit）。二者的事务完成方向又可以通过@Transactional配置显式的指定，如rollbackFor/noRollbackFor等。<br>
Spring容器还支持使用setRollbackOnly的方式显式的控制事务完成方向。</li>
<li>TCC拦截器的执行顺序必须在本地事务拦截器之后<br>
自行拦截业务方法的拦截器和Spring的事务处理的拦截器还会存在执行先后、拦截范围不同等问题。例如，如果自行拦截器执行在前，就会出现业务方法虽然已经执行完毕但此时其参与的RM本地事务还没有commit/rollback。</li>
</ol>
<h3 id="异常分析"><a class="header-anchor" href="#异常分析">¶</a>异常分析</h3>
<p>实际应用中，会有各种故障出现，很多都会造成事务的中断，从而使得统一提交/回滚全局事务的目标不能达到，甚至出现”一部分分支事务已经提交，而另一部分分支事务则已回滚”的情况。常见错误包括：<br>
业务系统服务器宕机、重启；数据库服务器宕机、重启；网络故障；断电等。这些故障可能单独发生，也可能会同时发生。</p>
<p>在整个流程,我们主要需要关注的是<code>cancel</code>失败和<code>confirm</code>失败引起的数据不一致现象：<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/TCC%E5%BC%82%E5%B8%B8%E5%88%86%E6%9E%90.jpeg" alt="TCC异常分析" title="TCC异常分析"><br>
TCC事务框架要支持故障恢复，就必须记录相应的事务日志。事务日志是故障恢复的基础和前提，它记录了事务的各项数据。TCC事务框架做故障恢复时，可以根据事务日志的数据将中断的事务恢复至正确的状态，并在此基础上继续执行先前未完成的提交/回滚操作。</p>
<h3 id="异常情况-cancel与try乱序-或并发执行"><a class="header-anchor" href="#异常情况-cancel与try乱序-或并发执行">¶</a>异常情况 - Cancel与Try乱序（或并发执行）</h3>
<p>这应该算TCC事务机制特有的一个不可思议的陷阱。一般来说，一个特定的TCC服务，其Try操作的执行，是应该在其Confirm/Cancel操作之前的。Try操作执行完毕之后，Spring容器再根据Try操作的执行情况，指示TCC事务框架提交/回滚全局事务。然后，TCC事务框架再去逐个调用各TCC服务的Confirm/Cancel操作。<br>
然而，超时、网络故障、服务器的重启等故障的存在，使得这个顺序会被打乱。比如：<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/Cancel%E4%B8%8ETry%E4%B9%B1%E5%BA%8F.jpg" alt="Cancel与Try乱序" title="Cancel与Try乱序"><br>
上图中，假设[B:Try]操作执行过程中，网络闪断，[A:Try]会收到一个RPC远程调用异常。A不处理该异常，导致全局事务决定回滚，TCC事务框架就会去调用[B:Cancel]，而此刻A、B之间网络刚好已经恢复。如果[B:Try]操作耗时较长（网络阻塞/数据库操作阻塞），就会出现[B:Try]和[B:Cancel]二者并行处理的现象，甚至[B:Cancel]先完成的现象。<br>
这种情况下，由于[B:Cancel]执行时，[B:Try]尚未生效（其RM本地事务尚未提交），因此，[B:Cancel]是不能执行的，至少是不能生效（执行了其RM本地事务也要rollback）的。<br>
然而，当[B:Cancel]处理完毕（跳过执行、或者执行后rollback其RM本地事务）后，[B:Try]操作完成又生效了（其RM本地事务成功提交），这就使得[B:Cancel]虽然提供了，但却没有起到回撤[B:Try]的作用，导致数据的不一致。</p>
<p>所以，TCC框架在这种情况下，需要：</p>
<ol>
<li>将[B:Try]的本地事务标注为Marked_ReadOnly，阻止其后续生效；</li>
<li>禁止其再次将事务上下文传递给其他远程分支，否则该问题将在其他分支上出现；</li>
<li>相应地，[B:Cancel]也不必执行，至少不能生效。</li>
</ol>
<blockquote>
<p>当然，TCC事务框架也可以简单的选择阻塞[B:Cancel]，待[B:Try]执行完毕后，再根据它的执行情况判断是否需要执行[B:Cancel]。不过，这种处理方式因为需要等待，所以，处理效率上会有所不及。</p>
</blockquote>
<p>同样的情况也会出现在confirm业务上，只不过，发生在Confirm业务上的处理逻辑与发生在Cancel业务上的处理逻辑会不一样，TCC框架必须保证：</p>
<ol>
<li>Confirm业务在Try业务之后执行，若发现并行，则只能阻塞相应的Confirm业务操作；</li>
<li>在进入Confirm执行阶段之后，也不可以再提交同一全局事务内的新的Try操作的RM本地事务。</li>
</ol>
<h3 id="tcc中心化-使用一个tcc服务器来集中回调confirm和cancel方法"><a class="header-anchor" href="#tcc中心化-使用一个tcc服务器来集中回调confirm和cancel方法">¶</a>TCC中心化（使用一个TCC服务器来集中回调confirm和cancel方法）</h3>
<p>基于TCC的中心化事务一致性解决方法,各个应用服务器如果需要感知某次事务是否成功的成本很高,所以对于自身而言进行事务补偿成本就会很高.举个例子：<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/TCC%E4%B8%AD%E5%BF%83%E5%8C%96.jpeg" alt="TCC中心化" title="TCC中心化"></p>
<ol>
<li>每次成功的执行本应用服务器的事务以后,都需要把成功执行的事务Id记录</li>
<li>继续confirm或者将confirm完的数据回滚,对用户都很不友好,特别是需要confirm订单或者回滚订单数据</li>
<li>可以根据事务开始的时间,并且设计一个事务超时时间,如果在这个时间范围以外事务还没有处理完成,就可以当做这个事务已经失败,将预处理数据删除<br>
总体来说,事务补偿机制,心智负担过于沉重.所以只能依赖TCC服务器的失败重试机制,如果失败重试机制不能处理,只能人肉去处理(建议全程人肉,因为同时进行失败重试和人肉的话,因为如果失败重试和人肉都在操作同一条数据,还需要考虑这种竞争的场景,对重试次数需要限定)</li>
</ol>
<h3 id="无tcc服务器设计-去中心化"><a class="header-anchor" href="#无tcc服务器设计-去中心化">¶</a>无TCC服务器设计（去中心化）</h3>
<p>可以让<strong>交易链路</strong>来充当TCC服务器的角色,但是长期来看,TCC相当于是一个公用的组件,所以其它地方也需要TCC分布式事务,可以公用这一个组件(交易链路可以完成TCC所能完成的一切操作,把TCC单独部署一个服务,仅仅是考虑整个系统的抽象结构和功能复用)。<br>
像框架<code>tcc-transaction</code>中每次第一个发起事务的服务器就起到了这个TCC服务器的作用。</p>
<h3 id="幂等性"><a class="header-anchor" href="#幂等性">¶</a>幂等性</h3>
<p>TCC服务支持接口失败重试,所以对TCC暴露的接口都需要满足幂等性(根据事务Id很好满足)，幂等性的实现方式可以是：</p>
<ol>
<li>通过唯一键值做处理，即每次调用的时候传入唯一键值，通过唯一键值判断业务是否被操作，如果已被操作，则不再重复操作</li>
<li>通过状态机处理，给业务数据设置状态，通过业务状态判断是否需要重复执行</li>
</ol>
<h3 id="调用链路"><a class="header-anchor" href="#调用链路">¶</a>调用链路</h3>
<p>就想本地事务通过方法调用来传递，分布式事务也需要在进行远程调用时传递该事务的标识（称为调用链路ID，有时会包装到一个事务上下文内）<br>
服务为了确认自己处于哪个事务中，必须将调用链路ID作为参数在远程调用时进行传递，这和实现密切相关，待补充。。。。</p>
<h2 id="结合mq消息中间件实现的可靠消息最终一致性"><a class="header-anchor" href="#结合mq消息中间件实现的可靠消息最终一致性">¶</a>结合MQ消息中间件实现的可靠消息最终一致性</h2>
<p>可靠消息最终一致性，需要业务系统结合MQ消息中间件实现，在实现过程中需要保证消息的成功发送及成功消费。即需要通过业务系统控制MQ的消息状态。<br>
所谓的消息事务本质上就是基于消息中间件的两阶段提交，是对消息中间件的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，保证要么本地操作成功成功并且对外发消息成功，要么两者都失败，开源的RocketMQ就支持这一特性，具体原理如下：<br>
<img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/%E6%B6%88%E6%81%AF%E4%BA%8B%E5%8A%A1.png" alt="消息事务" title="消息事务"><br>
步骤1失败：则整个事务失败，不会执行A的本地操作；<br>
步骤2失败：同样整个事务失败，不会执行A的本地操作（被本地数据库回滚掉了）；<br>
步骤3失败：消息中间件需要有回查机制，回查A系统该事务是否被本地执行成功了，如果成功则照常继续执行，如果失败则将预备消息回滚了，其实这指的就是步骤4的回调。</p>
<p>虽然上面的方案能够完成A和B的操作，但是A和B并不是严格一致的，而是最终一致的，我们在这里牺牲了一致性，换来了性能的大幅度提升。当然，这种玩法也是有风险的，如果B一直执行不成功，那么一致性会被破坏，具体要不要玩，还是得看业务能够承担多少风险。</p>
<h3 id="实例-下单"><a class="header-anchor" href="#实例-下单">¶</a>实例 - 下单</h3>
<p><img src="http://47.88.24.11/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/%E6%B6%88%E6%81%AF%E4%BA%8B%E5%8A%A1-%E4%B8%8B%E5%8D%95.jpeg" alt="消息事务-下单" title="消息事务-下单"></p>
<ol>
<li>预创建订单失败:如果实际预创建订单成功,订单定时补偿机制,定时删除这部分订单,不影响数据一致性,下单失败；</li>
<li>预扣减库存失败:如果预扣减库存真实失败,则下单失败(订单由定时补偿机制定时删除,其它应用参照场景4的处理方式,下单失败;如果实际预扣减库存成功,参照场景4的处理方式,下单失败；</li>
<li>实际创建订单失败:如果创建订单真实失败(不需要发送下单失败消息,防止实际创建订单成功场景),订单的预处理数据通过订单的定时补偿机制尝试删除(需要考虑事务处理时间,将超过某个时间范围该事务还处于预处理状态的订单删除),下单失败;如果实际创建订单成功,其它应用参照场景4的处理方式,下单成功(提示用户下单失败)；</li>
<li>发送订单创建成功消息失败/库存服务由于各种原因没有接到下单成功消息:库存服务定时轮询处理数据(需要考虑事务处理时间,将超过某个时间范围该事务还处于预处理状态的订单筛选出来),询问订单服务改订单Id对应的订单是否创建成功,根据订单创建成功与否选取相应的事务补偿机制</li>
</ol>
<h3 id="和tcc比较"><a class="header-anchor" href="#和tcc比较">¶</a>和TCC比较</h3>
<ol>
<li>TCC是把所有的订单创建步骤平等看待，只要有一个失败,整个下单流程全部失败(比较TCC里面的confirm失败和基于MQ实际创建订单失败的补偿难易程度)</li>
<li>TCC是通过发消息给TCC服务器，然后由TCC服务调用应用服务；<br>
基于MQ的分布式事务补偿机制，是通过将消息发送到MQ，然后由应用自己去监听MQ的事件。</li>
</ol>
<h3 id="注意-v2"><a class="header-anchor" href="#注意-v2">¶</a>注意</h3>
<p>消息中间件在系统中扮演一个重要的角色, 所有的事务消息都需要通过它来传达, 所以消息中间件也需要支持 HA 来确保事务消息不丢失.<br>
根据业务逻辑的具体实现不同，还可能需要对消息中间件增加消息不重复, 不乱序等其它要求.</p>
<h3 id="适用场景-v2"><a class="header-anchor" href="#适用场景-v2">¶</a>适用场景</h3>
<ol>
<li>执行周期较长</li>
<li>实时性要求不高</li>
</ol>
<p>例如:</p>
<ul>
<li>跨行转账/汇款业务(两个服务分别在不同的银行中)</li>
<li>退货/退款业务</li>
<li>财务, 账单统计业务(先发送到消息中间件, 然后进行批量记账)</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/5f3f10ab.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/5f3f10ab.html" itemprop="url">分布式事务-从本地事务到分布式事务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-06T10:26:49+08:00">
                2020-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/分布式事务/" itemprop="url" rel="index">
                    <span itemprop="name">分布式事务</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5.1k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  18 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>这篇文档集中于概念的梳理，不会谈太多实现上的细节。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/5f3f10ab.html#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/22fb3f5f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/22fb3f5f.html" itemprop="url">从Spring改造成SpringBoot项目</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-18T17:39:29+08:00">
                2020-11-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Spring/" itemprop="url" rel="index">
                    <span itemprop="name">Spring</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="为什么要改造"><a class="header-anchor" href="#为什么要改造">¶</a>为什么要改造</h2>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/6a07ad6.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/6a07ad6.html" itemprop="url">Redis 性能调优</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-10T12:21:48+08:00">
                2020-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  26 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Redis 监控</h1>
<p>这里把一些常见的监控命令总结一下，时不时都会用到。</p>
<h2 id="redis-cli"><a class="header-anchor" href="#redis-cli">¶</a>redis-cli</h2>
<p>命令行客户端。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建连接，可以用PING-PONG来检查连接是否OK</span><br><span class="line">redis-cli -h localhost -p 6379</span><br><span class="line"># 监控Redis的连接和读写操作</span><br><span class="line">redis-cli -h localhost -p 6379 monitor</span><br><span class="line"># Redis服务器的统计信息</span><br><span class="line">redis-cli -h localhost -p 6379 info</span><br></pre></td></tr></table></figure>
<ul>
<li>内存使用<br>
<code>Memory</code>下可以查看 Redis 内存使用情况。如果 Redis 使用的内存超出了可用的物理内存大小，那么 Redis 很可能系统会被杀掉。针对这一点，你可以通过 info 命令对 used_memory 和 used_memory_peak 进行监控，为使用内存量设定阀值，并设定相应的报警机制。当然，报警只是手段，重要的是你得预先计划好，当内存使用量过大后，你应该做些什么，是清除一些没用的冷数据，还是把 Redis 迁移到更强大的机器上去。</li>
<li>持久化<br>
<code>Persistence</code>下可以查看 RDB 和 AOF 的备份情况。如果因为你的机器或 Redis 本身的问题导致 Redis 崩溃了，那么你唯一的救命稻草可能就是 dump 出来的 rdb 文件了，所以，对 Redis dump 文件进行监控也是很重要的。可以通过对 rdb_last_save_time 进行监控，了解最近一次 dump 数据操作的时间，还可以通过对 rdb_changes_since_last_save 进行监控来获得如果这时候出现故障，会丢失（即已改变）多少数据。</li>
<li>Keys<br>
通过获取 Keyspace 中的结果得到各个数据库中 key 的数量</li>
<li>QPS<br>
即每分钟执行的命令个数，即：(total_commands_processed2-total_commands_processed1)/span，为了实时得到 QPS，可以设定脚本在后台运行，记录过去几分钟的 total_commands_processed。在计算 QPS 时，利用过去的信息和当前的信息得出 QPS 的估计值。</li>
</ul>
<h2 id="redis-stat"><a class="header-anchor" href="#redis-stat">¶</a>redis-stat</h2>
<p>Redis 服务器的<strong>实时</strong>信息。<br>
这个命令不是 Redis 官方提供的，而是一个三方用 ruby 写的监控程序，安装起来有点麻烦，这里就不说明了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># usage:redis-stat [HOST[:PORT] ...] [INTERVAL [COUNT]]</span><br><span class="line"># 每1s收集一次</span><br><span class="line">redis-stat 1</span><br><span class="line"># 指定主机和服务器端口，间隔为1s，收集10次</span><br><span class="line">redis-stat localhost:6379 1 10</span><br><span class="line"># 启动一个redis-stat服务进程，提供一个Dashboard来查看Redis服务器的状态，按如下启动，可以访问 `localhost:8080` 查看</span><br><span class="line">redis-stat localhost:6379 --server=8080 5 --daemon</span><br></pre></td></tr></table></figure>
<p>-a, --auth=PASSWORD 密码<br>
-v, --verbose       展示更多信息<br>
–style=STYLE       输出样式：unicode|ascii<br>
–no-color          去掉颜色<br>
–csv[=CSV_FILE]    打印或将结果保存到 CSV 文件内<br>
–es=ELASTICSEARCH_URL  将结果发送到 ElasticSearch：[http://]HOST[:PORT][/INDEX]<br>
–server[=PORT]     启动 redis-stat 服务器（默认端口是 63790）<br>
–daemon            启动 redis-stat 作为守护进程，必须和 --server 选项一起使用<br>
–version           版本<br>
–help              帮助信息</p>
<h2 id="slowlog"><a class="header-anchor" href="#slowlog">¶</a>slowlog</h2>
<p>慢查询日志。<br>
可以在 redis.conf 中配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 记录执行时间超过5秒的查询</span><br><span class="line">config set slowlog-log-slower-than 5000</span><br><span class="line"># 最多保存25条日志</span><br><span class="line">config set slowlog-max-len 25</span><br></pre></td></tr></table></figure>
<p>使用 redis-cli 登录查看慢查询日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 获取10条日志</span><br><span class="line">slowlog get 10</span><br></pre></td></tr></table></figure>
<h2 id="redis-benchmark"><a class="header-anchor" href="#redis-benchmark">¶</a>redis-benchmark</h2>
<p>redis-benchmark 是 Redis 官方提供的 Redis 服务器性能基准测试工具：<br>
-t 选择你想测试的命令，比如 redis-benchmark -t set<br>
-p 指定 port redis-benchmark -p 6379<br>
-l 一直循环<br>
-c 指定客户端数量<br>
-n 指定 request 数量<br>
-q Quiet，不显示额外信息（多少时间内完成了多少条之类的），只显示 query/sec 的值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 测试并发连接性能，100个并发连接，总共发100000个请求</span><br><span class="line">redis-benchmark -h localhost -p 6379 -c 100 -n 100000</span><br><span class="line"># 测试大数据包读写性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q -d 100</span><br><span class="line"># 只测试某些操作的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -t set,lpush -n 100000 -q</span><br><span class="line"># 只测试某些数值存取的性能</span><br><span class="line">redis-benchmark -h localhost -p 6379 -q script load &quot;redis.call(&apos;set&apos;, &apos;foo&apos;, &apos;bar&apos;)&quot;</span><br></pre></td></tr></table></figure>
<h2 id="rdb-文件分析"><a class="header-anchor" href="#rdb-文件分析">¶</a>RDB 文件分析</h2>
<p>Redis 内存比较大的时候不容易查出是哪些 key 比较占空间，这时可以使用 <a href="https://github.com/sripathikrishnan/redis-rdb-tools" target="_blank" rel="noopener">redis-rdb-tools</a> 这种工具来查看报告。</p>
<h1>Redis性能问题排查</h1>
<h2 id="哪些场景会导致redis阻塞？"><a class="header-anchor" href="#哪些场景会导致redis阻塞？">¶</a>哪些场景会导致Redis阻塞？</h2>
<p>Redis实例运行期间会和多种对象进行交互：</p>
<ul>
<li>客户端：网络 IO，键值对增删改查操作，数据库操作；</li>
<li>磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；</li>
<li>主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件；</li>
<li>切片集群实例：向其他实例传输哈希槽信息，数据迁移。</li>
</ul>
<h2 id="如果redis变慢-可能是什么导致的？"><a class="header-anchor" href="#如果redis变慢-可能是什么导致的？">¶</a>如果Redis变慢，可能是什么导致的？</h2>
<ol>
<li>Redis是单线程模型，如果前面有请求执行比较慢，后面的都要排队等着；<br>
耗时的操作包括：
<ul>
<li>集合全量查询和聚合操作：比如HGETALL、SMEMBERS</li>
<li>操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；<br>
特别是删除大key时需要释放内存，操作系统需要将释放掉的内存块插入到一个空闲内存块的链表，以便后续进行管理和再分配（指malloc/free）。</li>
<li>使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</li>
<li>大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</li>
<li>淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</li>
<li>AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</li>
<li>主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；<br>
对此，需要业务人员主动规避上述可能导致超时的情况；</li>
</ul>
</li>
<li>并发非常大，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。<br>
对此，Redis6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据。</li>
</ol>
<h2 id="如何检测redis是否变慢？"><a class="header-anchor" href="#如何检测redis是否变慢？">¶</a>如何检测Redis是否变慢？</h2>
<p>如何排查Redis是否真的变慢，一个直接的方法是查看Redis的<strong>响应延迟</strong>，但是响应延迟多长算慢呢？不同硬件性能不同，这个值的判断也是不同的，并没有绝对的标准。<br>
另一种方法是测算当前环境下的 Redis <strong>基线性能</strong>，也就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。<br>
从 2.8.7 版本开始，<code>redis-cli</code> 命令提供了<code>–intrinsic-latency</code> 选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能。<br>
一般我们可以把Redis基线性能和响应延迟结合起来判断Redis是否变慢了，如果观察到Redis延迟是其基线性能的2倍以上，就可以认定Redis变慢了。</p>
<h1>Redis性能优化</h1>
<h2 id="内存优化"><a class="header-anchor" href="#内存优化">¶</a>内存优化</h2>
<ol>
<li>压缩的类型<br>
在数据量比较少时，Redis会使用占用内存更少的数据类型，包括hash、list、set、zset均为如此，占用的内存大小甚至可以达到普通类型的1/5。<br>
hash-max-ziplist-entries 512<br>
hash-max-ziplist-value 64<br>
zset-max-ziplist-entries 128<br>
zset-max-ziplist-value 64<br>
set-max-intset-entries 512<br>
压缩的类型是“拿时间换空间”，因此效率肯定是比不上普通类型的，只是数据量比较小的情况下二者是差不多的，试想：虽然一个压缩类型对象并不能省多少空间，但是如果很多很多对象都经过压缩，那么最终总体上就能省很多空间了。<br>
当对象占用内存超过配置的最大值，Redis会自动将其转换为普通类型。</li>
<li>尽量使用散列表<br>
小散列表占用的内存非常小</li>
</ol>
<h2 id="慢查询命令"><a class="header-anchor" href="#慢查询命令">¶</a>慢查询命令</h2>
<p>使用Redis前必须先了解各种指令的复杂度，比如get、set是O(1)的，set的smembers是O(N)的。<br>
当发现性能变慢时，可以通过：</p>
<ol>
<li>Redis日志查询变慢的请求；</li>
<li>latency monitor工具查询变慢请求；</li>
</ol>
<p>如果确实有大量满查询命令，可以：</p>
<ol>
<li>用其他高效命令代替；</li>
<li>sort、sunion、sinter这些复杂操作可以将逻辑转移到客户端完成。<br>
如果业务逻辑就是得用慢查询命令完成，那可以考虑采用性能更好的CPU，从而更快地完成查询命令。</li>
</ol>
<h2 id="过期key操作"><a class="header-anchor" href="#过期key操作">¶</a>过期key操作</h2>
<p>Redis4.0之前，淘汰key的机制中，删除操作是阻塞的，而淘汰机制会不断抽样，直到过期的key只占不到25%的比例，因此淘汰很有可能会影响主线程；在Redis4.0之后采用异步线程机制来减少阻塞影响）。<br>
比如同一时间有很多key设置了相同的过期时间，就会导致这种情况。</p>
<h2 id="批量请求优化"><a class="header-anchor" href="#批量请求优化">¶</a>批量请求优化</h2>
<p>使用管道Pipelineing：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ (printf &quot;PING\r\nPING\r\nPING\r\n&quot;; sleep 1) | nc localhost 6379</span><br></pre></td></tr></table></figure>
<p>优点：</p>
<ol>
<li>一次连接就可以执行多次请求；</li>
</ol>
<p>缺点：</p>
<ol>
<li>使用管道发送命令时，服务器将被迫回复一个队列答复，占用很多内存。所以，如果你需要发送大量的命令，最好是把他们按照合理数量分批次的处理，例如10K的命令，读回复，然后再发送另一个10k的命令，等等。这样速度几乎是相同的，但是在回复这10k命令队列需要非常大量的内存用来组织返回数据内容。</li>
</ol>
<h2 id="大量数据插入"><a class="header-anchor" href="#大量数据插入">¶</a>大量数据插入</h2>
<p>大量数据插入时会面临以下问题：</p>
<ol>
<li>一个一个插入的话会有很多时间浪费在请求的往返上，因此需要批量执行<br>
批量执行可以是：管道、lua脚本</li>
<li>批量插入的过程怎么保证所有key都能插入成功</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SET Key0 Value0</span><br><span class="line">SET Key1 Value1</span><br><span class="line">...</span><br><span class="line">SET KeyN ValueN</span><br></pre></td></tr></table></figure>
<p>如果是如下的pipeline，其实并不可靠，因为执行过程中不能检查错误。<br>
<code>(cat data.txt; sleep 10) | nc localhost 6379 &gt; /dev/null</code><br>
一种更好的方式是使用redis-cli中的<strong>pipe mode</strong>，期间会把错误输出到终端：<br>
<code>cat data.txt | redis-cli --pipe</code></p>
<h2 id="大-key-问题"><a class="header-anchor" href="#大-key-问题">¶</a>大 Key 问题</h2>
<blockquote>
<p>大key大的是value。</p>
</blockquote>
<p>大 Key 有两种状况：</p>
<ol>
<li>Redis 中单个简单的 Key 存储的 value 很大</li>
<li>hash、set、zset、list 中存储的元素过多（以万为单位）。</li>
</ol>
<p>由于 Redis 的单线程模型，读写大 Key 时服务器的耗时可能会比较长、甚至阻塞。</p>
<p>分析大key可以通过<code>--bigkeys</code>进行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hgc@hgc-X555LD:~$ redis-cli -h 127.0.0.1 -p 6379 -n 0 --bigkeys</span><br><span class="line"></span><br><span class="line"># Scanning the entire keyspace to find biggest keys as well as</span><br><span class="line"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span><br><span class="line"># per 100 SCAN commands (not usually needed).</span><br><span class="line"></span><br><span class="line">[00.00%] Biggest string found so far &apos;143&apos; with 35 bytes</span><br><span class="line">[00.00%] Biggest string found so far &apos;a&apos; with 184 bytes</span><br><span class="line">[73.33%] Biggest hash   found so far &apos;b&apos; with 1 fields</span><br><span class="line"></span><br><span class="line">-------- summary -------</span><br><span class="line"></span><br><span class="line">Sampled 15 keys in the keyspace!</span><br><span class="line">Total key length in bytes is 41 (avg len 2.73)</span><br><span class="line"></span><br><span class="line">Biggest   hash found &apos;b&apos; has 1 fields</span><br><span class="line">Biggest string found &apos;a&apos; has 184 bytes</span><br><span class="line"></span><br><span class="line">0 lists with 0 items (00.00% of keys, avg size 0.00)</span><br><span class="line">1 hashs with 1 fields (06.67% of keys, avg size 1.00)</span><br><span class="line">14 strings with 639 bytes (93.33% of keys, avg size 45.64)</span><br><span class="line">0 streams with 0 entries (00.00% of keys, avg size 0.00)</span><br><span class="line">0 sets with 0 members (00.00% of keys, avg size 0.00)</span><br><span class="line">0 zsets with 0 members (00.00% of keys, avg size 0.00)</span><br></pre></td></tr></table></figure>
<p><code>bigkeys</code>是通过scan指令来实现的，所以并不会造成服务器长时间的阻塞，当然这种数据库全扫命令最好还是少用。</p>
<p>解决方案一般是能拆则拆，对于单个大 Key 的情况：<br>
1.1 将大 Key 进行分割，拆成几个小的 key-value，使用 multiGet 获取值。<br>
这样分拆的意义是将单次操作的压力分摊到多个 Redis 实例上，降低对单个 Redis 的 IO 影响，而且大 Key 拆分之后每次只查询一部分，减小了 IO 阻塞的风险。<br>
为了均匀分割，可以对 field 进行 hash 并通过质数 N 取余，将余数加到 key 上面。<br>
1.2 将大 Key 拆分成多个 key-value，并将这些存储在一个 hash 中，每个 field 代表一个具体的属性，使用 hget、hmget 来获取部分的 value，使用 hset、hmset 来更新部分属性</p>
<p>对于 hash、set、zset、list 中存储的元素过多的情况，可以控制将 field 分散到多个集合内。<br>
比如以下代码将属于一个大 hash 内的 field 分散到 10000 个拆分后的小 hash 内：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">newHashKey = hashKey + (hash(field) % 10000)</span><br><span class="line">hset(newHashKey, field, value)</span><br><span class="line">hget(newHashKey, field)</span><br></pre></td></tr></table></figure>
<p>对于一些需要考虑顺序的场景，比如 lpop、zrange，需要在 hash 函数上做些文章，比如按照时间来拆分。</p>
<h2 id="redis与cpu的关系"><a class="header-anchor" href="#redis与cpu的关系">¶</a>Redis与CPU的关系</h2>
<p>在现代CPU架构中，每个物理核心都会有一个私有的L1 cache和L2 cache，不同核之间共用一个L3缓存，尽可能避免访问主存。<br>
应用程序会被分配到一个CPU上执行，但是进程调度机制可能会将Redis进程调度到另一个核心上，导致之前加载的缓存都白费了。<br>
可以通过taskset命令将Redis进程绑定在一个核上运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># -c 用于设置要绑定的核编号</span><br><span class="line">taskset -c 0 ./redis-server</span><br></pre></td></tr></table></figure>
<h2 id="内存碎片"><a class="header-anchor" href="#内存碎片">¶</a>内存碎片</h2>
<p>Redis底层分配内存函数是jmalloc，它分配的内存大小总是2的幂倍数，如果分配的内存大小比实际使用的要多一些，就会产生内存碎片，内存碎片多了后就会有很多内存的浪费情况，特别是<strong>分配键值对的大小不一的情况下，内存碎片会尤其严重</strong>。</p>
<h3 id="查看内存碎片"><a class="header-anchor" href="#查看内存碎片">¶</a>查看内存碎片</h3>
<p>查看内存碎片情况很容易，可以直接使用<code>info</code>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">10.32.140.14:6211&gt; info memory</span><br><span class="line"># Memory</span><br><span class="line">used_memory:1441123632</span><br><span class="line">used_memory_human:1.34G</span><br><span class="line">used_memory_rss:1853603840</span><br><span class="line">used_memory_rss_human:1.73G</span><br><span class="line">...</span><br><span class="line">mem_fragmentation_ratio:1.29</span><br></pre></td></tr></table></figure>
<p>其中<code>mem_fragmentation_ratio</code>这个指标就是Redis当前的内存碎片率，它的值其实就是<code>used_memory_rss</code>和<code>used_memory</code>相除的结果（<code>used_memory_rss/used_memory</code>），前者是OS分配给Redis的内存空间，包含碎片，后者不包含碎片。</p>
<ul>
<li><code>mem_fragmentation_ratio</code>在<code>[1,1.5]</code>范围内是合理的，因为内存碎片无法完全避免</li>
<li><code>mem_fragmentation_ratio</code>大于1.5则需要采取一些措施来减小内存碎片率。</li>
</ul>
<h3 id="处理内存碎片"><a class="header-anchor" href="#处理内存碎片">¶</a>处理内存碎片</h3>
<ul>
<li>重启Redis实例。这是最简单的方法，但是重启后Redis内存中的数据会全部丢失，除非进行了持久化，但恢复也是需要不少时间的。</li>
<li>从Redis4.0-RC3后，Redis自身提供了内存碎片清理的功能，也即将内存数据拷贝到一块新的内存位置，可以设置参数控制碎片清理的开始、结束时机、占用的内存比例等：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 开启内存碎片清理功能</span><br><span class="line">config set activedefrag yes</span><br><span class="line"># 表示内存碎片达到100MB时开始清理</span><br><span class="line">active-defrag-ignore-bytes 100mb</span><br><span class="line"># 表示内存碎片空间占Redis总空间大小的10%时</span><br><span class="line">tive-defrag-threshold-lower 10</span><br><span class="line"># 控制清理过程占用CPU时间比例不低于25%，保证清理能正常</span><br><span class="line">adtive-defrag-cycle-min 25</span><br><span class="line"># 控制清理过程占用CPU时间比例不高于75%，尽量不要影响主线程</span><br><span class="line">active-defrag-cycle-max 75</span><br></pre></td></tr></table></figure>
<h2 id="其他优化点"><a class="header-anchor" href="#其他优化点">¶</a>其他优化点</h2>
<ul>
<li>单进程单线程，无法充分发挥服务器多核 cpu 的性能；大流量下造成 IO 阻塞，同样是由于单进程单线程, cpu 在处理业务逻辑的时候,网络 IO 被阻塞住, 造成无法处理更多的请求.<br>
多线程 master + N<em>work 工作模式.master 线程负责监听网络事件, 在接收到一个新的连接后, master 会把新的 fd 注册到 worker 的 epoll 事件中, 交由 worker 处理这个 fd 的所有读写事件, 这样 master 线程就可以完全被释放出来接收更多的连接, 同时又不妨碍 worker 处理业务逻辑和 IO 读写.<br>
采用这种 master + N</em>worker 的网络层事件模型,可以实现 redis 性能的平行扩展. 真正的让 redis 在面临高并发请求时可以丛容面对.</li>
<li>维护成本高, 如果想要充分发挥服务器的所有资源包括 cpu, 网络 io 等, 就必须建立多个 instance, 但此时不可避免会增加维护成本. 拿 24 核服务器举例来讲, 如果部署 24 个单机版的 instance,理论上可以实现 10w*24core= 240wQPS 的总体性能.但是每个 instance 有各自独立的数据,占用资源如内存也会同比上升,反过来制约一台服务器又未必能支持这么多的 instance. 如果部署 24 个 Instance 来构成单机集群, 虽然可以共享数据，但是因为节点增加, redis 的状态通讯更加频繁和费时,性能也下会降很多. 并且两种方式都意味着要维护 24 个 Instance，运维成本都会成倍增加.</li>
<li>持久化：redis 提供了两种 save 方式 1)save 触发. 2)bgsave. 当然也可以使用 3)aof 来实现持久化, 但是这 3 点都有弊端.
<ul>
<li>save: 由于是单进程单线程, redis 会阻塞住所有请求, 来遍历所有 redisDB, 把 key-val 写入 dump.rdb. 如果内存数据量过大, 会造成短时间几秒到几十秒甚至更长的时间停止服务, 这种方案对于 twitter, taobao 等大流量的网站, 显然是不可取的.</li>
<li>bgsave: 在触发 bgsave 时, redis 会 fork 自身, child 进程会进入 1)的处理方式,这意味着服务器内存要有一半的冗余才可以, 如今内存已变得越来越廉价, 但是对于存储海量数据的情况,内存以及服务器的成本还是不容忽视的.</li>
<li>aof: 说到持久化, redis 提供的 aof 算是最完美的方案了, 但是有得必有失, 严重影响性能! 因为 redis 每接收到一条请求, 就要把命令内容完整的写到磁盘文件, 且不说频繁读写会影响磁盘寿命,写磁盘的时间足以拖垮 redis 整体性能 . 当然熟悉 redis 的开发者会想到用 appendfsync 等参数来调整, 但都不是完美.即使使用 SSD，性能也只是略有提升，并且性价比不高。</li>
</ul>
</li>
<li>优化 jemalloc, 采用大内存页. Redis 在使用内存方面可谓苛刻至极, 压缩, string 转 number 等, 能省就省, 但是在实际生产环境中, 为了追求性能, 对于内存的使用可以适度（不至于如 bgsave 般浪费）通融处理, 因此 AliRedis 对 jemalloc 做了微调, 通过调整 pagesize 来让一次 je_malloc 分配更多 run 空间来储备更多的用户态可用内存, 同时可以减轻换页表的负载, 降低 user sys 的切换频率, 来提高申请内存的性能, 对 jemalloc 有兴趣的开发者可以参考 jemalloc 源码中的 bin, run, chunk 数据结构进行分析.</li>
</ul>
<h1>Redis配置</h1>
<h2 id="内存"><a class="header-anchor" href="#内存">¶</a>内存</h2>
<p>因为系统的内存大小有限，所以我们在使用 Redis 的时候可以配置 Redis 能使用的最大的内存大小。<br>
redis.conf：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Redis最大占用内存大小</span><br><span class="line">maxmemory 100mb</span><br></pre></td></tr></table></figure>
<p>通过命令修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set maxmemory 100mb</span><br><span class="line">127.0.0.1:6379&gt; config get maxmemory</span><br></pre></td></tr></table></figure>
<p>如果不设置最大内存大小或设置最大内存大小为 0，在 64 位操作系统下不限制内存大小，在 32 位操作系统下最大使用 3GB 内存。</p>
<h2 id="修改数据库配置"><a class="header-anchor" href="#修改数据库配置">¶</a>修改数据库配置</h2>
<p>redis 默认创建 16 个数据库（类似一个数组），默认值对应在 redis.conf 配置文件中 database 的值。<br>
默认使用 0 号库，可以使用 select 命令来选择其他库。</p>
<h2 id="过期时间的设置"><a class="header-anchor" href="#过期时间的设置">¶</a>过期时间的设置</h2>
<p>如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。</p>
<h2 id="连接设置"><a class="header-anchor" href="#连接设置">¶</a>连接设置</h2>
<h3 id="redis连接配置"><a class="header-anchor" href="#redis连接配置">¶</a>Redis连接配置</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>port 16371</td>
<td>指定Redis监听端口，默认端口为6379</td>
<td></td>
</tr>
<tr>
<td>bind 10.56.50.164</td>
<td>绑定的主机地址</td>
<td></td>
</tr>
<tr>
<td>timeout 2000</td>
<td>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</td>
<td>在压测时需要修改</td>
</tr>
<tr>
<td>tcp-keepalive 0</td>
<td>redis服务端主动向空闲的客户端发起ack请求，以判断连接是否有效，0表示未启用。定时向client发送tcp_ack包来探测client是否存活的。默认不探测，官方建议值为60秒</td>
<td>建议开启，避免连接意外中断后，服务端不能释放</td>
</tr>
<tr>
<td>maxclients 30000</td>
<td>设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="修改最大tcp连接"><a class="header-anchor" href="#修改最大tcp连接">¶</a>修改最大TCP连接</h3>
<p>1、编辑文件 sudo vim /etc/security/limits.conf ，添加如下内容</p>
<ul>
<li>soft nproc 60240</li>
<li>hard nproc 60240</li>
<li>soft nofile 65535</li>
<li>hard nofile 65535<br>
2、编辑文件 vi /etc/pam.d/login，在末尾添加如下内容<br>
session required /usr/lib64/security/pam_limits.so<br>
3、编辑文件 /etc/pam.d/system-auth ，添加如下内容<br>
session required /lib/security/$ISA/pam_limits.so<br>
4、重启虚机</li>
</ul>
<h3 id="修改tcp连接等待队列长度"><a class="header-anchor" href="#修改tcp连接等待队列长度">¶</a>修改TCP连接等待队列长度</h3>
<p>编辑系统控制文件，加入tcp最长队列参数<br>
1、编辑文件 vim /etc/sysctl.conf 添加如下内容<br>
net.core.somaxconn=5120<br>
2、查看修改<br>
sudo sysctl -p<br>
3、同步修改<br>
sudo sysctl vm.overcommit_memory=1<br>
4、关闭透明大页</p>
<ul>
<li>具有sudo权限的用户 （尝试过echo 命令 ，权限不允许）<br>
sudo vim  /etc/grub2.cfg 文件尾加上<br>
transparent_hugepage=never<br>
【或者使用root用户执行 echo “transparent_hugepage=never”&gt;&gt; /etc/grub2.cfg 】</li>
<li>root用户</li>
</ul>
<h1>echo never&gt;/sys/kernel/mm/transparent_hugepage/enabled</h1>
<ul>
<li>验证结果 返回 0 说明生效<br>
$ grep -i HugePages_Total /proc/meminfo<br>
HugePages_Total:       0<br>
$ cat /proc/sys/vm/nr_hugepages<br>
0</li>
</ul>
<h2 id="持久化"><a class="header-anchor" href="#持久化">¶</a>持久化</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>
<p>指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合<br>
save <seconds> <changes><br>
分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。<br>
建议值：</changes></seconds></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 20</span><br><span class="line">save 300 2000</span><br><span class="line">save 60 200000</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>stop-writes-on-bgsave-error yes</td>
<td>配置项stop-writes-on-bgsave-error no （默认值为yes），即当bgsave快照操作出错时停止写数据到磁盘，这样后面写错做均会失败，为了不影响后续写操作，故需将该项值改为no。</td>
<td>强制关闭Redis快照可能会导致不能持久化。MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.</td>
</tr>
<tr>
<td>rdbcompression yes</td>
<td>指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大</td>
<td>开启压缩</td>
</tr>
<tr>
<td>rdbchecksum yes</td>
<td>(对rdb数据进行校验,耗费CPU资源,默认为yes)默认值是yes。在存储快照后，让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td>
<td>建议关闭</td>
</tr>
<tr>
<td>appendfsync everysec	指定更新日志条件，共有3个可选值：no表示等操作系统进行数据缓存同步到磁盘（快）；always表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）；everysec表示每秒同步一次（折衷，默认值）</td>
<td></td>
<td></td>
</tr>
<tr>
<td>no-appendfsync-on-rewrite no</td>
<td>是否在后台写时同步单写，默认值no(表示需要同步).这里的后台写，表示后台正在重写文件(包括bgsave和bgrewriteaof.bgrewriteaof网上很多资料都没有涉及到。其实关掉bgsave之后，主要的即是aof重写文件了).no表示新的主进程的set操作会被阻塞掉，而yes表示新的主进程的set不会被阻塞，待整个后台写完成之后再将这部分set操作同步到aof文件中。但这可能会存在数据丢失的风险(机率很小)，如果对性能有要求，可以设置为yes，仅在后台写时会异步处理命令.</td>
<td>压测时建议修改成yes</td>
</tr>
<tr>
<td>auto-aof-rewrite-percentage 100</td>
<td>aof文件增长比例，指当前aof文件比上次重写的增长比例大小。aof重写即在aof文件在一定大小之后，重新将整个内存写到aof文件当中，以反映最新的状态(相当于bgsave)。这样就避免了，aof文件过大而实际内存数据小的问题(频繁修改数据问题).</td>
<td></td>
</tr>
<tr>
<td>auto-aof-rewrite-min-size 64mb</td>
<td>aof文件重写最小的文件大小，即最开始aof文件必须要达到这个文件时才触发，后面的每次重写就不会根据这个变量了(根据上一次重写完成之后的大小).此变量仅初始化启动redis有效.如果是redis恢复时，则lastSize等于初始aof文件大小.</td>
<td></td>
</tr>
<tr>
<td>aof-load-truncated yes</td>
<td>指redis在恢复时，会忽略最后一条可能存在问题的指令。默认值yes。即在aof写入时，可能存在指令写错的问题(突然断电，写了一半)，这种情况下，yes会log并继续，而no会直接恢复失败.</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="主从配置"><a class="header-anchor" href="#主从配置">¶</a>主从配置</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>slave-serve-stale-data yes</td>
<td>slave-serve-stale-data参数设置成yes，主从复制中，从服务器可以响应客户端请求</td>
<td></td>
</tr>
<tr>
<td>slave-read-only yes</td>
<td>如果为 yes，代表为只读状态，但并不表示客户端用集群方式以从节点为入口连入集群时，不可以进行 set 操作，且 set 操作的数据不会被放在从节点的槽上，会被放到某主节点的槽上</td>
<td></td>
</tr>
<tr>
<td>repl-diskless-sync no</td>
<td>一个RDB文件从master端传到slave端，分为两种情况：1、支持disk：master端将RDB file写到disk，稍后再传送到slave端；2、无磁盘diskless：master端直接将RDB file传到slave socket，不需要与disk进行交互。</td>
<td></td>
</tr>
<tr>
<td>无磁盘diskless方式适合磁盘读写速度慢但网络带宽非常高的环境。repl-diskless-sync no 默认不使用diskless同步方式</td>
<td></td>
<td></td>
</tr>
<tr>
<td>repl-diskless-sync-delay 5</td>
<td>无磁盘diskless方式在进行数据传递之前会有一个时间的延迟，以便slave端能够进行到待传送的目标队列中，这个时间默认是5秒</td>
<td></td>
</tr>
<tr>
<td>repl-disable-tcp-nodelay no</td>
<td>是否启用TCP_NODELAY，如果启用则会使用少量的TCP包和带宽去进行数据传输到slave端，当然速度会比较慢；如果不启用则传输速度比较快，但是会占用比较多的带宽。</td>
<td></td>
</tr>
<tr>
<td>slave-priority 100</td>
<td>slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。</td>
<td></td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/1942bbd0.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/1942bbd0.html" itemprop="url">Redis事务和Lua</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-09T22:42:14+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.7k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="缓存系统如何工作"><a class="header-anchor" href="#缓存系统如何工作">¶</a>缓存系统如何工作</h2>
<h3 id="缓存的两个特征"><a class="header-anchor" href="#缓存的两个特征">¶</a>缓存的两个特征</h3>
<ol>
<li>在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。</li>
<li>缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。</li>
</ol>
<h3 id="redis作为旁路缓存"><a class="header-anchor" href="#redis作为旁路缓存">¶</a>Redis作为旁路缓存</h3>
<p>作为缓存，我们在访问数据时可能会：</p>
<ul>
<li>命中：直接将缓存中的数据返回；</li>
<li>miss：缓存缺失，回源到MySQL读取数据，加载到缓存中；</li>
</ul>
<p>这种情况下，Redis就作为旁路缓存使用，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p>
<ul>
<li>如果是只读缓存，那么上述的旁路缓存设计就足够了；</li>
<li>如果是读写缓存，还有同步直写（写缓存的同时写DB）和异步写回（写缓存后异步写DB）这两种策略，各有优缺点。<br>
同步直写效率低，但是一致性高；<br>
异步写回效率高，但是一致性低。</li>
</ul>
<h2 id="缓存满了怎么办？"><a class="header-anchor" href="#缓存满了怎么办？">¶</a>缓存满了怎么办？</h2>
<h3 id="缓存淘汰-缓存失效策略和主键失效机制"><a class="header-anchor" href="#缓存淘汰-缓存失效策略和主键失效机制">¶</a>缓存淘汰（缓存失效策略和主键失效机制）</h3>
<p>作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略，比如 Redis 只能存 5G 数据，可是你写了 10G，那多出来的 5G 数据怎么删？你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高？这就需要深入到 Redis 的主键失效和淘汰策略中去了。</p>
<h4 id="key-的过期时间控制"><a class="header-anchor" href="#key-的过期时间控制">¶</a>key 的过期时间控制</h4>
<p>在 Redis 当中，有生存期的 key 被称为 volatile。在创建缓存时，要为给定的 key 设置生存期，当 key 过期的时候（生存期为 0），它可能会被删除。</p>
<ol>
<li>影响生存时间的一些操作<br>
生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改 key 对应的 value 和使用另外相同的 key 和 value 来覆盖以后，当前数据的生存时间不同。<br>
比如说，对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。<br>
RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用 PERSIST 命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个 persistent key 。</li>
<li>如何更新生存时间<br>
可以对一个已经带有生存时间的 key 执行 EXPIRE 命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在 1ms 之内，主键失效的时间复杂度是 O（1），<br>
EXPIRE 和 TTL 命令搭配使用，TTL 可以查看 key 的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。</li>
<li>最大缓存配置<br>
在 redis 中，允许用户设置最大使用内存大小 <code>server.maxmemory</code><br>
默认为 0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使 redis 崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。</li>
</ol>
<h4 id="key-的删除策略"><a class="header-anchor" href="#key-的删除策略">¶</a>key 的删除策略</h4>
<p>redis 采用的是定期删除+惰性删除策略。</p>
<ol>
<li>为什么不用定时删除策略?<br>
定时删除,用一个定时器来负责监视 key,过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 key,因此没有采用这一策略.</li>
<li>定期删除+惰性删除是如何工作的呢?<br>
定期删除，redis 默认每个 100ms 检查，是否有过期的 key,有过期 key 则删除。需要说明的是，redis 不是每个 100ms 将所有的 key 检查一次，而是随机抽取进行检查(如果每隔 100ms,全部 key 进行检查，redis 岂不是卡死)。因此，如果只采用定期删除策略，会导致很多 key 到时间没有删除。<br>
于是，惰性删除派上用场。也就是说在你获取某个 key 的时候，redis 会检查一下，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</li>
<li>采用定期删除+惰性删除就没其他问题了么?<br>
不是的，如果定期删除没删除 key。然后你也没即时去请求 key，也就是说惰性删除也没生效。这样，redis 的内存会越来越高。那么就应该采用内存淘汰机制。</li>
</ol>
<h4 id="redis-的数据淘汰策略"><a class="header-anchor" href="#redis-的数据淘汰策略">¶</a>Redis 的数据淘汰策略</h4>
<p>在 redis.conf 中有一行配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># maxmemory-policy volatile-lru</span><br></pre></td></tr></table></figure>
<p>redis 提供 6种数据淘汰策略：</p>
<ol>
<li>no-enviction（驱逐）：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错（应该没人用）</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰（这种情况一般是把 redis 既当缓存，又做持久化存储的时候才用。不推荐）</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰（不推荐）<br>
可以在一些需要“置顶”的业务场景里采用，比如一些新闻、视频需要置顶，这些数据不需要设置过期时间，<code>volatile-ttl</code>就不会删除它们。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰（不推荐）</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰（推荐）</li>
<li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
</ol>
<p>注意这里的 6 种机制：</p>
<ul>
<li>volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据；</li>
<li>lru、ttl 以及 random 是三种不同的淘汰策略，ttl 和 random 比较容易理解、实现也会比较简单，lru 会对 key 按失效时间排序，然后取最先失效的 key 进行淘汰。</li>
<li>如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。</li>
</ul>
<p><strong>使用策略规则</strong></p>
<ol>
<li>如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru</li>
<li>如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 allkeys-random</li>
</ol>
<h4 id="自定义缓存淘汰策略"><a class="header-anchor" href="#自定义缓存淘汰策略">¶</a>自定义缓存淘汰策略</h4>
<p>除了缓存服务器自带的缓存失效策略之外（Redis 默认有 6 种策略可选），我们还可以根据具体的业务需求自定义缓存淘汰策略，常见的策略有两种：</p>
<ol>
<li>定时去清除过期的缓存；</li>
<li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存；</li>
</ol>
<p>两种策略各有优劣，第一种的缺点是维护大量缓存的 key 是比较麻烦的，第二种的缺点是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂。需要根据应用场景的特点来权衡选择。</p>
<h4 id="缓存淘汰的实现"><a class="header-anchor" href="#缓存淘汰的实现">¶</a>缓存淘汰的实现</h4>
<ol>
<li>设置过期时间<br>
过期时间到了后，Redis 会在读的时候判断是否过期并清除，或者由一个定时任务执行清除操作。</li>
<li>超过 maxmemory 回收<br>
可以设置淘汰机制，比如 LRU、LFU。</li>
</ol>
<p>LRU 算法的一种简单实现<br>
简单版本的 LRU 算法分两个部分：</p>
<ol>
<li>一个链表记录 key 的最终访问次序，比如最新访问的在链表头部，最久没访问的在链表末尾，LRU 淘汰机制就是删除链表末尾的节点；</li>
<li>一个散列表记录某个 key 是否存在，并可以找到其在链表中的位置；</li>
</ol>
<p>Redis 中的 LRU<br>
<img src="http://47.88.24.11/imgs/Redis/Redis-LRU%E7%AE%97%E6%B3%95.png" alt="Redis-LRU算法" title="Redis-LRU算法"><br>
代码位置：<code>evict.c/freeMemoryIfNeeded</code><br>
Redis 中并没有直接使用上述的 LRU 算法，主要是因为维护LRU链表开销较大，而是退一步使用了抽样淘汰的机制：</p>
<ol>
<li>每次从缓存对象集合中随机取出一部分样本（20个key），进行下面的过期检测；</li>
<li>按 LRU 算法排序；</li>
<li>取 idle 值（评分）最小的淘汰；</li>
<li>如果有多于25%的key是过期了的，则重复步骤1。</li>
</ol>
<h2 id="缓存系统中存在的问题"><a class="header-anchor" href="#缓存系统中存在的问题">¶</a>缓存系统中存在的问题</h2>
<p><img src="http://47.88.24.11/imgs/JVM/%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E7%9A%84%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%E9%97%AE%E9%A2%98.jpg" alt="旁路缓存的雪崩、击穿、穿透问题" title="旁路缓存的雪崩、击穿、穿透问题"><br>
<img src="http://47.88.24.11/imgs/JVM/%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98.jpg" alt="旁路缓存的不一致问题" title="旁路缓存的不一致问题"></p>
<h3 id="缓存穿透"><a class="header-anchor" href="#缓存穿透">¶</a>缓存穿透</h3>
<p>缓存穿透即即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。这也是经常提的缓存命中率问题。<br>
应付大规模缓存穿透的方案如下：</p>
<ol>
<li>
<p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试</p>
</li>
<li>
<p>采用异步更新策略，无论 key 是否取到值，都直接返回。value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做<strong>缓存预热</strong>(项目启动前，先加载缓存)操作。</p>
</li>
<li>
<p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用<strong>布隆过滤器</strong>，内部维护一系列合法有效的 key，将这些数据 hash 到一个足够大的 bitmap 中。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p>
</li>
<li>
<p>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过 5 分钟，通过这个直接设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 击穿到db</span><br><span class="line">        cacheValue = getFromDB();</span><br><span class="line">        if (cacheValue == null) &#123;</span><br><span class="line">            // 如果发现为空，则缓存个默认值</span><br><span class="line">            cacheValue = &quot;&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把空结果也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。同时也可以单独设置一个缓存区域存储空值，对要查询的key进行进行预先校验，然后再放行给后面的正常缓存处理逻辑。</p>
</li>
</ol>
<h3 id="缓存雪崩"><a class="header-anchor" href="#缓存雪崩">¶</a>缓存雪崩</h3>
<p>缓存雪崩即缓存同一时间大面积的失效（例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期），这个时候又来了一波请求，结果请求都怼到数据库上，而对数据库 CPU 和内存造成巨大压力，从而导致数据库连接异常，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。<br>
缓存雪崩的解决方案如下：</p>
<ol>
<li>
<p>使用互斥锁，但是该方案吞吐量明显下降了，适用于并发量不是特别多的情况下。具体地来说，使用最多的方案是加锁排队，伪代码如下：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    String lockKey = cacheKey;</span><br><span class="line">    </span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (cacheValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        synchronized (lockKey) &#123;</span><br><span class="line">            cacheValue = getFromRedis(cacheKey);</span><br><span class="line">            if (cacheValue != null) &#123;</span><br><span class="line">                return cacheValue;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                cacheValue = getFromDB();</span><br><span class="line">                putToRedis(cacheKey, cacheValue, cacheTime);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这时过来1000个请求、999个都在阻塞，同样会导致用户等待超时，属于治标不治本的方案，而且还需要解决分布式锁的问题。</p>
</li>
<li>
<p>设置过期标志更新缓存。给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存，实现伪代码如下所示：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public Object queryProduct() &#123;</span><br><span class="line">    int cacheTime = 30;</span><br><span class="line">    String cacheKey = &quot;product&quot;;</span><br><span class="line">    // 缓存标记</span><br><span class="line">    String signKey = cacheKey + &quot;_sign&quot;;</span><br><span class="line"></span><br><span class="line">    String signValue = getFromRedis(signKey);</span><br><span class="line">    String cacheValue = getFromRedis(cacheKey);</span><br><span class="line">    if (signValue != null) &#123;</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        putToRedis(signKey, &quot;1&quot;, cacheTime);</span><br><span class="line">        threadPool.submit(() -&gt; &#123;</span><br><span class="line">            cacheValue = getFromDB();</span><br><span class="line">            putToRedis(cacheKey, cacheValue, cacheTime * 2);</span><br><span class="line">        &#125;);</span><br><span class="line">        return cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>缓存标记记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。<br>
缓存数据的过期时间比缓存标记的时间延长 1 倍，例如：标记缓存时间 30 分钟，数据缓存 60 分钟，这样，当缓存标记 key 过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。</p>
</li>
<li>
<p>给缓存的失效时间，加上一个随机值，避免集体失效。</p>
</li>
<li>
<p>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。然后细分以下几个小点：</p>
<ol>
<li>从缓存 A 读数据库，有则直接返回</li>
<li>A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程。</li>
<li>更新线程同时更新缓存 A 和缓存 B。</li>
</ol>
</li>
</ol>
<h3 id="缓存预热"><a class="header-anchor" href="#缓存预热">¶</a>缓存预热</h3>
<p>缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统，避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户可以直接查询事先被预热的缓存数据。常见的缓存预热方案包括：</p>
<ol>
<li>直接写个缓存刷新页面，上线时手工操作下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存。</li>
</ol>
<h3 id="缓存和数据库双写一致性问题"><a class="header-anchor" href="#缓存和数据库双写一致性问题">¶</a>缓存和数据库双写一致性问题</h3>
<p>一致性问题是分布式常见问题，讨论比较多的是最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。<br>
在回答这个问题前，必须先强调一个前提，就是<strong>如果对数据有强一致性要求，不能放缓存</strong>。我们所做的一切，只能保证最终一致性，从根本上来说，只是降低不一致发生的概率，无法完全避免，因此，我们说有强一致性要求的数据，不能放缓存。</p>
<ul>
<li>首先，采取正确更新策略，先更新数据库，再删缓存。</li>
<li>其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用<strong>消息队列</strong>。</li>
</ul>
<p>具体的设计方案和优缺点可以参考：<a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener">【原创】分布式之数据库和缓存双写一致性方案解析</a></p>
<p>下面是对所有策略的分析：</p>
<h4 id="先失效缓存-后更新数据库数据"><a class="header-anchor" href="#先失效缓存-后更新数据库数据">¶</a>先失效缓存 -&gt; 后更新数据库数据</h4>
<ol>
<li>缺点<br>
如果缓存失效失败,根据策略可能会影响后续的正常的数据更新操作<br>
直接失效缓存会增加后续的一次缓存查询的 Miss</li>
<li>优点<br>
避免数据库更新成功,缓存失效失败,导致缓存中是旧数据</li>
<li>场景<br>
对缓存准确率要求比较高的业务</li>
<li>异常情况<br>
线程 A 需要更新数据库数据，失效缓存；<br>
线程 B 发现缓存没有命中，查询数据库中取出旧的值；<br>
线程 A 更新数据库数据，提交事务，线程 A 将数据放入缓存。</li>
</ol>
<h4 id="延时双删"><a class="header-anchor" href="#延时双删">¶</a>延时双删</h4>
<p>在《先失效缓存 -&gt; 后更新数据库数据》这种方案的基础上，增加了一个延时过期的步骤。<br>
即：过期Redis -&gt; 更新数据库 -&gt; 延迟一会再过期一次Redis<br>
这样就可以缓解上边提到的脏读问题了。<br>
但是缺点是过期两次，会占用更多的数据库资源。</p>
<h4 id="先更新数据库数据-后失效缓存"><a class="header-anchor" href="#先更新数据库数据-后失效缓存">¶</a>先更新数据库数据 -&gt; 后失效缓存</h4>
<ol>
<li>缺点<br>
如果数据更新成功,但是缓存失效失败,缓存中存放的是旧数据<br>
直接失效缓存会增加一次缓存查询的 Miss</li>
<li>优点<br>
更新数据不会强依赖缓存,就算失效缓存失败,也不会影响数据库的更新</li>
<li>场景<br>
对缓存和数据库的一致性要求不是很高的场景</li>
<li>异常情况<br>
在更新数据库数据和失效缓存之前的所有查询,查询到的都是旧数据</li>
</ol>
<h4 id="更新数据库数据-更新缓存"><a class="header-anchor" href="#更新数据库数据-更新缓存">¶</a>更新数据库数据 -&gt; 更新缓存</h4>
<ol>
<li>优点<br>
避免了一次额外的缓存查询 Miss<br>
实时性比较高</li>
<li>缺点<br>
数据库更新成功，但是更新缓存失败，缓存中存储的是旧数据<br>
选择同步还是异步来更新缓存呢？如果是同步更新，更新磁盘成功了，但是更新缓存失败了，你是不是要反复重试来保证更新成功？如果多次重试都失败，那这次更新是算成功还是失败呢？如果是异步更新缓存，怎么保证更新的时序？<br>
比如，我先把一个文件中的某个数据设置成 0，然后又设为 1，这个时候文件中的数据肯定是 1，但是缓存中的数据可不一定就是 1 了。因为把缓存中的数据更新为 0，和更新为 1 是两个并发的异步操作，不一定谁会先执行。<br>
这些问题都会导致缓存的数据和磁盘中的数据不一致，而且，在下次更新这条数据之前，这个不一致的问题它是一直存在的。当然，这些问题也不是不能解决的，比如，你可以使用分布式事务来解决，只是付出的性能、实现复杂度等代价比较大。</li>
<li>场景<br>
缓存粒度比较小,缓存的数据不需要经过计算(更新商品数据,但是缓存还需要用户数据)</li>
<li>异常情况<br>
A 线程查询缓存发现缓存中没有数据,查询数据库；<br>
B 线程更新数据库并且更新了缓存；<br>
A 再把查询的数据放入缓存,缓存中将会是旧数据</li>
</ol>
<h4 id="更新缓存-更新数据库数据"><a class="header-anchor" href="#更新缓存-更新数据库数据">¶</a>更新缓存 -&gt; 更新数据库数据</h4>
<ol>
<li>优点<br>
避免了一次额外的缓存查询 Miss</li>
<li>缺点<br>
缓存更新成功,但是数据库更新失败,导致缓存数据是旧数据;<br>
并且更新缓存失败,根据策略可能导致更新数据库失败。</li>
<li>场景<br>
缓存粒度比较小,缓存的数据不需要经过计算(更新商品数据,但是缓存还需要用户数据)</li>
<li>异常情况<br>
在更新缓存成功和更新数据库数据之前拿到的缓存是和数据库不一致的(不过这种情况造成的负面影响很小)</li>
</ol>
<h4 id="更新数据库数据-定时同步到缓存"><a class="header-anchor" href="#更新数据库数据-定时同步到缓存">¶</a>更新数据库数据 -&gt; 定时同步到缓存</h4>
<ol>
<li>优点<br>
实现简单、鲁棒性高<br>
就算某次同步过程中发生了错误，等到下一个同步周期也会自动把数据纠正过来。</li>
<li>缺点<br>
缓存更新不实时。<br>
如果缓存的数据太大，更新速度慢到无法接受，可以选择增量更新，每次只更新从上次缓存同步至今这段时间内变化的数据，代价是实现起来会稍微有些复杂。</li>
</ol>
<h4 id="缓存更新总结"><a class="header-anchor" href="#缓存更新总结">¶</a>缓存更新总结</h4>
<ul>
<li>如果对一致性要求没有那么高，一般是先更新数据库然后删除缓存。</li>
<li>如果对一致性要求比较高，那么在缓存删除失败后，需要把删除事件放到队列里消费。</li>
<li>如果对一致性要求更高点，那么需要将更新数据库、更新缓存、查询缓存的操作放到一个队列里消费</li>
</ul>
<h3 id="如何解决-redis-的并发竞争-key-问题"><a class="header-anchor" href="#如何解决-redis-的并发竞争-key-问题">¶</a>如何解决 redis 的并发竞争 key 问题</h3>
<p>这个问题大致就是，同时有多个子系统去 set 一个 key。这个时候要注意什么呢？大家思考过么。百度上的答案基本都是推荐用 redis 事务机制，但这里<strong>不推荐使用 redis 的事务机制</strong>。因为我们的生产环境，基本都是 redis 集群环境，做了数据分片操作，你一个事务中有涉及到多个 key 操作的时候，这多个 key 不一定都存储在同一个 redis-server 上。因此，<strong>Redis 的事务机制，十分鸡肋</strong>。</p>
<ol>
<li>如果对这个 key 操作，<strong>不要求顺序</strong><br>
这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</li>
<li>如果对这个 key 操作，<strong>要求顺序</strong><br>
假设有一个 key1,系统 A 需要将 key1 设置为 valueA,系统 B 需要将 key1 设置为 valueB,系统 C 需要将 key1 设置为 valueC.<br>
期望按照 key1 的 value 值按照 valueA–&gt;valueB–&gt;valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下<br>
系统 A key 1 {valueA 3:00}<br>
系统 B key 1 {valueB 3:05}<br>
系统 C key 1 {valueC 3:10}<br>
那么，假设这会系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了。以此类推。<br>
其他方法，比如利用队列，将 set 方法变成串行访问也可以。</li>
</ol>
<h3 id="缓存降级"><a class="header-anchor" href="#缓存降级">¶</a>缓存降级</h3>
<p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。<br>
降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。<br>
在进行降级之前要对系统进行梳理，看看哪些服务是必须誓死保护的、哪些是可降级的。比如可以参考日志级别设置预案：</p>
<ol>
<li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li>
<li>警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降级或人工降级，并发送告警；</li>
<li>错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li>
<li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li>
</ol>
<h3 id="缓存污染"><a class="header-anchor" href="#缓存污染">¶</a>缓存污染</h3>
<p>什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。</p>
<p>我们来看一下各种过期策略是否能解决缓存污染问题：</p>
<ul>
<li>allkeys-random：对所有key进行随机的淘汰，因为不确定之后同一个key是否还会被访问到，所以这个策略会导致缓存缺失问题。</li>
<li>volatile-random：和allkeys-random类似。</li>
<li>volatile-ttl：针对的是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉，这种策略并不能直接反映数据被再次访问的情况，也有导致缓存缺失的问题。<br>
一般业务会根据数据生效时间范围来决定数据的过期时间，因此过期时间短的很有可能就是用一下就不用的数据，所以这种情况下volatile-ttl是可以缓解缓存污染问题的。</li>
<li>lru<br>
把使用最少的淘汰掉。<br>
但是使用LRU策略在处理扫描式单次查询操作时，无法解决缓存污染，因为这些key被扫描过一次后最近访问时间都是一样的。因为存在这种问题，因此Redis4.0增加了LRU淘汰策略。</li>
<li>lfu<br>
与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。<br>
LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/b4105807.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/b4105807.html" itemprop="url">《设计数据密集型应用》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-08T11:12:18+08:00">
                2020-11-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/读书/" itemprop="url" rel="index">
                    <span itemprop="name">读书</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>可靠、弹性、可维护的应用</h1>
<h1>数据模型和查询语言</h1>
<ul>
<li>应用数据<br>
定义业务对象的数据结构，比如商品、菜单、用户等</li>
<li>数据模型<br>
存储的数据模型，如何表达它们，比如JSON、XML、关系数据库表、图模型等。</li>
<li>数据组织<br>
如何用缓存、磁盘、网络表达这些数据，来应对上层的查询、搜索、写入等操作。</li>
<li>物理层<br>
决定计算机如何存储数据。</li>
</ul>
<h2 id="关系模型和文档模型"><a class="header-anchor" href="#关系模型和文档模型">¶</a>关系模型和文档模型</h2>
<h2 id="数据查询语言"><a class="header-anchor" href="#数据查询语言">¶</a>数据查询语言</h2>
<h1>存储和检索</h1>
<h2 id="数据库的数据结构"><a class="header-anchor" href="#数据库的数据结构">¶</a>数据库的数据结构</h2>
<h2 id="事务处理"><a class="header-anchor" href="#事务处理">¶</a>事务处理</h2>
<h1>编码和演变</h1>
<h2 id="数据格式"><a class="header-anchor" href="#数据格式">¶</a>数据格式</h2>
<h2 id="数据流"><a class="header-anchor" href="#数据流">¶</a>数据流</h2>
<h1>复制（Replication）</h1>
<p>复制数据的原因：</p>
<ul>
<li>放到离用户更近的地方，减少延迟；</li>
<li>即使系统的部分fail了，系统仍旧是可用的；</li>
<li>扩容系统提高吞吐量以应对查询。</li>
</ul>
<p>复制的三种算法：</p>
<ol>
<li>单主（single-leader）</li>
<li>多主（multi-leader）</li>
<li>无主（leaderless）</li>
</ol>
<h2 id="主从复制"><a class="header-anchor" href="#主从复制">¶</a>主从复制</h2>
<p>可以通过主从复制来保证数据被保存到了所有的副本上：</p>
<blockquote>
<p>leader和master、follower和slave这里是同义词</p>
</blockquote>
<ol>
<li>写请求均被发给leader；</li>
<li>follower拷贝leader的replication log并重演到本地。</li>
<li>读请求被发给leader或follower都可以。</li>
</ol>
<h3 id="同步-or-异步复制"><a class="header-anchor" href="#同步-or-异步复制">¶</a>同步 OR 异步复制</h3>
<p>同步复制的优点：</p>
<ol>
<li>能确保数整体性能据被拷贝到了follower；</li>
</ol>
<p>同步复制的缺点：</p>
<ol>
<li>leader被复制过程阻塞了，会影响性能；</li>
<li>如果复制失败——比如follower短暂的不可用，整个请求也会失败。</li>
</ol>
<p>异步复制的优点：</p>
<ol>
<li>不影响leader响应请求的性能；</li>
</ol>
<p>异步复制的缺点：</p>
<ol>
<li>如果数据还没被复制到任何follower的情况下leader挂掉了，且leader不可恢复（或者暂时不可恢复），则数据就3额丢失了；</li>
</ol>
<p>一般会采用权衡的方案，即半同步（semi-synchronous）的模式。</p>
<h3 id="复制的一般过程"><a class="header-anchor" href="#复制的一般过程">¶</a>复制的一般过程</h3>
<ol>
<li>follower从leader下载一个全新的快照；</li>
<li>follower从leader请求最新数据，也就是上面快照之后写入的新数据；</li>
</ol>
<h3 id="故障恢复-follower故障"><a class="header-anchor" href="#故障恢复-follower故障">¶</a>故障恢复 - Follower故障</h3>
<p>Follower故障了只需要重启后从Leader下载log然后加载即可。</p>
<h3 id="故障转移-failover-leader故障"><a class="header-anchor" href="#故障转移-failover-leader故障">¶</a>故障转移（Failover） - Leader故障</h3>
<ol>
<li>判断leader宕机<br>
一般是<strong>大部分</strong>副本均PING leader超时就认为leader宕机了。</li>
<li>选择新leader<br>
通过选举或一个controller node来选择下一个新leader。<br>
一般优先选择数据最新的副本。</li>
<li>更新配置以选择新leader<br>
客户端需要将请求发给新的leader<br>
旧leader重启后，需要成为新leader的follower，以免发生脑裂。</li>
</ol>
<h3 id="replication-log的实现"><a class="header-anchor" href="#replication-log的实现">¶</a>Replication Log的实现</h3>
<p>Replication Log的实现方式：</p>
<ul>
<li>基于语句的<br>
日志中记录的写入语句，比如SQL的INSERT、UPDATE、DELETE。<br>
缺点是：一些每次执行结果都会变的语句，在leader和follower上执行结果不一致，比如now()、rand()，最好在写入日志时进行替换；一些语句的执行是有顺序要求的，复制指令的过程中不能乱序；一些语句有副作用，可能会导致不同副本上执行结果不一样。</li>
<li>WAL（写前日志）<br>
如MySQL里的redolog和undolog。</li>
<li>逻辑日志<br>
如MySQL里的binlog</li>
</ul>
<h2 id="复制延迟-replication-lag"><a class="header-anchor" href="#复制延迟-replication-lag">¶</a>复制延迟（Replication Lag）</h2>
<p>数据被拷贝到从服务器期间，主从是不一致的，一般情况下这个间隔时间是很短的，但是如果网络出现了问题就有可能会变得比较严重了。<br>
TODO：我需要先研究下MySQL中是怎么处理这种延迟的。</p>
<h2 id="多主复制-multi-leader-replication"><a class="header-anchor" href="#多主复制-multi-leader-replication">¶</a>多主复制（Multi-Leader Replication）</h2>
<h2 id="无主复制-leaderless-replication"><a class="header-anchor" href="#无主复制-leaderless-replication">¶</a>无主复制（Leaderless Replication）</h2>
<h1>分区</h1>
<h2 id="分区和复制"><a class="header-anchor" href="#分区和复制">¶</a>分区和复制</h2>
<p>数据只存在于一个分区，而一个分区可以有多个复制，因此分区和复制是一对多的关系。</p>
<h2 id="kv数据库的分区"><a class="header-anchor" href="#kv数据库的分区">¶</a>KV数据库的分区</h2>
<p>倾斜（<strong>skew</strong>）指一些分区存储的数据比其他的多，或接受更多的查询请求。倾斜会导致大部分请求被打到了少数节点上，产生<strong>热点问题</strong>。</p>
<ul>
<li>解决热点问题的一种最简单的方式是<strong>随机分配数据</strong><br>
但是这种方式的问题是不知道数据被分配到了哪个节点上，所以可能需要遍历所有节点才能获取到数据。</li>
<li>根据范围分区<br>
根据范围边界我们可以快速得知一个key存在于哪个分区，如果已知分区和节点的映射关系，我们就可以直接将key定位到一个节点上。<br>
优点除了找得快外，每个分区里的key也可以是有序的，这样顺序查找会快一些。<br>
缺点是可能出现热点数据，比如按创建时间分区的话，最近产生的数据就会被扎堆访问。所以分区的key需要谨慎选择。<br>
例子：Bigtable</li>
<li>根据key的hash值进行分区<br>
这种方式的好处是key在分区间能分布得比较均匀（和hash函数有关）。<br>
缺点是范围查询非常不便。<br>
Cassandra和MongoDB采用MD5作为hash函数；<br>
Redis（Cluster）采用CRC16。</li>
</ul>
<p>即使用hash的方式来分区，极端情况下仍有可能发生热点问题，比如大部分请求集中于少数的key上。<br>
为了解决这种倾斜问题，应用可以通过设计数据分布方案来分散数据，比如给key加上一些随机数来帮助key分散得更均匀。</p>
<h2 id="二级索引-关系数据库-文档数据库-的分区"><a class="header-anchor" href="#二级索引-关系数据库-文档数据库-的分区">¶</a>二级索引（关系数据库、文档数据库）的分区</h2>
<ul>
<li>根据文档分片<br>
最常用的文档数据库比如Elasticsearch，如果将MySQL的每一行看作一个文档，二级索引实际上就是为文档建立索引。<br>
二级索引服务于单个数据库实例（一个分片），因此又被称为<strong>本地索引</strong>，如果要查询数据库的多个分片，就需要从每个分片对应的二级索引上查询一次。<br>
ShardingJDBC的分库分表方案就是采用这种每个库都建一个索引的方式。<br>
MongoDB、Elasticsearch等均是采用的这种方案。</li>
<li>根据Term（词）分片<br>
Term可以看作文档中的一个字段，根据Term索引即将一个范围内的Term索引到同一分片内，不考虑对应文档实际所处的分片，这种索引方式被称为<strong>全局索引（global term-partitioned）</strong>。<br>
比如文档有一个颜色字段，我们可以将颜色首字母a-r的索引到第一个分片，s-z的索引到第二个分片，查询时如果判断要查询的颜色是红色（red）则可以直接定位到第一个分片上去查到所有的Term，然后再取到所有的文档。<br>
好处是我们不需要遍历每个分片上的每个索引了。<br>
缺点是写操作变得非常复杂，因为一次写入会影响多个分片，而且还需要分布式事务来保证这个过程的原子性。<br>
这种方案比较少见，已知的有Riak、Oracle data warehouse。</li>
</ul>
<h2 id="分片再平衡-扩容"><a class="header-anchor" href="#分片再平衡-扩容">¶</a>分片再平衡（扩容）</h2>
<p>Rebalancing：在集群中将一个节点的负载转移到另一个节点的过程称为Rebalancing。</p>
<ul>
<li>hash mod N<br>
N变大的情况下将原来对其他节点的请求打到新节点上。<br>
但是只要N变大原来key的定位就会发生变化，会发生很多不必要的Rebalancing，一个key第一次可能会被定位到节点0，第二次扩容可能会被定位到节点1，等等。</li>
<li>固定数量的分片<br>
类似于Redis的做法，分片数量固定，且大于节点数，分片被平均分配到节点上，扩容也是针对分片进行的。</li>
<li>动态分片</li>
</ul>
<h1>事务</h1>
<h1>分布式系统的挑战</h1>
<h1>一致性和共识</h1>
<h1>批处理</h1>
<h1>流处理</h1>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/52fcb70f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/52fcb70f.html" itemprop="url">Lab_2_Raft</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-04T19:26:49+08:00">
                2020-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/6-824/" itemprop="url" rel="index">
                    <span itemprop="name">6.824</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  15 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>前置知识</h1>
<h2 id="gfs"><a class="header-anchor" href="#gfs">¶</a>GFS</h2>
<h2 id="fault-tolerant-virtual-machines-容错虚拟机"><a class="header-anchor" href="#fault-tolerant-virtual-machines-容错虚拟机">¶</a>Fault-Tolerant Virtual Machines（容错虚拟机）</h2>
<h2 id="raft"><a class="header-anchor" href="#raft">¶</a>Raft</h2>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/ea705bce.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/ea705bce.html" itemprop="url">Apollo 原理总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-20T18:14:10+08:00">
                2020-10-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Apollo/" itemprop="url" rel="index">
                    <span itemprop="name">Apollo</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>概念</h1>
<ul>
<li>App: App信息</li>
<li>AppNamespace: App下Namespace的元信息</li>
<li>Cluster: 集群信息</li>
<li>Namespace: 集群下的namespace</li>
<li>Item: Namespace的配置，每个Item是一个key, value组合</li>
<li>Release: Namespace发布的配置，每个发布包含发布时该Namespace的所有配置</li>
<li>Commit: Namespace下的配置更改记录</li>
<li>Audit: 审计信息，记录用户在何时使用何种方式操作了哪个实体。</li>
</ul>
<h1>Apollo架构</h1>
<p><img src="http://47.88.24.11/imgs/Apollo/Apollo%E6%9E%B6%E6%9E%84.png" alt="Apollo架构——图片来自Apollo-github"></p>
<ul>
<li>Apollo Client：为应用提供配置查询功能；</li>
<li>Apollo Config Service：提供配置的读取、推送等功能，服务对象是 Apollo Client；</li>
<li>Apollo Portal：Apollo管理界面，为开发者提供配置修改功能；</li>
<li>Apollo Admin Service：提供配置修改、发布等功能，服务对象是Apollo Portal。</li>
</ul>
<h1>服务发现和负载均衡</h1>
<p>在Apollo中，Config Service和Admin Service都是<strong>多实例</strong>、<strong>无状态</strong>部署的，需要将自己注册到<strong>Eureka</strong>。<br>
Eureka负责服务发现，在Eureka之上Apollo又架了一层<strong>Meta Server</strong>用于封装Eureka的服务发现接口：</p>
<ul>
<li>Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做<strong>load balance</strong>、<strong>错误重试</strong>；</li>
<li>Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做<strong>load balance</strong>、<strong>错误重试</strong>。</li>
</ul>
<p>为什么Apollo使用Eureka而不是别的服务发现组件，比如ZooKeeper？</p>
<ol>
<li>提供了完整的服务注册和发现实现，用起来省心；</li>
<li>项目基础是SpringCloud，已经有应用Eureka的基础；</li>
</ol>
<p>Meta Server部署在哪里？<br>
Meta Server只是一个逻辑角色，在部署时和Config Service是在一个JVM进程中的，所以IP、端口和Config Service一致</p>
<h1>服务端实现原理</h1>
<p>服务端的主要任务是维护配置信息，以及将配置信息推送到客户端。</p>
<h2 id="服务端推送大体流程"><a class="header-anchor" href="#服务端推送大体流程">¶</a>服务端推送大体流程</h2>
<ol>
<li>用户在Portal操作配置发布</li>
<li>Portal调用Admin Service的接口操作发布</li>
<li>Admin Service发布配置后，发送<strong>ReleaseMessage</strong>给各个Config Service</li>
<li>Config Service收到ReleaseMessage后，<strong>通知对应的客户端</strong></li>
</ol>
<h2 id="发送releasemessage给config-service的过程"><a class="header-anchor" href="#发送releasemessage给config-service的过程">¶</a>发送ReleaseMessage给Config Service的过程</h2>
<p><img src="http://47.88.24.11/imgs/Apollo/Apollo%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E7%9A%84%E5%8F%91%E5%B8%83.png" alt="Apollo配置信息的发布——图片来自Apollo-github"><br>
用户操作配置发布后，Admin Service会往<strong>ReleaseMessage</strong>表插入一条消息记录，然后Config Service<strong>定时轮询</strong>这张表来消费消息。<br>
ApolloPortol会调Admin服务发出<strong>消息</strong>，这时，Admin Service作为<strong>Producer</strong>发出消息，各个ConfigService作为<strong>Consumer</strong>消费消息，为了减少对外部的依赖，Apollo发送消息的功能是<strong>通过数据库自己实现的一个简单的消息队列</strong>。</p>
<ol>
<li>Admin操作Release：<code>com.ctrip.framework.apollo.portal.controller.ReleaseController#createRelease</code><br>
在Admin Service的后台操作界面上可以看到Release操作入口。</li>
<li>Admin向ReleaseMessage表插入一条消息记录：<code>com.ctrip.framework.apollo.adminservice.controller.ReleaseController#publish</code><br>
该消息的内容就是配置发布的AppId+Cluster+Namespace。<br>
注意在“发消息”前，先把发布信息存到了Release表中。</li>
<li>定时扫描消息，<br>
扫描消息：<code>com.ctrip.framework.apollo.biz.message.ReleaseMessageScanner</code><br>
定时任务逻辑：批量处理，每次扫描500条，每条消息分别触发所有消息监听器（ReleaseMessageListener）。<br>
定时任务线程池配置：每100毫秒执行一次，core线程数只有1，但是总线程数为Integer.MAX_INT。</li>
<li>Config Service通知客户端<br>
代码入口：<code>NotificationControllerV2#handleMessage</code><br>
注意NotificationControllerV2这个Controller本身也是个消息监听器。<br>
Config Service会从消息中获取配置发布的AppId+Cluster+Namespace，然后通知客户端（通知客户端的过程见下面）。</li>
</ol>
<h2 id="config-service通知客户端的过程"><a class="header-anchor" href="#config-service通知客户端的过程">¶</a>Config Service通知客户端的过程</h2>
<ol>
<li>客户端发起一个HTTP请求到Config Service<br>
入口：/notifications/v2，对应NotificationControllerV2（注意和上面的消息监听器是同一个类）。</li>
<li>Config Service将请求挂起<br>
通过Spring 的 DeferredResult将请求挂起，默认等待60秒。<br>
如果在等待期间有该客户端关注的配置（Namespace）发布，则NotificationControllerV2会调用DeferredResult#setResult传入变化的Namespace信息，同时该请求也会立刻返回。<br>
反之，如果60秒内都没有该客户端关注的配置发布，则返回HTTP状态码304给客户端。</li>
<li>客户端请求最新的Namespace配置<br>
如果Config Service返回了配置信息、客户端获取到变化的Namespace信息后，客户端就会立即请求Config Service获取该Namespace的最新配置。</li>
</ol>
<h1>客户端实现原理</h1>
<p>客户端主要任务是从Config Service获取配置信息（Push和Pull都有），并在本地维护一个配置文件缓存。<br>
<img src="http://47.88.24.11/imgs/Apollo/Apollo%E9%85%8D%E7%BD%AE%E5%9C%A8%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%BB%B4%E6%8A%A4.png" alt="Apollo配置在客户端的维护——图片来自Apollo-github"></p>
<h2 id="客户端long-polling"><a class="header-anchor" href="#客户端long-polling">¶</a>客户端long-polling</h2>
<p>客户端会和服务端维持一个长连接，以及时接收到配置的变更信息。<br>
入口：<code>com.ctrip.framework.apollo.internals.RemoteConfigLongPollService#startLongPolling</code><br>
客户端长轮询的是Config Service的配置变更通知接口。当有新通知时就会触发RemoteConfigRepository，立即轮询Config Service的配置读取<code>/configs/{appId}/{clusterName}/{namespace:.+}</code>接口。</p>
<h2 id="客户端定时pull"><a class="header-anchor" href="#客户端定时pull">¶</a>客户端定时Pull</h2>
<p>客户端定时从Config Service拉取应用的配置信息，使用的接口和上面的long-polling一样：<code>/configs/{appId}/{clusterName}/{namespace:.+}</code>。<br>
入口：<code>RemoteConfigRepository#scheduleLongPollingRefresh</code><br>
这是一个fallback机制，主要目的是防止推送机制失效导致配置不更新。<br>
客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified。<br>
定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。</p>
<h2 id="客户端本地对配置的维护"><a class="header-anchor" href="#客户端本地对配置的维护">¶</a>客户端本地对配置的维护</h2>
<ol>
<li>客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中</li>
<li>客户端会把从服务端获取到的配置在本地文件系统缓存一份<br>
在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置</li>
<li>应用程序可以从Apollo客户端获取最新的配置、订阅配置更新通知</li>
</ol>
<h1>参考</h1>
<ol>
<li><a href="https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97" target="_blank" rel="noopener">Java客户端使用指南</a></li>
<li><a href="https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E8%AE%BE%E8%AE%A1#31-%E5%92%8Cspring%E9%9B%86%E6%88%90%E7%9A%84%E5%8E%9F%E7%90%86" target="_blank" rel="noopener">Apollo配置中心设计</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">133</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">64</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  














  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
