<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="ElasticSearch,">










<meta name="description" content="这篇文档总结ES中的基础数据结构，并介绍如何操作它们，最后介绍ES是如何存储这些文档的。">
<meta name="keywords" content="ElasticSearch">
<meta property="og:type" content="article">
<meta property="og:title" content="ES索引和文档存储">
<meta property="og:url" content="https://tallate.github.io/e0007243.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:description" content="这篇文档总结ES中的基础数据结构，并介绍如何操作它们，最后介绍ES是如何存储这些文档的。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E4%B8%80%E4%B8%AALucene%E7%B4%A2%E5%BC%95%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4%E7%82%B9%E5%92%8C%E4%B8%89%E4%B8%AA%E6%AE%B5.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%96%B0%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E7%BC%93%E5%AD%98.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E7%BC%93%E5%86%B2%E5%8C%BA%E8%A2%AB%E5%86%99%E5%85%A5%E6%AE%B5%E4%BD%86%E6%9C%AA%E5%AE%8C%E6%88%90%E6%8F%90%E4%BA%A4.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%8F%90%E4%BA%A4%E5%90%8E%E7%94%9F%E6%88%90%E6%96%B0%E6%AE%B5%E4%B8%94%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%96%B0%E7%9A%84%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%E5%B9%B6%E4%B8%94%E8%A2%AB%E8%BF%BD%E5%8A%A0%E5%88%B0%E4%BA%86%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/Refresh%E5%AE%8C%E6%88%90%E5%90%8E%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%BD%86%E6%98%AF%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E4%BC%9A.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E6%96%AD%E7%A7%AF%E7%B4%AF%E6%96%87%E6%A1%A3.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/Flush%E4%B9%8B%E5%90%8E%E6%AE%B5%E8%A2%AB%E5%85%A8%E9%87%8F%E6%8F%90%E4%BA%A4%E5%B9%B6%E4%B8%94%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E8%A2%AB%E6%B8%85%E7%A9%BA.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E4%B8%A4%E4%B8%AA%E6%8F%90%E4%BA%A4%E4%BA%86%E7%9A%84%E6%AE%B5%E5%92%8C%E4%B8%80%E4%B8%AA%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%90%88%E5%B9%B6%E5%88%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E7%9A%84%E6%AE%B5.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%90%88%E5%B9%B6%E7%BB%93%E6%9D%9F%E5%90%8E%E8%80%81%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%88%A0%E9%99%A4.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%96%B0%E5%A2%9E%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%A0%E9%99%A4.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%8F%96%E5%9B%9E%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%B1%80%E9%83%A8%E6%9B%B4%E6%96%B0.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%89%B9%E9%87%8F%E8%AF%BB.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%89%B9%E9%87%8F%E6%94%B9.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E9%97%AE%E9%A2%98.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/%E5%A4%9A%E8%8A%82%E7%82%B9%E5%A4%9A%E5%88%86%E7%89%87%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/ES%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://tallate.top/imgs/ES/ES%E7%9A%84GET%E6%B5%81%E7%A8%8B.png">
<meta property="og:updated_time" content="2021-05-24T17:03:27.647Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ES索引和文档存储">
<meta name="twitter:description" content="这篇文档总结ES中的基础数据结构，并介绍如何操作它们，最后介绍ES是如何存储这些文档的。">
<meta name="twitter:image" content="https://tallate.top/imgs/ES/%E4%B8%80%E4%B8%AALucene%E7%B4%A2%E5%BC%95%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4%E7%82%B9%E5%92%8C%E4%B8%89%E4%B8%AA%E6%AE%B5.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tallate.github.io/e0007243.html">







  <title>ES索引和文档存储 | Tallate</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tallate</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不乱于心，不困于情，不畏将来，不念过往</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>

      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e0007243.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tallate">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">ES索引和文档存储</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-21T09:03:54+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/ElasticSearch/" itemprop="url" rel="index">
                    <span itemprop="name">ElasticSearch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  18k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  71 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这篇文档总结ES中的基础数据结构，并介绍如何操作它们，最后介绍ES是如何存储这些文档的。</p>
<a id="more"></a>
<h1>ES存储的基础概念 - 索引、映射和文档</h1>
<p>几个概念的映射关系：<br>
Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns<br>
Elasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields</p>
<blockquote>
<p>将 Type 类比为 Table 并不恰当，因为 ES 中一个索引下的多个类型共用相同的空间。</p>
</blockquote>
<h2 id="文档"><a class="header-anchor" href="#文档">¶</a>文档</h2>
<ul>
<li>ES是面向文档的，文档是所有可搜索数据的最小单位。</li>
<li>文档会被序列化成JSON格式，保存在ES中；<br>
JSON对象由字段组成，每个字段都有对应的字段类型。</li>
<li>每个文档都有一个Unique ID。<br>
这个Unique ID可以自己指定或由ES自动生成。</li>
</ul>
<h3 id="文档和字段-document-field"><a class="header-anchor" href="#文档和字段-document-field">¶</a>文档和字段 - Document、Field</h3>
<p>一个文档是一个可被索引的基础信息单元，文档以 JSON 格式来表示。<br>
在一个 index/type 里面，可以存储任意多的文档，每个文档都有唯一 id。<br>
每个文档包含多个字段(fields)，即 json 数据里的字段。</p>
<h3 id="文档元数据"><a class="header-anchor" href="#文档元数据">¶</a>文档元数据</h3>
<p>一个文档不仅仅包含它的数据，也包含 元数据 —— 有关 文档的信息。 三个必须的元数据元素如下：</p>
<ul>
<li>_index<br>
一个 索引 应该是因共同的特性被分组到一起的文档集合。<br>
索引名字必须小写，不能以下划线开头，不能包含逗号。</li>
<li>_type<br>
Lucene 没有文档类型的概念，而是使用一个元数据字段_type 文档表示的对象类别，数据可能在索引中只是松散的组合在一起，但是通常明确定义一些数据中的子分区是很有用的，不同 types 的文档可能有不同的字段，但最好能够非常相似。<br>
一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号， 并且长度限制为 256 个字符。<br>
当我们要检索某个类型的文档时, Elasticsearch 通过在 _type 字段上使用过滤器限制只返回这个类型的文档。</li>
<li>_id<br>
文档唯一标识，和 _index 以及 _type 组合就可以唯一确定 Elasticsearch 中的一个文档。<br>
id 也可以由 Elasticsearch 自动生成。</li>
<li>_version<br>
在 Elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时（包括删除）， _version 的值会递增。这个字段用来确保这些改变在跨多节点时以正确的顺序执行。<br>
版本号——不管是内部的还是引用外部的——都必须是在(0, 9.2E+18)范围内的一个 long 类型的正数。</li>
<li>_source<br>
即索引数据时发送给 Elasticsearch 的原始 JSON 文档。</li>
<li>_score<br>
相关性打分</li>
<li><s>_all</s><br>
整合所有字段内容到该字段，已被废除。</li>
</ul>
<h3 id="文档属性"><a class="header-anchor" href="#文档属性">¶</a>文档属性</h3>
<p>文档里有几个最重要的设置：</p>
<ul>
<li>
<p>type<br>
字段的数据类型，例如 string 或 date</p>
</li>
<li>
<p>index<br>
字段是否应当被当成全文来搜索（analyzed），或被当成一个准确的值（not_analyzed），还是完全不可被搜索（ no ）</p>
</li>
<li>
<p>analyzer<br>
确定在索引和搜索时全文字段使用的 analyzer</p>
</li>
<li>
<p>_source<br>
存储代表文档体的 JSON 字符串，和所有被存储的字段一样， _source 字段在被写入磁盘之前先会被压缩。这个字段有以下作用：</p>
<ol>
<li>搜索结果包括了整个可用的文档——不需要额外的从另一个的数据仓库来取文档。</li>
<li>如果没有 _source 字段，部分 update 请求不会生效。</li>
<li>当你的映射改变时，你需要重新索引你的数据，有了_source 字段你可以直接从 Elasticsearch 这样做，而不必从另一个（通常是速度更慢的）数据仓库取回你的所有文档。</li>
<li>当你不需要看到整个文档时，单个字段可以从 _source 字段提取和通过 get 或者 search 请求返回。</li>
</ol>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125;&#125;,</span><br><span class="line">    &quot;_source&quot;: [ &quot;title&quot;, &quot;created&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>调试查询语句更加简单，因为你可以直接看到每个文档包括什么，而不是从一列 id 猜测它们的内容。<br>
也可以调用下面的映射来禁用_source 字段：</li>
</ol>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;my_type&quot;: &#123;</span><br><span class="line">            &quot;_source&quot;: &#123;</span><br><span class="line">                &quot;enabled&quot;: false</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="对象和文档"><a class="header-anchor" href="#对象和文档">¶</a>对象和文档</h3>
<p>通常情况下，我们使用的术语 对象 和 文档 是可以互相替换的。不过，有一个区别：<br>
一个对象仅仅是类似于 hash 、 hashmap 、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。 对象可能包含了另外一些对象。<br>
文档指最顶层或者根对象，这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID 及一些必须的文档元数据。</p>
<h2 id="索引-index"><a class="header-anchor" href="#索引-index">¶</a>索引 - Index</h2>
<p>一个<strong>索引(index)<strong>就像是传统关系数据库中的数据库，它是相关文档存储的地方，实际上是组织数据的逻辑</strong>命名空间</strong>。<br>
在一个索引中，可以定义一种或多种<strong>类型</strong>。</p>
<ul>
<li>
<p>作为名词，一个 索引 类似于传统关系数据库中的一个 数据库，是一个存储关系型文档的地方；</p>
</li>
<li>
<p>作为动词，索引一个文档 就是存储一个文档到一个 索引 （名词）中以便它可以被检索和查询到，文档已存在时会被覆盖掉。</p>
</li>
<li>
<p>Index体现了<strong>逻辑空间</strong>的概念，每个索引都有自己的<strong>Mapping</strong>定义，用于定义包含的文档的字段名和字段类型；</p>
</li>
<li>
<p>Shard体现了<strong>物理空间</strong>的概念，索引中的数据分散在Shard上。</p>
</li>
</ul>
<h2 id="类型-type"><a class="header-anchor" href="#类型-type">¶</a>类型 - Type</h2>
<p>一个<strong>类型</strong>是索引的一个逻辑上的分类，代表一类相似的文档，类型由 <strong>名称</strong>（比如 user 或 blogpost）和 <strong>映射</strong> 组成。但是<strong>在 ES 6.0.0 以后，这个概念会被废弃</strong>。<br>
类型可以很好的抽象划分相似但不相同的数据，但由于 Lucene 的处理方式，类型的使用有些限制。Lucene 没有文档类型的概念，每个文档的类型名被存储在一个叫 _type 的元数据字段上。 当我们要检索某个类型的文档时, Elasticsearch 通过在 _type 字段上使用过滤器限制只返回这个类型的文档。<br>
每个 Lucene 索引中的所有字段都包含一个单一的、扁平的模式。一个特定字段可以映射成 string 类型也可以是 number 类型，但是不能两者兼具（比如两个类型都有一个 name 字段，但是他们映射到不同的数据类型）。</p>
<h2 id="映射-mapping"><a class="header-anchor" href="#映射-mapping">¶</a>映射 - Mapping</h2>
<p><strong>映射</strong>就像数据库中的 schema ，描述了数据在每个字段内如何存储，包括文档可能具有的字段或 属性 、 每个字段的数据类型—比如 string, integer 或 date —以及 Lucene 是如何索引和存储这些字段的。<br>
Lucene 也没有映射的概念，映射是 Elasticsearch 将复杂 JSON 文档 映射 成 Lucene 需要的扁平化数据的方式。</p>
<ul>
<li>比如下面的索引名叫 data，其中定义了 people 和 transactions 类型：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;data&quot;: &#123;</span><br><span class="line">      &quot;mappings&quot;: &#123;</span><br><span class="line">         &quot;people&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">               &quot;name&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">               &#125;,</span><br><span class="line">               &quot;address&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;transactions&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">               &quot;timestamp&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">                  &quot;format&quot;: &quot;strict_date_optional_time&quot;</span><br><span class="line">               &#125;,</span><br><span class="line">               &quot;message&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;: &quot;string&quot;</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会被转换为类似下面的映射保存：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;data&quot;: &#123;</span><br><span class="line">      &quot;mappings&quot;: &#123;</span><br><span class="line">        &quot;_type&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">          &quot;index&quot;: &quot;not_analyzed&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;address&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;timestamp&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &quot;message&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以<strong>虽然创建一个文档后其类型就确定了，但是实际上这个文档所占用的空间是该索引内所有字段的总和</strong>。<br>
所以有一条建议：一个索引中的类型应当都是相似的，他们有类似的字段，比如 man 和 woman 共享 name 属性；如果两个类型的字段集互不相同，创建一个 类型的文档后将浪费很多空间，而是应该将他们分到不同的索引中。</p>
<h2 id="动态映射机制"><a class="header-anchor" href="#动态映射机制">¶</a>动态映射机制</h2>
<p>在索引一个新的文档时，es 会自动为每个字段推断类型，这个过程称为<strong>动态映射</strong>。这意味着如果你通过引号( “123” )索引一个数字，它会被映射为 string 类型，而不是 long 。但是，如果这个域已经映射为 long ，那么 Elasticsearch 会尝试将这个字符串转化为 long ，如果无法转化，则抛出一个异常。</p>
<h2 id="分析和搜索-analysis-search"><a class="header-anchor" href="#分析和搜索-analysis-search">¶</a>分析和搜索 - Analysis、Search</h2>
<p>分析表示全文是如何处理使之可以被搜索的。<br>
Elasticsearch 除了支持在各种字段上的结构化查询，还支持排序、全文检索并分析相关性。</p>
<h2 id="query-dsl"><a class="header-anchor" href="#query-dsl">¶</a>Query DSL</h2>
<p>特定的查询语言，查询主要分为<strong>评分查询（query）<strong>和</strong>不评分查询（filter）</strong>，前者在查询完毕后还需要为文档进行评分，主要用于全文搜索，而后者只需要决定是否采用结果，所以速度会快一些。<br>
es 提供的查询 DSL 将语句分为<strong>叶子语句（如 match）<strong>和</strong>复合语句（如 bool）</strong>，通过组合可以表达复杂的语义。</p>
<h2 id="倒排索引"><a class="header-anchor" href="#倒排索引">¶</a>倒排索引</h2>
<p>关系型数据库通过增加一个 索引，比如一个 B 树（B-tree）索引 到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 <strong>倒排索引</strong> 的结构来达到相同的目的。</p>
<h2 id="根对象"><a class="header-anchor" href="#根对象">¶</a>根对象</h2>
<p>映射的最高一层被称为 根对象 ，它可能包含下面几项：</p>
<ul>
<li>一个 properties 节点，列出了文档中可能包含的每个字段的映射</li>
<li>各种元数据字段，它们都以一个下划线开头，例如 _type 、 _id 和 _source</li>
<li>设置项，控制如何动态处理新的字段，例如 analyzer 、 dynamic_date_formats 和 dynamic_templates</li>
<li>其他设置，可以同时应用在根对象和其他 object 类型的字段上，例如 enabled 、 dynamic 和 include_in_all</li>
</ul>
<h2 id="精确值和全文"><a class="header-anchor" href="#精确值和全文">¶</a>精确值和全文</h2>
<p><strong>精确值</strong>是结构化的，如日期或者用户 ID，字符串也可以表示精确值，例如用户名或邮箱地址，对于精确值来讲，Foo 和 foo 是不同的，2014 和 2014-09-15 也是不同的。<br>
查询精确值很容易，结果是二进制的：要么匹配查询，要么不匹配。<br>
<strong>全文</strong>是指文本数据（通常以人类容易识别的语言书写），例如一个推文的内容或一封邮件的内容。<br>
查询全文数据要微妙的多。我们问的不只是“这个文档匹配查询吗”，而是“该文档匹配查询的程度有多大？”换句话说，该文档与给定查询的相关性如何？es 解决这个需求的办法是为文档建立倒排索引。</p>
<h1>常用操作 - 索引（Index）</h1>
<h2 id="查询"><a class="header-anchor" href="#查询">¶</a>查询</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cat/indices</span><br></pre></td></tr></table></figure>
<h2 id="创建"><a class="header-anchor" href="#创建">¶</a>创建</h2>
<p>在 Elasticsearch 中，我们的数据是被存储和索引在 分片 中，而一个索引仅仅是逻辑上的命名空间， 这个命名空间由一个或者多个分片组合在一起。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT /megacorp/employee/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; : &quot;John&quot;,</span><br><span class="line">    &quot;last_name&quot; : &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot; : 25,</span><br><span class="line">    &quot;about&quot; : &quot;I love to go rock climbing&quot;,</span><br><span class="line">    &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一行指定了索引名/类型名/特定雇员id，其他所有的创建索引、指定每个属性的数据类型等工作都由后台默认设置完成。<br>
如果你想禁止自动创建索引，你 可以通过在 config/elasticsearch.yml 的每个节点下添加下面的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">action.auto_create_index: false</span><br></pre></td></tr></table></figure>
<h2 id="删除"><a class="header-anchor" href="#删除">¶</a>删除</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE /index_one,index_two</span><br><span class="line">DELETE /index_*</span><br></pre></td></tr></table></figure>
<p>删除所有索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_all</span><br><span class="line">DELETE /*</span><br></pre></td></tr></table></figure>
<p>如果想要避免意外删除所有数据带来的风险，可以在配置文件 elasticsearch.yml 中加入下面配置来禁止使用_all 和通配符删除索引：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">action.destructive_requires_name: true</span><br></pre></td></tr></table></figure>
<h1>常用操作 - 映射（Mapping）</h1>
<h2 id="一些默认的映射"><a class="header-anchor" href="#一些默认的映射">¶</a>一些默认的映射</h2>
<p>布尔型: true 或者 false | boolean<br>
整数: 123 | long<br>
浮点数: 123.45 | double<br>
字符串，有效日期: 2014-09-15 | date<br>
字符串: foo bar | string<br>
整数 : byte, short, integer<br>
浮点数: float</p>
<h2 id="自定义映射"><a class="header-anchor" href="#自定义映射">¶</a>自定义映射</h2>
<p>TODO<br>
全文字符串域和精确值字符串域的区别<br>
使用特定语言分析器<br>
优化域以适应部分匹配<br>
指定自定义数据格式</p>
<h2 id="查看映射"><a class="header-anchor" href="#查看映射">¶</a>查看映射</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /megacrp/_mapping</span><br><span class="line">GET /megacrp/employee/_mapping</span><br></pre></td></tr></table></figure>
<p>返回属性包括：</p>
<ul>
<li>index 属性控制怎样索引字符串
<ul>
<li>analyzed 分析字符串再索引（全文索引），字符串且只有字符串可以取这个属性</li>
<li>not_analyzed 不分析、直接索引精确值</li>
<li>no 不索引、不能被搜索到</li>
</ul>
</li>
<li>analyzer 对于 analyzed 字符串域，用 analyzer 属性指定在搜索和索引时使用的分析器，默认时 standard</li>
</ul>
<h2 id="更新映射"><a class="header-anchor" href="#更新映射">¶</a>更新映射</h2>
<ul>
<li>可以通过更新一个映射来添加一个新域，并为其设置映射（<a href="https://discuss.elastic.co/t/elasticsearch-5-not-analyzed/68411" target="_blank" rel="noopener">后来版本取消了 string 类型，改成了<strong>text</strong>，要注意</a>）</li>
<li>不能将一个存在的域从 analyzed 改为 not_analyzed。因为如果一个域的映射已经存在，那么该域的数据可能已经被索引。如果你意图修改这个域的映射，索引的数据可能会出错，不能被正常的搜索。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT /gb</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;testmapping&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;tweetgjghjggh&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;date&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;date&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;user_id&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;long&quot;</span><br><span class="line">        &#125;&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<h1>常用操作 - 对象（文档 Document）</h1>
<h2 id="更新-put"><a class="header-anchor" href="#更新-put">¶</a>更新 - PUT</h2>
<p>更新现有的对象需要自己指定对象的 id，如果不存在将自动创建一个，文档更新后_version 字段的值也会相应提高。在内部，Elasticsearch 已将旧文档标记为已删除，并增加一个全新的文档。 尽管你不能再对旧版本的文档进行访问，但它并不会立即消失。当继续索引更多的数据，Elasticsearch 会在后台清理这些已删除文档。<br>
检索 和 重建索引 步骤的间隔越小，变更冲突的机会越小。 但是它并不能完全消除冲突的可能性。 还是有可能在 update 设法重新索引之前，来自另一进程的请求修改了文档。为了避免数据丢失， update API 在 检索 步骤时检索得到文档当前的 _version 号，并传递版本号到 重建索引 步骤的 index 请求。 如果另一个进程修改了处于检索和重新索引步骤之间的文档，那么 _version 号将不匹配，更新请求将会失败。为了实现版本号控制只需要在请求参数中加入 version（如上所示）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Just trying this out...&quot;,</span><br><span class="line">  &quot;date&quot;: &quot;2014/01/01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果已经有自己的 _id 、而又想执行创建，那么我们必须告诉 Elasticsearch ，只有在相同的 _index 、 _type 和 _id 不存在时才接受我们的索引请求——而不是覆盖掉，有两种方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123?op_type=create</span><br><span class="line">&#123; ... &#125;</span><br><span class="line">PUT /website/blog/123/_create</span><br><span class="line">&#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p><strong>文档是不可变的</strong>：他们不能被修改，只能被替换。 update API 必须遵循同样的规则。 从外部来看，我们在一个文档的某个位置进行部分更新。然而在内部， update API 简单使用与之前描述相同的 <strong>检索-修改-重建索引</strong> 的处理过程。 区别在于这个过程发生在分片内部，这样就<strong>避免了多次请求的网络开销</strong>。通过减少检索和重建索引步骤之间的时间，我们也<strong>减少了其他进程的变更带来冲突的可能性</strong>。</p>
<h2 id="创建-post"><a class="header-anchor" href="#创建-post">¶</a>创建 - POST</h2>
<p>不需要指定对象 id，由 Elasticsearch 自动生成，自动生成的 ID 是 URL-safe、 基于 Base64 编码且长度为 20 个字符的 GUID 字符串。 这些 GUID 字符串由可修改的 <strong>FlakeID</strong> 模式生成，这种模式允许多个节点并行生成唯一 ID ，且互相之间的冲突概率几乎为零。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My second blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Still trying this out...&quot;,</span><br><span class="line">  &quot;date&quot;: &quot;2014/01/01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="部分更新-post"><a class="header-anchor" href="#部分更新-post">¶</a>部分更新 - POST</h2>
<p>update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数， 它只是与现有的文档进行合并。对象被合并到一起，覆盖现有的字段，增加新的字段。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/1/_update</span><br><span class="line">&#123;</span><br><span class="line">   &quot;doc&quot; : &#123;</span><br><span class="line">      &quot;tags&quot; : [ &quot;testing&quot; ],</span><br><span class="line">      &quot;views&quot;: 0</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>使用脚本部分更新文档</strong>：脚本可以在 update API 中用来改变 _source 的字段内容， 它在更新脚本中称为 ctx._source ，运行在一个沙盒内，默认使用 Painless 语言作为脚本语言。下面这个脚本在页面不存在时执行新增并初始化 views=1（第一次运行这个请求时， <strong>upsert</strong> 值作为新文档被索引，初始化 views 字段为 1 ；在后续的运行中，由于文档已经存在， script 更新操作将替代 upsert 进行应用，对 views 计数器进行累加）、页面被浏览 2 次后执行删除，其他情况浏览量+1 并添加一个新标签：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/zVmOW2EBsZ0GEqF92yf6/_update</span><br><span class="line">&#123;</span><br><span class="line">   &quot;script&quot; : &#123;</span><br><span class="line">      &quot;source&quot; : &quot;if(ctx._source.views == params.count) &#123; ctx.op = &apos;delete&apos;&#125; ctx._source.views+=1; ctx._source.tags.add(params.new_tag)&quot;,</span><br><span class="line">      &quot;params&quot; : &#123;</span><br><span class="line">        &quot;new_tag&quot; : &quot;search&quot;,</span><br><span class="line">        &quot;count&quot;: 2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;upsert&quot;: &#123;</span><br><span class="line">        &quot;views&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>重试</strong>：<br>
正如之前所说，update 操作是<strong>检索-修改-重新索引</strong>的过程， 检索 和 重建索引 步骤的间隔越小，变更冲突的机会越小。 但是它并不能完全消除冲突的可能性。 还是有可能在 update 设法重新索引之前，来自另一进程的请求修改了文档。为了避免数据丢失， update API 在 检索 步骤时检索得到文档当前的 _version 号，并传递版本号到 重建索引 步骤的 index 请求。 如果另一个进程修改了处于检索和重新索引步骤之间的文档，那么 _version 号将不匹配，更新请求将会失败。<br>
对于部分更新的很多使用场景，文档已经被改变也没有关系。 例如，如果两个进程都对页面访问量计数器进行递增操作，它们发生的先后顺序其实不太重要； 如果冲突发生了，我们唯一需要做的就是尝试再次更新。这可以通过 设置参数 retry_on_conflict 来自动完成， 这个参数规定了失败之前 update 应该重试的次数，它的默认值为 0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/zVmOW2EBsZ0GEqF92yf6/_update?retry_on_conflict=5 </span><br><span class="line">&#123;</span><br><span class="line">   &quot;script&quot; : &quot;ctx._source.views+=1&quot;,</span><br><span class="line">   &quot;upsert&quot;: &#123;</span><br><span class="line">       &quot;views&quot;: 0</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="get-搜索"><a class="header-anchor" href="#get-搜索">¶</a>GET（搜索）</h2>
<p>在请求的查询串参数中加上 pretty 参数，这将会调用 Elasticsearch 的 pretty-print 功能，该功能 使得 JSON 响应体更加可读，但其中的 _source 字段并不是被当成字符串打印出来，而是格式化成了 JSON 串：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET /website/blog/123?pretty</span><br><span class="line">GET /website/blog/123/_source</span><br><span class="line">GET /website/blog/123?_source=title,text</span><br></pre></td></tr></table></figure>
<p>将多个请求合并成一个，避免单独处理每个请求花费的网络延时和开销。 如果你需要从 Elasticsearch 检索很多文档，那么使用 multi-get 或者 mget API 来将这些检索请求放在一个请求中，将比逐个文档请求更快地检索到全部文档。<br>
mget API 要求有一个 docs 数组作为参数，每个 元素包含需要检索文档的元数据， 包括 _index 、 _type 和 _id 。如果你想检索一个或者多个特定的字段，那么你可以通过 _source 参数来指定这些字段的名字：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GET /_mget</span><br><span class="line">&#123;</span><br><span class="line">   &quot;docs&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;_index&quot; : &quot;website&quot;,</span><br><span class="line">         &quot;_type&quot; : &quot;blog&quot;,</span><br><span class="line">         &quot;_id&quot; : &quot;zVmOW2EBsZ0GEqF92yf6&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;_index&quot; : &quot;website&quot;,</span><br><span class="line">         &quot;_type&quot; : &quot;blog&quot;,</span><br><span class="line">         &quot;_id&quot; : 1,</span><br><span class="line">         &quot;_source&quot;: &quot;views&quot;</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br><span class="line">GET /website/blog/_mget</span><br><span class="line">&#123;</span><br><span class="line">   &quot;ids&quot; : [ &quot;2&quot;, &quot;1&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="head-ping"><a class="header-anchor" href="#head-ping">¶</a>HEAD（ping）</h2>
<p>如果只想检查一个文档是否存在——根本不想关心内容——那么用 HEAD 方法来代替 GET 方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD /website/blog/124</span><br></pre></td></tr></table></figure>
<h2 id="delete-删除"><a class="header-anchor" href="#delete-删除">¶</a>DELETE（删除）</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /website/blog/123</span><br></pre></td></tr></table></figure>
<h2 id="bulk-批量操作"><a class="header-anchor" href="#bulk-批量操作">¶</a>bulk（批量操作）</h2>
<p>每一行——包括最后一行——都必须以换行符结尾，格式如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123; action: &#123; metadata &#125;&#125;\n</span><br><span class="line">&#123; request body &#125;\n</span><br><span class="line">&#123; action: &#123; metadata &#125;&#125;\n</span><br><span class="line">&#123; request body &#125;\n</span><br></pre></td></tr></table></figure>
<p>action/metadata 行指定 哪一个文档 做 什么操作 。action 必须是以下选项之一:<br>
create：如果文档不存在，那么就创建它。类似<code>POST</code>或<code>PUT /_create</code>。<br>
index：创建一个新文档或者替换一个现有的文档。类似<code>POST</code>或<code>PUT</code>。<br>
update：部分更新一个文档。类似<code>POST /_update</code>。<br>
delete：删除一个文档。类似<code>DELETE</code>。<br>
metadata 应该 指定被索引、创建、更新或者删除的文档的 _index 、 _type 和 _id ，每个请求的 metadata 都会覆盖请求 URL 中带上的默认元数据。<br>
request body 行由文档的 _source 本身组成–文档包含的字段和值。它是 index、create、update 操作所必需的。<br>
为什么不直接用一个 JSON 数组来保存？主要是考虑效率问题，解析为数组需要有更多的 RAM 空间，且 JVM 要花时间进行 gc。而直接使用原始数据只需要多注意每条数据之间的间隔（换行符）。<br>
每个子请求都是<strong>独立执行</strong>，因此某个子请求的失败不会对其他子请求的成功与否造成影响。 如果其中任何子请求失败，最顶层的 error 标志被设置为 true ，并且在相应的请求报告出错误明细。这也意味着 <strong>bulk 请求不是原子的</strong>： 不能用它来实现事务控制。每个请求是单独处理的，因此一个请求的成功或失败不会影响其他的请求。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST /_bulk</span><br><span class="line">&#123; &quot;delete&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; &#125;&#125; </span><br><span class="line">&#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;My first blog post&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot; &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;My second blog post&quot; &#125;</span><br><span class="line">&#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;webiite&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125;</span><br><span class="line">&#123; &quot;doc&quot; : &#123;&quot;title&quot; : &quot;My updated blog post&quot;&#125; &#125;</span><br></pre></td></tr></table></figure>
<p>批量请求的大小有一个最佳值，大于这个值，性能将不再提升，甚至会下降。 但是<strong>最佳值不是一个固定的值，它完全取决于硬件、文档的大小和复杂度、索引和搜索的负载的整体情况</strong>。<br>
幸运的是，很容易找到这个 最佳点 ：通过批量索引典型文档，并不断增加批量大小进行尝试。 当性能开始下降，那么你的批量大小就太大了。一个好的办法是开始时将 1,000 到 5,000 个文档作为一个批次, 如果你的文档非常大，那么就减少批量的文档个数。并且请求的文档也最好不要太大，一个好的批量大小在开始处理后所占用的物理大小约为 5-15 MB。</p>
<h1>索引原理</h1>
<p>基于 Lucene，ES 实现了分布式的索引管理。</p>
<h2 id="索引策略"><a class="header-anchor" href="#索引策略">¶</a>索引策略</h2>
<p>在 Elasticsearch 中， <strong>每个字段的所有数据 都是 默认被索引的</strong> 。 即每个字段都有为了快速检索设置的专用<strong>倒排索引</strong>。<br>
倒排索引由一些词项组成，每个词项包含了它所有曾出现过的文档的列表。<br>
Term  | Doc 1 | Doc 2 | Doc 3 |</p>
<hr>
<p>brown |   X   |       |  X    | …<br>
fox   |   X   |   X   |  X    | …<br>
quick |   X   |   X   |       | …<br>
the   |   X   |       |  X    | …</p>
<p>另外，这个倒排索引相比特定词项出现过的文档列表，会包含更多其它信息。它会保存每一个词项出现过的文档总数， 在对应的文档中一个具体词项出现的总次数，词项在文档中的顺序，每个文档的长度，所有文档的平均长度，等等。这些统计信息允许 Elasticsearch 决定哪些词比其它词更重要，哪些文档比其它文档更重要，用于搜索时计算文档的相关性。</p>
<h2 id="不变性"><a class="header-anchor" href="#不变性">¶</a>不变性</h2>
<p>倒排索引被写入磁盘后是 不可改变 的:它永远不会修改。 不变性有重要的价值：</p>
<ul>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li>
<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
<li>其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
<li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。</li>
</ul>
<p>当然，一个不变的索引也有不好的地方：</p>
<ul>
<li>由于不变性，你不能修改它，如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这对一个索引能包含的数据量和被更新频率造成很大限制。</li>
</ul>
<h2 id="段和提交点"><a class="header-anchor" href="#段和提交点">¶</a>段和提交点</h2>
<p><img src="https://tallate.top/imgs/ES/%E4%B8%80%E4%B8%AALucene%E7%B4%A2%E5%BC%95%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4%E7%82%B9%E5%92%8C%E4%B8%89%E4%B8%AA%E6%AE%B5.png" alt="一个Lucene索引包含一个提交点和三个段" title="一个Lucene索引包含一个提交点和三个段"></p>
<ul>
<li>每一个段本身都是一个倒排索引，索引在 Lucene 中表示所有段的集合。</li>
</ul>
<blockquote>
<p>一个 Lucene 索引在 Elasticsearch 中被称作分片，一个 Elasticsearch 索引是分片的集合，当 Elasticsearch 在索引中搜索的时候，会发送查询请求到每一个属于该索引的分片，然后合并每个分片的结果到一个全局的结果集中。</p>
</blockquote>
<ul>
<li>提交点是一个列出了所有已知段的文件，Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</li>
</ul>
<h2 id="动态更新索引"><a class="header-anchor" href="#动态更新索引">¶</a>动态更新索引</h2>
<ol>
<li>新文档首先被添加到内存索引缓存中；<br>
<img src="https://tallate.top/imgs/ES/%E6%96%B0%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E7%BC%93%E5%AD%98.png" alt="新文档被添加到缓存" title="新文档被添加到缓存"></li>
<li>提交是针对缓存进行的：
<ul>
<li>生成一个新的段（倒排索引）并被写入磁盘；</li>
<li>一个新的包含新段名字的<strong>提交点</strong>被写入磁盘，此时文档在缓存中、还未被刷新到磁盘，如下图所示；</li>
<li>磁盘同步（<code>fsync</code>），所有在文件系统缓存中等待的写入都被刷新到磁盘，以确保它们被写入物理文件。<br>
<img src="https://tallate.top/imgs/ES/%E7%BC%93%E5%86%B2%E5%8C%BA%E8%A2%AB%E5%86%99%E5%85%A5%E6%AE%B5%E4%BD%86%E6%9C%AA%E5%AE%8C%E6%88%90%E6%8F%90%E4%BA%A4.png" alt="缓冲区被写入段但未完成提交" title="缓冲区被写入段但未完成提交"></li>
</ul>
</li>
<li>新的段被开启，它包含的文档可以被搜索；</li>
<li>内存缓存被清空，等待接收新的文档。<br>
<img src="https://tallate.top/imgs/ES/%E6%8F%90%E4%BA%A4%E5%90%8E%E7%94%9F%E6%88%90%E6%96%B0%E6%AE%B5%E4%B8%94%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA.png" alt="提交后生成新段且缓存被清空" title="提交后生成新段且缓存被清空"></li>
</ol>
<p>当一个查询被触发时，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。</p>
<h2 id="删除和更新索引"><a class="header-anchor" href="#删除和更新索引">¶</a>删除和更新索引</h2>
<p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个 <code>.del</code> 文件，文件中会列出这些被删除文档的段信息。<br>
当一个文档被 <strong>删除</strong> 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。<br>
文档<strong>更新</strong>也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p>
<h2 id="准实时搜索与刷新策略"><a class="header-anchor" href="#准实时搜索与刷新策略">¶</a>准实时搜索与刷新策略</h2>
<p>对一个文档进行更新操作后可能会发现属性还是旧的值，我们称之为<strong>准实时现象</strong>：更新的数据还存在于内存中、还未刷新到磁盘上。</p>
<ul>
<li>在索引期新文档会写入<strong>索引段</strong>，这些索引段是独立的，这意味着查询是可以与索引并行的，只是不时会有新增的索引段被添加到可被搜索的索引段集合之中。</li>
<li>Lucene 通过创建后续的（基于索引只写一次的特性）segments_N 文件来实现此功能，且该文件列举了索引中的索引段。这个过程称为<strong>提交（committing）</strong>，Lucene 以一种安全的方式来执行该操作，能确保索引更改以原子操作方式写入索引，即便有错误发生，也能保证索引数据的一致性。</li>
</ul>
<p>随着按段搜索（per-segment）的发展，一个新的文档从索引到可被搜索的延迟显著降低，新文档在几分钟内即可被检索，但是这个速度还是不够快。磁盘在这里称为了瓶颈，提交（Commiting）一个新的段到磁盘需要一个 <code>fsync</code> 来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 <code>fsync</code> 操作代价很大，如果每次索引一个文档都去执行一次的话会造成很大的性能问题。<br>
在 Lucene 中提交后，内存索引缓冲区中的文档会被写入到一个新的段中，但是这里新段会被先写入到文件系统缓存——这一步代价会比较低，稍后再被刷新到磁盘——这一步代价比较高，不过只要文件已经在缓存中就可以像其他文件一样被打开和读取了。<br>
另外，Lucene 使用了一个叫作<strong>Searcher</strong>的抽象类来执行索引的读取，如果索引更新提交了，但 Searcher 实例并没有重新打开，那么它觉察不到新索引段的加入。写入和 Searcher 重新打开新段的过程叫作<strong>刷新（refresh）</strong>。出于性能考虑，Lucene 推迟了耗时的刷新，因此它不会在每次新增一个文档（或批量增加文档）的时候刷新，但 Searcher 会<strong>默认每秒刷新一次</strong>。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。<br>
因此新索引的数据找不到可能有以下两个原因：</p>
<ol>
<li>可能还未执行提交 commit 操作</li>
<li>Searcher 未重新打开执行刷新</li>
</ol>
<p>如果有必要执行强制刷新，可以使用下面的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 刷新所有索引</span><br><span class="line">POST /_refresh</span><br><span class="line"># 只刷新一个索引</span><br><span class="line">POST /my_index/_refresh</span><br></pre></td></tr></table></figure>
<p>可以更改 ElasticSearch 配置文件中的 index.refresh_interval，，或者使用下面的命令来修改自动刷新时间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;5m&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;refresh_interval&quot;: &quot;30s&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>刷新操作是很耗资源的，因此刷新间隔时间越长，索引速度越快。如果需要长时间高速建索引、或建一个比较大的新索引，并且在建索引结束之前暂不执行查询，那么可以考虑将 index.refresh_interval 参数值设置为-1，然后在建索引结束以后再将该参数恢复为初始值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 关闭自动刷新</span><br><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;refresh_interval&quot;: -1</span><br><span class="line">&#125;</span><br><span class="line"># 每秒自动刷新</span><br><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;refresh_interval&quot;: &quot;1s&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意 refresh_interval 的单位，设置为 1 实际上表示的是 1 毫秒，这显然会导致集群陷入瘫痪。<br>
尽管刷新是比提交轻量很多的操作，它还是会有性能开销。 当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</p>
</blockquote>
<h2 id="事务日志-translog"><a class="header-anchor" href="#事务日志-translog">¶</a>事务日志（TransLog）</h2>
<h3 id="lucene-不能保证索引数据不丢失"><a class="header-anchor" href="#lucene-不能保证索引数据不丢失">¶</a>Lucene 不能保证索引数据不丢失</h3>
<p>Lucene 能保证索引的一致性，但是这并不能保证当往索引中写数据（fsync）失败时不会损失数据（如磁盘空间不足、设备损坏，或没有足够的文件句柄供索引文件使用）。<br>
另外，频繁提交操作会导致严重的性能问题（因为每提交一次就会触发一个索引段的创建操作，同时也可能触发索引段的合并）。<br>
即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。</p>
<h3 id="使用事务日志记录未提交事务"><a class="header-anchor" href="#使用事务日志记录未提交事务">¶</a>使用事务日志记录未提交事务</h3>
<p>Elasticsearch 增加了一个 <code>translog</code> ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。<br>
ElasticSearch 通过使用<code>translog</code>保存所有的未提交的事务，而 ElasticSearch 会不时创建一个新的日志文件用于记录每个事务的后续操作。当有错误发生时，就会检查事务日志，必要时会再次执行某些操作，以确保没有丢失任何更改信息。而且，事务日志的相关操作都是自动完成的，用户并不会意识到某个特定时刻触发的更新提交。事务日志中的信息与存储介质之间的同步（同时清空事务日志）称为事务日志刷新（<code>Flush</code>），Flush 操作会截断 translog。<br>
注意事务日志刷新与 Searcher 刷新的区别。大多数情况下，Searcher 刷新是你所期望的，即搜索到最新的文档。而事务日志刷新用来确保数据正确写入了索引并清空了事务日志。</p>
<p>通过<code>translog</code>，整个流程看起来是下面这样：</p>
<ol>
<li>一个文档被索引之后，就会被添加到内存缓冲区，并且 追加到了 translog；<br>
<img src="https://tallate.top/imgs/ES/%E6%96%B0%E7%9A%84%E6%96%87%E6%A1%A3%E8%A2%AB%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%E5%B9%B6%E4%B8%94%E8%A2%AB%E8%BF%BD%E5%8A%A0%E5%88%B0%E4%BA%86%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97.png" alt="新的文档被添加到内存缓冲区并且被追加到了事务日志" title="新的文档被添加到内存缓冲区并且被追加到了事务日志"></li>
<li>分片每秒被刷新（refresh）一次：
<ul>
<li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。</li>
<li>这个段被打开，使其可被搜索。</li>
<li>内存缓冲区被清空。<br>
<img src="https://tallate.top/imgs/ES/Refresh%E5%AE%8C%E6%88%90%E5%90%8E%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B8%85%E7%A9%BA%E4%BD%86%E6%98%AF%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E4%BC%9A.png" alt="Refresh完成后缓存被清空但是事务日志不会" title="Refresh完成后缓存被清空但是事务日志不会"></li>
</ul>
</li>
<li>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志；<br>
<img src="https://tallate.top/imgs/ES/%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E4%B8%8D%E6%96%AD%E7%A7%AF%E7%B4%AF%E6%96%87%E6%A1%A3.png" alt="事务日志不断积累文档" title="事务日志不断积累文档"></li>
<li>每隔一段时间，索引会被刷新（Flush），一个新的 translog 被创建，并且一个全量提交被执行。
<ul>
<li>所有在内存缓冲区的文档都被写入一个新的段。</li>
<li>缓冲区被清空。</li>
<li>一个提交点被写入硬盘。</li>
<li>文件系统缓存通过 fsync 被刷新（flush）。</li>
<li>老的 translog 被删除。<br>
translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。<br>
translog 也被用来提供实时 CRUD 。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。<br>
<img src="https://tallate.top/imgs/ES/Flush%E4%B9%8B%E5%90%8E%E6%AE%B5%E8%A2%AB%E5%85%A8%E9%87%8F%E6%8F%90%E4%BA%A4%E5%B9%B6%E4%B8%94%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%E8%A2%AB%E6%B8%85%E7%A9%BA.png" alt="Flush之后段被全量提交并且事务日志被清空" title="Flush之后段被全量提交并且事务日志被清空"></li>
</ul>
</li>
</ol>
<h3 id="手动执行事务日志刷新"><a class="header-anchor" href="#手动执行事务日志刷新">¶</a>手动执行事务日志刷新</h3>
<p>分片每 30 分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /_flush</span><br><span class="line">POST /my_index/_flush</span><br><span class="line"># Flush所有的索引并且并且等待所有刷新在返回前完成。 </span><br><span class="line">POST /_flush?wait_for_ongoing</span><br><span class="line"># 在事务日志刷新之后，调用Searcher刷新操作，打开一个新的Searcher实例</span><br><span class="line">POST /my_index/_refresh</span><br></pre></td></tr></table></figure>
<p>一般不需要自己手动执行<code>Flush</code>操作，自动刷新就足够了。一般重启节点或关闭索引之前都需要执行一次<code>Flush</code>。<br>
当 Elasticsearch 尝试恢复或重新打开一个索引， 它需要重放 translog 中所有的操作，如果日志越短，恢复越快。</p>
<h3 id="异步-fsync"><a class="header-anchor" href="#异步-fsync">¶</a>异步 fsync</h3>
<p>默认 translog 是每 5 秒被 fsync 刷新到硬盘，或者在每次写请求（index, delete, update, bulk）完成之后执行。这个过程在主分片和复制分片都会发生，这意味着在整个请求被 fsync 到主分片和复制分片的 translog 之前，客户端不会得到一个 200 OK 响应。<br>
对于一些大容量的偶尔丢失几秒数据问题也不严重的集群，使用异步的 fsync 相对来说更好，比如，写入的数据被缓存到内存中，再每 5 秒执行一次 fsync ，可以使用如下命令配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然，如果不确定丢失几秒数据的后果能否接受，最好还是使用默认的参数：<code>&quot;index.translog.durability&quot;: &quot;request&quot;</code>。</p>
<h3 id="配置"><a class="header-anchor" href="#配置">¶</a>配置</h3>
<p>以下参数既可以通过修改 elasticsearch.yml 文件来配置，也可以通过索引配置更新 API 来更改。</p>
<ul>
<li>index.translog.flush_threshold_period：该参数的默认值为 30 分钟，它控制了强制自动事务日志刷新的时间间隔，即便是没有新数据写入。强制进行事务日志刷新通常会导致大量的 I/O 操作，因此当事务日志涉及少量数据时，才更适合进行这项操作。</li>
<li>index.translog.flush_threshold_ops：该参数确定了一个最大操作数，即在上次事务日志刷新以后，当索引更改操作次数超过该参数值时，强制进行事务日志刷新操作，默认值为 5000。</li>
<li>index.translog.flush_threshold_size：该参数确定了事务日志的最大容量，当容量大于等于该参数值，就强制进行事务日志刷新操作，默认值为 200MB。</li>
<li>index.translog.disable_flush:禁用事务日志刷新。尽管默认情况下事务日志刷新是可用的，但对它临时性地禁用能带来其他方面的便利。例如，向索引中导入大量文档的时候。</li>
</ul>
<p>或者调用 API 动态修改配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;translog.disable_flush&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>前述命令在向索引导入大量数据之前执行、可以大幅提高索引的速度。但是请记住，当数据导入完毕之后，要重新设置事务日志刷新相关参数。</p>
<h2 id="段合并"><a class="header-anchor" href="#段合并">¶</a>段合并</h2>
<p>由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增，而段数目太多会带来较大的麻烦：</p>
<ul>
<li>每一个段都会消耗文件句柄、内存和 cpu 运行周期；</li>
<li>更重要的是，每个搜索请求都必须轮流检查每个段，所以段越多，搜索也就越慢。</li>
</ul>
<p>Elasticsearch 通过在后台进行段合并来解决这个问题：</p>
<ul>
<li>小的段被合并到大的段，然后这些大的段再被合并到更大的段。</li>
<li>段合并的时候会将那些旧的已删除文档 从文件系统中清除。 被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</li>
</ul>
<h3 id="段合并流程"><a class="header-anchor" href="#段合并流程">¶</a>段合并流程</h3>
<p>进行索引和搜索时会自动进行段合并：</p>
<ol>
<li>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</li>
<li>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。<br>
<img src="https://tallate.top/imgs/ES/%E4%B8%A4%E4%B8%AA%E6%8F%90%E4%BA%A4%E4%BA%86%E7%9A%84%E6%AE%B5%E5%92%8C%E4%B8%80%E4%B8%AA%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%90%88%E5%B9%B6%E5%88%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E7%9A%84%E6%AE%B5.png" alt="两个提交了的段和一个未提交的段被合并到一个更大的段" title="两个提交了的段和一个未提交的段被合并到一个更大的段"></li>
<li>合并完成后：
<ul>
<li>新的段被刷新（flush）到了磁盘。写入一个包含新段且排除旧的和较小的段的新提交点。</li>
<li>新的段被打开用来搜索。</li>
<li>老的段被删除。<br>
<img src="https://tallate.top/imgs/ES/%E5%90%88%E5%B9%B6%E7%BB%93%E6%9D%9F%E5%90%8E%E8%80%81%E7%9A%84%E6%AE%B5%E8%A2%AB%E5%88%A0%E9%99%A4.png" alt="合并结束后老的段被删除" title="合并结束后老的段被删除"></li>
</ul>
</li>
</ol>
<h3 id="optimize-api"><a class="header-anchor" href="#optimize-api">¶</a>optimize API</h3>
<p>optimize API 用于手动触发段合并。<br>
将一个分片强制合并到 max_num_segments 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。<br>
optimize API 不应该被用在一个活跃的索引上，Elasticsearch 后台会自动触发合并。<br>
在特定情况下，使用 optimize API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的，它们也并不太可能会发生变化，将历史段合并成一个单独的段就很有用了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 合并索引中的每个分片为一个单独的段 </span><br><span class="line">POST /logstash-2014-10/_optimize?max_num_segments=1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用 optimize API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的 I/O 资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配把索引移到一个安全的节点，再执行。</p>
</blockquote>
<h1>分布式文档存储</h1>
<h2 id="相关配置"><a class="header-anchor" href="#相关配置">¶</a>相关配置</h2>
<ul>
<li>wait_for_active_shards：开始执行写入操作前需要等待的活跃分片数量，主要用于维护写一致性。</li>
</ul>
<h2 id="文档路由"><a class="header-anchor" href="#文档路由">¶</a>文档路由</h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>
<p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （<strong>主分片的数量</strong>）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。<br>
这就解释了为什么我们要在<strong>创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量</strong>：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。<br>
所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。</p>
<blockquote>
<p>主节点数固定不是一件好事，我们会在<strong>集群扩容</strong>里提到如何解决扩容问题。</p>
</blockquote>
<h2 id="分发机制"><a class="header-anchor" href="#分发机制">¶</a>分发机制</h2>
<p>可以将请求发送到 集群中的任何节点 ，包括主节点。<strong>每个节点都知道任意文档所处的位置</strong>，并且能够将我们的请求直接转发到存储我们所需文档的节点。无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。<br>
一个分片是一个 Lucene 实例，我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互的。Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。当你的集群规模扩大或者缩小时，Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。<br>
我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。但是为了更好地实现负载均衡，我们一般会轮询节点，每次接受请求的节点称为 <strong>（协调节点）</strong>，比如下面的 Node1。</p>
<h2 id="consistency"><a class="header-anchor" href="#consistency">¶</a>consistency</h2>
<p>为了保证一致性，在默认设置下，即使仅仅是在试图执行一个_写_操作之前，主分片都会要求 必须要有 <strong>规定数量(quorum)</strong>（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。</p>
<p>注意：下面的参数只对 ElasticSearch 5.0 以下的版本有效，在 ElasticSearch 5.0 之后貌似使用 wait_for_active_shards 代替了 consistency。所以之前的参数了解即可，实际可以参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-create-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-create-index.html</a><br>
consistency 有三种取值：</p>
<ol>
<li>
<p>quorum（规定大多数，默认）</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int( (primary + number_of_replicas) / 2 ) + 1</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>one（只要主分片 ok 就可以）</p>
</li>
<li>
<p>all（必须要主分片和所有副本分片的状态都没问题才允许执行写操作）</p>
</li>
</ol>
<h2 id="timeout"><a class="header-anchor" href="#timeout">¶</a>timeout</h2>
<p>如果没有足够的副本分片数，Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待 1 分钟。可以设置 timeout 的值来修改等待时间。</p>
<h2 id="创建-索引-删除"><a class="header-anchor" href="#创建-索引-删除">¶</a>创建、索引、删除</h2>
<p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片，所以需要：</p>
<ol>
<li>先<strong>根据 id 确定其所属的主分片位置</strong>；</li>
<li>主分片若执行成功，将请求并行转发到副本分片上；</li>
<li>Node3 上的主分片执行成功，向协调节点报告成功，协调节点再汇报给客户端；<br>
<img src="https://tallate.top/imgs/ES/%E6%96%B0%E5%A2%9E%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%A0%E9%99%A4.png" alt="新增、索引、删除" title="新增、索引、删除"></li>
</ol>
<h2 id="取回单个文档"><a class="header-anchor" href="#取回单个文档">¶</a>取回单个文档</h2>
<p>可以从主分片或者从其它任意副本分片检索文档：</p>
<ol>
<li>向协调节点发送请求，请求方式是轮询，比如上次从 2 获取到数据，则这次从 3 开始；</li>
<li>使用 id 确定文档所处主分片位置，如果存在多份则返回第一份即可；</li>
<li>协调节点将文档返回给客户端<br>
<img src="https://tallate.top/imgs/ES/%E5%8F%96%E5%9B%9E%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png" alt="取回单个文档" title="取回单个文档"></li>
</ol>
<h2 id="局部更新"><a class="header-anchor" href="#局部更新">¶</a>局部更新</h2>
<p>部分更新包括读取和写入两个过程：</p>
<ol>
<li>同样先向协调节点发送更新请求；</li>
<li>从 id 计算出文档所在的主分片位置；</li>
<li>从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</li>
<li>如果成功地更新文档，它将新版本的文档（而<strong>不是更新请求本身</strong>，因为如果以错误的顺序到达，可能导致文档损坏）并行转发到其他节点的副本分片，重新建立索引。</li>
<li>一旦所有副本分片都返回成功，向协调节点也返回成功，协调节点向客户端返回成功。<br>
<img src="https://tallate.top/imgs/ES/%E5%B1%80%E9%83%A8%E6%9B%B4%E6%96%B0.png" alt="局部更新" title="局部更新"></li>
</ol>
<h2 id="mget-批量读"><a class="header-anchor" href="#mget-批量读">¶</a>mget（批量读）</h2>
<p>mget 和 bulk API 的 模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。</p>
<ol>
<li>将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点；</li>
<li>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。<br>
<img src="https://tallate.top/imgs/ES/%E6%89%B9%E9%87%8F%E8%AF%BB.png" alt="批量读" title="批量读"></li>
</ol>
<h2 id="bulk-批量改"><a class="header-anchor" href="#bulk-批量改">¶</a>bulk（批量改）</h2>
<ol>
<li>协调节点接受请求，为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机；</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<blockquote>
<p>bulk API 格式中有换行符，这是因为请求文档可能属于不同的主分片，如果将这些文档放到一个 JSON 数组中，则需要解析它们并重新创建请求数组，这需要占用大量 RAM 空间来存储原数据的副本，JVM 将不得不花费时间进行垃圾回收。<br>
<img src="https://tallate.top/imgs/ES/%E6%89%B9%E9%87%8F%E6%94%B9.png" alt="批量改" title="批量改"></p>
</blockquote>
<h1>存储管理</h1>
<p>之前讨论的都是集群视角下ES怎么组织所有节点的，现在再深入到节点内部存储的数据，看看节点之间是如何组织分片的。<br>
分片也分为主分片和副分片，也存在主分片的选举问题，选出主分片后由主分片来执行所有写请求，副分片来分担搜索请求。</p>
<h2 id="数据副本模型"><a class="header-anchor" href="#数据副本模型">¶</a>数据副本模型</h2>
<p>主从模型是分布式的经典模型之一，通过主节点的选举可以实现高可用。的那个然主从只能提高可用性，如果要性能上的可伸缩性，一般还会对数据进行 hash。<br>
主从模型实际上也是下面将要讨论的分布式文档存储、搜索的基础。</p>
<blockquote>
<p>HDFS、Cassandra 等使用的是对等模型。</p>
</blockquote>
<h3 id="pacifica-算法"><a class="header-anchor" href="#pacifica-算法">¶</a>PacificA 算法</h3>
<p>ES 的主副本模型的实现参考了微软的 PacificA 算法，下面是算法中涉及到的几个概念：</p>
<ul>
<li>Replica Group</li>
<li>Configuration</li>
<li>Configuration Version</li>
<li>Serial Number（SN）</li>
</ul>
<p>PacificA 算法运行在分布式系统之上，对系统有以下几项假设：</p>
<ul>
<li>节点可以失效，对消息延迟的上限不做假设；</li>
<li>消息可以丢失、乱序，但不能被篡改，即不存在<strong>拜占庭问题</strong>；</li>
</ul>
<blockquote>
<p>拜占庭问题</p>
</blockquote>
<ul>
<li>网络分区可以发生，系统时钟可以不同步，但<strong>漂移</strong>是有限度的。</li>
</ul>
<blockquote>
<p>漂移</p>
</blockquote>
<h3 id="存储管理-写入"><a class="header-anchor" href="#存储管理-写入">¶</a>存储管理 - 写入</h3>
<p>数据的读取和更新策略，及使用多副本方式保证数据的可靠性和可用性。<br>
数据写流程如下：<br>
<img src="https://tallate.top/imgs/ES/%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png" alt="数据写入流程" title="数据写入流程"></p>
<ol>
<li>写请求进入主副本节点；</li>
<li>节点为该请求分配 SN，并使用该 SN 创建 UpdateRequest，然后将该 UpdateRequest 插入自己的 prepareList；</li>
<li>主副本将携带 SN 的 UpdateRequest 发往从副本节点，从节点收到后同样插入 prepareList；</li>
<li>主副本节点接收到所有从副本节点的 ACK 响应，确认该数据已经被写入到所有的从副本节点；</li>
<li>此时达到了可提交的状态，主副本将此 UpdateRequest 放入 committedList，committedList 向前移动；</li>
<li>主副本节点回复客户端更新成功。</li>
<li>主节点向从节点发送 commit 通知，告诉它们自己的 committed point 位置，从节点收到通知后根据指示来移动 committed point 到相同位置。</li>
</ol>
<p>数据存储流程中遵循不变式<code>Commit Invariant</code>：</p>
<ol>
<li>主节点 committedList 是任何一个从节点 prepareList 的前缀（子集）；</li>
<li>任一从节点上的 committedList 是主节点上 committedList 的前缀（子集）。</li>
</ol>
<h1>写入（POST、PUT、DELETE）流程源码分析</h1>
<h2 id="refresh和flush-实时性和可靠性之间的权衡"><a class="header-anchor" href="#refresh和flush-实时性和可靠性之间的权衡">¶</a>refresh和flush - 实时性和可靠性之间的权衡</h2>
<p><img src="https://tallate.top/imgs/ES/%E5%88%B7%E7%9B%98%E6%B5%81%E7%A8%8B.png" alt="刷盘流程" title="刷盘流程"></p>
<h3 id="近实时性"><a class="header-anchor" href="#近实时性">¶</a>近实时性</h3>
<p>ES中数据写入后并不能被马上查到，而是必须先执行refresh，默认是1s，最快可到100ms。</p>
<h3 id="可靠性"><a class="header-anchor" href="#可靠性">¶</a>可靠性</h3>
<p>搜索系统对可靠性要求都不高，一般数据的可靠性通过将原始数据存储在另一个存储系统来保证，当搜索系统的数据发生丢失时，再从其他存储系统导一份数据过来重新rebuild就可以了。<br>
ES采用多副本模型，可以避免单机发生故障时丢失数据，但是ES同时为了提升读写性能，一般是每隔一段时间才会把Lucene的Segment flush到磁盘实现持久化，这样减少了磁盘IO，但是数据未flush期间，如果发生了宕机就很容易导致数据的丢失。对于这个问题，ES中的解决方法类似数据库中的CommitLog，ES中引入了一个TransLog。<br>
可以通过设置TransLog的Flush频率来控制写入缓存的数据什么时候刷到磁盘上，要么是按请求，每次请求都Flush；要么是按时间，每隔一段时间Flush一次。一般为了性能考虑，会设置为每隔5秒或者1分钟Flush一次，Flush间隔时间越长，可靠性就会越低。</p>
<h3 id="es的刷盘流程"><a class="header-anchor" href="#es的刷盘流程">¶</a>ES的刷盘流程</h3>
<p>之前我们已经讨论了数据如何定位到某个node、某个shard。</p>
<ol>
<li>在每个shard上，数据会先写入Lucene，此时数据还在内存里；<br>
写Lucene内存后还不可被搜索，需要先通过Refresh将内存对象转成完整Segment后，再次reopen后才可被搜索。<br>
但是简单的Get操作是GetById的，这种查询可以直接从TransLog中查询，因此这种情况下是实时的。</li>
<li>接着去写TransLog，写完TransLog后会刷新TransLog数据到磁盘上；</li>
</ol>
<blockquote>
<p>和数据库不同，数据库是先写CommitLog再写内存，而ES是先写内存（Lucene）再写TransLog，原因是Lucene的内存写入有很复杂的逻辑，比如分词、字段长度超过限制等，很容易失败，为了避免TransLog中有大量无效记录，减少recover的复杂度和提高速度，所以把写Lucene放到了前面。</p>
</blockquote>
<ol>
<li>等到TransLog数据被刷新到磁盘上后，返回写成功给用户。</li>
<li>隔一段比较长的时间后，Lucene会把内存中新生成的Segment Flush到磁盘，之后就会把TransLog清空掉。</li>
</ol>
<h3 id="es会丢失数据吗？"><a class="header-anchor" href="#es会丢失数据吗？">¶</a>ES会丢失数据吗？</h3>
<ul>
<li>Lucene每隔1秒生成Segment文件，此时Segment还在缓存中，还未刷盘，如果这时挂掉，<strong>内存中的数据仍然可以从TransLog中恢复</strong>；</li>
<li>TransLog中的数据是每隔5秒刷新到磁盘，显然这还不能保证数据安全，最多会导致丢失TransLog中5秒内的数据，<strong>可以通过配置增加TransLog刷磁盘的频率来增加数据可靠性，但是会对性能有比较大的影响</strong>。</li>
<li>即使Master分片所在节点宕掉，导致TransLog丢失了，仍然<strong>可以从副本恢复</strong>。</li>
</ul>
<h2 id="文档更新-部分更新"><a class="header-anchor" href="#文档更新-部分更新">¶</a>文档更新（部分更新）</h2>
<p>Lucene中不支持文档的部分更新，因此需要在Elasticsearch中实现该功能：</p>
<ol>
<li>收到Update请求后，从Segment或TransLog中读取该id的完整文档，记录版本为V1；</li>
<li>将版本V1的文档和请求中的部分字段文档合并，同时更新内存中的versionMap，得到V2，之后Update请求就变成了对V2的Index请求；</li>
<li>加锁；</li>
<li>再次从versionMap中读取该id的最大版本号V2，如果没有再从Segment或TransLog中读取，但是versionMap中基本都可以获取到；</li>
<li>检查版本是否冲突（V1和V2），如果冲突则回退到开始的Update阶段重新执行，否则继续执行Index请求；</li>
<li>在Index阶段，首先版本+1得到V3，再将文档加入到Lucene中去，Lucene中会删除同id的旧文档，然后再新增文档。写入成功后，将V3更新到versionMap中；</li>
<li>释放锁。</li>
</ol>
<h2 id="乐观并发控制"><a class="header-anchor" href="#乐观并发控制">¶</a>乐观并发控制</h2>
<p><img src="https://tallate.top/imgs/ES/%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E9%97%AE%E9%A2%98.png" alt="并发更新问题" title="并发更新问题"><br>
如上图所示 Web-2 不知道自己的对象拷贝已经过期，结果执行更新时会认为库存尚充足。<br>
像这样的变更越频繁，读数据和更新数据的间隙越长，也就越可能丢失变更。<br>
在数据库领域中，有两种策略通常被用来确保并发更新时变更不会丢失：</p>
<ul>
<li>悲观并发控制<br>
这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此<strong>阻塞访问资源以防止冲突</strong>。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。</li>
<li>乐观并发控制<br>
Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，<strong>如果源数据在读写当中被修改，更新将会失败</strong>。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。</li>
</ul>
<p>Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些<strong>复制请求被并行发送，并且到达目的地时也许 顺序是乱的</strong>。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。</p>
<ol>
<li>
<p>内部版本号<br>
当我们之前讨论 index ， GET 和 delete 请求时，我们指出每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。<br>
当我们在更新数据时，需要指定想要修改文档的_version，如果该版本不是当前版本号，我们的请求将会失败。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/1?version=1 </span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Starting to get the hang of this...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>外部版本号<br>
一个常见的设置是使用其它数据库作为主要的数据存储，使用 Elasticsearch 做数据检索，Elasticsearch 提供了一种机制来重用主数据库中已经存在的版本号字段。<br>
外部版本号的处理方式和我们之前讨论的内部版本号的处理方式有些不同， Elasticsearch 不是检查当前 _version 和请求中指定的版本号是否相同， 而是检查当前 _version 是否 小于 指定的版本号。 如果是则请求成功，外部的版本号作为文档的新 _version 进行存储，这意味着每次请求必须先在主数据库中增加版本号的值，再将新版本的数据索引到 Elasticsearch 中。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/2?version=5&amp;version_type=external</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first external blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Starting to get the hang of this...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="文档操作类型"><a class="header-anchor" href="#文档操作类型">¶</a>文档操作类型</h2>
<p>文档操作分为单个的（Index）和批量的（Bulk），它们最终都会被统一封装为批量操作请求（BulkRequest）。</p>
<h2 id="请求入口"><a class="header-anchor" href="#请求入口">¶</a>请求入口</h2>
<p>在ES中，所有action的入口都注册在ActionModule中，比如Bulk Request有两个注册入口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">actions.register(BulkAction.INSTANCE, TransportBulkAction.class,</span><br><span class="line">        TransportShardBulkAction.class);</span><br><span class="line"></span><br><span class="line">registerHandler.accept(new RestBulkAction(settings, restController));</span><br></pre></td></tr></table></figure>
<p>对于Rest请求，会在RestBulkAction中解析请求，并最终转换成TransportAction处理。</p>
<p>比如对请求：<code>localhost:9200/website/blog/123</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Just trying this out...&quot;,</span><br><span class="line">  &quot;date&quot;: &quot;2014/01/01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会先被dispatch到<code>RestIndexAction</code>，然后转发给<code>TransportBulkAction#doExecute</code>，下面对文档写入流程的分析也将从这个入口开始。</p>
<h2 id="文档写入流程"><a class="header-anchor" href="#文档写入流程">¶</a>文档写入流程</h2>
<p>由上边对ES数据模型的讨论可知，ES文档的写入必须是先成功写入到主分片，然后才能复制到相关的副分片。<br>
<img src="https://tallate.top/imgs/ES/%E5%A4%9A%E8%8A%82%E7%82%B9%E5%A4%9A%E5%88%86%E7%89%87%E6%A8%A1%E5%9E%8B.png" alt="多节点多分片模型" title="多节点多分片模型"></p>
<ol>
<li>第一个接收请求的节点是协调节点；</li>
<li>先根据_routing规则选择发给哪个shard（分片）；<br>
优先使用IndexRequest中的设置，其次使用mapping中的配置，如果都没有则使用_id作为路由参数；</li>
<li>从集群的meta中找出该shard的节点，此时，请求会被转发到<strong>primary shard</strong>所在的节点；</li>
<li>请求接着发送给primary shard执行写操作；</li>
<li>primary shard执行成功后再发送给多个replica shard；</li>
<li>请求在多个replica shard上执行成功并返回给协调节点后，写入执行成功，协调节点返回结果给客户端。</li>
</ol>
<p>从上述写入的概述可知，写入流程具体的，可以分为<code>协调节点</code>、<code>主分片节点</code>及<code>副分片节点</code>三种角色的写入过程。<br>
<img src="https://tallate.top/imgs/ES/ES%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png" alt="ES写入流程" title="ES写入流程"></p>
<h3 id="协调节点处理流程"><a class="header-anchor" href="#协调节点处理流程">¶</a>协调节点处理流程</h3>
<p>1、自动创建索引<br>
入口：<code>TransportBulkAction#doExecute</code><br>
找出请求中需要自动创建的索引</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">for (String index : indices) &#123;</span><br><span class="line">    boolean shouldAutoCreate;</span><br><span class="line">    try &#123;</span><br><span class="line">        shouldAutoCreate = shouldAutoCreate(index, state);</span><br><span class="line">    &#125; catch (IndexNotFoundException e) &#123;</span><br><span class="line">        shouldAutoCreate = false;</span><br><span class="line">        indicesThatCannotBeCreated.put(index, e);</span><br><span class="line">    &#125;</span><br><span class="line">    if (shouldAutoCreate) &#123;</span><br><span class="line">        autoCreateIndices.add(index);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行创建索引的请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void createIndex(String index, TimeValue timeout, ActionListener&lt;CreateIndexResponse&gt; listener) &#123;</span><br><span class="line">    CreateIndexRequest createIndexRequest = new CreateIndexRequest();</span><br><span class="line">    createIndexRequest.index(index);</span><br><span class="line">    createIndexRequest.cause(&quot;auto(bulk api)&quot;);</span><br><span class="line">    createIndexRequest.masterNodeTimeout(timeout);</span><br><span class="line">    createIndexAction.execute(createIndexRequest, listener);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、路由请求<br>
入口：<code>TransportBulkAction.BulkOperation#doRun</code><br>
不同类型的请求路由逻辑也不同：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">switch (docWriteRequest.opType()) &#123;</span><br><span class="line">    // 创建索引、mapping请求</span><br><span class="line">    case CREATE:</span><br><span class="line">    case INDEX:</span><br><span class="line">        IndexRequest indexRequest = (IndexRequest) docWriteRequest;</span><br><span class="line">        final IndexMetaData indexMetaData = metaData.index(concreteIndex);</span><br><span class="line">        MappingMetaData mappingMd = indexMetaData.mappingOrDefault(indexRequest.type());</span><br><span class="line">        Version indexCreated = indexMetaData.getCreationVersion();</span><br><span class="line">        indexRequest.resolveRouting(metaData);</span><br><span class="line">        indexRequest.process(indexCreated, mappingMd, concreteIndex.getName());</span><br><span class="line">        break;</span><br><span class="line">    // 更新文档请求</span><br><span class="line">    case UPDATE:</span><br><span class="line">        TransportUpdateAction.resolveAndValidateRouting(metaData, concreteIndex.getName(), (UpdateRequest) docWriteRequest);</span><br><span class="line">        break;</span><br><span class="line">    // 删除文档操作</span><br><span class="line">    case DELETE:</span><br><span class="line">        docWriteRequest.routing(metaData.resolveWriteIndexRouting(docWriteRequest.parent(), docWriteRequest.routing(), docWriteRequest.index()));</span><br><span class="line">        // check if routing is required, if so, throw error if routing wasn&apos;t specified</span><br><span class="line">        if (docWriteRequest.routing() == null &amp;&amp; metaData.routingRequired(concreteIndex.getName(), docWriteRequest.type())) &#123;</span><br><span class="line">            throw new RoutingMissingException(concreteIndex.getName(), docWriteRequest.type(), docWriteRequest.id());</span><br><span class="line">        &#125;</span><br><span class="line">        break;</span><br><span class="line">    default: throw new AssertionError(&quot;request type not supported: [&quot; + docWriteRequest.opType() + &quot;]&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后计算文档ID的hash值，将其分配给对应的shard：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 根据文档ID分配给对应的shardId</span><br><span class="line">// first, go over all the requests and create a ShardId -&gt; Operations mapping</span><br><span class="line">Map&lt;ShardId, List&lt;BulkItemRequest&gt;&gt; requestsByShard = new HashMap&lt;&gt;();</span><br><span class="line">for (int i = 0; i &lt; bulkRequest.requests.size(); i++) &#123;</span><br><span class="line">    DocWriteRequest request = bulkRequest.requests.get(i);</span><br><span class="line">    if (request == null) &#123;</span><br><span class="line">        continue;</span><br><span class="line">    &#125;</span><br><span class="line">    String concreteIndex = concreteIndices.getConcreteIndex(request.index()).getName();</span><br><span class="line">    ShardId shardId = clusterService.operationRouting().indexShards(clusterState, concreteIndex, request.id(), request.routing()).shardId();</span><br><span class="line">    List&lt;BulkItemRequest&gt; shardRequests = requestsByShard.computeIfAbsent(shardId, shard -&gt; new ArrayList&lt;&gt;());</span><br><span class="line">    shardRequests.add(new BulkItemRequest(i, request));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (requestsByShard.isEmpty()) &#123;</span><br><span class="line">    listener.onResponse(new BulkResponse(responses.toArray(new BulkItemResponse[responses.length()]), buildTookInMillis(startTimeNanos)));</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、轮询分片，分发请求</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">final AtomicInteger counter = new AtomicInteger(requestsByShard.size());</span><br><span class="line">// 当前节点ID</span><br><span class="line">String nodeId = clusterService.localNode().getId();</span><br><span class="line">for (Map.Entry&lt;ShardId, List&lt;BulkItemRequest&gt;&gt; entry : requestsByShard.entrySet()) &#123;</span><br><span class="line">    // 对每个分片</span><br><span class="line">    final ShardId shardId = entry.getKey();</span><br><span class="line">    final List&lt;BulkItemRequest&gt; requests = entry.getValue();</span><br><span class="line">    // 创建该分片的批量操作请求</span><br><span class="line">    BulkShardRequest bulkShardRequest = new BulkShardRequest(shardId, bulkRequest.getRefreshPolicy(),</span><br><span class="line">            requests.toArray(new BulkItemRequest[requests.size()]));</span><br><span class="line">    bulkShardRequest.waitForActiveShards(bulkRequest.waitForActiveShards());</span><br><span class="line">    bulkShardRequest.timeout(bulkRequest.timeout());</span><br><span class="line">    if (task != null) &#123;</span><br><span class="line">        bulkShardRequest.setParentTask(nodeId, task.getId());</span><br><span class="line">    &#125;</span><br><span class="line">    // 执行该请求</span><br><span class="line">    shardBulkAction.execute(bulkShardRequest, new ActionListener&lt;BulkShardResponse&gt;() &#123;</span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、将分片请求发往节点<br>
代码入口：<code>TransportReplicationAction.ReroutePhase#doRun</code><br>
将请求路由到主分片所在的节点上，并重试失败的操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 找到主分片</span><br><span class="line">final ShardRouting primary = primary(state);</span><br><span class="line">if (retryIfUnavailable(state, primary)) &#123;</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br><span class="line">final DiscoveryNode node = state.nodes().get(primary.currentNodeId());</span><br><span class="line">// 主分片在当前节点就直接本地执行，否则就调用该远程节点执行</span><br><span class="line">if (primary.currentNodeId().equals(state.nodes().getLocalNodeId())) &#123;</span><br><span class="line">    performLocalAction(state, primary, node, indexMetaData);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    performRemoteAction(state, primary, node);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="主分片节点处理流程"><a class="header-anchor" href="#主分片节点处理流程">¶</a>主分片节点处理流程</h3>
<p>如上所述，协调节点会将请求发送给主分片所在节点，该节点接收请求，并执行该请求对应的处理器。<br>
消息接收入口：<code>TransportReplicationAction.PrimaryOperationTransportHandler#messageReceived</code><br>
主节点执行逻辑：<code>ReplicationOperation#execute</code><br>
1、判断活跃的shard是否足够<br>
代码入口：<code>ReplicationOperation#checkActiveShardCount</code><br>
活跃的分片越多，执行写入后同步的备份也越多，数据也越不容易丢失；默认为1，表示主分片可用就执行写入。<br>
2、主分片执行<br>
代码入口：<code>ReplicationOperation.Primary#perform</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public PrimaryResult perform(Request request) throws Exception &#123;</span><br><span class="line">    PrimaryResult result = shardOperationOnPrimary(request, indexShard);</span><br><span class="line">    assert result.replicaRequest() == null || result.finalFailure == null : &quot;a replica request [&quot; + result.replicaRequest()</span><br><span class="line">        + &quot;] with a primary failure [&quot; + result.finalFailure + &quot;]&quot;;</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、主分片执行索引操作<br>
代码中需要对请求进行dispatch，<code>TransportShardBulkAction#executeBulkItemRequest</code>，以UPDATE操作为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">private static BulkItemResultHolder executeUpdateRequest(UpdateRequest updateRequest, IndexShard primary,</span><br><span class="line">                                                         IndexMetaData metaData, BulkShardRequest request,</span><br><span class="line">                                                         int requestIndex, UpdateHelper updateHelper,</span><br><span class="line">                                                         LongSupplier nowInMillis,</span><br><span class="line">                                                         final MappingUpdatePerformer mappingUpdater) throws Exception &#123;</span><br><span class="line">    BulkItemRequest primaryItemRequest = request.items()[requestIndex];</span><br><span class="line">    assert primaryItemRequest.request() == updateRequest</span><br><span class="line">            : &quot;expected bulk item request to contain the original update request, got: &quot; +</span><br><span class="line">            primaryItemRequest.request() + &quot; and &quot; + updateRequest;</span><br><span class="line"></span><br><span class="line">    BulkItemResultHolder holder = null;</span><br><span class="line">    // There must be at least one attempt</span><br><span class="line">    // 保证至少执行一次，因此重试</span><br><span class="line">    int maxAttempts = Math.max(1, updateRequest.retryOnConflict());</span><br><span class="line">    for (int attemptCount = 0; attemptCount &lt; maxAttempts; attemptCount++) &#123;</span><br><span class="line"></span><br><span class="line">        holder = executeUpdateRequestOnce(updateRequest, primary, metaData, request.index(), updateHelper,</span><br><span class="line">                nowInMillis, primaryItemRequest, request.items()[requestIndex].id(), mappingUpdater);</span><br><span class="line"></span><br><span class="line">        // It was either a successful request, or it was a non-conflict failure</span><br><span class="line">        if (holder.isVersionConflict() == false) &#123;</span><br><span class="line">            return holder;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // We ran out of tries and haven&apos;t returned a valid bulk item response, so return the last one generated</span><br><span class="line">    return holder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>路径很长，最后调用了<code>InternalEngine#index</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">public IndexResult index(Index index) throws IOException &#123;</span><br><span class="line">    assert Objects.equals(index.uid().field(), uidField) : index.uid().field();</span><br><span class="line">    final boolean doThrottle = index.origin().isRecovery() == false;</span><br><span class="line">    try (ReleasableLock releasableLock = readLock.acquire()) &#123;</span><br><span class="line">        ensureOpen();</span><br><span class="line">        assert assertIncomingSequenceNumber(index.origin(), index.seqNo());</span><br><span class="line">        assert assertVersionType(index);</span><br><span class="line">        try (Releasable ignored = versionMap.acquireLock(index.uid().bytes());</span><br><span class="line">            Releasable indexThrottle = doThrottle ? () -&gt; &#123;&#125; : throttle.acquireThrottle()) &#123;</span><br><span class="line">            lastWriteNanos = index.startTime();</span><br><span class="line">            /* A NOTE ABOUT APPEND ONLY OPTIMIZATIONS:</span><br><span class="line">             * if we have an autoGeneratedID that comes into the engine we can potentially optimize</span><br><span class="line">             * and just use addDocument instead of updateDocument and skip the entire version and index lookupVersion across the board.</span><br><span class="line">             * Yet, we have to deal with multiple document delivery, for this we use a property of the document that is added</span><br><span class="line">             * to detect if it has potentially been added before. We use the documents timestamp for this since it&apos;s something</span><br><span class="line">             * that:</span><br><span class="line">             *  - doesn&apos;t change per document</span><br><span class="line">             *  - is preserved in the transaction log</span><br><span class="line">             *  - and is assigned before we start to index / replicate</span><br><span class="line">             * NOTE: it&apos;s not important for this timestamp to be consistent across nodes etc. it&apos;s just a number that is in the common</span><br><span class="line">             * case increasing and can be used in the failure case when we retry and resent documents to establish a happens before relationship.</span><br><span class="line">             * for instance:</span><br><span class="line">             *  - doc A has autoGeneratedIdTimestamp = 10, isRetry = false</span><br><span class="line">             *  - doc B has autoGeneratedIdTimestamp = 9, isRetry = false</span><br><span class="line">             *</span><br><span class="line">             *  while both docs are in in flight, we disconnect on one node, reconnect and send doc A again</span><br><span class="line">             *  - now doc A&apos; has autoGeneratedIdTimestamp = 10, isRetry = true</span><br><span class="line">             *</span><br><span class="line">             *  if A&apos; arrives on the shard first we update maxUnsafeAutoIdTimestamp to 10 and use update document. All subsequent</span><br><span class="line">             *  documents that arrive (A and B) will also use updateDocument since their timestamps are less than maxUnsafeAutoIdTimestamp.</span><br><span class="line">             *  While this is not strictly needed for doc B it is just much simpler to implement since it will just de-optimize some doc in the worst case.</span><br><span class="line">             *</span><br><span class="line">             *  if A arrives on the shard first we use addDocument since maxUnsafeAutoIdTimestamp is &lt; 10. A` will then just be skipped or calls</span><br><span class="line">             *  updateDocument.</span><br><span class="line">             */</span><br><span class="line">            final IndexingStrategy plan;</span><br><span class="line"></span><br><span class="line">            if (index.origin() == Operation.Origin.PRIMARY) &#123;</span><br><span class="line">                plan = planIndexingAsPrimary(index);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // non-primary mode (i.e., replica or recovery)</span><br><span class="line">                plan = planIndexingAsNonPrimary(index);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            final IndexResult indexResult;</span><br><span class="line">            if (plan.earlyResultOnPreFlightError.isPresent()) &#123;</span><br><span class="line">                indexResult = plan.earlyResultOnPreFlightError.get();</span><br><span class="line">                assert indexResult.getResultType() == Result.Type.FAILURE : indexResult.getResultType();</span><br><span class="line">            &#125; else if (plan.indexIntoLucene) &#123;</span><br><span class="line">                indexResult = indexIntoLucene(index, plan);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                indexResult = new IndexResult(</span><br><span class="line">                        plan.versionForIndexing, getPrimaryTerm(), plan.seqNoForIndexing, plan.currentNotFoundOrDeleted);</span><br><span class="line">            &#125;</span><br><span class="line">            if (index.origin() != Operation.Origin.LOCAL_TRANSLOG_RECOVERY) &#123;</span><br><span class="line">                final Translog.Location location;</span><br><span class="line">                if (indexResult.getResultType() == Result.Type.SUCCESS) &#123;</span><br><span class="line">                    location = translog.add(new Translog.Index(index, indexResult));</span><br><span class="line">                &#125; else if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) &#123;</span><br><span class="line">                    // if we have document failure, record it as a no-op in the translog with the generated seq_no</span><br><span class="line">                    location = translog.add(new Translog.NoOp(indexResult.getSeqNo(), index.primaryTerm(), indexResult.getFailure().toString()));</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    location = null;</span><br><span class="line">                &#125;</span><br><span class="line">                indexResult.setTranslogLocation(location);</span><br><span class="line">            &#125;</span><br><span class="line">            if (plan.indexIntoLucene &amp;&amp; indexResult.getResultType() == Result.Type.SUCCESS) &#123;</span><br><span class="line">                final Translog.Location translogLocation = trackTranslogLocation.get() ? indexResult.getTranslogLocation() : null;</span><br><span class="line">                versionMap.maybePutIndexUnderLock(index.uid().bytes(),</span><br><span class="line">                    new IndexVersionValue(translogLocation, plan.versionForIndexing, plan.seqNoForIndexing, index.primaryTerm()));</span><br><span class="line">            &#125;</span><br><span class="line">            if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) &#123;</span><br><span class="line">                localCheckpointTracker.markSeqNoAsCompleted(indexResult.getSeqNo());</span><br><span class="line">            &#125;</span><br><span class="line">            indexResult.setTook(System.nanoTime() - index.startTime());</span><br><span class="line">            indexResult.freeze();</span><br><span class="line">            return indexResult;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (RuntimeException | IOException e) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            maybeFailEngine(&quot;index&quot;, e);</span><br><span class="line">        &#125; catch (Exception inner) &#123;</span><br><span class="line">            e.addSuppressed(inner);</span><br><span class="line">        &#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="副分片执行"><a class="header-anchor" href="#副分片执行">¶</a>副分片执行</h3>
<p>同样是在主节点的<code>ReplicationOperation#execute</code>中，需要调用副分片的写入接口。<br>
1、调用副分片<br>
代码入口：<code>ReplicationOperation#performOnReplicas</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">private void performOnReplica(final ShardRouting shard, final ReplicaRequest replicaRequest, final long globalCheckpoint) &#123;</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;[&#123;&#125;] sending op [&#123;&#125;] to replica &#123;&#125; for request [&#123;&#125;]&quot;, shard.shardId(), opType, shard, replicaRequest);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    totalShards.incrementAndGet();</span><br><span class="line">    pendingActions.incrementAndGet();</span><br><span class="line">    // 发HTTP请求给副分片</span><br><span class="line">    replicasProxy.performOn(shard, replicaRequest, globalCheckpoint, new ActionListener&lt;ReplicaResponse&gt;() &#123;</span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、副分片接收请求写入文档的流程与主分片基本一致。<br>
消息接收入口是：<code>TransportReplicationAction.ReplicaOperationTransportHandler#messageReceived</code></p>
<h1>GET流程源码分析</h1>
<h2 id="实时性"><a class="header-anchor" href="#实时性">¶</a>实时性</h2>
<p>Elasticsearch中的GET请求也能保证是实时的，因为GET请求会直接读内存中尚未Flush到磁盘的TransLog。<br>
但是GET请求只支持通过doc_id进行查询，所以对于条件查询（Search）依然无法实现实时。</p>
<h2 id="get执行流程"><a class="header-anchor" href="#get执行流程">¶</a>GET执行流程</h2>
<p>GET指的是单个文档的查询请求，文档的唯一标识是ID，因此GET就是根据ID来找到一个文档。<br>
ES集群中的节点分为<code>协调节点</code>和<code>数据节点</code>，GET请求会先打到协调节点，然后转发到数据节点上；如果一个节点执行失败，则转发到其他节点上进行读取。<br>
<img src="https://tallate.top/imgs/ES/ES%E7%9A%84GET%E6%B5%81%E7%A8%8B.png" alt="ES的GET流程" title="ES的GET流程"></p>
<h3 id="协调节点执行流程"><a class="header-anchor" href="#协调节点执行流程">¶</a>协调节点执行流程</h3>
<p>代码入口：<code>TransportSingleShardAction.AsyncSingleAction#perform</code><br>
注意<code>AsyncSingleAction</code>构造方法中会先准备集群状态、节点列表等信息。<br>
1、计算文档所在的shardid，即它所在的分片；<br>
在构造方法中，会先根据请求进行路由：`TransportGetAction#shards</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">private AsyncSingleAction(Request request, ActionListener&lt;Response&gt; listener) &#123;</span><br><span class="line">    this.listener = listener;</span><br><span class="line"></span><br><span class="line">    ClusterState clusterState = clusterService.state();</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;executing [&#123;&#125;] based on cluster state version [&#123;&#125;]&quot;, request, clusterState.version());</span><br><span class="line">    &#125;</span><br><span class="line">    // 集群nodes列表</span><br><span class="line">    nodes = clusterState.nodes();</span><br><span class="line">    ClusterBlockException blockException = checkGlobalBlock(clusterState);</span><br><span class="line">    if (blockException != null) &#123;</span><br><span class="line">        throw blockException;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    String concreteSingleIndex;</span><br><span class="line">    if (resolveIndex(request)) &#123;</span><br><span class="line">        concreteSingleIndex = indexNameExpressionResolver.concreteSingleIndex(clusterState, request).getName();</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        concreteSingleIndex = request.index();</span><br><span class="line">    &#125;</span><br><span class="line">    this.internalRequest = new InternalRequest(request, concreteSingleIndex);</span><br><span class="line">    // 解析请求，更新自定义routing</span><br><span class="line">    resolveRequest(clusterState, internalRequest);</span><br><span class="line"></span><br><span class="line">    blockException = checkRequestBlock(clusterState, internalRequest);</span><br><span class="line">    if (blockException != null) &#123;</span><br><span class="line">        throw blockException;</span><br><span class="line">    &#125;</span><br><span class="line">    // 根据路由算法计算得到目的shard迭代器，或者根据优先级选择目标节点</span><br><span class="line">    this.shardIt = shards(clusterState, internalRequest);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、发送请求<br>
检查目标节点是不是本地节点，如果是则直接调本地的<code>TransportService#sendLocalRequest</code>；如果是远程节点则执行远程调用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public &lt;T extends TransportResponse&gt; void sendRequest(final DiscoveryNode node, final String action,</span><br><span class="line">                                                            final TransportRequest request,</span><br><span class="line">                                                            final TransportResponseHandler&lt;T&gt; handler) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        Transport.Connection connection = getConnection(node);</span><br><span class="line">        sendRequest(connection, action, request, TransportRequestOptions.EMPTY, handler);</span><br><span class="line">    &#125; catch (NodeNotConnectedException ex) &#123;</span><br><span class="line">        // the caller might not handle this so we invoke the handler</span><br><span class="line">        handler.handleException(ex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public Transport.Connection getConnection(DiscoveryNode node) &#123;</span><br><span class="line">    if (isLocalNode(node)) &#123;</span><br><span class="line">        return localNodeConnection;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return transport.getConnection(node);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="数据节点执行流程"><a class="header-anchor" href="#数据节点执行流程">¶</a>数据节点执行流程</h3>
<p>代码入口：<code>TransportSingleShardAction.ShardTransportHandler#messageReceived</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void messageReceived(final Request request, final TransportChannel channel) throws Exception &#123;</span><br><span class="line">    if (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(&quot;executing [&#123;&#125;] on shard [&#123;&#125;]&quot;, request, request.internalShardId);</span><br><span class="line">    &#125;</span><br><span class="line">    Response response = shardOperation(request, request.internalShardId);</span><br><span class="line">    channel.sendResponse(response);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protected GetResponse shardOperation(GetRequest request, ShardId shardId) &#123;</span><br><span class="line">    IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());</span><br><span class="line">    IndexShard indexShard = indexService.getShard(shardId.id());</span><br><span class="line"></span><br><span class="line">    if (request.refresh() &amp;&amp; !request.realtime()) &#123;</span><br><span class="line">        indexShard.refresh(&quot;refresh_flag_get&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GetResult result = indexShard.getService().get(request.type(), request.id(), request.storedFields(),</span><br><span class="line">            request.realtime(), request.version(), request.versionType(), request.fetchSourceContext());</span><br><span class="line">    return new GetResponse(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>1、读取数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">private GetResult innerGet(String type, String id, String[] gFields, boolean realtime, long version, VersionType versionType,</span><br><span class="line">                           FetchSourceContext fetchSourceContext, boolean readFromTranslog) &#123;</span><br><span class="line">    fetchSourceContext = normalizeFetchSourceContent(fetchSourceContext, gFields);</span><br><span class="line">    final Collection&lt;String&gt; types;</span><br><span class="line">    // 处理_all选项</span><br><span class="line">    if (type == null || type.equals(&quot;_all&quot;)) &#123;</span><br><span class="line">        types = mapperService.types();</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        types = Collections.singleton(type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Engine.GetResult get = null;</span><br><span class="line">    for (String typeX : types) &#123;</span><br><span class="line">        Term uidTerm = mapperService.createUidTerm(typeX, id);</span><br><span class="line">        if (uidTerm != null) &#123;</span><br><span class="line">            // 调用Engine读取数据</span><br><span class="line">            get = indexShard.get(new Engine.Get(realtime, readFromTranslog, typeX, id, uidTerm)</span><br><span class="line">                    .version(version).versionType(versionType));</span><br><span class="line">            if (get.exists()) &#123;</span><br><span class="line">                type = typeX;</span><br><span class="line">                break;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                get.release();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">        // 过滤返回结果</span><br><span class="line">        // 根据type、id、DocumentMapper等信息从刚刚获取的信息中获取数据，对指定的field、source进行过滤</span><br><span class="line">        // 把结果存于GetResult返回</span><br><span class="line">        return innerGetLoadFromStoredFields(type, id, gFields, fetchSourceContext, get, mapperService);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、从InternalEngine读取数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">public Engine.GetResult get(Engine.Get get) &#123;</span><br><span class="line">    readAllowed();</span><br><span class="line">    return getEngine().get(get, this::acquireSearcher);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public GetResult get(Get get, BiFunction&lt;String, SearcherScope, Searcher&gt; searcherFactory) throws EngineException &#123;</span><br><span class="line">    assert Objects.equals(get.uid().field(), uidField) : get.uid().field();</span><br><span class="line">    try (ReleasableLock ignored = readLock.acquire()) &#123;</span><br><span class="line">        ensureOpen();</span><br><span class="line">        SearcherScope scope;</span><br><span class="line">        // 处理realtime选项，判断是否需要刷盘</span><br><span class="line">        if (get.realtime()) &#123;</span><br><span class="line">            VersionValue versionValue = null;</span><br><span class="line">            // versionMap写入索引的时候添加的，不会写入磁盘</span><br><span class="line">            try (Releasable ignore = versionMap.acquireLock(get.uid().bytes())) &#123;</span><br><span class="line">                // we need to lock here to access the version map to do this truly in RT</span><br><span class="line">                versionValue = getVersionFromMap(get.uid().bytes());</span><br><span class="line">            &#125;</span><br><span class="line">            if (versionValue != null) &#123;</span><br><span class="line">                if (versionValue.isDelete()) &#123;</span><br><span class="line">                    return GetResult.NOT_EXISTS;</span><br><span class="line">                &#125;</span><br><span class="line">                // 版本是否冲突</span><br><span class="line">                if (get.versionType().isVersionConflictForReads(versionValue.version, get.version())) &#123;</span><br><span class="line">                    throw new VersionConflictEngineException(shardId, get.type(), get.id(),</span><br><span class="line">                        get.versionType().explainConflictForReads(versionValue.version, get.version()));</span><br><span class="line">                &#125;</span><br><span class="line">                if (get.isReadFromTranslog()) &#123;</span><br><span class="line">                    // this is only used for updates - API _GET calls will always read form a reader for consistency</span><br><span class="line">                    // the update call doesn&apos;t need the consistency since it&apos;s source only + _parent but parent can go away in 7.0</span><br><span class="line">                    if (versionValue.getLocation() != null) &#123;</span><br><span class="line">                        try &#123;</span><br><span class="line">                            Translog.Operation operation = translog.readOperation(versionValue.getLocation());</span><br><span class="line">                            if (operation != null) &#123;</span><br><span class="line">                                // in the case of a already pruned translog generation we might get null here - yet very unlikely</span><br><span class="line">                                TranslogLeafReader reader = new TranslogLeafReader((Translog.Index) operation, engineConfig</span><br><span class="line">                                    .getIndexSettings().getIndexVersionCreated());</span><br><span class="line">                                return new GetResult(new Searcher(&quot;realtime_get&quot;, new IndexSearcher(reader)),</span><br><span class="line">                                    new VersionsAndSeqNoResolver.DocIdAndVersion(0, ((Translog.Index) operation).version(), reader, 0));</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (IOException e) &#123;</span><br><span class="line">                            maybeFailEngine(&quot;realtime_get&quot;, e); // lets check if the translog has failed with a tragic event</span><br><span class="line">                            throw new EngineException(shardId, &quot;failed to read operation from translog&quot;, e);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        trackTranslogLocation.set(true);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                // 执行刷盘操作</span><br><span class="line">                refresh(&quot;realtime_get&quot;, SearcherScope.INTERNAL);</span><br><span class="line">            &#125;</span><br><span class="line">            scope = SearcherScope.INTERNAL;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // we expose what has been externally expose in a point in time snapshot via an explicit refresh</span><br><span class="line">            scope = SearcherScope.EXTERNAL;</span><br><span class="line">        &#125;</span><br><span class="line">        // 调用Searcher读取数据</span><br><span class="line">        // no version, get the version from the index, we know that we refresh on flush</span><br><span class="line">        return getFromSearcher(get, searcherFactory, scope);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ElasticSearch/" rel="tag"># ElasticSearch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/e43d540f.html" rel="next" title="使用 Arthas 排查线上问题">
                <i class="fa fa-chevron-left"></i> 使用 Arthas 排查线上问题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/1c3259ad.html" rel="prev" title="ES 分布式搜索">
                ES 分布式搜索 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>

  

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tallate</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">144</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">74</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">ES存储的基础概念 - 索引、映射和文档</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#文档"><span class="nav-number">1.1.</span> <span class="nav-text">¶文档</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#文档和字段-document-field"><span class="nav-number">1.1.1.</span> <span class="nav-text">¶文档和字段 - Document、Field</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档元数据"><span class="nav-number">1.1.2.</span> <span class="nav-text">¶文档元数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文档属性"><span class="nav-number">1.1.3.</span> <span class="nav-text">¶文档属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对象和文档"><span class="nav-number">1.1.4.</span> <span class="nav-text">¶对象和文档</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#索引-index"><span class="nav-number">1.2.</span> <span class="nav-text">¶索引 - Index</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类型-type"><span class="nav-number">1.3.</span> <span class="nav-text">¶类型 - Type</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#映射-mapping"><span class="nav-number">1.4.</span> <span class="nav-text">¶映射 - Mapping</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#动态映射机制"><span class="nav-number">1.5.</span> <span class="nav-text">¶动态映射机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分析和搜索-analysis-search"><span class="nav-number">1.6.</span> <span class="nav-text">¶分析和搜索 - Analysis、Search</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#query-dsl"><span class="nav-number">1.7.</span> <span class="nav-text">¶Query DSL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#倒排索引"><span class="nav-number">1.8.</span> <span class="nav-text">¶倒排索引</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#根对象"><span class="nav-number">1.9.</span> <span class="nav-text">¶根对象</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#精确值和全文"><span class="nav-number">1.10.</span> <span class="nav-text">¶精确值和全文</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">常用操作 - 索引（Index）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#查询"><span class="nav-number">2.1.</span> <span class="nav-text">¶查询</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建"><span class="nav-number">2.2.</span> <span class="nav-text">¶创建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#删除"><span class="nav-number">2.3.</span> <span class="nav-text">¶删除</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">常用操作 - 映射（Mapping）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一些默认的映射"><span class="nav-number">3.1.</span> <span class="nav-text">¶一些默认的映射</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义映射"><span class="nav-number">3.2.</span> <span class="nav-text">¶自定义映射</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查看映射"><span class="nav-number">3.3.</span> <span class="nav-text">¶查看映射</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更新映射"><span class="nav-number">3.4.</span> <span class="nav-text">¶更新映射</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">常用操作 - 对象（文档 Document）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#更新-put"><span class="nav-number">4.1.</span> <span class="nav-text">¶更新 - PUT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建-post"><span class="nav-number">4.2.</span> <span class="nav-text">¶创建 - POST</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#部分更新-post"><span class="nav-number">4.3.</span> <span class="nav-text">¶部分更新 - POST</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get-搜索"><span class="nav-number">4.4.</span> <span class="nav-text">¶GET（搜索）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#head-ping"><span class="nav-number">4.5.</span> <span class="nav-text">¶HEAD（ping）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#delete-删除"><span class="nav-number">4.6.</span> <span class="nav-text">¶DELETE（删除）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bulk-批量操作"><span class="nav-number">4.7.</span> <span class="nav-text">¶bulk（批量操作）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">索引原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#索引策略"><span class="nav-number">5.1.</span> <span class="nav-text">¶索引策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#不变性"><span class="nav-number">5.2.</span> <span class="nav-text">¶不变性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#段和提交点"><span class="nav-number">5.3.</span> <span class="nav-text">¶段和提交点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#动态更新索引"><span class="nav-number">5.4.</span> <span class="nav-text">¶动态更新索引</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#删除和更新索引"><span class="nav-number">5.5.</span> <span class="nav-text">¶删除和更新索引</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准实时搜索与刷新策略"><span class="nav-number">5.6.</span> <span class="nav-text">¶准实时搜索与刷新策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#事务日志-translog"><span class="nav-number">5.7.</span> <span class="nav-text">¶事务日志（TransLog）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#lucene-不能保证索引数据不丢失"><span class="nav-number">5.7.1.</span> <span class="nav-text">¶Lucene 不能保证索引数据不丢失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用事务日志记录未提交事务"><span class="nav-number">5.7.2.</span> <span class="nav-text">¶使用事务日志记录未提交事务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#手动执行事务日志刷新"><span class="nav-number">5.7.3.</span> <span class="nav-text">¶手动执行事务日志刷新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#异步-fsync"><span class="nav-number">5.7.4.</span> <span class="nav-text">¶异步 fsync</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置"><span class="nav-number">5.7.5.</span> <span class="nav-text">¶配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#段合并"><span class="nav-number">5.8.</span> <span class="nav-text">¶段合并</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#段合并流程"><span class="nav-number">5.8.1.</span> <span class="nav-text">¶段合并流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#optimize-api"><span class="nav-number">5.8.2.</span> <span class="nav-text">¶optimize API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">分布式文档存储</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#相关配置"><span class="nav-number">6.1.</span> <span class="nav-text">¶相关配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文档路由"><span class="nav-number">6.2.</span> <span class="nav-text">¶文档路由</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发机制"><span class="nav-number">6.3.</span> <span class="nav-text">¶分发机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#consistency"><span class="nav-number">6.4.</span> <span class="nav-text">¶consistency</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#timeout"><span class="nav-number">6.5.</span> <span class="nav-text">¶timeout</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建-索引-删除"><span class="nav-number">6.6.</span> <span class="nav-text">¶创建、索引、删除</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#取回单个文档"><span class="nav-number">6.7.</span> <span class="nav-text">¶取回单个文档</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#局部更新"><span class="nav-number">6.8.</span> <span class="nav-text">¶局部更新</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mget-批量读"><span class="nav-number">6.9.</span> <span class="nav-text">¶mget（批量读）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bulk-批量改"><span class="nav-number">6.10.</span> <span class="nav-text">¶bulk（批量改）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">存储管理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据副本模型"><span class="nav-number">7.1.</span> <span class="nav-text">¶数据副本模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pacifica-算法"><span class="nav-number">7.1.1.</span> <span class="nav-text">¶PacificA 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存储管理-写入"><span class="nav-number">7.1.2.</span> <span class="nav-text">¶存储管理 - 写入</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">写入（POST、PUT、DELETE）流程源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#refresh和flush-实时性和可靠性之间的权衡"><span class="nav-number">8.1.</span> <span class="nav-text">¶refresh和flush - 实时性和可靠性之间的权衡</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#近实时性"><span class="nav-number">8.1.1.</span> <span class="nav-text">¶近实时性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可靠性"><span class="nav-number">8.1.2.</span> <span class="nav-text">¶可靠性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es的刷盘流程"><span class="nav-number">8.1.3.</span> <span class="nav-text">¶ES的刷盘流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es会丢失数据吗？"><span class="nav-number">8.1.4.</span> <span class="nav-text">¶ES会丢失数据吗？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文档更新-部分更新"><span class="nav-number">8.2.</span> <span class="nav-text">¶文档更新（部分更新）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#乐观并发控制"><span class="nav-number">8.3.</span> <span class="nav-text">¶乐观并发控制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文档操作类型"><span class="nav-number">8.4.</span> <span class="nav-text">¶文档操作类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#请求入口"><span class="nav-number">8.5.</span> <span class="nav-text">¶请求入口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文档写入流程"><span class="nav-number">8.6.</span> <span class="nav-text">¶文档写入流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协调节点处理流程"><span class="nav-number">8.6.1.</span> <span class="nav-text">¶协调节点处理流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主分片节点处理流程"><span class="nav-number">8.6.2.</span> <span class="nav-text">¶主分片节点处理流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#副分片执行"><span class="nav-number">8.6.3.</span> <span class="nav-text">¶副分片执行</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">GET流程源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#实时性"><span class="nav-number">9.1.</span> <span class="nav-text">¶实时性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get执行流程"><span class="nav-number">9.2.</span> <span class="nav-text">¶GET执行流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协调节点执行流程"><span class="nav-number">9.2.1.</span> <span class="nav-text">¶协调节点执行流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据节点执行流程"><span class="nav-number">9.2.2.</span> <span class="nav-text">¶数据节点执行流程</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tallate</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>








        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '72bdd1c9479eb0679788',
          clientSecret: '62c9c0cb45aadb1478ca66cfc3c69c9623f50290',
          repo: 'tallate.github.io',
          owner: 'tallate',
          admin: ['tallate'],
          id: location.pathname,
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>



  





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
